{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Inicio"},{"location":"#_1","text":"","title":""},{"location":"acerca/","tags":["requisitos","costos","inscripci\u00f3n","horarios","programa"],"text":"Correlativas para alumnos de grado UNSAM CB14 Estadistica Aplicada CB07 Biolog\u00eda Molecular Requisitos Conocimientos de biolog\u00eda molecular: Dogma de la biolog\u00eda molecular, codificaci\u00f3n de informaci\u00f3n en forma de ADN, ARN, proteinas, transcripci\u00f3n, traducci\u00f3n, organizaci\u00f3n celular en procariotas, eucariotas. Conocimientos b\u00e1sicos de estad\u00edstica: distribuciones, probabilidades. Manejo b\u00e1sico de computadoras. Costos Alumnos de Grado UNSAM: Gratis. Alumnos de Post-Grado UNSAM: Gratis. Alumnos de Post-Grado de otras Universidades P\u00fablicas: $5500 Docentes Universidades Nacionales: $5500 Alumnos de Posgrado Universidades Privadas: $7500 Empresas/Profesionales Independientes: $11500 Alumnos / Docentes / Profesionales Internacionales: USD $300 Horarios 2do Cuatrimestre 2022 (Virtual) Virtual: Martes y Jueves 9 a 13hs. Presencial: Aula a confirmar! Jueves 18 de Agosto: 14 a 18 hs Jueves 22 de Septiembre: 14 a 18 hs Jueves 13 de Octubre: 14 a 18 hs Asistencia Te\u00f3ricas: Asistencia opcional Pr\u00e1cticas: Asistencia obligatoria al 80% de los TPs Evaluaci\u00f3n Evaluaci\u00f3n te\u00f3rica: Un examen hacia el final de la cursada, con recuperatorio. El examen se divide en bloques tem\u00e1ticos que deben ser aprobados por separado. Cada bloque se aprueba con 5 y se promociona con 7. Evaluaci\u00f3n pr\u00e1ctica: Informes de trabajos pr\u00e1cticos. Se aprueban con 5. Promoci\u00f3n: Todas las instancias evaluatorias (te\u00f3rico + pr\u00e1ctico) con puntaje de 7 o m\u00e1s. Examen Final: En caso de instancias evaluatorias aprobadas con 5, o en caso de tener que recuperar. Recursa: En caso de no cumplir con requisito de asistencia o instancias evaluatorias no aprobadas. Inscripci\u00f3n Para inscribirte vas a necesitar: Si sos alumno UNSAM: Tu n\u00famero de legajo Si sos posgrado, investigador o trabajas en la industria: Breve descripci\u00f3n de tu l\u00ednea de trabajo Carta de motivaci\u00f3n Cierre de Inscripci\u00f3n 25 de Julio, 2022 Notificaci\u00f3n de Aceptaci\u00f3n Los cupos para estudiantes de posgrado, investigadores y trabajadores de la industria son limitados. Aquellas personas que sean aceptadas para el curso ser\u00e1n notficadas el 29 de Julio, 2022 Inscribirse","title":"Acerca de"},{"location":"acerca/#correlativas-para-alumnos-de-grado-unsam","text":"CB14 Estadistica Aplicada CB07 Biolog\u00eda Molecular","title":"Correlativas para alumnos de grado UNSAM"},{"location":"acerca/#requisitos","text":"Conocimientos de biolog\u00eda molecular: Dogma de la biolog\u00eda molecular, codificaci\u00f3n de informaci\u00f3n en forma de ADN, ARN, proteinas, transcripci\u00f3n, traducci\u00f3n, organizaci\u00f3n celular en procariotas, eucariotas. Conocimientos b\u00e1sicos de estad\u00edstica: distribuciones, probabilidades. Manejo b\u00e1sico de computadoras.","title":"Requisitos"},{"location":"acerca/#costos","text":"Alumnos de Grado UNSAM: Gratis. Alumnos de Post-Grado UNSAM: Gratis. Alumnos de Post-Grado de otras Universidades P\u00fablicas: $5500 Docentes Universidades Nacionales: $5500 Alumnos de Posgrado Universidades Privadas: $7500 Empresas/Profesionales Independientes: $11500 Alumnos / Docentes / Profesionales Internacionales: USD $300","title":"Costos"},{"location":"acerca/#horarios-2do-cuatrimestre-2022-virtual","text":"Virtual: Martes y Jueves 9 a 13hs. Presencial: Aula a confirmar! Jueves 18 de Agosto: 14 a 18 hs Jueves 22 de Septiembre: 14 a 18 hs Jueves 13 de Octubre: 14 a 18 hs","title":"Horarios 2do Cuatrimestre 2022 (Virtual)"},{"location":"acerca/#asistencia","text":"Te\u00f3ricas: Asistencia opcional Pr\u00e1cticas: Asistencia obligatoria al 80% de los TPs","title":"Asistencia"},{"location":"acerca/#evaluacion","text":"Evaluaci\u00f3n te\u00f3rica: Un examen hacia el final de la cursada, con recuperatorio. El examen se divide en bloques tem\u00e1ticos que deben ser aprobados por separado. Cada bloque se aprueba con 5 y se promociona con 7. Evaluaci\u00f3n pr\u00e1ctica: Informes de trabajos pr\u00e1cticos. Se aprueban con 5. Promoci\u00f3n: Todas las instancias evaluatorias (te\u00f3rico + pr\u00e1ctico) con puntaje de 7 o m\u00e1s. Examen Final: En caso de instancias evaluatorias aprobadas con 5, o en caso de tener que recuperar. Recursa: En caso de no cumplir con requisito de asistencia o instancias evaluatorias no aprobadas.","title":"Evaluaci\u00f3n"},{"location":"acerca/#inscripcion","text":"Para inscribirte vas a necesitar: Si sos alumno UNSAM: Tu n\u00famero de legajo Si sos posgrado, investigador o trabajas en la industria: Breve descripci\u00f3n de tu l\u00ednea de trabajo Carta de motivaci\u00f3n","title":"Inscripci\u00f3n"},{"location":"acerca/#cierre-de-inscripcion","text":"25 de Julio, 2022","title":"Cierre de Inscripci\u00f3n"},{"location":"acerca/#notificacion-de-aceptacion","text":"Los cupos para estudiantes de posgrado, investigadores y trabajadores de la industria son limitados. Aquellas personas que sean aceptadas para el curso ser\u00e1n notficadas el 29 de Julio, 2022 Inscribirse","title":"Notificaci\u00f3n de Aceptaci\u00f3n"},{"location":"contenidos/","text":"Contenidos te\u00f3ricos Experimentos Bioinform\u00e1ticos Conceptos b\u00e1sicos de computaci\u00f3n, algoritmos Bases de datos Ontolog\u00edas Alineamientos de a pares, similitud de secuencias Alineamientos m\u00faltiples Sequence profiles, Hidden Markov Models (I y II) Informaci\u00f3n contenida en alineamientos m\u00faltiples M\u00e9todos de predicci\u00f3n basados en datos, machine learning Reconstrucci\u00f3n de filogenias Bioinform\u00e1tica estructural Data clustering Secuenciaci\u00f3n y ensamblado de genomas Contenidos Pr\u00e1cticos Introducci\u00f3n a UNIX EMBOSS Suite Alineamientos de a pares B\u00fasquedas de secuencias por similitud y alineamientos m\u00faltiples Perfiles de secuencia, HMM y PSI-BLAST Filogenias, \u00e1rboles filogen\u00e9ticos y filogen\u00f3mica HMM y Redes Neuronales Programando en Biolog\u00eda Bioinform\u00e1tica estructural: Predicci\u00f3n de desorden Bioinform\u00e1tica estructural: Motivos funcionales en prote\u00ednas Bioinform\u00e1tica estructural: Dominios 3D y Modelado por Homolog\u00eda Data mining Visualizaci\u00f3n de genomas Gen\u00f3mica comparativa Short Read Mapping","title":"Contenidos"},{"location":"contenidos/#contenidos-teoricos","text":"Experimentos Bioinform\u00e1ticos Conceptos b\u00e1sicos de computaci\u00f3n, algoritmos Bases de datos Ontolog\u00edas Alineamientos de a pares, similitud de secuencias Alineamientos m\u00faltiples Sequence profiles, Hidden Markov Models (I y II) Informaci\u00f3n contenida en alineamientos m\u00faltiples M\u00e9todos de predicci\u00f3n basados en datos, machine learning Reconstrucci\u00f3n de filogenias Bioinform\u00e1tica estructural Data clustering Secuenciaci\u00f3n y ensamblado de genomas","title":"Contenidos te\u00f3ricos"},{"location":"contenidos/#contenidos-practicos","text":"Introducci\u00f3n a UNIX EMBOSS Suite Alineamientos de a pares B\u00fasquedas de secuencias por similitud y alineamientos m\u00faltiples Perfiles de secuencia, HMM y PSI-BLAST Filogenias, \u00e1rboles filogen\u00e9ticos y filogen\u00f3mica HMM y Redes Neuronales Programando en Biolog\u00eda Bioinform\u00e1tica estructural: Predicci\u00f3n de desorden Bioinform\u00e1tica estructural: Motivos funcionales en prote\u00ednas Bioinform\u00e1tica estructural: Dominios 3D y Modelado por Homolog\u00eda Data mining Visualizaci\u00f3n de genomas Gen\u00f3mica comparativa Short Read Mapping","title":"Contenidos Pr\u00e1cticos"},{"location":"cronograma/","tags":["cronograma","fechas","feriados"],"text":"Fecha Hora Donde Clase Tipo Docente Martes, 02 Agosto 2022 9:00 hs Online T1. Presentaci\u00f3n de la materia Te\u00f3rica F. Ag\u00fcero Jueves, 04 Agosto 2022 9:00 hs Online P1. Introducci\u00f3n a UNIX Pr\u00e1ctica A. Ricci Martes, 09 Agosto 2022 9:00 hs Online T2. Bases de datos y ontolog\u00edas Te\u00f3rica F. Ag\u00fcero Jueves, 11 Agosto 2022 9:00 hs Online P2. EMBOSS Suite Pr\u00e1ctica A. Ricci Martes, 16 Agosto 2022 9:00 hs Online T3. Alineamientos de a pares y B\u00fasqueda de secuencias por Similitud Te\u00f3rica F. Ag\u00fcero Jueves, 18 Agosto 2022 9:00 hs Online T4. Alineamientos m\u00faltiples Te\u00f3rica F. Ag\u00fcero Jueves, 18 Agosto 2022 14:00 hs Aula a definir TE1. Te\u00f3rica Extra 1 Te\u00f3rica F. Ag\u00fcero Martes, 23 Agosto 2022 9:00 hs Online P3. Alineamientos de a pares Pr\u00e1ctica H. Garc\u00eda A Jueves, 25 Agosto 2022 9:00 hs Online P4. B\u00fasqueda de secuencias por similitud y Alineamientos M\u00faltiples Pr\u00e1ctica H. Garc\u00eda A Martes, 30 Agosto 2022 9:00 hs Online T5. Informaci\u00f3n contenida en alineamientos m\u00faltiples Te\u00f3rica M. Nielsen Jueves, 01 Septiembre 2022 9:00 hs Online P5. Perfiles de secuencia y PSI-BLAST Pr\u00e1ctica H. Garc\u00eda A Martes, 06 Septiembre 2022 9:00 hs Online T6. Reconstrucci\u00f3n de filogenias Te\u00f3rica F. Ag\u00fcero Jueves, 08 Septiembre 2022 9:00 hs Online P6. Filogenias, \u00e1rboles filogen\u00e9ticos y filogen\u00f3mica Pr\u00e1ctica J. Glavina Martes, 13 Septiembre 2022 9:00 hs Online T7. M\u00e9todos de predicci\u00f3n de Machine Learning basados en datos (HMM y ANN) Te\u00f3rica M. Nielsen Jueves, 15 Septiembre 2022 9:00 hs Online P7. HMM y Redes neuronales Pr\u00e1ctica H. Garc\u00eda A. Martes, 20 Septiembre 2022 9:00 hs Online P8a. Programando en Biolog\u00eda Pr\u00e1ctica A. Ricci Jueves, 22 Septiembre 2022 9:00 hs Online P8b. Programando en Biolog\u00eda Pr\u00e1ctica A. Ricci Martes, 27 Septiembre 2022 9:00 hs Online T8. Bioinform\u00e1tica Estructural: Desorden Te\u00f3rica L. Chemes Jueves, 29 Septiembre 2022 9:00 hs Online P9. Bioinform\u00e1tica Estructural: Predicci\u00f3n de Desorden Pr\u00e1ctica J. Glavina Jueves, 29 Septiembre 2022 14:00 hs Aula a definir TE2. Te\u00f3rica Extra 2 Te\u00f3rica L. Chemes Martes, 04 Octubre 2022 9:00 hs Online T9. Bioinform\u00e1tica Estructural: Motivos lineales Te\u00f3rica L. Chemes Jueves, 06 Octubre 2022 9:00 hs Online P10. Bioinform\u00e1tica Estructural: Motivos funcionales en prote\u00ednas Pr\u00e1ctica J. Glavina Martes, 11 Octubre 2022 9:00 hs Online T10. Bioinform\u00e1tica Estructural: Dominios Te\u00f3rica L. Chemes Jueves, 13 Octubre 2022 9:00 hs Online P11. Bioinform\u00e1tica Estructural: Dominios 3D y Modelado por homolog\u00eda Pr\u00e1ctica J. Glavina Martes, 18 Octubre 2022 9:00 hs Online T11. Data clustering Te\u00f3rica F. Ag\u00fcero Jueves, 20 Octubre 2022 9:00 hs Online P12a. Data mining Pr\u00e1ctica A. Ricci Jueves, 20 Octubre 2022 14:00 hs Aula a definir TE3. Te\u00f3rica Extra 3 Te\u00f3rica J. Glavina Martes, 25 Octubre 2022 9:00 hs Online T12. Secuenciaci\u00f3n y ensamblado de genomas Te\u00f3rica F. Ag\u00fcero Jueves, 27 Octubre 2022 9:00 hs Online P12b. Data mining Pr\u00e1ctica A. Ricci Martes, 01 Noviembre 2022 9:00 hs Online P13. Visualizando genomas con Artemis Pr\u00e1ctica J. Glavina Jueves, 03 Noviembre 2022 9:00 hs Online P14. Gen\u00f3mica comparativa Pr\u00e1ctica J. Glavina Martes, 08 Noviembre 2022 9:00 hs Online Repaso Te\u00f3rica F. Ag\u00fcero L. Chemes M. Nielsen Jueves, 10 Noviembre 2022 9:00 hs A definir Examen F. Ag\u00fcero L. Chemes M. Nielsen Martes, 15 Noviembre 2022 9:00 hs LIBRE Jueves, 17 Noviembre 2022 9:00 hs Online Revisi\u00f3n examen F. Ag\u00fcero L. Chemes M. Nielsen Martes, 22 Noviembre 2022 9:00 hs LIBRE Jueves, 24 Noviembre 2022 9:00 hs LIBRE Martes, 29 Noviembre 2022 9:00 hs A definir Recuperatorio F. Ag\u00fcero L. Chemes M. Nielsen Jueves, 1 Diciembre 2022 9:00 hs Online Revisi\u00f3n examen F. Ag\u00fcero L. Chemes M. Nielsen","title":"Cronograma"},{"location":"docentes/","tags":["Docentes","Instructores"],"text":"Docentes Profesor Titular Dr. Fern\u00e1n Ag\u00fcero Profesores invitados Dr. Morten Nielsen Dra. Luc\u00eda B. Chemes Jefa de Trabajos Pr\u00e1cticos Dra. Juliana Glavina Ayudantes de 1ra Lic. Heli Garc\u00eda \u00c1lvarez Lic. Alejandro Ricci","title":"Docentes"},{"location":"docentes/#docentes","text":"","title":"Docentes"},{"location":"docentes/#profesor-titular","text":"Dr. Fern\u00e1n Ag\u00fcero","title":"Profesor Titular"},{"location":"docentes/#profesores-invitados","text":"Dr. Morten Nielsen Dra. Luc\u00eda B. Chemes","title":"Profesores invitados"},{"location":"docentes/#jefa-de-trabajos-practicos","text":"Dra. Juliana Glavina","title":"Jefa de Trabajos Pr\u00e1cticos"},{"location":"docentes/#ayudantes-de-1ra","text":"Lic. Heli Garc\u00eda \u00c1lvarez Lic. Alejandro Ricci","title":"Ayudantes de 1ra"},{"location":"tags/","text":"A continuaci\u00f3n una lista de tags relevantes en el sitio: [TAGS]","title":"Tags"},{"location":"77_useful_code/grid_test/","text":"#ci_grid { border-width:0; } #ci_grid td { text-align:center; vertical-align: middle; padding: 10px 5px 10px 5px; border-width:2px; } #ci_grid td:hover { opacity: 0.9; } #ci_grid tr:hover { background-color: white; } #ci_grid img { height: 150px; } Grid test TP 1 TP 2 TP 3 TP 4 TP 5 TP 6 TP 7 TP 8","title":"Grid test"},{"location":"77_useful_code/grid_test/#grid-test","text":"TP 1 TP 2 TP 3 TP 4 TP 5 TP 6 TP 7 TP 8","title":"Grid test"},{"location":"instructivos/inicio/","tags":["instructivos"],"text":"En esta p\u00e1gina encontrar\u00e1n los instructivos que le permitir\u00e1n ir resolviendo algunas cosas t\u00e9cnicas, como por ejemplo: la instalaci\u00f3n de una m\u00e1quina virtual! Consultas y Canales de Comunicaci\u00f3n Si tu consulta est\u00e1 relacionada con alg\u00fan problema con la instalaci\u00f3n o funcionamiento de la m\u00e1quina virtual: Antes de consultar por favor, asegurate que no se encuentre ya resuelto en la secci\u00f3n de problemas con la m\u00e1quina virtual. Si no se encuentra resuelto o no est\u00e1 relacionado con la m\u00e1quina virtual podes encontrarnos en: en Slack en el canal dedicado consultas-vm o preguntas-y-respuestas si no est\u00e1 relacionado con la m\u00e1quina virtual.","title":"Inicio"},{"location":"instructivos/inicio/#consultas-y-canales-de-comunicacion","text":"Si tu consulta est\u00e1 relacionada con alg\u00fan problema con la instalaci\u00f3n o funcionamiento de la m\u00e1quina virtual: Antes de consultar por favor, asegurate que no se encuentre ya resuelto en la secci\u00f3n de problemas con la m\u00e1quina virtual. Si no se encuentra resuelto o no est\u00e1 relacionado con la m\u00e1quina virtual podes encontrarnos en: en Slack en el canal dedicado consultas-vm o preguntas-y-respuestas si no est\u00e1 relacionado con la m\u00e1quina virtual.","title":"Consultas y Canales de Comunicaci\u00f3n"},{"location":"instructivos/maquina_virtual/","tags":["instructivos","maquina virtual"],"text":"\u00bfQu\u00e9 es una m\u00e1quina virtual? Las m\u00e1quinas virtuales no son m\u00e1s que computadoras virtuales (denominadas invitadas o guests ), emuladas dentro de una computadora real (denominada hospedadora o host ). Algunos de sus principales usos son compartir una misma computadora entre muchas personas, tener una computadora que se puede mover completa en un pendrive o similar, o instalar multiples sistemas operativos en una misma computadora de una forma mucho m\u00e1s simple. La virtualizaci\u00f3n es un proceso costoso , ya que si bien nos permite crear nuevas compus, al momento de correrlas estaremos repartiendo los recursos reales (espacio en disco, memoria RAM y velocidad de procesamiento CPU) del host (es decir, de nuestra computadora ) entre todas las m\u00e1quinas virtuales guest que est\u00e9n activas. Es por esto que debemos ser cuidadosos al momento de generarlas, d\u00e1ndoles suficientes recursos para funcionar, pero no todos los recursos del host (es decir, de nuestra computadora ). El disco de m\u00e1quina virtual El disco de una m\u00e1quina virtual es una \u201cfoto\u201d de un disco de almacenamiento. Todo lo que un disco duro tiene guardado, incluyendo el sistema operativo y los programas instalados, quedar\u00e1n guardados en un archivo cuando la creemos con las herramientas adecuadas. Como no existe un disco duro f\u00edsico se lo considera disco virtual . Este archivo permite regenerar el estado de la computadora desde la que se cre\u00f3 dicho disco al momento de sacar la foto. Los docentes ya hemos ensamblado, para la materia, un disco de m\u00e1quina virtual con Lubuntu 18 (una distribuci\u00f3n versi\u00f3n ultra liviana de Ubuntu 18) en la que hemos instalado todos los programas y herramientas que usaremos en la asignatura. En adelante, nos referiremos a \u00e9ste como IBioinfo. Puesta en funcionamiento de m\u00e1quina virtual Este es un instructivo corto sobre c\u00f3mo hacer para correr la m\u00e1quina virtual de la materia en sus computadoras. Vamos a necesitar: Software y archivos a usar Oracle VM VirtualBox instalado en nuestras compus. Forma de descomprimir un archivo comprimido ZIP (por ejemplo WinZip para Windows o GUnzip para Linux) El disco de la m\u00e1quina virtual (VMDK) Requerimientos de Hardware m\u00ednimos 20 GB de espacio libre en disco duro (para VMDK) 2 GB de RAM. Paso 1. Descargar la M\u00e1quina Virtual Pueden usar este link, que tiene la m\u00e1quina que usamos en los TPs (es un link a Dropbox). M\u00e1quina Virtual Descargar desde Dropbox usando wget En vez de usar una descarga directa para bajar el archivo desde Dropbox, se puede bajar mediante el comando wget . La ventaja de usar wget es que si la descarga est\u00e1 incompleta o les dice que est\u00e1 da\u00f1ado el archivo, pueden volver a correr wget con la opci\u00f3n -c (continuar descarga) para completarla, y volver a probar si pueden validar los checksums o descomprimirlo. En Ubuntu: Abran la terminal en la ubicaci\u00f3n donde quieren descargar la VM (despu\u00e9s la pueden mover antes de descomprimir) Corran el siguiente comando: wget https://www.dropbox.com/s/2187nlnjc03g8ki/IBioinfo-Lubuntu-32%20v1.3.zip En Windows: Descarguen la version portable (ZIP) de la \u00faltima versi\u00f3n de wget desde esta p\u00e1gina Descompriman el ZIP en la ubicaci\u00f3n donde quieren descargar la VM (despu\u00e9s la pueden mover antes de descomprimir) Abran la terminal o consola en esa carpeta Corran el siguiente comando: ./wget.exe https://www.dropbox.com/s/2187nlnjc03g8ki/IBioinfo-Lubuntu-32%20v1.3.zip Reanudar descarga: Como mencionamos antes, si tienen alg\u00fan problema con la descarga pueden usar la opci\u00f3n -c para completarla. En Ubuntu, un segundo intento ser\u00eda: wget -c https://www.dropbox.com/s/2187nlnjc03g8ki/IBioinfo-Lubuntu-32%20v1.3.zip O bien, si eso falla, pueden probar este link, que es un link a Drive. M\u00e1quina Virtual desde Drive Atenci\u00f3n Son archivos pesados (~ 9GB ). Desc\u00e1rguenlos con tiempo y con conexi\u00f3n estable . Si no cuentan con una conexi\u00f3n estable, pueden escribirnos para buscar alguna soluci\u00f3n alternativa. O bien, si los dos anteriores fallan pueden probar descargar el archivo zip de la m\u00e1quina virtual partido. Download zip Download z01 Download z02 Download z03 Download z04 Download z05 Download z06 Download z07 Download z08 Download MD5 y SHA256 Atenci\u00f3n Una vez finalizada la descarga de TODOS los archivos que van a estar guardados en una misma carpeta tienen que descomprimir el archivo .zip como siempre. Paso 2. Validar la descarga Una vez descargado el archivo hay que validar la descarga usando checksums. Pueden usar cualquiera de estos checksums (MD5, SHA256), y como respuesta tienen que obtener estos valores. Si los valores no coinciden, la descarga no fue exitosa (el archivo est\u00e1 corrupto y no va a funcionar!). Los valores de los checksums son hexadecimales, da igual si las letras est\u00e1n en mayuscula o minuscula, mientras coincidan est\u00e1 OK. Info IBioinfo-Lubuntu-32 v1.3.zip, MD5 checksum: 8266E14E765D03920E743AA1B09EA56B IBioinfo-Lubuntu-32 v1.3.zip, SHA256 checksum: 7F23F297BDD497704E2DAF712C2E96673600C63978E983D222819F0EE34518FE Pueden estar en may\u00fasculas o min\u00fasculas. Como validar los checksums. Dependiendo de si est\u00e1n usando Windows (Powershell), OSX (Mac, Terminal), o Linux (Terminal), estos son los comandos que tienen que usar: # Windows Poweshell # asumimos que descargaron el archivo en C:\\Downloads, si no es as\u00ed, cambien el Path! Get-FileHash -Algorithm MD5 -Path 'C:\\Downloads\\IBioinfo-Lubuntu-32 v1.3.zip' Get-FileHash -Algorithm SHA256 -Path 'C:\\Downloads\\IBioinfo-Lubuntu-32 v1.3.zip' # OS X (Terminal App) # tienen que cambiarse primero al directorio donde hicieron la descarga, por ej Downloads cd Downloads md5 IBioinfo-Lubuntu-32 v1.3.zip shasum -a 256 IBioinfo-Lubuntu-32 v1.3.zip # Linux (Terminal) # tienen que cambiarse primero al directorio donde hicieron la descarga, por ej Downloads cd Downloads md5sum IBioinfo-Lubuntu-32 v1.3.zip sha256sum IBioinfo-Lubuntu-32 v1.3.zip Luego, solamente si los checksums coinciden (la descarga fue exitosa), descomprimir para obtener el vmdk (pesa alrededor de 15GB, pero puede llegar a crecer un poco durante la cursada). Elegir la ubicaci\u00f3n Elijan la ubicaci\u00f3n final del archivo vmdk ya que una vez creada la Virtual Machine NO se puede mover el archivo .vmdk de lugar. Paso 3. Instalar Virtual Box Mientras descarga la imagen, aprovechen el tiempo muerto para descargar Oracle VM VirtualBox. El programa es gratuito y pueden descargarlo desde la p\u00e1gina oficial . Descarguen la \u00faltima versi\u00f3n (v6.1) apropiada para su sistema operativo (Windows, OSX o Linux) y sigan las instrucciones del instalador hasta que hayan terminado. Paso 4. Crear una m\u00e1quina virtual Virtual Box es un virtualizador de entornos. Nos permite generar m\u00e1quinas virtuales . Vamos a crear nuestra m\u00e1quina virtual con el archivo de disco virtual IBioinfo-Lubuntu-32.vmdk que acabamos de descargar. Para eso: Abrimos Virtual Box: Hacemos click en New o Nueva Aparecer\u00e1 una caja de di\u00e1logo, en donde deberemos indicar: Name o Nombre: Es el nombre que queremos darle a la m\u00e1quina virtual. Elijan el que quieran. Machine Folder o Carpeta de M\u00e1quina: Es la ubicaci\u00f3n de la configuraci\u00f3n de la m\u00e1quina virtual. Elijan la que quieran. Type o Tipo: Es el tipo de virtualizaci\u00f3n. Elijan Linux. Version o Versi\u00f3n: Es la versi\u00f3n del sistema operativo. Ubuntu 32 bits. En el mismo panel deberemos indicar la cantidad de memoria RAM que vamos a prestarle a la m\u00e1quina virtual. Pongan la m\u00e1xima que puedan dentro de la regi\u00f3n verde (recuerden que al momento de usar la m\u00e1quina virtual, \u00e9sta sustraer\u00e1 autom\u00e1ticamente recursos de nuestra compu). Estos valores depender\u00e1n de la cantidad de RAM f\u00edsica que tenga nuestro host . Cuanto m\u00e1s RAM le demos a la m\u00e1quina virtual, m\u00e1s r\u00e1pido va a andar. Para las tareas que realizaremos, darle entre 2 y 4 GB de ram (2048-4096 MB) estar\u00e1 bien. Y finalmente el disco duro. Aqu\u00ed es donde entra nuestro archivo IBioinfo-Lubuntu.vmdk : Haciendo click en el icono de la carpeta a la derecha, agregaremos nuestro disco virtual: A\u00f1adir --> elegimos nuestro VMDK Con esto habremos finalizado la creaci\u00f3n y podremos comenzar. Si todo sali\u00f3 bien, deber\u00e1n ver una entrada con su m\u00e1quina virtual recientemente creada en el Inicio del Virtual Box. Intenten correr la m\u00e1quina virtual haciendo click en \u201cIniciar\u201d. En breve deber\u00edan ver el logo de Lubuntu y pronto el escritorio del sistema operativo. Contrase\u00f1a Si les pide alguna contrase\u00f1a, la misma es unsam . No cambiar ubicaci\u00f3n Una vez creada la Virtual Machine NO muevan el archivo .vmdk de lugar. Si lo hicieron, f\u00edjense en la secci\u00f3n de problemas que est\u00e1 la soluci\u00f3n.","title":"M\u00e1quina Virtual"},{"location":"instructivos/maquina_virtual/#que-es-una-maquina-virtual","text":"Las m\u00e1quinas virtuales no son m\u00e1s que computadoras virtuales (denominadas invitadas o guests ), emuladas dentro de una computadora real (denominada hospedadora o host ). Algunos de sus principales usos son compartir una misma computadora entre muchas personas, tener una computadora que se puede mover completa en un pendrive o similar, o instalar multiples sistemas operativos en una misma computadora de una forma mucho m\u00e1s simple. La virtualizaci\u00f3n es un proceso costoso , ya que si bien nos permite crear nuevas compus, al momento de correrlas estaremos repartiendo los recursos reales (espacio en disco, memoria RAM y velocidad de procesamiento CPU) del host (es decir, de nuestra computadora ) entre todas las m\u00e1quinas virtuales guest que est\u00e9n activas. Es por esto que debemos ser cuidadosos al momento de generarlas, d\u00e1ndoles suficientes recursos para funcionar, pero no todos los recursos del host (es decir, de nuestra computadora ).","title":"\u00bfQu\u00e9 es una m\u00e1quina virtual?"},{"location":"instructivos/maquina_virtual/#el-disco-de-maquina-virtual","text":"El disco de una m\u00e1quina virtual es una \u201cfoto\u201d de un disco de almacenamiento. Todo lo que un disco duro tiene guardado, incluyendo el sistema operativo y los programas instalados, quedar\u00e1n guardados en un archivo cuando la creemos con las herramientas adecuadas. Como no existe un disco duro f\u00edsico se lo considera disco virtual . Este archivo permite regenerar el estado de la computadora desde la que se cre\u00f3 dicho disco al momento de sacar la foto. Los docentes ya hemos ensamblado, para la materia, un disco de m\u00e1quina virtual con Lubuntu 18 (una distribuci\u00f3n versi\u00f3n ultra liviana de Ubuntu 18) en la que hemos instalado todos los programas y herramientas que usaremos en la asignatura. En adelante, nos referiremos a \u00e9ste como IBioinfo.","title":"El disco de m\u00e1quina virtual"},{"location":"instructivos/maquina_virtual/#puesta-en-funcionamiento-de-maquina-virtual","text":"Este es un instructivo corto sobre c\u00f3mo hacer para correr la m\u00e1quina virtual de la materia en sus computadoras. Vamos a necesitar:","title":"Puesta en funcionamiento de m\u00e1quina virtual"},{"location":"instructivos/maquina_virtual/#software-y-archivos-a-usar","text":"Oracle VM VirtualBox instalado en nuestras compus. Forma de descomprimir un archivo comprimido ZIP (por ejemplo WinZip para Windows o GUnzip para Linux) El disco de la m\u00e1quina virtual (VMDK)","title":"Software y archivos a usar"},{"location":"instructivos/maquina_virtual/#requerimientos-de-hardware-minimos","text":"20 GB de espacio libre en disco duro (para VMDK) 2 GB de RAM.","title":"Requerimientos de Hardware m\u00ednimos"},{"location":"instructivos/maquina_virtual/#paso-1-descargar-la-maquina-virtual","text":"Pueden usar este link, que tiene la m\u00e1quina que usamos en los TPs (es un link a Dropbox). M\u00e1quina Virtual Descargar desde Dropbox usando wget En vez de usar una descarga directa para bajar el archivo desde Dropbox, se puede bajar mediante el comando wget . La ventaja de usar wget es que si la descarga est\u00e1 incompleta o les dice que est\u00e1 da\u00f1ado el archivo, pueden volver a correr wget con la opci\u00f3n -c (continuar descarga) para completarla, y volver a probar si pueden validar los checksums o descomprimirlo. En Ubuntu: Abran la terminal en la ubicaci\u00f3n donde quieren descargar la VM (despu\u00e9s la pueden mover antes de descomprimir) Corran el siguiente comando: wget https://www.dropbox.com/s/2187nlnjc03g8ki/IBioinfo-Lubuntu-32%20v1.3.zip En Windows: Descarguen la version portable (ZIP) de la \u00faltima versi\u00f3n de wget desde esta p\u00e1gina Descompriman el ZIP en la ubicaci\u00f3n donde quieren descargar la VM (despu\u00e9s la pueden mover antes de descomprimir) Abran la terminal o consola en esa carpeta Corran el siguiente comando: ./wget.exe https://www.dropbox.com/s/2187nlnjc03g8ki/IBioinfo-Lubuntu-32%20v1.3.zip Reanudar descarga: Como mencionamos antes, si tienen alg\u00fan problema con la descarga pueden usar la opci\u00f3n -c para completarla. En Ubuntu, un segundo intento ser\u00eda: wget -c https://www.dropbox.com/s/2187nlnjc03g8ki/IBioinfo-Lubuntu-32%20v1.3.zip O bien, si eso falla, pueden probar este link, que es un link a Drive. M\u00e1quina Virtual desde Drive Atenci\u00f3n Son archivos pesados (~ 9GB ). Desc\u00e1rguenlos con tiempo y con conexi\u00f3n estable . Si no cuentan con una conexi\u00f3n estable, pueden escribirnos para buscar alguna soluci\u00f3n alternativa. O bien, si los dos anteriores fallan pueden probar descargar el archivo zip de la m\u00e1quina virtual partido. Download zip Download z01 Download z02 Download z03 Download z04 Download z05 Download z06 Download z07 Download z08 Download MD5 y SHA256 Atenci\u00f3n Una vez finalizada la descarga de TODOS los archivos que van a estar guardados en una misma carpeta tienen que descomprimir el archivo .zip como siempre.","title":"Paso 1. Descargar la M\u00e1quina Virtual"},{"location":"instructivos/maquina_virtual/#paso-2-validar-la-descarga","text":"Una vez descargado el archivo hay que validar la descarga usando checksums. Pueden usar cualquiera de estos checksums (MD5, SHA256), y como respuesta tienen que obtener estos valores. Si los valores no coinciden, la descarga no fue exitosa (el archivo est\u00e1 corrupto y no va a funcionar!). Los valores de los checksums son hexadecimales, da igual si las letras est\u00e1n en mayuscula o minuscula, mientras coincidan est\u00e1 OK. Info IBioinfo-Lubuntu-32 v1.3.zip, MD5 checksum: 8266E14E765D03920E743AA1B09EA56B IBioinfo-Lubuntu-32 v1.3.zip, SHA256 checksum: 7F23F297BDD497704E2DAF712C2E96673600C63978E983D222819F0EE34518FE Pueden estar en may\u00fasculas o min\u00fasculas. Como validar los checksums. Dependiendo de si est\u00e1n usando Windows (Powershell), OSX (Mac, Terminal), o Linux (Terminal), estos son los comandos que tienen que usar: # Windows Poweshell # asumimos que descargaron el archivo en C:\\Downloads, si no es as\u00ed, cambien el Path! Get-FileHash -Algorithm MD5 -Path 'C:\\Downloads\\IBioinfo-Lubuntu-32 v1.3.zip' Get-FileHash -Algorithm SHA256 -Path 'C:\\Downloads\\IBioinfo-Lubuntu-32 v1.3.zip' # OS X (Terminal App) # tienen que cambiarse primero al directorio donde hicieron la descarga, por ej Downloads cd Downloads md5 IBioinfo-Lubuntu-32 v1.3.zip shasum -a 256 IBioinfo-Lubuntu-32 v1.3.zip # Linux (Terminal) # tienen que cambiarse primero al directorio donde hicieron la descarga, por ej Downloads cd Downloads md5sum IBioinfo-Lubuntu-32 v1.3.zip sha256sum IBioinfo-Lubuntu-32 v1.3.zip Luego, solamente si los checksums coinciden (la descarga fue exitosa), descomprimir para obtener el vmdk (pesa alrededor de 15GB, pero puede llegar a crecer un poco durante la cursada). Elegir la ubicaci\u00f3n Elijan la ubicaci\u00f3n final del archivo vmdk ya que una vez creada la Virtual Machine NO se puede mover el archivo .vmdk de lugar.","title":"Paso 2. Validar la descarga"},{"location":"instructivos/maquina_virtual/#paso-3-instalar-virtual-box","text":"Mientras descarga la imagen, aprovechen el tiempo muerto para descargar Oracle VM VirtualBox. El programa es gratuito y pueden descargarlo desde la p\u00e1gina oficial . Descarguen la \u00faltima versi\u00f3n (v6.1) apropiada para su sistema operativo (Windows, OSX o Linux) y sigan las instrucciones del instalador hasta que hayan terminado.","title":"Paso 3. Instalar Virtual Box"},{"location":"instructivos/maquina_virtual/#paso-4-crear-una-maquina-virtual","text":"Virtual Box es un virtualizador de entornos. Nos permite generar m\u00e1quinas virtuales . Vamos a crear nuestra m\u00e1quina virtual con el archivo de disco virtual IBioinfo-Lubuntu-32.vmdk que acabamos de descargar. Para eso: Abrimos Virtual Box: Hacemos click en New o Nueva Aparecer\u00e1 una caja de di\u00e1logo, en donde deberemos indicar: Name o Nombre: Es el nombre que queremos darle a la m\u00e1quina virtual. Elijan el que quieran. Machine Folder o Carpeta de M\u00e1quina: Es la ubicaci\u00f3n de la configuraci\u00f3n de la m\u00e1quina virtual. Elijan la que quieran. Type o Tipo: Es el tipo de virtualizaci\u00f3n. Elijan Linux. Version o Versi\u00f3n: Es la versi\u00f3n del sistema operativo. Ubuntu 32 bits. En el mismo panel deberemos indicar la cantidad de memoria RAM que vamos a prestarle a la m\u00e1quina virtual. Pongan la m\u00e1xima que puedan dentro de la regi\u00f3n verde (recuerden que al momento de usar la m\u00e1quina virtual, \u00e9sta sustraer\u00e1 autom\u00e1ticamente recursos de nuestra compu). Estos valores depender\u00e1n de la cantidad de RAM f\u00edsica que tenga nuestro host . Cuanto m\u00e1s RAM le demos a la m\u00e1quina virtual, m\u00e1s r\u00e1pido va a andar. Para las tareas que realizaremos, darle entre 2 y 4 GB de ram (2048-4096 MB) estar\u00e1 bien. Y finalmente el disco duro. Aqu\u00ed es donde entra nuestro archivo IBioinfo-Lubuntu.vmdk : Haciendo click en el icono de la carpeta a la derecha, agregaremos nuestro disco virtual: A\u00f1adir --> elegimos nuestro VMDK Con esto habremos finalizado la creaci\u00f3n y podremos comenzar. Si todo sali\u00f3 bien, deber\u00e1n ver una entrada con su m\u00e1quina virtual recientemente creada en el Inicio del Virtual Box. Intenten correr la m\u00e1quina virtual haciendo click en \u201cIniciar\u201d. En breve deber\u00edan ver el logo de Lubuntu y pronto el escritorio del sistema operativo. Contrase\u00f1a Si les pide alguna contrase\u00f1a, la misma es unsam . No cambiar ubicaci\u00f3n Una vez creada la Virtual Machine NO muevan el archivo .vmdk de lugar. Si lo hicieron, f\u00edjense en la secci\u00f3n de problemas que est\u00e1 la soluci\u00f3n.","title":"Paso 4. Crear una m\u00e1quina virtual"},{"location":"instructivos/problemasVM/","text":"Problemas y posibles soluciones No funciona y eligieron la virtualizaci\u00f3n de 32 bits (es la \u00fanica que se est\u00e1 ofreciendo) Soluci\u00f3n: Habilitar una opci\u00f3n de virtualizaci\u00f3n especial ( PAN/NX ), sobre todo en sistemas nuevos. Para hacerlo: Click derecho en la m\u00e1quina virtual --> Configuraci\u00f3n --> Sistema --> Procesador --> Habilitar PAE/NX Habilitar PAE/NX tiene que estar con el tick Sigue sin funcionar Habilitar PAE/NX est\u00e1 tildado y la m\u00e1quina virtual se queda congelada en una pantalla similar a la siguiente: Soluci\u00f3n: Click derecho en la m\u00e1quina virtual --> Configuraci\u00f3n --> Sistema --> Procesador Prueben con 2 o 4 procesadores en la barra que dice Procesador(es), siempre manej\u00e1ndose dentro del rango verde. Mensaje de Error: \"This computer does not have hardware-assisted virtualization\" La computadora, por defecto, no permite la virtualizaci\u00f3n. Soluci\u00f3n: Sigan los pasos descritos en este post . En sistema aparece cartel que dice: el hardware de virtualizaci\u00f3n est\u00e1 habilitado en la secci\u00f3n de aceleraci\u00f3n de la p\u00e1gina de Sistema... Soluci\u00f3n: Accedan a la pesta\u00f1a de Aceleraci\u00f3n y aseg\u00farense de que no haya ninguna interfaz de paravirtualizaci\u00f3n seleccionada. Error: \"Could not open medium\" Es posible que hayan movido el archivo vmdk. Soluci\u00f3n: Vayan a: Archivo --> Biblioteca de Medios (Virtual media manager) y remuevan el disco problem\u00e1tico. Si la opci\u00f3n de remover les aparece deshabilitada, deber\u00e1n \u201cLiberarlo\u201d primero. Luego, borren la m\u00e1quina virtual y vu\u00e9lvanla a crear usando la nueva (y definitiva ) ubicaci\u00f3n del archivo vmdk. Error: Kernel driver not installed (rc=-1908) Soluci\u00f3n para m\u00e1quina f\u00edsica/host con sistema operativo Ubuntu: Abrir la terminal y correr los siguientes comandos: sudo dpkg-reconfigure virtualbox-dkms sudo /sbin/vboxconfig Luego de esto, abrir nuevamente VirtualBox e iniciar la maquina virtual. El error se deber\u00eda haber solucionado.","title":"Problemas instalando la M\u00e1quina Virtual"},{"location":"instructivos/problemasVM/#problemas-y-posibles-soluciones","text":"","title":"Problemas y posibles soluciones"},{"location":"instructivos/problemasVM/#no-funciona-y-eligieron-la-virtualizacion-de-32-bits-es-la-unica-que-se-esta-ofreciendo","text":"Soluci\u00f3n: Habilitar una opci\u00f3n de virtualizaci\u00f3n especial ( PAN/NX ), sobre todo en sistemas nuevos. Para hacerlo: Click derecho en la m\u00e1quina virtual --> Configuraci\u00f3n --> Sistema --> Procesador --> Habilitar PAE/NX Habilitar PAE/NX tiene que estar con el tick","title":"No funciona y eligieron la virtualizaci\u00f3n de 32 bits (es la \u00fanica que se est\u00e1 ofreciendo)"},{"location":"instructivos/problemasVM/#sigue-sin-funcionar","text":"Habilitar PAE/NX est\u00e1 tildado y la m\u00e1quina virtual se queda congelada en una pantalla similar a la siguiente: Soluci\u00f3n: Click derecho en la m\u00e1quina virtual --> Configuraci\u00f3n --> Sistema --> Procesador Prueben con 2 o 4 procesadores en la barra que dice Procesador(es), siempre manej\u00e1ndose dentro del rango verde.","title":"Sigue sin funcionar"},{"location":"instructivos/problemasVM/#mensaje-de-error-this-computer-does-not-have-hardware-assisted-virtualization","text":"La computadora, por defecto, no permite la virtualizaci\u00f3n. Soluci\u00f3n: Sigan los pasos descritos en este post .","title":"Mensaje de Error: \"This computer does not have hardware-assisted virtualization\""},{"location":"instructivos/problemasVM/#en-sistema-aparece-cartel-que-dice-el-hardware-de-virtualizacion-esta-habilitado-en-la-seccion-de-aceleracion-de-la-pagina-de-sistema","text":"Soluci\u00f3n: Accedan a la pesta\u00f1a de Aceleraci\u00f3n y aseg\u00farense de que no haya ninguna interfaz de paravirtualizaci\u00f3n seleccionada.","title":"En sistema aparece cartel que dice: el hardware de virtualizaci\u00f3n est\u00e1 habilitado en la secci\u00f3n de aceleraci\u00f3n de la p\u00e1gina de Sistema..."},{"location":"instructivos/problemasVM/#error-could-not-open-medium","text":"Es posible que hayan movido el archivo vmdk. Soluci\u00f3n: Vayan a: Archivo --> Biblioteca de Medios (Virtual media manager) y remuevan el disco problem\u00e1tico. Si la opci\u00f3n de remover les aparece deshabilitada, deber\u00e1n \u201cLiberarlo\u201d primero. Luego, borren la m\u00e1quina virtual y vu\u00e9lvanla a crear usando la nueva (y definitiva ) ubicaci\u00f3n del archivo vmdk.","title":"Error: \"Could not open medium\""},{"location":"instructivos/problemasVM/#error-kernel-driver-not-installed-rc-1908","text":"Soluci\u00f3n para m\u00e1quina f\u00edsica/host con sistema operativo Ubuntu: Abrir la terminal y correr los siguientes comandos: sudo dpkg-reconfigure virtualbox-dkms sudo /sbin/vboxconfig Luego de esto, abrir nuevamente VirtualBox e iniciar la maquina virtual. El error se deber\u00eda haber solucionado.","title":"Error: Kernel driver not installed (rc=-1908)"},{"location":"instructivos/tipsVM/","text":"Maximizar la ventana Si maximizamos la ventana a pantalla completa , ser\u00e1 como estar usando la m\u00e1quina virtual solamente. Esto para algunos puede resultar m\u00e1s c\u00f3modo. Pueden probarlo presionando las teclas Ctrl derecho + F juntas. Con volver a presionar esas teclas salen de la pantalla completa . Acceso a la l\u00ednea de comandos Para acceder a la l\u00ednea de comandos hay varias formas: Forma 1: Inicio Herramientas del sistema LXTerminal Forma 2: Presionar las teclas Ctrl + Alt + T , las tres juntas. Ctrl y Alt tienen que ser los de la izquierda. Forma 3: Presionando la tecla F4 en la carpeta donde nos encontremos. Cambiar el layout del teclado Para cambiar el layout del teclado (en que tecla est\u00e1 el @, el |, los par\u00e9ntesis, etc): Click derecho en el panel: Seleccionar A\u00f1adir/quitar elementos del panel Seleccionar A\u00f1adir Agente de distribuci\u00f3n del teclado Hacer click en A\u00f1adir y cerrar la ventana. En el panel aparecer\u00e1 al lado del bot\u00f3n de apagado la bandera espa\u00f1ola, click derecho sobre la bandera y seleccionar la primera opci\u00f3n: Configuraci\u00f3n de Agente de distribuci\u00f3n de teclado Se abrir\u00e1 una ventana. Destildar la opci\u00f3n: Mantener las distribuciones del sistema y se habilitar\u00e1n las opciones: En Distribuciones del teclado elegir A\u00f1adir y busca en la lista el teclado correspondiente. Los m\u00e1s comunes son: Espa\u00f1ol (es) Espa\u00f1ol latinoamericano (latam) Ingl\u00e9s (EE.UU.) (us) Si no sab\u00e9s cual es: pod\u00e9s chequear algunos teclados en Wiki en la secci\u00f3n QUERTY. Selecciona el que corresponda y haz click en Aceptar. Volver\u00e1 a la ventana anterior donde puedes subir la configuraci\u00f3n que desees usar (o quitar la que no quieres usar). 8. Si dejaste m\u00e1s de una configuraci\u00f3n, haciendo click sobre la banderita en el panel pod\u00e9s cambiar a las distintas configuraciones (va cambiando la etiqueta). Copiar y pegar de m\u00e1quina host a m\u00e1quina virtual y viceversa Para copiar y pegar de la m\u00e1quina host (es decir, sus compus f\u00edsicas ) a la m\u00e1quina virtual (la de la materia) tienen que: Con la m\u00e1quina virtual abierta Van a Devices / Dispositivos Shared Clipboard / Portapapeles Compartido y seleccionan Bidirectional / Bidireccional Compartir una carpeta con la m\u00e1quina host Una manera simple de compartir archivos entre la m\u00e1quina host (es decir, sus compus f\u00edsicas ) y la m\u00e1quina virtual o viceversa es crear una carpeta compartida, para esto: Con la m\u00e1quina virtual abierta Van a Devices / Dispositivos Shared Folder / Carpetas Compartidas y seleccionan Shared Folders Settings / Preferencias de carpetas compartidas . Se les abrir\u00e1 una ventana, donde deben elegir la carpetita con el s\u00edmbolo m\u00e1s que est\u00e1 a la derecha para agregar una carpeta compartida y se les abrir\u00e1 una nueva ventana. Folder Path: Indican la ruta a la carpeta que van a compartir en la m\u00e1quina host (SU computadora). Folder Name: El nombre con el que aparecer\u00e1 la carpeta en la m\u00e1quina virtual Auto-mount: Tiene que estar tickeado. Make Permanent: Tiene que estar tickeado. Click en Ok. Deber\u00edan ver algo similar a lo siguiente: Click en Ok. Se les debe haber creado un \u00edcono en el escritorio de la m\u00e1quina virtual con el nombre que eligieron en Folder Name Si hacen click, deber\u00edan poder acceder a la carpeta. Si aparece un cartel donde dice que no tienen los permisos necesarios, entonces hacen lo siguiente. Abren una terminal utilizando las teclas: Ctrl + Alt + T Escriben lo siguiente en la terminal: sudo usermod -a -G vboxsf $( whoami ) Si les pide una clave es unsam Acceso a Internet Es necesario que la m\u00e1quina virtual tenga acceso a internet. Puede ser que esto funcione automaticamente, pero de no ser as\u00ed pueden hacer: Van a Settings / Configuraci\u00f3n Network / Red Habilitan en la pesta\u00f1a Adapter 1 la opci\u00f3n Enable Network Adapter Enable Network Adapter tiene que estar tildado. Resoluci\u00f3n de Pantalla Por defecto, la pantalla de la m\u00e1quina virtual deber\u00eda agrandarse seg\u00fan el tama\u00f1o de su monitor. Si esto no sucede pueden agrandar la pantalla a mano haciendo: Click en el Bot\u00f3n inicio de Lubuntu (esquina inferior izquierda) Click en Preferencias Click en Ajustes del monitor Pasar la resoluci\u00f3n a la mayor posible (podemos usar la misma que usamos en el sistema operativo del host) Click en Aplicar y, si estamos conformes, en Guardar . Para que la resoluci\u00f3n de pantalla elegida sea permanente: Esta versi\u00f3n de lubuntu presenta un bug donde la resoluci\u00f3n cambia cada vez que se suspende la VM. Por lo tanto la forma m\u00e1s sencilla de solucionarlo es configurando la VM para no suspenderse m\u00e1s: Click en el Bot\u00f3n inicio de Lubuntu (esquina inferior izquierda) Click en Preferencias Click en Administrador de energ\u00eda Click en la pesta\u00f1a Pantalla y luego mover las tres barras hasta la izquierda como se muestra en la siguiente imagen: Click en la pesta\u00f1a Seguridad y luego seleccionar \"Nunca\" en la lista desplegable que aparece al lado de Bloquear sesi\u00f3n autom\u00e1ticamente y luego destildar donde dice \"Bloquear la pantalla cuando el sistema vaya a suspensi\u00f3n\". Tiene que quedar como se ve en la siguiente imagen:","title":"Tips and Tricks para usar la M\u00e1quina Virtual m\u00e1s c\u00f3modos"},{"location":"instructivos/tipsVM/#maximizar-la-ventana","text":"Si maximizamos la ventana a pantalla completa , ser\u00e1 como estar usando la m\u00e1quina virtual solamente. Esto para algunos puede resultar m\u00e1s c\u00f3modo. Pueden probarlo presionando las teclas Ctrl derecho + F juntas. Con volver a presionar esas teclas salen de la pantalla completa .","title":"Maximizar la ventana"},{"location":"instructivos/tipsVM/#acceso-a-la-linea-de-comandos","text":"Para acceder a la l\u00ednea de comandos hay varias formas: Forma 1: Inicio Herramientas del sistema LXTerminal Forma 2: Presionar las teclas Ctrl + Alt + T , las tres juntas. Ctrl y Alt tienen que ser los de la izquierda. Forma 3: Presionando la tecla F4 en la carpeta donde nos encontremos.","title":"Acceso a la l\u00ednea de comandos"},{"location":"instructivos/tipsVM/#cambiar-el-layout-del-teclado","text":"Para cambiar el layout del teclado (en que tecla est\u00e1 el @, el |, los par\u00e9ntesis, etc): Click derecho en el panel: Seleccionar A\u00f1adir/quitar elementos del panel Seleccionar A\u00f1adir Agente de distribuci\u00f3n del teclado Hacer click en A\u00f1adir y cerrar la ventana. En el panel aparecer\u00e1 al lado del bot\u00f3n de apagado la bandera espa\u00f1ola, click derecho sobre la bandera y seleccionar la primera opci\u00f3n: Configuraci\u00f3n de Agente de distribuci\u00f3n de teclado Se abrir\u00e1 una ventana. Destildar la opci\u00f3n: Mantener las distribuciones del sistema y se habilitar\u00e1n las opciones: En Distribuciones del teclado elegir A\u00f1adir y busca en la lista el teclado correspondiente. Los m\u00e1s comunes son: Espa\u00f1ol (es) Espa\u00f1ol latinoamericano (latam) Ingl\u00e9s (EE.UU.) (us) Si no sab\u00e9s cual es: pod\u00e9s chequear algunos teclados en Wiki en la secci\u00f3n QUERTY. Selecciona el que corresponda y haz click en Aceptar. Volver\u00e1 a la ventana anterior donde puedes subir la configuraci\u00f3n que desees usar (o quitar la que no quieres usar). 8. Si dejaste m\u00e1s de una configuraci\u00f3n, haciendo click sobre la banderita en el panel pod\u00e9s cambiar a las distintas configuraciones (va cambiando la etiqueta).","title":"Cambiar el layout del teclado"},{"location":"instructivos/tipsVM/#copiar-y-pegar-de-maquina-host-a-maquina-virtual-y-viceversa","text":"Para copiar y pegar de la m\u00e1quina host (es decir, sus compus f\u00edsicas ) a la m\u00e1quina virtual (la de la materia) tienen que: Con la m\u00e1quina virtual abierta Van a Devices / Dispositivos Shared Clipboard / Portapapeles Compartido y seleccionan Bidirectional / Bidireccional","title":"Copiar y pegar de m\u00e1quina host a m\u00e1quina virtual y viceversa"},{"location":"instructivos/tipsVM/#compartir-una-carpeta-con-la-maquina-host","text":"Una manera simple de compartir archivos entre la m\u00e1quina host (es decir, sus compus f\u00edsicas ) y la m\u00e1quina virtual o viceversa es crear una carpeta compartida, para esto: Con la m\u00e1quina virtual abierta Van a Devices / Dispositivos Shared Folder / Carpetas Compartidas y seleccionan Shared Folders Settings / Preferencias de carpetas compartidas . Se les abrir\u00e1 una ventana, donde deben elegir la carpetita con el s\u00edmbolo m\u00e1s que est\u00e1 a la derecha para agregar una carpeta compartida y se les abrir\u00e1 una nueva ventana. Folder Path: Indican la ruta a la carpeta que van a compartir en la m\u00e1quina host (SU computadora). Folder Name: El nombre con el que aparecer\u00e1 la carpeta en la m\u00e1quina virtual Auto-mount: Tiene que estar tickeado. Make Permanent: Tiene que estar tickeado. Click en Ok. Deber\u00edan ver algo similar a lo siguiente: Click en Ok. Se les debe haber creado un \u00edcono en el escritorio de la m\u00e1quina virtual con el nombre que eligieron en Folder Name Si hacen click, deber\u00edan poder acceder a la carpeta. Si aparece un cartel donde dice que no tienen los permisos necesarios, entonces hacen lo siguiente. Abren una terminal utilizando las teclas: Ctrl + Alt + T Escriben lo siguiente en la terminal: sudo usermod -a -G vboxsf $( whoami ) Si les pide una clave es unsam","title":"Compartir una carpeta con la m\u00e1quina host"},{"location":"instructivos/tipsVM/#acceso-a-internet","text":"Es necesario que la m\u00e1quina virtual tenga acceso a internet. Puede ser que esto funcione automaticamente, pero de no ser as\u00ed pueden hacer: Van a Settings / Configuraci\u00f3n Network / Red Habilitan en la pesta\u00f1a Adapter 1 la opci\u00f3n Enable Network Adapter Enable Network Adapter tiene que estar tildado.","title":"Acceso a Internet"},{"location":"instructivos/tipsVM/#resolucion-de-pantalla","text":"Por defecto, la pantalla de la m\u00e1quina virtual deber\u00eda agrandarse seg\u00fan el tama\u00f1o de su monitor. Si esto no sucede pueden agrandar la pantalla a mano haciendo: Click en el Bot\u00f3n inicio de Lubuntu (esquina inferior izquierda) Click en Preferencias Click en Ajustes del monitor Pasar la resoluci\u00f3n a la mayor posible (podemos usar la misma que usamos en el sistema operativo del host) Click en Aplicar y, si estamos conformes, en Guardar . Para que la resoluci\u00f3n de pantalla elegida sea permanente: Esta versi\u00f3n de lubuntu presenta un bug donde la resoluci\u00f3n cambia cada vez que se suspende la VM. Por lo tanto la forma m\u00e1s sencilla de solucionarlo es configurando la VM para no suspenderse m\u00e1s: Click en el Bot\u00f3n inicio de Lubuntu (esquina inferior izquierda) Click en Preferencias Click en Administrador de energ\u00eda Click en la pesta\u00f1a Pantalla y luego mover las tres barras hasta la izquierda como se muestra en la siguiente imagen: Click en la pesta\u00f1a Seguridad y luego seleccionar \"Nunca\" en la lista desplegable que aparece al lado de Bloquear sesi\u00f3n autom\u00e1ticamente y luego destildar donde dice \"Bloquear la pantalla cuando el sistema vaya a suspensi\u00f3n\". Tiene que quedar como se ve en la siguiente imagen:","title":"Resoluci\u00f3n de Pantalla"},{"location":"practicos/inicio/","tags":["practicos"],"text":"Esta es la p\u00e1gina de inicio de los pr\u00e1cticos de este curso. A continuaci\u00f3n una lista de datos \u00fatiles. Consultas y Canales de Comunicaci\u00f3n Por email a la direcci\u00f3n de la JTP. en Slack pueden mandar mensajes a todo el grupo en los distintos canales. Informes Alguno de los trabajos pr\u00e1cticos de la cursada requieren una resoluci\u00f3n de un problema a informar. Al final de la gu\u00eda de trabajos pr\u00e1cticos se indicar\u00e1 el problema a resolver. La funci\u00f3n de los informes es: Que ustedes puedan aplicar los conocimientos y herramientas adquiridas durante la cursada a un problema puntual Evaluar la capacidad t\u00e9cnica para producir resultados, as\u00ed como tambi\u00e9n el criterio a la hora de evaluar el significado biol\u00f3gico de los mismos y la comprensi\u00f3n de las potencialidades y limitaciones de los algoritmos o herramientas empleadas. Evaluar la capacidad de elaborar informes Cada informe de cada trabajo pr\u00e1ctico puede (o no) estar relacionado con alguno anterior. Por lo tanto: Guarden los archivos y sean prolijos. El trabajo deber\u00e1 ser realizado con las mismas personas con la que realizan los trabajos pr\u00e1cticos normalmente. Es UNA entrega por grupo. Esta entrega deber\u00e1 ser realizada en tiempo y forma, por correo electr\u00f3nico a la persona encargada del trabajo pr\u00e1ctico. Formato Correo Electr\u00f3nico de Entrega de TP Cuando env\u00edan el correo. El asunto del correo debe ser: Entrega Informe TP01 - Grupo 01 Durante la cursada deber\u00e1n ir entregando de forma individual los ejercicios correspondientes a cada trabajo pr\u00e1ctico, los cuales ser\u00e1n aprobados o desaprobados. En caso de estar desaprobado tendr\u00e1n una semana despu\u00e9s de la devoluci\u00f3n para re-entregarlo. Formato a respetar para los informes Los informes deben constar de: 1 hoja de Car\u00e1tula. En esta hoja se incluir\u00e1: N\u00famero y t\u00edtulo del trabajo pr\u00e1ctico (respetar el n\u00famero que figura en la gu\u00eda) N\u00famero de grupo Nombre y Apellido y direcci\u00f3n de correo electr\u00f3nico de cada uno de los integrantes del grupo Fecha de entrega 5 hojas m\u00e1ximo. En estas 5 hojas se debe incluir: Introducci\u00f3n: 1 hoja m\u00e1ximo y NO debe ser la que se utiliza en el trabajo pr\u00e1ctico que entregan los docentes. Objetivo general y objetivos espec\u00edficos M\u00e9todos y resultados Discusi\u00f3n Bibliograf\u00eda (10 referencias m\u00e1ximo) Anexo. No hay l\u00edmite de hojas pero se tendr\u00e1 en cuenta si es referenciado o no en el cuerpo del informe (es decir, no pongan cosas innecesarias) Respecto del formato: Se deber\u00e1n entregar en archivos PDFs nombrados de la siguiente manera: TPXX_GRUPO_XX.pdf (por ejemplo, TP08_GRUPO_01.pdf ) Tama\u00f1o de hoja: A4 Interlineado: 1.15 Letra y tama\u00f1o de letra: Arial 11pts Margen: 2 cm Aviso El formato ser\u00e1 considerado en la puntuaci\u00f3n final del trabajo pr\u00e1ctico Consulten siempre que tengan dudas !!","title":"Inicio"},{"location":"practicos/inicio/#consultas-y-canales-de-comunicacion","text":"Por email a la direcci\u00f3n de la JTP. en Slack pueden mandar mensajes a todo el grupo en los distintos canales.","title":"Consultas y Canales de Comunicaci\u00f3n"},{"location":"practicos/inicio/#informes","text":"Alguno de los trabajos pr\u00e1cticos de la cursada requieren una resoluci\u00f3n de un problema a informar. Al final de la gu\u00eda de trabajos pr\u00e1cticos se indicar\u00e1 el problema a resolver. La funci\u00f3n de los informes es: Que ustedes puedan aplicar los conocimientos y herramientas adquiridas durante la cursada a un problema puntual Evaluar la capacidad t\u00e9cnica para producir resultados, as\u00ed como tambi\u00e9n el criterio a la hora de evaluar el significado biol\u00f3gico de los mismos y la comprensi\u00f3n de las potencialidades y limitaciones de los algoritmos o herramientas empleadas. Evaluar la capacidad de elaborar informes Cada informe de cada trabajo pr\u00e1ctico puede (o no) estar relacionado con alguno anterior. Por lo tanto: Guarden los archivos y sean prolijos. El trabajo deber\u00e1 ser realizado con las mismas personas con la que realizan los trabajos pr\u00e1cticos normalmente. Es UNA entrega por grupo. Esta entrega deber\u00e1 ser realizada en tiempo y forma, por correo electr\u00f3nico a la persona encargada del trabajo pr\u00e1ctico. Formato Correo Electr\u00f3nico de Entrega de TP Cuando env\u00edan el correo. El asunto del correo debe ser: Entrega Informe TP01 - Grupo 01 Durante la cursada deber\u00e1n ir entregando de forma individual los ejercicios correspondientes a cada trabajo pr\u00e1ctico, los cuales ser\u00e1n aprobados o desaprobados. En caso de estar desaprobado tendr\u00e1n una semana despu\u00e9s de la devoluci\u00f3n para re-entregarlo.","title":"Informes"},{"location":"practicos/inicio/#formato-a-respetar-para-los-informes","text":"Los informes deben constar de: 1 hoja de Car\u00e1tula. En esta hoja se incluir\u00e1: N\u00famero y t\u00edtulo del trabajo pr\u00e1ctico (respetar el n\u00famero que figura en la gu\u00eda) N\u00famero de grupo Nombre y Apellido y direcci\u00f3n de correo electr\u00f3nico de cada uno de los integrantes del grupo Fecha de entrega 5 hojas m\u00e1ximo. En estas 5 hojas se debe incluir: Introducci\u00f3n: 1 hoja m\u00e1ximo y NO debe ser la que se utiliza en el trabajo pr\u00e1ctico que entregan los docentes. Objetivo general y objetivos espec\u00edficos M\u00e9todos y resultados Discusi\u00f3n Bibliograf\u00eda (10 referencias m\u00e1ximo) Anexo. No hay l\u00edmite de hojas pero se tendr\u00e1 en cuenta si es referenciado o no en el cuerpo del informe (es decir, no pongan cosas innecesarias) Respecto del formato: Se deber\u00e1n entregar en archivos PDFs nombrados de la siguiente manera: TPXX_GRUPO_XX.pdf (por ejemplo, TP08_GRUPO_01.pdf ) Tama\u00f1o de hoja: A4 Interlineado: 1.15 Letra y tama\u00f1o de letra: Arial 11pts Margen: 2 cm Aviso El formato ser\u00e1 considerado en la puntuaci\u00f3n final del trabajo pr\u00e1ctico Consulten siempre que tengan dudas !!","title":"Formato a respetar para los informes"},{"location":"practicos/resumen/","tags":["practicos","fin","resumen"],"text":"This is the end ... Bueno, hemos llegado al final de la parte pr\u00e1ctica del curso. Felicitaciones! quer\u00e9s seguir explorando t\u00f3picos y ganando experiencia, te dejamos a continuaci\u00f3n algunos links a distintos materiales y recursos: Libros Libro 1 Libro 2 Online Material 1 Material 2 Presencial Presencial 1 Presencial 2 Grupos Asociaci\u00f3n Argentina de Bioinform\u00e1tica y Biolog\u00eda Computacional (A 2 B 2 C) RSG-Argentina","title":"Resumen"},{"location":"practicos/resumen/#this-is-the-end","text":"Bueno, hemos llegado al final de la parte pr\u00e1ctica del curso. Felicitaciones! quer\u00e9s seguir explorando t\u00f3picos y ganando experiencia, te dejamos a continuaci\u00f3n algunos links a distintos materiales y recursos: Libros Libro 1 Libro 2 Online Material 1 Material 2 Presencial Presencial 1 Presencial 2 Grupos Asociaci\u00f3n Argentina de Bioinform\u00e1tica y Biolog\u00eda Computacional (A 2 B 2 C) RSG-Argentina","title":"This is the end ... "},{"location":"practicos/tpsGrid/","text":"TP 1 hola","title":"tpsGrid"},{"location":"practicos/TP01_Linux/","text":"TP 1 . Introducci\u00f3n a Lubuntu, Bash y Programaci\u00f3n Materiales Slides mostrados en la clase Introducci\u00f3n a la programaci\u00f3n Cierre TP Videos de la clase grabada Presentacion de la Materia Introducci\u00f3n a la programaci\u00f3n Cierre TP Recursos Online Command-line bootcamp Programando en Bash Comando AWK Consola de Linux online (y otra ) Compilador de Bash online (y otro ) Objetivos Familiarizarse un poco con Lubuntu y su estructura de directorios Familiarizarse con el uso b\u00e1sico de los comandos de Bash Familiarizarse con los bloques l\u00f3gicos b\u00e1sicos de la programaci\u00f3n Introducci\u00f3n al Tema En este trabajo pr\u00e1ctico vamos a aprender a usar la l\u00ednea de comando de Lubuntu (tambi\u00e9n referida como terminal , consola o shell ). Para muchos de nosotros, que estamos acostumbrados a la interfaz gr\u00e1fica de sistemas operativos como los de Windows o GUI (por las siglas en ingles: Graphic User Interface ), la linea de comando puede parecer un desaf\u00edo, pero con pr\u00e1ctica y algo de paciencia descubrir\u00e1n que puede resultar amena. Su uso tiene dos ventajas destacables para nuestro campo: Nos permitir\u00e1 trabajar en entornos o programas sin interfaz gr\u00e1fica (GUI) Mediante el uso de programas o scripts , nos permitir\u00e1 automatizar procesos, acelerando el trabajo y minimizando la cantidad de errores que podemos cometer con tareas repetitivas \u00bfUnix? \u00bfLinux? \u00bfUbuntu? \u00bfLubuntu? Dependiendo que tan familiares esten con Linux, todos estos nombres pueden resultar un poco confusos. Vamos por partes: Unix es un sistema operativo creado en 1969 por dos programadores estadounidenses que trabajaban para Bell Labs, una compan\u00eda de investigaci\u00f3n y desarrollo cient\u00edfico que en su momento era propiedad de AT&T (compa\u00f1ia estadounidense de tel\u00e9fonos). Al ser un sistema operativo portable, multitarea y multiusuario se hizo r\u00e1pidamente popular y se difundi\u00f3 por instituciones acad\u00e9micas y empresas Debido a su popularidad, otros programadores quisieron hacer sus propias versiones de sistemas operativos basados en Unix, pero como sus sistemas operativos ten\u00edan c\u00f3digo original de Unix, AT&T los demand\u00f3, paralizando esta tendenc\u00eda En 1983 se crea el proyecto GNU con el objetivo de crear un sistema operativo similar a Unix, pero gratis y de c\u00f3digo abierto. GNU significa \"GNU's Not Unix\" (es un anagrama recursivo, los programadores se divierten barato). Hacia el fin de los 80s el proyecto ya ten\u00eda casi todos los programas que necesitaba, pero les faltaba conseguir un buen kernel (principal responsable de facilitar a los distintos programas acceso seguro al hardware de la computadora) En 1991, Linus Torvalds empieza a crear lo que terminar\u00eda siendo Linux , un sistema operativo con su propio kernel que usaba muchas de los programas del proyecto GNU. Esta versi\u00f3n se volvi\u00f3 r\u00e1pidamente la m\u00e1s popular de todas las versiones de GNU, llevando a que en 1993 se creara el Debian Project , un proyecto comunal con el objetivo de mejorar una distrubuci\u00f3n de Linux que denominaron Debian GNU/Linux (tambi\u00e9n llamada simplemente Debian ). Ubuntu es una distribuci\u00f3n de Linux creada en 2004 basada en Debian. Al d\u00eda de la fecha es la distrubuci\u00f3n m\u00e1s popular de Linux con m\u00e1s del 50% de los usuarios. Lubuntu es una distribuci\u00f3n de Linux creada en 2009 basada Ubuntu. Es bastante similar a Ubuntu en todo lo que es consola, pero tiene una interfaz gr\u00e1fica que consume menos recursos, haciendolo ideal para maquinas m\u00e1s viejas (o en nuestro caso, maquinas virtuales que pesen lo menos posible). Estructura de directorios de Lubuntu La organizaci\u00f3n de archivos en Ubuntu y Lubuntu es bastante diferente a la de Windows. Si bien no vamos a detallar completamente toda la estructura y que es cada carpeta (porque el 95% no lo van a usar en esta materia), es importante tener una idea de lo b\u00e1sico: / Carpeta raiz, o root . Contiene al resto de las carpetas /etc Configuraciones del sistema para todos los usuarios (mucho cuidado al tocar) /home Ubicaci\u00f3n de los directorios de los diferentes usuarios (o en este caso el \u00fanico usuario) /home/ibioinfo Directorio del usuario ibioinfo . Es el lugar donde van a trabajar la mayor\u00eda del tiempo (incluye tanto el Escritorio como Documentos) y donde se abre por defecto la terminal (m\u00e1s sobre esto en un ratito). Comunmente referida como home directory o home del usuario ibioinfo /media Si fuera una computadora normal (no VM) aca aparecer\u00edan los pendrives. En nuestro caso aca aparecen por defecto las carpetas compartidas con la PC host /tmp Ubicaci\u00f3n de los archivos temporales de los programas /var Ubicaci\u00f3n de los archivos variables de los programas, como logs, bases de datos, paginas webs, etc /var/log Probablemente la subcarpeta m\u00e1s usada de /var . Contiene los logs de los programas (que a veces es la \u00fanica forma de saber porque algo no anduvo) Esto es simplemente un vistazo r\u00e1pido. Si quieren la lista completa de subdirectorios de Lubuntu la pueden encontrar en esta p\u00e1gina , pero tengan en cuenta que tocar cualquier cosa fuera de /home conlleva la posibilidad de arruinar la computadora. En esta materia vamos a usar principalmente /home y /media . L\u00ednea de comando Como ya dijimos en la introducci\u00f3n la l\u00ednea de comando tiene varios nombres, y en esta guia nos vamos a referir a ella como terminal o consola . Hay varias formas de abrir la terminal: Desde cualquier lado: Ctrl + Alt + T Desde cualquier lado: Inicio (menu de abajo a la izquierda) Herramientas del sistema LXterminal Desde afuera de una carpeta: Boton derecho en la carpeta Abrir en el terminal Desde adentro de una carpeta: Herramientas Abrir la carpeta actual en un terminal (o apretar F4 ) La terminal funciona como un explorador de archivos que se mueve entre las carpetas. Los primeros dos m\u00e9todos van a abrir la terminal en /home/ibioinfo , mientras que los \u00faltimos dos m\u00e9todos van a abrir la terminal en la carpeta elegida. Si en algun momento les decimos que abran la terminal y no aclaramos otra cosa nos referimos a abrirla en /home/ibioinfo . Abran la terminal en /home/ibioinfo y deberian ver algo as\u00ed: ibioinfo@ibioinfo-VirtualBox:~$ Donde ibioinfo es el nombre del usuario actual e ibioinfo-VirtualBox el nombre de la computadora (que justo en este caso son similares, pero no es necesario). El ~ despu\u00e9s de los dos puntos (conocido como \"virgulilla\", \"t\u00edlde\" o \"cosito de la \u00f1\") parece ser parte de la terminal, pero en realidad est\u00e1 indicando la carpeta en la que se encuentra en este momento. Como cada usuario trabaja mas que nada en su carpeta, Lubuntu le asigna el s\u00edmbolo ~ a esa carpeta para simplificar los directorios que aparecen en la terminal. En nuestro caso ~ equivale a /home/ibioinfo y puede ser que nos refiramos a esa carpeta como su home directory o simplemente su home . Info Aclaraciones por si son fan\u00e1ticos de los atajos de teclado: Para copiar texto en la terminal hay que usar Ctrl + Shift + C . En en resto de Lubuntu es normal ( Ctrl + C ). Para pegar texto en la terminal hay que usar Ctrl + Shift + V . En en resto de Lubuntu es normal ( Ctrl + V ). De apretar Ctrl + C en la terminal le estan diciendo que corte forzosamente el programa que est\u00e1 corriendo. Si bien hay que tener cuidado con no cortar un proceso importante a la mitad, este atajo del teclado es util si un programa se te qued\u00f3 colgado o similar. Bash: Ubicarse en la terminal La terminal acepta una variedad de comandos en lenguaje Bash , que es el lenguaje de la terminal de GNU. El formato general de los comandos es: comando -opciones parametro1 parametro2 etc Donde comando es el nombre del programa a correr, opciones son comunmente una o m\u00e1s letras luego de un gui\u00f3n que indican alguna modificaci\u00f3n a las opciones por defecto del programa, y los diferentes parametros son cosas que necesita el programa para correr, como puede ser un archivo que esta leyendo. Todo esto va a ir quedando m\u00e1s claro con los diferentes ejemplos. Usted est\u00e1 aqu\u00ed Al ser la terminal b\u00e1sicamente un explorador de archivos, es necesario saber en que carpeta estoy y que hay adentro de dicha carpeta. pwd es un comando que imprime el directorio actual en la terminal ( P rint W orking D irectory). Pruebenlo a ver si ~ era realmente /home/ibioinfo : pwd Bien, ahora que ganamos su confianza, vean que hay adentro de esa carpeta usando ls : ls Si bien por ahora todo lo que ven son carpetas azules, tengan en cuenta que ls va a colorear diferentes tipos de archivos (y de carpetas) de diferentes colores. Este comando es una buena oportunidad de entender un poco mas sobre opciones y parametros . Por defecto ls lista los archivos de la carpeta actual, pero de darle un par\u00e1metro muestra los de dicha carpeta. Prueben correr lo siguiente: ls /etc/perl/Net En este caso est\u00e1n viendo los contenidos de una carpeta diferente a donde estamos parados en la terminal. Si yo quisiera mas informaci\u00f3n sobre los archivos que se encuentran dentro de esta carpeta puedo hacer: Tip El pr\u00f3ximo comando es muy parecido al anterior. Pueden usar Up y Down en su terminal para navegar por los ultimos comandos utilizados y modificar lo necesario. ls -l /etc/perl/Net Donde la opcion -l agrega informaci\u00f3n sobre los permisos del archivo (quien puede leerlo o modificarlo). Con un poco de suerte esta es la primera y ultima vez en toda la materia que vamos a hablar de los permisos de Lubuntu (y de como a veces dan dolores de cabeza). Info La lista completa de las opciones para cada comando se puede ver con el comando man (de manual ). En este caso ser\u00eda man ls . Moverse entre las carpetas Ahora que ya saben donde estan y que carpetas hay adentro es importante saber como moverse entre ellas. Esto se hace principalmente con el comando cd . Asegurense que la terminal esta en su home y usen ls para ver nuevamente la lista de carpetas dentro. Primero vamos a la carpeta Escritorio y vemos que archivos hay adentro, para eso hacer: Tip Tab funciona como autocompletar en la consola. Al escribir el pr\u00f3ximo comando prueben escribir solo cd Es y apretar Tab cd Escritorio Ahora veran que la parte de la izquierda de la terminal cambio a: ibioinfo@ibioinfo-VirtualBox:~/Escritorio$ Indicando que estan en /home/ibioinfo/Escritorio . Usen el comando adecuado para ver que archivos hay adentro de esta carpeta. Ahora quiero volver a su home y para eso escribo: cd .. Vean ahora en que carpeta est\u00e1n. En todo lo que es Ubuntu y Lubuntu .. significa \"una carpeta para arriba\". \u00bfQu\u00e9 pasa entonces si estan en /home/ibioinfo/Escritorio/TP01/Version3/Intento2/Edicion1 y quieren volver a su home ? \u00bfTienen que escribir cd .. 5 veces? Tecnicamente funciona, pero por defecto el comando cd te lleva a tu home si no le das ningun par\u00e1metro. cd Paths relativos y absolutos Cuando corrimos ls /etc/perl/Net estaban ubicados en su home ( /home/ibioinfo ) y si vemos las carpetas dentro de home resulta que no existe ninguna llamada /etc . \u00bfD\u00f3nde est\u00e1 la carpeta /etc en relaci\u00f3n a /home/ibioinfo ? (ver Estructura de directorio de Lubuntu arriba si no se acuerdan) \u00bfC\u00f3mo pudimos acceder a /etc/perl/Net si la terminal estaba ubicada en una carpeta sin ninguna relaci\u00f3n? La respuesta a todo esto son los paths relativos y absolutos: Paths absolutos El path /etc/perl/Net es lo que se llama un path absoluto ; no importa donde est\u00e9n en la terminal en ese momento, /etc/perl/Net va a siempre apuntar al mismo lugar y el comando ls /etc/perl/Net va a siempre andar bien. Una forma f\u00e1cil de identificar paths absolutos es que siempre empiezan en el root o / . Recuerden que ~ apunta a /home/ibioinfo , y por lo tanto el comando cd ~/Escritorio est\u00e1 usando un path absoluto, ya que sin importar de donde se use va a funcionar y va a ir a /home/ibioinfo/Escritorio . Paths relativos Ahora bien, cuando nosotros estabamos ubicados en home y corrimos cd Escritorio pudimos entrar a /home/ibioinfo/Escritorio , pero si volvieramos a correr cd Escritorio el comando no funcionar\u00eda, ya que no existe la carpeta /home/ibioinfo/Escritorio/Escritorio . Esto se debe a que en este caso Escritorio es un path relativo a la ubicaci\u00f3n actual de la terminal. Otra forma de escribir paths relativos en Ubuntu es empezar con . , simbolo que indica \"la carpeta actual\". Volviendo al ejemplo anterior, es equivalente escribir cd Escritorio o cd ./Escritorio . Otro caso de path relativo que ya vimos es cd .. , donde apunta a la \"carpeta de arriba\" de la posici\u00f3n actual de la terminal. Ambos tipos de paths tienen sus ventajas y desventajas. Los paths absolutos tienen la ventaja de funcionar siempre, pero al usar toda la estructura toman m\u00e1s tiempo de escribir y son mas suceptibles a cambios de directorios (si muevo un archivo de lugar tengo que reescribir el comando). Por otro lado los paths relativos son mucho m\u00e1s r\u00e1pidos de escribir y en muchos casos funcionan en diferentes ubicaciones (o computadoras), pero al depender de la ubicaci\u00f3n de la terminal esto puede causar problemas si pienso que estoy en una carpeta pero estoy realmente en otra. En esta cursada vamos a usar ambos para diferentes casos. Ejercicio 1. Ubicarse en la terminal Identifique cual o cuales de los siguientes comandos te llevar\u00edan desde cualquier carpeta al home del usuario ibioinfo . cd ~ cd home/ibioinfo cd home / ibioinfo cd / home / ibioinfo cd /home/ibioinfo cd /ibioinfo/home cd ././ibioinfo cd ./home/ibioinfo \u00bfCambiarian la respuesta en algunos de los puntos anteriores si el usuario logueado actualmente en la computadora no es ibioinfo ? \u00bfPor qu\u00e9? Identifique en la siguiente lista cuales paths son paths relativos : /var/temp/tom_jerry var/temp/tom_jerry /home/tom/Documentos/catfood.png ../../jerry/Documentos/cheese.png ./Videos/Capitulos/ ~/Videos/Capitulos/ ./Descargas/tom_jerry_cap1.torrent /home/tom/Descargas/tom_jerry_cap1.torrent Bash: Crear y eliminar Todo lo que es crear, copiar, mover y eliminar archivos y directorios se puede hacer usando la interfaz gr\u00e1fica como lo har\u00edan en cualquier otro sistema operativo, sin embargo hay situaciones (por ejemplo dentro de un script ) donde es necesario hacerlo mediante la consola. Si bien por ahora les vamos a pedir que usen los siguientes comandos para pr\u00e1cticarlos, en el d\u00eda a d\u00eda hagan lo que les sea m\u00e1s c\u00f3modo. Crear y eliminar directorios Los directorios se pueden crear con: mkdir FOLDER Info En el resto de la guia van a aparecer ciertas palabras en may\u00fascula en los c\u00f3digos, como por ejemplo FOLDER . Estas palabras son variables o placeholders que tienen que ser reemplazadas por lo que corresponda. Donde FOLDER es un path absoluto o relativo con el nombre de la carpeta. Prueben ir en su terminal a /home/ibioinfo/Documentos y usar el comando: mkdir testfolder Y vean si efectivamente apareci\u00f3 una carpeta nueva. Luego usen el comando de nuevo a ver que pasa. Para eliminar directorios se puede usar: rmdir FOLDER Por defecto este comando solo puede eliminar directorios vacios (lo cual puede no ser muy util, pero a la vez es seguro). Usen el comando anterior y borren la carpeta que acaban de crear (reemplacen FOLDER por lo que corresponda). Prueben correr el comando una vez m\u00e1s a ver que pasa. Tip muy importante Este es un buen momento para hablar de que nombres ponerles a las cosas que uno crea un Lubuntu. Si bien cualquier nombre funciona en un principio, por un tema de compatibilidad entre los diferentes programas que pueden llegar a usar se recomienda: Muy recomendado: No usar comillas dobles, simples o ap\u00f3strofes Recomendado: No usar espacios, par\u00e9ntesis, \u00d1, acentos, di\u00e9resis u otros diacr\u00edticos (el espacio comunmente se remplaza por un gui\u00f3n o gui\u00f3n bajo) Crear y eliminar archivos Hay varias formas de crear archivos en Lubuntu y la mas simple es touch ARCHIVO , que crea un archivo de texto vacio donde ARCHIVO es el nombre del archivo (que puede incluir un path antes). Para entender lo que quiero decir vayan a su home y corran: touch Documentos/testfile Aca estoy usando un path relativo para crear el archivo. Se van a dar cuenta que el archivo no tiene extensi\u00f3n (por ejemplo .txt ). En Lubuntu van a ver muchos archivos de texto sin extensi\u00f3n, pero se la pueden agregar sin problema si quieren. Entren a Documentos y vean si el archivo realmente existe. Lo que le vamos a ense\u00f1ar a continuaci\u00f3n es probablemente uno de los comandos m\u00e1s peligrosos de Bash si se usa incorrectamente. rm es el comando usado para eliminar archivos (o carpetas, o discos enteros) y es la base de cientos de historias en internet de como alguien se qued\u00f3 sin trabajo. El comando se usa: rm ARCHIVO Donde ARCHIVO es el archivo a eliminar. rm no les va a pedir confirmaci\u00f3n y el archivo va a ser borrado permanentemente (si borran archivos desde la interfaz gr\u00e1fica s\u00ed hay confirmaci\u00f3n y s\u00ed van a la papelera). Entonces, con cuidado, asegurense que estan en Documentos y borren el archivo testfile . Danger \u00bfSe entendi\u00f3 que hay que tener cuidado con rm ? \u00bfSi? Buenisimo. Mover y copiar archivos y carpetas Adentro de Documentos creen una carpeta llamada testfolder2 y dos archivos de texto vacio, uno llamado testfile_mv y otro testfile_cp . Nuestro objetivo va a ser mover testfile_mv a la carpeta testfolder2 y copiar testfile_cp a la misma carpeta. Los archivos se mueven con mv y se copian con cp y ambos tienen un formato similar que es mv ARCHIVO_ORIGEN FOLDER_DESTINO Donde en este caso ARCHIVO_ORIGEN es el archivo a mover y FOLDER_DESTINO el path a donde moverlo. Prueben entonces mover testfile_mv y copiar testfile_cp adentro de la carpeta testfolder2 . Tip Usando la opci\u00f3n -i al comando, les va a pedir confirmaci\u00f3n si el archivo de destino ya existe. Recuerden que pueden usar man mv o man cp para ver mas opciones. Estos dos comandos tambi\u00e9n pueden ser usados como: mv ARCHIVO_ORIGEN ARCHIVO_DESTINO En este caso ARCHIVO_DESTINO no es una carpeta, sino un archivo adentro del FOLDER_DESTINO , lo que permite renombrar el ARCHIVO_ORIGEN al copiarlo / moverlo. Para que se entienda mejor este uso, ubiquens\u00e9 en Documentos y corran: cp testfile_cp testfolder2/testfile_cp_nuevo Con lo cual acabo de copiar testfile_cp de nuevo a la carpeta testfolder2 , pero ahora con otro nombre. Interesantemente, usar mv de esta manera es la forma de Ubuntu de renombrar archivos desde la terminal. Prueben entrar a testfolder2 y corran: mv testfile_cp_nuevo testfile_cp_otroNombre Y vean que pas\u00f3. Una vez que todo haya funcionado bien, usen rm para eliminar todos los testfile uno a uno y luego usen rmdir para eliminar testfolder2 . Ambos comandos funcionan tambi\u00e9n para copiar, mover y renombrar carpetas, en cuyo caso el formato es: mv FOLDER_ORIGEN FOLDER_DESTINO Danger Hay que ser cuidadosos al usar mv y cp ya que si el archivo de destino ya existe lo van a sobreescribir sin preguntar antes. A ambos comandos se le puede agregar la opci\u00f3n -i para que pregunte antes de sobreescribir de ya existir el archivo de destino. Bash: Archivos de texto Escribir archivos de texto En Lubuntu hay varias formas de escribir en archivos de texto, pero una de las m\u00e1s \u00fatiles para nosotros va a ser el > quien redirige la salida de informaci\u00f3n de la consola. Se usa: comando -opciones parametro1 parametro2 > ARCHIVO_DESTINO Donde lo de la izquierda de > es el comando como lo correr\u00edas normalmente y ARCHIVO_DESTINO es un archivo donde va a ser guardada la salida de ese comando (lo que normalmente ver\u00edan en la consola). Para entender un poco m\u00e1s, vayan a su home y corran: ls -l > Documentos/output_de_ls Ver\u00e1n que en un principio parece que no paso nada. Entren ahora a Documentos y van a ver que hay un nuevo archivo con el nombre output_de_ls . Vamos a abir el archivo usando Leafpad , el editor de texto de la interfaz \u01f5r\u00e1fica de Lubuntu. Asegurandose que estan Documentos , en la consola escriban: leafpad output_de_ls Van a ver que se abre el editor de texto de igual forma que si ubieran hecho doble click en el \u00edcono en el explorador de archivos de la GUI. Puede ser que aparezca un warning o advertencia en la consola, pero la podemos ignorar. Tip Por defecto Leafpad usa una fuente llamada \"Ubuntu\" , que si bien sirve para escribir cuentos, nos va a dar problemas al momento de ver ciertos archivos que vamos a usar en esta materia. En Leafpad vayan a Opciones Tipograf\u00eda... , seleccionen la fuente \"Ubuntu Mono\" y aprieten Aceptar . Las fuentes que tienen Mono en su nombre estan indicando que son monoespaciadas, o sea, que todos sus caracteres tienen el mismo ancho. Esto es ideal para cuando se quieren ver tablas o alineamientos con Leafpad , cosa que vamos a hacer bastante en esta materia. Leafpad funciona como un editor de texto bastante normal. Agreguen una nueva linea abajo de todo (con cualquier texto) y guarden el archivo. Al momento sabemos como guardar en un archivo de texto cualquier salida de un comando de Lubuntu, pero, \u00bfc\u00f3mo hacemos para poner lo que nosotros queremos en un archivo de texto? Simple, \u00a1con otro comando de Lubuntu! El comando echo hace lo que su nombre indica y devuelve por la terminal el texto que le pases. Prueben escribir echo TEXTO , donde TEXTO es cualquier oraci\u00f3n, por ejemplo: echo Probando, uno, dos, tres Tal vez ya se dieron cuenta, pero combinando echo con > podemos escribir nuestros propios archivos de texto desde la terminal. Asegurandose que estan adentro de Documentos , corran: echo Esta es la primera linea del documento > mi_documento Confirmen que se escribi\u00f3 el archivo y que tiene el texto adentro. \u00bfQu\u00e9 piensan que pasa si ahora corr\u00f3 el siguiente comando? Pruebenl\u00f3: echo Quiero agregar otra linea al documento > mi_documento Usen Leafpad para leer el documento. Van a ver que la primera linea que agregamos desapareci\u00f3. Esto es porque cada uso de > sobreescribe el archivo. Si queremos agregar otra linea a un documento que ya tiene informaci\u00f3n tenemos que usar el comando >> quien agrega el texto al archivo en una nueva linea al final sin modificar el contenido anterior. As\u00ed que ahora que sabemos esto podemos correr estos dos comandos: echo Esta es la primera linea del documento > mi_documento echo Esta es la segunda linea del documento >> mi_documento Y vean con Leafpad si funcion\u00f3 como quer\u00edamos. Danger Hay que ser cuidadosos al usar > ya que si el archivo de destino ya existe lo va a sobreescribir sin preguntar antes. Leer archivos de texto Qu\u00e9 comando usar al leer archivos de texto en la consola depende mucho de que tan largo es el archivo y que me interesa de \u00e9l: \u00bfTiene solo pocas lineas de texto? cat va a abrir el archivo y escribirlo todo en la terminal. \u00bfTiene muchas lineas de texto y quiero ver las primeras p\u00e1ginas a ver de que se trata? less va a abrir el archivo y mostrar solo el texto que entra en la terminal. Aprentando Space pasa a la pr\u00f3xima p\u00e1gina y apretando Q deja de leerlo. \u00bfTiene muchas lineas de texto y quiero ver solo las primeras lineas? head te muestra las primeras 10 lineas del archivo. Se puede especificar la cantidad de lineas agregando una opci\u00f3n, por ejemplo, head -3 muestra solo las primeras 3 l\u00edneas. \u00bfTiene muchas lineas de texto y quiero ver solo las \u00faltimas lineas? tail te muestra las \u00faltimas 10 l\u00edneas del archivo. Este n\u00famero se puede cambiar de la misma forma que para head . \u00bfNo saben que tan largo es un archivo dado? Pueden averiguarlo con el comando wc , que devuelve el numero de lineas, palabras y letras (en ese orden) en el archivo. De pasarle la opci\u00f3n -l , el comando devuelve solo el n\u00famero de lineas. Todos estos funcionan de la forma: comando ARCHIVO Usando el archivo martin_fierro que se encuentra en los materiales del TP (boton al principio de todo), prueben los 5 comandos anteriores. Buscar palabras en archivos de texto Va a ser com\u00fan cuando trabajemos con tablas que nos interese encontrar filas con cierto valor y una forma r\u00e1pida de hacer eso es usar grep , comando al que le pasas una palabra o patr\u00f3n y busca filas dentro de un archivo que contengan dicha palabra o patr\u00f3n. En formato general el comando es: grep PALABRA ARCHIVO Usando el archivo martin_fierro con en que trabajamos en la secci\u00f3n anterior podemos correr: grep cantar martin_fierro Y vamos a ver todas las lineas del documento donde aparece la palabra \"cantar\". Hay mucho para hablar sobre grep , pero por ahora lo que nos va a importar es: La opci\u00f3n -v devuelve las l\u00edneas que no contienen PALABRA La opci\u00f3n -c devuelve el n\u00famero de l\u00edneas que contienen PALABRA Es posible pasarle varias opciones a un programa. De hacer grep -v -c voy a estar contando el n\u00famero de l\u00edneas que no contengan PALABRA (el orden de las opciones no afecta el comportamiento) Info Mencion\u00e9 antes que grep tambi\u00e9n funciona con patrones, quienes son conocidos como Expresiones Regulares, o RegEx . Como este es un tema complejo y ya tenemos bastante que procesar no vamos a profundizar mas sobre ellos en este momento, pero explicaremos cualquier patr\u00f3n que usemos en la materia cuando aparezca. Combinar comandos En Bash es posible combinar comandos, lo que quiere decir pasarle la salida de un comando directamente como entrada a otro comando. Esto se hace dividiendo los diferentes comandos con | (o pipe ). Para entender un poco mejor veamos un ejemplo. Digamos que quiero ver las cuales de las primeras 10 lineas del archivo martin_fierro contienen la palabra \"cantar\". Para esto tengo que hacer: head -10 martin_fierro | grep cantar Fijens\u00e9 que en este caso parecer\u00eda que a grep no le estoy pasando ningun ARCHIVO , pero lo que pasa es que va usar como entrada la salida de head . De esta forma se puede concatenar cualquier cantidad de comandos que seran ejecutados de izquierda a derecha. Ejercicio 2. Archivos de texto Para este ejercicio vamos a seguir usando el archivo martin_fierro . \u00bfCu\u00e1ntas l\u00edneas tiene el archivo? \u00bfCu\u00e1ntas l\u00edneas contienen la palabra \"cantar\"? \u00bfCu\u00e1ntas l\u00edneas no contienen la palabra \"guitarra\"? Cree otro archivo de texto llamado martin_fierro_sinA con las l\u00edneas del archivo martin_fierro que no tengan la letra \"a\". Sin borrar el contenido y usando la consola, agregue una l\u00ednea al final de martin_fierro_sinA que indique el autor del Martin Fierro (Jos\u00e9 Hern\u00e1ndez). Volviendo al archivo original, \u00bfcu\u00e1ntas l\u00edneas no contienen la letra \"o\" y s\u00ed contienen la letra \"i\"? (Tip: use | para encadenar comandos) Bash: Programaci\u00f3n y Scripts Info A continuaci\u00f3n vamos a ver una peque\u00f1a introducci\u00f3n a la programaci\u00f3n usando Bash como lenguaje. El objetivo de lo que sigue no es aprenderse de memoria las estructuras y si hay que poner una llave aca o dejar un espacio all\u00e1, sino entender la l\u00f3gica detr\u00e1s de la programaci\u00f3n y como se pueden usar variables, condicionales y ciclos para obtener el resultado deseado. Scripts Los scripts de Bash son b\u00e1sicamente una lista de muchos de los comandos que nosotros corrimos en la terminal, pero escritos dentro de un archivo. Al ejecutar ese archivo todos los comandos dentro de \u00e9l ser\u00e1n corridos uno a uno de arriba a abajo. Para simplificar un poco la tarea y enfocarnos en lo que importa en esta secci\u00f3n, vamos a utilizar la interfaz gr\u00e1fica de Lubuntu. Vayan a Documentos y creen un archivo llamado primer_programa.sh (Boton derecho Crear nuevo... Archivo vac\u00edo). Luego abran el archivo en Leafpad (doble click) y escriban lo siguiente: echo \"----------------\" echo \"| Hello world! |\" echo \"----------------\" Ahora salven el archivo, abran la terminal en esa carpeta ( F4 ) y vamos a ejecutar el script con: bash primer_programa.sh \u00a1Felicidades, ya pueden decir que son programadores! Como pudieron observar, los scripts de Bash se corren con el comando bash SCRIPT y al hacerlo se ejecutaron los 3 comandos echo en el orden que estaban dentro del script. Este tipo de scripts son \u00fatiles si quiero dejar evidencia de los comandos que corr\u00ed en Bash, ya sea para volver a hacerlo otro d\u00eda o para pasarselos a algui\u00e9n m\u00e1s y que los corra en su propia computadora; sin embargo, para realmente programar necesitamos m\u00e1s herramientas. Variables Las variables son palabras que guardan dentro de ellas un n\u00famero o un string (texto), entre otro tipo de valores posibles que veremos m\u00e1s adelante. Veamos un ejemplo de como usar variables (vean ambas pesta\u00f1as): C\u00f3digo C\u00f3digo con comentarios nombre = \"Unsamer\" echo \"Hola $nombre , \u00bftodo bien?\" # Las lineas que empiezan con # son comentarios, no afectan el c\u00f3digo y sirven para aclarar que estas # haciendo en tu programa o script # Al declarar una variable en Bash no se puede poner espacio entre la variable, el = y el valor # Las comillas se usan para indicar que lo de adentro es una cadena de caracteres, o *string* nombre = \"Unsamer\" # Cuando se usa la variable, se le agrega el prefijo $ echo \"Hola $nombre , \u00bftodo bien?\" \u00bfQu\u00e9 piensan que va a pasar de correr este c\u00f3digo en un script? Pruebenl\u00f3. Info Desgraciadamente Bash es muy estricto al momento de programar y perdona bastante poco (como por ejemplo el tema de tener un espacio m\u00e1s o menos). M\u00e1s adelante vamos a usar el lenguaje R que va a ser una de nuestras principales herramientas al momento de analizar y plotear datos y es mucho m\u00e1s amigable. En este momento pueden estar pensando que hubiera sido mucho m\u00e1s f\u00e1cil poner solo echo \"Hola Unsamer, \u00bftodo bien?\" y ahorrarme el tema de la variable. Tienen raz\u00f3n. Por ahora. \u00bfSe acuerdan de los parametros de los comandos de Bash? Al pasarle par\u00e1metros a un script de Bash estos se asignan automaticamente a variables llamadas $1 , $2 , etc. Editemos ahora nuestro c\u00f3digo anterior: C\u00f3digo C\u00f3digo con comentarios nombre = $1 echo \"Hola $nombre , \u00bftodo bien?\" # $1 es el primer parametro que se le pasa al script de Bash # Le estoy asignando el valor de una variable a otra variable. $1 sigue existiendo, pero no la uso m\u00e1s nombre = $1 # Podr\u00eda usar $1 directamente aca, pero as\u00ed se entiende mucho m\u00e1s lo que hace el c\u00f3digo al leerlo # (y para programas muy complicados esto es muy importante) echo \"Hola $nombre , \u00bftodo bien?\" Y ahora corran: bash SCRIPT \"NOMBRE\" Por si la versi\u00f3n gen\u00e9rica no queda claro, si el script se llamara saludo.sh y quiero conseguir el mismo resultado que antes habr\u00eda que correr: bash saludo.sh \"Unsamer\" Info Tecnicamente si estoy pasando solo una palabra las comillas no son necesarias, pero si el string que estoy pasando tiene un espacio tengo que ponerlas si o si. Hay bastante m\u00e1s para hablar de las variables . Existen muchos tipos m\u00e1s de variables, como booleanos (variable que es verdadera o falsa), arreglos (o vectores) y listas. Otros lenguajes de programaci\u00f3n hasta tienen variables m\u00e1s complejas que pueden almacenar tablas enteras. Sin embargo, lo que acabamos de aprender es la base y va a ser suficiente por ahora. M\u00e1s informaci\u00f3n sobre las variables en Bash se puede ver en esta p\u00e1gina . Condicionales Las variables son importantes, pero gran parte de la programaci\u00f3n es controlar el \"flujo\" del programa, es decir, que un script haga algo m\u00e1s que simplemente ir de arriba a abajo ejecutando comandos. La primera herramienta que vamos a aprender para controlar el flujo del programa son los condicionales que permiten crear secciones de c\u00f3digo que se van a ejecutar solo si se cumple (o no se cumple) una condici\u00f3n. Por ejemplo: C\u00f3digo C\u00f3digo con comentarios numero = $1 echo \" $numero es un numero\" if (( $numero > 10 )) then echo \" $numero es mayor a 10\" fi # Igual que antes estoy agarrando un par\u00e1metro al correr el script numero = $1 echo \" $numero es un numero\" # *if* es la estructura m\u00e1s usada para condicionales. # Adentro de los dobles par\u00e9ntesis va la condici\u00f3n. # > es el comparador, o sea, estamos preguntando si $numero es mayor que 10 if (( $numero > 10 )) then # El codigo entre *then* y *fi* solo si ejecuta si la condici\u00f3n es verdad, de otra forma se saltea # Este codigo esta m\u00e1s a la derecha, o *indentado*. Esto se hace con tab y en la mayor\u00eda de los lenguajes # es solo para entender m\u00e1s f\u00e1cil el c\u00f3digo echo \" $numero es mayor a 10\" fi # *fi* indica donde termina el condicional Copien este c\u00f3digo a un script y prueben pasarle n\u00fameros menores y mayores a 10 a ver que pasa. Info Es importante remarcar que la condici\u00f3n del if (lo que en este caso se encuentra entre los corchetes) es b\u00e1sicamente una pregunta que puede tener solo una de dos respuestas posibles: S\u00ed (llamada en programaci\u00f3n Verdadero o True ) \u00f3 No (llamada en programaci\u00f3n Falso o False ) Como dije antes a un condicional se le puede poner tambi\u00e9n que pase algo cuando no es verdad, por ejemplo: C\u00f3digo C\u00f3digo con comentarios numero = $1 echo \" $numero es un numero\" if (( $numero > 10 )) then echo \" $numero es mayor a 10\" else echo \" $numero es menor o igual a 10\" fi numero = $1 echo \" $numero es un numero\" if (( $numero > 10 )) then # Ahora si la condici\u00f3n es verdad se va a ejecutar el c\u00f3digo entre *then* y *else* y luego va a # seguir a partir de *fi* echo \" $numero es mayor a 10\" else # El c\u00f3digo entre *else* y *fi* se ejecuta solo cuando la condici\u00f3n no es verdad echo \" $numero es menor o igual a 10\" fi Hay bastante m\u00e1s para hablar de los ifs . Hay muchos m\u00e1s comparadores y son diferentes si estoy comparando n\u00fameros o strings . Hay formas de poner m\u00e1s de una condici\u00f3n por if y hay otras estructuras como son los case que cumplen una funci\u00f3n similar. Sin embargo, lo que acabamos de aprender es la base y va a ser suficiente por ahora. M\u00e1s informaci\u00f3n sobre los condicionales en Bash, incluyendo una lista m\u00e1s detallada de los comparadores, se puede ver en esta p\u00e1gina y en esta p\u00e1gina (en Bash las condiciones pueden estar rodeadas por par\u00e9ntesis o corchetes y en cada caso los comparadores se comportan diferente, ojo con esto). Ciclos Digamos que por alguna extra\u00f1a raz\u00f3n quieren imprimir los numeros del 1 al 10 en la consola, tendr\u00edan que hacer echo 1 , echo 2 , etc, hasta llegar a echo 10 . \u00bfQu\u00e9 pasa si ahora les pido del 1 al 100, o al 1000?. Por suerte existen los ciclos , que son estructuras que nos permiten repetir algo varias veces y al usar variables podemos hacer que cada vez sea ligeramente diferente a la anterior. C\u00f3digo C\u00f3digo con comentarios for (( i = 1 ; i< = 1000 ; i++ )) do echo $i done # *for* es una de las estructuras m\u00e1s usadas para hacer ciclos # *i* es el nombre de la variable que va a cambiar de valor en cada ciclo. Se le podria poner cualquier nombre a # \u00e9sta variable, por ejemplo *numero* en nuestro caso, pero es costumbre ponele *i* # i=1 indica que el primer valor de $i es 1 # i<=1000 indica que el ciclo se va a repetir mientras $i sea menor o igual a 1000 # i++ indica que al final de cada ciclo el valor de $i va a subir en 1 for (( i = 1 ; i< = 1000 ; i++ )) do # El c\u00f3digo entre *do* y *done* se va a ejecutar una vez para cada posible $i en el rango echo $i done Hay otra versi\u00f3n del for que comunmente se denomina for each . En este caso $i no representa n\u00fameros que aumentan, sino diferentes elementos en una lista. Por ejemplo: C\u00f3digo C\u00f3digo con comentarios for color in rojo amarillo verde do echo \"Este es el color $color \" done # Como ahora la variable son elementos de una lista le pongo el nombre *color* para que se sepa que es, # pero podr\u00eda ser *i* # Esta es una forma bastante mala de usar listas de elementos, donde la estoy declarando en el mismo *for*; # comunmente las listas existen de antes en el programa o las obtengo de un archivo o comando de Lubuntu for color in rojo amarillo verde do echo \"Este es el color $color \" done Hay bastante m\u00e1s para hablar de los ciclos . Se pueden hacer ciclos que aumenten de 2 en 2 o hacer ciclos que disminuyan. Hay otros dos tipos de ciclos comunmente den\u00f3minados while y until (tambien llamado do ) y hay formas de forzar salir del ciclo o pasar a la pr\u00f3xima iteraci\u00f3n con break y continue (tambien llamado next ). Sin embargo, lo que acabamos de aprender es la base y va a ser suficiente por ahora. M\u00e1s informaci\u00f3n sobre los ciclos en Bash se puede ver en esta p\u00e1gina . Ejercicio 3. Programaci\u00f3n en Bash El objetivo de este ejercicio es hacer un script que: Use por lo menos un for y un if Recorra los n\u00fameros del 1 al 10 Por cada uno de esos n\u00fameros cree un archivo llamado archivo_NUMERO , d\u00f3nde hay que reemplazar NUMERO por el n\u00famero correspondiente (de 1 a 10) En los primeros 5 archivos ( archivo_1 a archivo_5 ) escriba el texto: Primera parte. Este es el archivo NUMERO. Donde hay que reemplazar NUMERO por el n\u00famero correspondiente (de 1 a 5) En los \u00faltimos 5 archivos ( archivo_6 a archivo_10 ) escriba el texto: Segunda parte. Este es el archivo NUMERO. Donde hay que reemplazar NUMERO por el n\u00famero correspondiente (de 6 a 10). Noten que ambas oraciones est\u00e1n en lineas diferentes Ahora que sabemos nuestro objetivo vayan a Documentos y creen una nueva carpeta donde vamos a trabajar llamada TP01_EJ3 . Dentro de ella creen un archivo vacio llamado crear_archivos.sh que va a ser nuestro script. Al momento de hacer programas complejos, especialmente en un lenguaje que reci\u00e9n aprenden, es recomendado ir por partes e ir probando en el medio. Unos posibles pasos a seguir son: Info La idea de hacerlo as\u00ed es ir probando de a poco si aparece algun error. \u00a1Prueben el script entre cada paso! Modifiquen el script para que cree un archivo llamado archivo_1 que adentro tenga el texto: Primera parte. Este es el archivo 1. Agreguen un for que vaya de 1 a 5 y cree los archivos archivo_1 a archivo_5 que adentro tengan el texto: Primera parte. Este es el archivo NUMERO. Donde hay que reemplazar NUMERO por el n\u00famero correspondiente (de 1 a 5). Expandan el for para que vaya de 1 a 10. Agreguen un if adentro del for que haga que los archivos se creen solo para los primeros 5 ciclos. Tip Aca les puede venir bien el comparador <= , que significa \"menor o igual\". Un ejemplo de <= seria: if (( $1 < = 7 )) Que en este caso es verdadero cuando el par\u00e1metro $1 es menor o igual a 7. Agreguen un else al if , recordando que los comandos adentro del else se van a ejecutar cuando la condici\u00f3n no sea verdadera. Asumiendo que usaron <= en la condici\u00f3n del if , modifiquen los comandos adentro del else para que en ese caso se creen los archivos archivo_6 a archivo_10 que adentro tengan el texto: Segunda parte. Este es el archivo NUMERO. Donde hay que reemplazar NUMERO por el n\u00famero correspondiente (de 6 a 10). \u00a1Y listo, deber\u00edan tener su programa andando! Bash: Tablas Lo ultimo que vamos a aprender hoy es un peque\u00f1o vistazo a como se pueden manipular tablas desde la consola de Lubuntu. Descarguen el archivo mtcars que se encuentra en los materiales del TP (boton al principio de todo) y ponganlo en Documentos . Esta tabla viene por defecto con el lenguaje de programaci\u00f3n R y nos va a servir para aprender como manipular tablas en Bash. Abran el archivo con Leafpad (doble click). Podemos ver que es una tabla en formato texto, donde la primera l\u00ednea es el encabezado o header de la tabla y en cada l\u00ed\u0144ea las columnas est\u00e1n separadas entre ellas con un Tab (a estos archivos se los conoce como TSV o \"Tab-Separated Values\"). Es bioinform\u00e1tica es muy com\u00fan querer seleccionar columnas espec\u00edficas en una tabla, o filtrar filas debido al valor de una de sus columnas; esto es lo que vamos a aprender a continuaci\u00f3n. Columnas de mtcars mtcars es una tabla que viene por defecto con el lenguaje de programaci\u00f3n R , sus columnas son: Nombre Descripci\u00f3n car_name Name of the car mpg Miles/(US) gallon cyl Number of cylinders disp Displacement (cu.in.) hp Gross horsepower drat Rear axle ratio wt Weight (1000 lbs) qsec 1/4 mile time vs Engine (0 = V-shaped, 1 = straight) am Transmission (0 = automatic, 1 = manual) gear Number of forward gears carb Number of carburetors AWK El comando awk (que recibe su nombre de las iniciales de los apellidos de las 3 personas que lo crearon) es uno de los comandos mas usados en Bash para manipular tablas por su gran flexibilidad, hasta el punto que es posible incorporar condicionales y ciclos dentro de \u00e9l. La forma m\u00e1s simple del comando es: awk -opciones 'instrucciones' ARCHIVO_TABLA Donde ARCHIVO_TABLA es el archivo que contiene a la tabla e instrucciones es que hacer con ese archivo una vez que se abra (las instrucciones siempre tienen que estar delimitadas por comillas simples, o ' ). Colocando a nuestra terminal en Documentos podemos correr: awk -F \"\\t\" '{print}' mtcars Donde -F es la opci\u00f3n que le dice a awk cual es el caracter que separa las diferentes columnas (en este caso es \\t , que es el s\u00edmbolo de Tab ) y {print} es la instrucci\u00f3n que simplemente dice que imprima en pantalla la tabla. Lo importante de awk es que nos permite trabajar con columnas individuales. Por ejemplo si ponemos: awk -F \"\\t\" '{print $1}' mtcars Vemos que awk imprime solo la primera columna, que en este caso es el nombre de los autos. Podemos asumir entonces que cada columna se puede referir con $1 , $2 , etc. Probemos imprimir muchas columnas corriendo: awk -F \"\\t\" '{print $1 $3 $5}' mtcars \u00bfQu\u00e9 ven que pasa aca? Debido a como funciona print , las diferentes columnas se imprimeron una pegada a la otra sin dejar espacios. Si quisieramos imprimir las columnas separadas con Tab como la tabla original tenemos que hacer: awk -F \"\\t\" '{print $1 \"\\t\" $3 \"\\t\" $5}' mtcars Ahora bien, una actividad normal cuando se tienen tablas con muchos datos es filtrar mis datos por alguna columna, o dicho de otra forma, usar condicionales. Un ejemplo de esto en awk seria: awk -F \"\\t\" '{if ($3 == 6) {print}}' mtcars \u00bfQu\u00e9 les parece que hace ese comando? Piensen que estan viendo una estructura de if que no vieron antes, pero aun as\u00ed probablemente puedan inferir que va a hacer el comando pensando en como funcionaba el if de Bash que aprendimos arriba. Esto es super normal en la programaci\u00f3n, donde la estructura exacta cambia, pero la l\u00f3gica detr\u00e1s se mantiene constante. Entonces, aca le estan diciendo a awk que imprima en la pantalla todas las filas que tengan un valor de 6 en la columna 3 (que si se fijan es cyl , o el n\u00famero de cilindros). Como siempre hay mucho m\u00e1s para decir sobre awk , pero por hoy estamos bien. Sepan sin embargo que awk tiene su propio grep y su propio for , que se pueden declarar variables dentro de \u00e9l y que tiene hasta una lista de comandos propios. Pueden ver mucha m\u00e1s informaci\u00f3n de awk en esta p\u00e1gina . Ejercicio Adicional 1. Programaci\u00f3n en Bash v2 Info Algunas guias van a tener ejercicios adicionales, que son ejercicios que pueden hacer si quieren practicar m\u00e1s el tema, pero no son obligatorios. Estos ejercicios pueden llegar a ser un poco m\u00e1s complicados que los ejercicios de la gu\u00eda. El objetivo de este Ejercicio va a ser hacer un script que: Reciba un n\u00famero por consola (vamos a asumir que dicho n\u00famero va a ser siempre un n\u00famero entero entre 1 y 1000) Recorra todos los n\u00fameros entre 1 y el n\u00famero que recibi\u00f3 por consola Para cada uno de esos n\u00fameros vea si es par Imprima los n\u00fameros pares por consola Dos cosas que van a necesitar para hacer esto son: # El operador % calcula el resto entre 2 n\u00fameros # En este caso $resto va a contener el resto de dividir 5 por 2 (que es 1) # Una forma muy usada en programac\u00edon para ver si un n\u00famero es par es ver si su resto al dividirlo por 2 es 0 # Los par\u00e9ntesis y signo $ bordeando a la operaci\u00f3n son necesarios para que funcione bien en Bash resto = $(( 5 % 2 )) # == es el comparador para igualdad usado en los *ifs* # Va a ser verdadero solo si lo de la izquierda es identico a lo de la derecha. if (( $1 == 2 )) Para hacer este ejercicio pueden usar como base el c\u00f3digo creado en el Ejercicio 3 que ambos tienen una estructura general bastante similar. Bibliograf\u00eda Consola Comando man","title":"TP 1 - Linux"},{"location":"practicos/TP01_Linux/#tp-1-introduccion-a-lubuntu-bash-y-programacion","text":"Materiales","title":"data-toc-label"},{"location":"practicos/TP01_Linux/#slides-mostrados-en-la-clase","text":"Introducci\u00f3n a la programaci\u00f3n Cierre TP","title":"Slides mostrados en la clase"},{"location":"practicos/TP01_Linux/#videos-de-la-clase-grabada","text":"Presentacion de la Materia Introducci\u00f3n a la programaci\u00f3n Cierre TP","title":"Videos de la clase grabada"},{"location":"practicos/TP01_Linux/#recursos-online","text":"Command-line bootcamp Programando en Bash Comando AWK Consola de Linux online (y otra ) Compilador de Bash online (y otro )","title":"Recursos Online"},{"location":"practicos/TP01_Linux/#objetivos","text":"Familiarizarse un poco con Lubuntu y su estructura de directorios Familiarizarse con el uso b\u00e1sico de los comandos de Bash Familiarizarse con los bloques l\u00f3gicos b\u00e1sicos de la programaci\u00f3n","title":"Objetivos"},{"location":"practicos/TP01_Linux/#introduccion-al-tema","text":"En este trabajo pr\u00e1ctico vamos a aprender a usar la l\u00ednea de comando de Lubuntu (tambi\u00e9n referida como terminal , consola o shell ). Para muchos de nosotros, que estamos acostumbrados a la interfaz gr\u00e1fica de sistemas operativos como los de Windows o GUI (por las siglas en ingles: Graphic User Interface ), la linea de comando puede parecer un desaf\u00edo, pero con pr\u00e1ctica y algo de paciencia descubrir\u00e1n que puede resultar amena. Su uso tiene dos ventajas destacables para nuestro campo: Nos permitir\u00e1 trabajar en entornos o programas sin interfaz gr\u00e1fica (GUI) Mediante el uso de programas o scripts , nos permitir\u00e1 automatizar procesos, acelerando el trabajo y minimizando la cantidad de errores que podemos cometer con tareas repetitivas","title":"Introducci\u00f3n al Tema"},{"location":"practicos/TP01_Linux/#unix-linux-ubuntu-lubuntu","text":"Dependiendo que tan familiares esten con Linux, todos estos nombres pueden resultar un poco confusos. Vamos por partes: Unix es un sistema operativo creado en 1969 por dos programadores estadounidenses que trabajaban para Bell Labs, una compan\u00eda de investigaci\u00f3n y desarrollo cient\u00edfico que en su momento era propiedad de AT&T (compa\u00f1ia estadounidense de tel\u00e9fonos). Al ser un sistema operativo portable, multitarea y multiusuario se hizo r\u00e1pidamente popular y se difundi\u00f3 por instituciones acad\u00e9micas y empresas Debido a su popularidad, otros programadores quisieron hacer sus propias versiones de sistemas operativos basados en Unix, pero como sus sistemas operativos ten\u00edan c\u00f3digo original de Unix, AT&T los demand\u00f3, paralizando esta tendenc\u00eda En 1983 se crea el proyecto GNU con el objetivo de crear un sistema operativo similar a Unix, pero gratis y de c\u00f3digo abierto. GNU significa \"GNU's Not Unix\" (es un anagrama recursivo, los programadores se divierten barato). Hacia el fin de los 80s el proyecto ya ten\u00eda casi todos los programas que necesitaba, pero les faltaba conseguir un buen kernel (principal responsable de facilitar a los distintos programas acceso seguro al hardware de la computadora) En 1991, Linus Torvalds empieza a crear lo que terminar\u00eda siendo Linux , un sistema operativo con su propio kernel que usaba muchas de los programas del proyecto GNU. Esta versi\u00f3n se volvi\u00f3 r\u00e1pidamente la m\u00e1s popular de todas las versiones de GNU, llevando a que en 1993 se creara el Debian Project , un proyecto comunal con el objetivo de mejorar una distrubuci\u00f3n de Linux que denominaron Debian GNU/Linux (tambi\u00e9n llamada simplemente Debian ). Ubuntu es una distribuci\u00f3n de Linux creada en 2004 basada en Debian. Al d\u00eda de la fecha es la distrubuci\u00f3n m\u00e1s popular de Linux con m\u00e1s del 50% de los usuarios. Lubuntu es una distribuci\u00f3n de Linux creada en 2009 basada Ubuntu. Es bastante similar a Ubuntu en todo lo que es consola, pero tiene una interfaz gr\u00e1fica que consume menos recursos, haciendolo ideal para maquinas m\u00e1s viejas (o en nuestro caso, maquinas virtuales que pesen lo menos posible).","title":"\u00bfUnix? \u00bfLinux? \u00bfLubuntu?"},{"location":"practicos/TP01_Linux/#estructura-de-directorios-de-lubuntu","text":"La organizaci\u00f3n de archivos en Ubuntu y Lubuntu es bastante diferente a la de Windows. Si bien no vamos a detallar completamente toda la estructura y que es cada carpeta (porque el 95% no lo van a usar en esta materia), es importante tener una idea de lo b\u00e1sico: / Carpeta raiz, o root . Contiene al resto de las carpetas /etc Configuraciones del sistema para todos los usuarios (mucho cuidado al tocar) /home Ubicaci\u00f3n de los directorios de los diferentes usuarios (o en este caso el \u00fanico usuario) /home/ibioinfo Directorio del usuario ibioinfo . Es el lugar donde van a trabajar la mayor\u00eda del tiempo (incluye tanto el Escritorio como Documentos) y donde se abre por defecto la terminal (m\u00e1s sobre esto en un ratito). Comunmente referida como home directory o home del usuario ibioinfo /media Si fuera una computadora normal (no VM) aca aparecer\u00edan los pendrives. En nuestro caso aca aparecen por defecto las carpetas compartidas con la PC host /tmp Ubicaci\u00f3n de los archivos temporales de los programas /var Ubicaci\u00f3n de los archivos variables de los programas, como logs, bases de datos, paginas webs, etc /var/log Probablemente la subcarpeta m\u00e1s usada de /var . Contiene los logs de los programas (que a veces es la \u00fanica forma de saber porque algo no anduvo) Esto es simplemente un vistazo r\u00e1pido. Si quieren la lista completa de subdirectorios de Lubuntu la pueden encontrar en esta p\u00e1gina , pero tengan en cuenta que tocar cualquier cosa fuera de /home conlleva la posibilidad de arruinar la computadora. En esta materia vamos a usar principalmente /home y /media .","title":"Estructura de directorios"},{"location":"practicos/TP01_Linux/#linea-de-comando","text":"Como ya dijimos en la introducci\u00f3n la l\u00ednea de comando tiene varios nombres, y en esta guia nos vamos a referir a ella como terminal o consola . Hay varias formas de abrir la terminal: Desde cualquier lado: Ctrl + Alt + T Desde cualquier lado: Inicio (menu de abajo a la izquierda) Herramientas del sistema LXterminal Desde afuera de una carpeta: Boton derecho en la carpeta Abrir en el terminal Desde adentro de una carpeta: Herramientas Abrir la carpeta actual en un terminal (o apretar F4 ) La terminal funciona como un explorador de archivos que se mueve entre las carpetas. Los primeros dos m\u00e9todos van a abrir la terminal en /home/ibioinfo , mientras que los \u00faltimos dos m\u00e9todos van a abrir la terminal en la carpeta elegida. Si en algun momento les decimos que abran la terminal y no aclaramos otra cosa nos referimos a abrirla en /home/ibioinfo . Abran la terminal en /home/ibioinfo y deberian ver algo as\u00ed: ibioinfo@ibioinfo-VirtualBox:~$ Donde ibioinfo es el nombre del usuario actual e ibioinfo-VirtualBox el nombre de la computadora (que justo en este caso son similares, pero no es necesario). El ~ despu\u00e9s de los dos puntos (conocido como \"virgulilla\", \"t\u00edlde\" o \"cosito de la \u00f1\") parece ser parte de la terminal, pero en realidad est\u00e1 indicando la carpeta en la que se encuentra en este momento. Como cada usuario trabaja mas que nada en su carpeta, Lubuntu le asigna el s\u00edmbolo ~ a esa carpeta para simplificar los directorios que aparecen en la terminal. En nuestro caso ~ equivale a /home/ibioinfo y puede ser que nos refiramos a esa carpeta como su home directory o simplemente su home . Info Aclaraciones por si son fan\u00e1ticos de los atajos de teclado: Para copiar texto en la terminal hay que usar Ctrl + Shift + C . En en resto de Lubuntu es normal ( Ctrl + C ). Para pegar texto en la terminal hay que usar Ctrl + Shift + V . En en resto de Lubuntu es normal ( Ctrl + V ). De apretar Ctrl + C en la terminal le estan diciendo que corte forzosamente el programa que est\u00e1 corriendo. Si bien hay que tener cuidado con no cortar un proceso importante a la mitad, este atajo del teclado es util si un programa se te qued\u00f3 colgado o similar.","title":"L\u00ednea de comando"},{"location":"practicos/TP01_Linux/#bash-ubicarse-en-la-terminal","text":"La terminal acepta una variedad de comandos en lenguaje Bash , que es el lenguaje de la terminal de GNU. El formato general de los comandos es: comando -opciones parametro1 parametro2 etc Donde comando es el nombre del programa a correr, opciones son comunmente una o m\u00e1s letras luego de un gui\u00f3n que indican alguna modificaci\u00f3n a las opciones por defecto del programa, y los diferentes parametros son cosas que necesita el programa para correr, como puede ser un archivo que esta leyendo. Todo esto va a ir quedando m\u00e1s claro con los diferentes ejemplos.","title":"Bash: Ubicarse en la terminal"},{"location":"practicos/TP01_Linux/#usted-esta-aqui","text":"Al ser la terminal b\u00e1sicamente un explorador de archivos, es necesario saber en que carpeta estoy y que hay adentro de dicha carpeta. pwd es un comando que imprime el directorio actual en la terminal ( P rint W orking D irectory). Pruebenlo a ver si ~ era realmente /home/ibioinfo : pwd Bien, ahora que ganamos su confianza, vean que hay adentro de esa carpeta usando ls : ls Si bien por ahora todo lo que ven son carpetas azules, tengan en cuenta que ls va a colorear diferentes tipos de archivos (y de carpetas) de diferentes colores. Este comando es una buena oportunidad de entender un poco mas sobre opciones y parametros . Por defecto ls lista los archivos de la carpeta actual, pero de darle un par\u00e1metro muestra los de dicha carpeta. Prueben correr lo siguiente: ls /etc/perl/Net En este caso est\u00e1n viendo los contenidos de una carpeta diferente a donde estamos parados en la terminal. Si yo quisiera mas informaci\u00f3n sobre los archivos que se encuentran dentro de esta carpeta puedo hacer: Tip El pr\u00f3ximo comando es muy parecido al anterior. Pueden usar Up y Down en su terminal para navegar por los ultimos comandos utilizados y modificar lo necesario. ls -l /etc/perl/Net Donde la opcion -l agrega informaci\u00f3n sobre los permisos del archivo (quien puede leerlo o modificarlo). Con un poco de suerte esta es la primera y ultima vez en toda la materia que vamos a hablar de los permisos de Lubuntu (y de como a veces dan dolores de cabeza). Info La lista completa de las opciones para cada comando se puede ver con el comando man (de manual ). En este caso ser\u00eda man ls .","title":"Usted est\u00e1 aqu\u00ed"},{"location":"practicos/TP01_Linux/#moverse-entre-las-carpetas","text":"Ahora que ya saben donde estan y que carpetas hay adentro es importante saber como moverse entre ellas. Esto se hace principalmente con el comando cd . Asegurense que la terminal esta en su home y usen ls para ver nuevamente la lista de carpetas dentro. Primero vamos a la carpeta Escritorio y vemos que archivos hay adentro, para eso hacer: Tip Tab funciona como autocompletar en la consola. Al escribir el pr\u00f3ximo comando prueben escribir solo cd Es y apretar Tab cd Escritorio Ahora veran que la parte de la izquierda de la terminal cambio a: ibioinfo@ibioinfo-VirtualBox:~/Escritorio$ Indicando que estan en /home/ibioinfo/Escritorio . Usen el comando adecuado para ver que archivos hay adentro de esta carpeta. Ahora quiero volver a su home y para eso escribo: cd .. Vean ahora en que carpeta est\u00e1n. En todo lo que es Ubuntu y Lubuntu .. significa \"una carpeta para arriba\". \u00bfQu\u00e9 pasa entonces si estan en /home/ibioinfo/Escritorio/TP01/Version3/Intento2/Edicion1 y quieren volver a su home ? \u00bfTienen que escribir cd .. 5 veces? Tecnicamente funciona, pero por defecto el comando cd te lleva a tu home si no le das ningun par\u00e1metro. cd","title":"Moverse entre las carpetas"},{"location":"practicos/TP01_Linux/#paths-relativos-y-absolutos","text":"Cuando corrimos ls /etc/perl/Net estaban ubicados en su home ( /home/ibioinfo ) y si vemos las carpetas dentro de home resulta que no existe ninguna llamada /etc . \u00bfD\u00f3nde est\u00e1 la carpeta /etc en relaci\u00f3n a /home/ibioinfo ? (ver Estructura de directorio de Lubuntu arriba si no se acuerdan) \u00bfC\u00f3mo pudimos acceder a /etc/perl/Net si la terminal estaba ubicada en una carpeta sin ninguna relaci\u00f3n? La respuesta a todo esto son los paths relativos y absolutos:","title":"Paths relativos y absolutos"},{"location":"practicos/TP01_Linux/#paths-absolutos","text":"El path /etc/perl/Net es lo que se llama un path absoluto ; no importa donde est\u00e9n en la terminal en ese momento, /etc/perl/Net va a siempre apuntar al mismo lugar y el comando ls /etc/perl/Net va a siempre andar bien. Una forma f\u00e1cil de identificar paths absolutos es que siempre empiezan en el root o / . Recuerden que ~ apunta a /home/ibioinfo , y por lo tanto el comando cd ~/Escritorio est\u00e1 usando un path absoluto, ya que sin importar de donde se use va a funcionar y va a ir a /home/ibioinfo/Escritorio .","title":"Paths absolutos"},{"location":"practicos/TP01_Linux/#paths-relativos","text":"Ahora bien, cuando nosotros estabamos ubicados en home y corrimos cd Escritorio pudimos entrar a /home/ibioinfo/Escritorio , pero si volvieramos a correr cd Escritorio el comando no funcionar\u00eda, ya que no existe la carpeta /home/ibioinfo/Escritorio/Escritorio . Esto se debe a que en este caso Escritorio es un path relativo a la ubicaci\u00f3n actual de la terminal. Otra forma de escribir paths relativos en Ubuntu es empezar con . , simbolo que indica \"la carpeta actual\". Volviendo al ejemplo anterior, es equivalente escribir cd Escritorio o cd ./Escritorio . Otro caso de path relativo que ya vimos es cd .. , donde apunta a la \"carpeta de arriba\" de la posici\u00f3n actual de la terminal. Ambos tipos de paths tienen sus ventajas y desventajas. Los paths absolutos tienen la ventaja de funcionar siempre, pero al usar toda la estructura toman m\u00e1s tiempo de escribir y son mas suceptibles a cambios de directorios (si muevo un archivo de lugar tengo que reescribir el comando). Por otro lado los paths relativos son mucho m\u00e1s r\u00e1pidos de escribir y en muchos casos funcionan en diferentes ubicaciones (o computadoras), pero al depender de la ubicaci\u00f3n de la terminal esto puede causar problemas si pienso que estoy en una carpeta pero estoy realmente en otra. En esta cursada vamos a usar ambos para diferentes casos.","title":"Paths relativos"},{"location":"practicos/TP01_Linux/#ejercicio-1-ubicarse-en-la-terminal","text":"Identifique cual o cuales de los siguientes comandos te llevar\u00edan desde cualquier carpeta al home del usuario ibioinfo . cd ~ cd home/ibioinfo cd home / ibioinfo cd / home / ibioinfo cd /home/ibioinfo cd /ibioinfo/home cd ././ibioinfo cd ./home/ibioinfo \u00bfCambiarian la respuesta en algunos de los puntos anteriores si el usuario logueado actualmente en la computadora no es ibioinfo ? \u00bfPor qu\u00e9? Identifique en la siguiente lista cuales paths son paths relativos : /var/temp/tom_jerry var/temp/tom_jerry /home/tom/Documentos/catfood.png ../../jerry/Documentos/cheese.png ./Videos/Capitulos/ ~/Videos/Capitulos/ ./Descargas/tom_jerry_cap1.torrent /home/tom/Descargas/tom_jerry_cap1.torrent","title":"Ejercicio 1"},{"location":"practicos/TP01_Linux/#bash-crear-y-eliminar","text":"Todo lo que es crear, copiar, mover y eliminar archivos y directorios se puede hacer usando la interfaz gr\u00e1fica como lo har\u00edan en cualquier otro sistema operativo, sin embargo hay situaciones (por ejemplo dentro de un script ) donde es necesario hacerlo mediante la consola. Si bien por ahora les vamos a pedir que usen los siguientes comandos para pr\u00e1cticarlos, en el d\u00eda a d\u00eda hagan lo que les sea m\u00e1s c\u00f3modo.","title":"Bash: Crear y eliminar"},{"location":"practicos/TP01_Linux/#crear-y-eliminar-directorios","text":"Los directorios se pueden crear con: mkdir FOLDER Info En el resto de la guia van a aparecer ciertas palabras en may\u00fascula en los c\u00f3digos, como por ejemplo FOLDER . Estas palabras son variables o placeholders que tienen que ser reemplazadas por lo que corresponda. Donde FOLDER es un path absoluto o relativo con el nombre de la carpeta. Prueben ir en su terminal a /home/ibioinfo/Documentos y usar el comando: mkdir testfolder Y vean si efectivamente apareci\u00f3 una carpeta nueva. Luego usen el comando de nuevo a ver que pasa. Para eliminar directorios se puede usar: rmdir FOLDER Por defecto este comando solo puede eliminar directorios vacios (lo cual puede no ser muy util, pero a la vez es seguro). Usen el comando anterior y borren la carpeta que acaban de crear (reemplacen FOLDER por lo que corresponda). Prueben correr el comando una vez m\u00e1s a ver que pasa. Tip muy importante Este es un buen momento para hablar de que nombres ponerles a las cosas que uno crea un Lubuntu. Si bien cualquier nombre funciona en un principio, por un tema de compatibilidad entre los diferentes programas que pueden llegar a usar se recomienda: Muy recomendado: No usar comillas dobles, simples o ap\u00f3strofes Recomendado: No usar espacios, par\u00e9ntesis, \u00d1, acentos, di\u00e9resis u otros diacr\u00edticos (el espacio comunmente se remplaza por un gui\u00f3n o gui\u00f3n bajo)","title":"Crear y eliminar directorios"},{"location":"practicos/TP01_Linux/#crear-y-eliminar-archivos","text":"Hay varias formas de crear archivos en Lubuntu y la mas simple es touch ARCHIVO , que crea un archivo de texto vacio donde ARCHIVO es el nombre del archivo (que puede incluir un path antes). Para entender lo que quiero decir vayan a su home y corran: touch Documentos/testfile Aca estoy usando un path relativo para crear el archivo. Se van a dar cuenta que el archivo no tiene extensi\u00f3n (por ejemplo .txt ). En Lubuntu van a ver muchos archivos de texto sin extensi\u00f3n, pero se la pueden agregar sin problema si quieren. Entren a Documentos y vean si el archivo realmente existe. Lo que le vamos a ense\u00f1ar a continuaci\u00f3n es probablemente uno de los comandos m\u00e1s peligrosos de Bash si se usa incorrectamente. rm es el comando usado para eliminar archivos (o carpetas, o discos enteros) y es la base de cientos de historias en internet de como alguien se qued\u00f3 sin trabajo. El comando se usa: rm ARCHIVO Donde ARCHIVO es el archivo a eliminar. rm no les va a pedir confirmaci\u00f3n y el archivo va a ser borrado permanentemente (si borran archivos desde la interfaz gr\u00e1fica s\u00ed hay confirmaci\u00f3n y s\u00ed van a la papelera). Entonces, con cuidado, asegurense que estan en Documentos y borren el archivo testfile . Danger \u00bfSe entendi\u00f3 que hay que tener cuidado con rm ? \u00bfSi? Buenisimo.","title":"Crear y eliminar archivos"},{"location":"practicos/TP01_Linux/#mover-y-copiar-archivos-y-carpetas","text":"Adentro de Documentos creen una carpeta llamada testfolder2 y dos archivos de texto vacio, uno llamado testfile_mv y otro testfile_cp . Nuestro objetivo va a ser mover testfile_mv a la carpeta testfolder2 y copiar testfile_cp a la misma carpeta. Los archivos se mueven con mv y se copian con cp y ambos tienen un formato similar que es mv ARCHIVO_ORIGEN FOLDER_DESTINO Donde en este caso ARCHIVO_ORIGEN es el archivo a mover y FOLDER_DESTINO el path a donde moverlo. Prueben entonces mover testfile_mv y copiar testfile_cp adentro de la carpeta testfolder2 . Tip Usando la opci\u00f3n -i al comando, les va a pedir confirmaci\u00f3n si el archivo de destino ya existe. Recuerden que pueden usar man mv o man cp para ver mas opciones. Estos dos comandos tambi\u00e9n pueden ser usados como: mv ARCHIVO_ORIGEN ARCHIVO_DESTINO En este caso ARCHIVO_DESTINO no es una carpeta, sino un archivo adentro del FOLDER_DESTINO , lo que permite renombrar el ARCHIVO_ORIGEN al copiarlo / moverlo. Para que se entienda mejor este uso, ubiquens\u00e9 en Documentos y corran: cp testfile_cp testfolder2/testfile_cp_nuevo Con lo cual acabo de copiar testfile_cp de nuevo a la carpeta testfolder2 , pero ahora con otro nombre. Interesantemente, usar mv de esta manera es la forma de Ubuntu de renombrar archivos desde la terminal. Prueben entrar a testfolder2 y corran: mv testfile_cp_nuevo testfile_cp_otroNombre Y vean que pas\u00f3. Una vez que todo haya funcionado bien, usen rm para eliminar todos los testfile uno a uno y luego usen rmdir para eliminar testfolder2 . Ambos comandos funcionan tambi\u00e9n para copiar, mover y renombrar carpetas, en cuyo caso el formato es: mv FOLDER_ORIGEN FOLDER_DESTINO Danger Hay que ser cuidadosos al usar mv y cp ya que si el archivo de destino ya existe lo van a sobreescribir sin preguntar antes. A ambos comandos se le puede agregar la opci\u00f3n -i para que pregunte antes de sobreescribir de ya existir el archivo de destino.","title":"Mover y copiar"},{"location":"practicos/TP01_Linux/#bash-archivos-de-texto","text":"","title":"Bash: Archivos de texto"},{"location":"practicos/TP01_Linux/#escribir-archivos-de-texto","text":"En Lubuntu hay varias formas de escribir en archivos de texto, pero una de las m\u00e1s \u00fatiles para nosotros va a ser el > quien redirige la salida de informaci\u00f3n de la consola. Se usa: comando -opciones parametro1 parametro2 > ARCHIVO_DESTINO Donde lo de la izquierda de > es el comando como lo correr\u00edas normalmente y ARCHIVO_DESTINO es un archivo donde va a ser guardada la salida de ese comando (lo que normalmente ver\u00edan en la consola). Para entender un poco m\u00e1s, vayan a su home y corran: ls -l > Documentos/output_de_ls Ver\u00e1n que en un principio parece que no paso nada. Entren ahora a Documentos y van a ver que hay un nuevo archivo con el nombre output_de_ls . Vamos a abir el archivo usando Leafpad , el editor de texto de la interfaz \u01f5r\u00e1fica de Lubuntu. Asegurandose que estan Documentos , en la consola escriban: leafpad output_de_ls Van a ver que se abre el editor de texto de igual forma que si ubieran hecho doble click en el \u00edcono en el explorador de archivos de la GUI. Puede ser que aparezca un warning o advertencia en la consola, pero la podemos ignorar. Tip Por defecto Leafpad usa una fuente llamada \"Ubuntu\" , que si bien sirve para escribir cuentos, nos va a dar problemas al momento de ver ciertos archivos que vamos a usar en esta materia. En Leafpad vayan a Opciones Tipograf\u00eda... , seleccionen la fuente \"Ubuntu Mono\" y aprieten Aceptar . Las fuentes que tienen Mono en su nombre estan indicando que son monoespaciadas, o sea, que todos sus caracteres tienen el mismo ancho. Esto es ideal para cuando se quieren ver tablas o alineamientos con Leafpad , cosa que vamos a hacer bastante en esta materia. Leafpad funciona como un editor de texto bastante normal. Agreguen una nueva linea abajo de todo (con cualquier texto) y guarden el archivo. Al momento sabemos como guardar en un archivo de texto cualquier salida de un comando de Lubuntu, pero, \u00bfc\u00f3mo hacemos para poner lo que nosotros queremos en un archivo de texto? Simple, \u00a1con otro comando de Lubuntu! El comando echo hace lo que su nombre indica y devuelve por la terminal el texto que le pases. Prueben escribir echo TEXTO , donde TEXTO es cualquier oraci\u00f3n, por ejemplo: echo Probando, uno, dos, tres Tal vez ya se dieron cuenta, pero combinando echo con > podemos escribir nuestros propios archivos de texto desde la terminal. Asegurandose que estan adentro de Documentos , corran: echo Esta es la primera linea del documento > mi_documento Confirmen que se escribi\u00f3 el archivo y que tiene el texto adentro. \u00bfQu\u00e9 piensan que pasa si ahora corr\u00f3 el siguiente comando? Pruebenl\u00f3: echo Quiero agregar otra linea al documento > mi_documento Usen Leafpad para leer el documento. Van a ver que la primera linea que agregamos desapareci\u00f3. Esto es porque cada uso de > sobreescribe el archivo. Si queremos agregar otra linea a un documento que ya tiene informaci\u00f3n tenemos que usar el comando >> quien agrega el texto al archivo en una nueva linea al final sin modificar el contenido anterior. As\u00ed que ahora que sabemos esto podemos correr estos dos comandos: echo Esta es la primera linea del documento > mi_documento echo Esta es la segunda linea del documento >> mi_documento Y vean con Leafpad si funcion\u00f3 como quer\u00edamos. Danger Hay que ser cuidadosos al usar > ya que si el archivo de destino ya existe lo va a sobreescribir sin preguntar antes.","title":"Escribir archivos de texto"},{"location":"practicos/TP01_Linux/#leer-archivos-de-texto","text":"Qu\u00e9 comando usar al leer archivos de texto en la consola depende mucho de que tan largo es el archivo y que me interesa de \u00e9l: \u00bfTiene solo pocas lineas de texto? cat va a abrir el archivo y escribirlo todo en la terminal. \u00bfTiene muchas lineas de texto y quiero ver las primeras p\u00e1ginas a ver de que se trata? less va a abrir el archivo y mostrar solo el texto que entra en la terminal. Aprentando Space pasa a la pr\u00f3xima p\u00e1gina y apretando Q deja de leerlo. \u00bfTiene muchas lineas de texto y quiero ver solo las primeras lineas? head te muestra las primeras 10 lineas del archivo. Se puede especificar la cantidad de lineas agregando una opci\u00f3n, por ejemplo, head -3 muestra solo las primeras 3 l\u00edneas. \u00bfTiene muchas lineas de texto y quiero ver solo las \u00faltimas lineas? tail te muestra las \u00faltimas 10 l\u00edneas del archivo. Este n\u00famero se puede cambiar de la misma forma que para head . \u00bfNo saben que tan largo es un archivo dado? Pueden averiguarlo con el comando wc , que devuelve el numero de lineas, palabras y letras (en ese orden) en el archivo. De pasarle la opci\u00f3n -l , el comando devuelve solo el n\u00famero de lineas. Todos estos funcionan de la forma: comando ARCHIVO Usando el archivo martin_fierro que se encuentra en los materiales del TP (boton al principio de todo), prueben los 5 comandos anteriores.","title":"Leer archivos de texto"},{"location":"practicos/TP01_Linux/#buscar-palabras-en-archivos-de-texto","text":"Va a ser com\u00fan cuando trabajemos con tablas que nos interese encontrar filas con cierto valor y una forma r\u00e1pida de hacer eso es usar grep , comando al que le pasas una palabra o patr\u00f3n y busca filas dentro de un archivo que contengan dicha palabra o patr\u00f3n. En formato general el comando es: grep PALABRA ARCHIVO Usando el archivo martin_fierro con en que trabajamos en la secci\u00f3n anterior podemos correr: grep cantar martin_fierro Y vamos a ver todas las lineas del documento donde aparece la palabra \"cantar\". Hay mucho para hablar sobre grep , pero por ahora lo que nos va a importar es: La opci\u00f3n -v devuelve las l\u00edneas que no contienen PALABRA La opci\u00f3n -c devuelve el n\u00famero de l\u00edneas que contienen PALABRA Es posible pasarle varias opciones a un programa. De hacer grep -v -c voy a estar contando el n\u00famero de l\u00edneas que no contengan PALABRA (el orden de las opciones no afecta el comportamiento) Info Mencion\u00e9 antes que grep tambi\u00e9n funciona con patrones, quienes son conocidos como Expresiones Regulares, o RegEx . Como este es un tema complejo y ya tenemos bastante que procesar no vamos a profundizar mas sobre ellos en este momento, pero explicaremos cualquier patr\u00f3n que usemos en la materia cuando aparezca.","title":"Buscar palabras"},{"location":"practicos/TP01_Linux/#combinar-comandos","text":"En Bash es posible combinar comandos, lo que quiere decir pasarle la salida de un comando directamente como entrada a otro comando. Esto se hace dividiendo los diferentes comandos con | (o pipe ). Para entender un poco mejor veamos un ejemplo. Digamos que quiero ver las cuales de las primeras 10 lineas del archivo martin_fierro contienen la palabra \"cantar\". Para esto tengo que hacer: head -10 martin_fierro | grep cantar Fijens\u00e9 que en este caso parecer\u00eda que a grep no le estoy pasando ningun ARCHIVO , pero lo que pasa es que va usar como entrada la salida de head . De esta forma se puede concatenar cualquier cantidad de comandos que seran ejecutados de izquierda a derecha.","title":"Combinar comandos"},{"location":"practicos/TP01_Linux/#ejercicio-2-archivos-de-texto","text":"Para este ejercicio vamos a seguir usando el archivo martin_fierro . \u00bfCu\u00e1ntas l\u00edneas tiene el archivo? \u00bfCu\u00e1ntas l\u00edneas contienen la palabra \"cantar\"? \u00bfCu\u00e1ntas l\u00edneas no contienen la palabra \"guitarra\"? Cree otro archivo de texto llamado martin_fierro_sinA con las l\u00edneas del archivo martin_fierro que no tengan la letra \"a\". Sin borrar el contenido y usando la consola, agregue una l\u00ednea al final de martin_fierro_sinA que indique el autor del Martin Fierro (Jos\u00e9 Hern\u00e1ndez). Volviendo al archivo original, \u00bfcu\u00e1ntas l\u00edneas no contienen la letra \"o\" y s\u00ed contienen la letra \"i\"? (Tip: use | para encadenar comandos)","title":"Ejercicio 2"},{"location":"practicos/TP01_Linux/#bash-programacion-y-scripts","text":"Info A continuaci\u00f3n vamos a ver una peque\u00f1a introducci\u00f3n a la programaci\u00f3n usando Bash como lenguaje. El objetivo de lo que sigue no es aprenderse de memoria las estructuras y si hay que poner una llave aca o dejar un espacio all\u00e1, sino entender la l\u00f3gica detr\u00e1s de la programaci\u00f3n y como se pueden usar variables, condicionales y ciclos para obtener el resultado deseado.","title":"Bash: Programaci\u00f3n y Scripts"},{"location":"practicos/TP01_Linux/#scripts","text":"Los scripts de Bash son b\u00e1sicamente una lista de muchos de los comandos que nosotros corrimos en la terminal, pero escritos dentro de un archivo. Al ejecutar ese archivo todos los comandos dentro de \u00e9l ser\u00e1n corridos uno a uno de arriba a abajo. Para simplificar un poco la tarea y enfocarnos en lo que importa en esta secci\u00f3n, vamos a utilizar la interfaz gr\u00e1fica de Lubuntu. Vayan a Documentos y creen un archivo llamado primer_programa.sh (Boton derecho Crear nuevo... Archivo vac\u00edo). Luego abran el archivo en Leafpad (doble click) y escriban lo siguiente: echo \"----------------\" echo \"| Hello world! |\" echo \"----------------\" Ahora salven el archivo, abran la terminal en esa carpeta ( F4 ) y vamos a ejecutar el script con: bash primer_programa.sh \u00a1Felicidades, ya pueden decir que son programadores! Como pudieron observar, los scripts de Bash se corren con el comando bash SCRIPT y al hacerlo se ejecutaron los 3 comandos echo en el orden que estaban dentro del script. Este tipo de scripts son \u00fatiles si quiero dejar evidencia de los comandos que corr\u00ed en Bash, ya sea para volver a hacerlo otro d\u00eda o para pasarselos a algui\u00e9n m\u00e1s y que los corra en su propia computadora; sin embargo, para realmente programar necesitamos m\u00e1s herramientas.","title":"Scripts"},{"location":"practicos/TP01_Linux/#variables","text":"Las variables son palabras que guardan dentro de ellas un n\u00famero o un string (texto), entre otro tipo de valores posibles que veremos m\u00e1s adelante. Veamos un ejemplo de como usar variables (vean ambas pesta\u00f1as): C\u00f3digo C\u00f3digo con comentarios nombre = \"Unsamer\" echo \"Hola $nombre , \u00bftodo bien?\" # Las lineas que empiezan con # son comentarios, no afectan el c\u00f3digo y sirven para aclarar que estas # haciendo en tu programa o script # Al declarar una variable en Bash no se puede poner espacio entre la variable, el = y el valor # Las comillas se usan para indicar que lo de adentro es una cadena de caracteres, o *string* nombre = \"Unsamer\" # Cuando se usa la variable, se le agrega el prefijo $ echo \"Hola $nombre , \u00bftodo bien?\" \u00bfQu\u00e9 piensan que va a pasar de correr este c\u00f3digo en un script? Pruebenl\u00f3. Info Desgraciadamente Bash es muy estricto al momento de programar y perdona bastante poco (como por ejemplo el tema de tener un espacio m\u00e1s o menos). M\u00e1s adelante vamos a usar el lenguaje R que va a ser una de nuestras principales herramientas al momento de analizar y plotear datos y es mucho m\u00e1s amigable. En este momento pueden estar pensando que hubiera sido mucho m\u00e1s f\u00e1cil poner solo echo \"Hola Unsamer, \u00bftodo bien?\" y ahorrarme el tema de la variable. Tienen raz\u00f3n. Por ahora. \u00bfSe acuerdan de los parametros de los comandos de Bash? Al pasarle par\u00e1metros a un script de Bash estos se asignan automaticamente a variables llamadas $1 , $2 , etc. Editemos ahora nuestro c\u00f3digo anterior: C\u00f3digo C\u00f3digo con comentarios nombre = $1 echo \"Hola $nombre , \u00bftodo bien?\" # $1 es el primer parametro que se le pasa al script de Bash # Le estoy asignando el valor de una variable a otra variable. $1 sigue existiendo, pero no la uso m\u00e1s nombre = $1 # Podr\u00eda usar $1 directamente aca, pero as\u00ed se entiende mucho m\u00e1s lo que hace el c\u00f3digo al leerlo # (y para programas muy complicados esto es muy importante) echo \"Hola $nombre , \u00bftodo bien?\" Y ahora corran: bash SCRIPT \"NOMBRE\" Por si la versi\u00f3n gen\u00e9rica no queda claro, si el script se llamara saludo.sh y quiero conseguir el mismo resultado que antes habr\u00eda que correr: bash saludo.sh \"Unsamer\" Info Tecnicamente si estoy pasando solo una palabra las comillas no son necesarias, pero si el string que estoy pasando tiene un espacio tengo que ponerlas si o si. Hay bastante m\u00e1s para hablar de las variables . Existen muchos tipos m\u00e1s de variables, como booleanos (variable que es verdadera o falsa), arreglos (o vectores) y listas. Otros lenguajes de programaci\u00f3n hasta tienen variables m\u00e1s complejas que pueden almacenar tablas enteras. Sin embargo, lo que acabamos de aprender es la base y va a ser suficiente por ahora. M\u00e1s informaci\u00f3n sobre las variables en Bash se puede ver en esta p\u00e1gina .","title":"Variables"},{"location":"practicos/TP01_Linux/#condicionales","text":"Las variables son importantes, pero gran parte de la programaci\u00f3n es controlar el \"flujo\" del programa, es decir, que un script haga algo m\u00e1s que simplemente ir de arriba a abajo ejecutando comandos. La primera herramienta que vamos a aprender para controlar el flujo del programa son los condicionales que permiten crear secciones de c\u00f3digo que se van a ejecutar solo si se cumple (o no se cumple) una condici\u00f3n. Por ejemplo: C\u00f3digo C\u00f3digo con comentarios numero = $1 echo \" $numero es un numero\" if (( $numero > 10 )) then echo \" $numero es mayor a 10\" fi # Igual que antes estoy agarrando un par\u00e1metro al correr el script numero = $1 echo \" $numero es un numero\" # *if* es la estructura m\u00e1s usada para condicionales. # Adentro de los dobles par\u00e9ntesis va la condici\u00f3n. # > es el comparador, o sea, estamos preguntando si $numero es mayor que 10 if (( $numero > 10 )) then # El codigo entre *then* y *fi* solo si ejecuta si la condici\u00f3n es verdad, de otra forma se saltea # Este codigo esta m\u00e1s a la derecha, o *indentado*. Esto se hace con tab y en la mayor\u00eda de los lenguajes # es solo para entender m\u00e1s f\u00e1cil el c\u00f3digo echo \" $numero es mayor a 10\" fi # *fi* indica donde termina el condicional Copien este c\u00f3digo a un script y prueben pasarle n\u00fameros menores y mayores a 10 a ver que pasa. Info Es importante remarcar que la condici\u00f3n del if (lo que en este caso se encuentra entre los corchetes) es b\u00e1sicamente una pregunta que puede tener solo una de dos respuestas posibles: S\u00ed (llamada en programaci\u00f3n Verdadero o True ) \u00f3 No (llamada en programaci\u00f3n Falso o False ) Como dije antes a un condicional se le puede poner tambi\u00e9n que pase algo cuando no es verdad, por ejemplo: C\u00f3digo C\u00f3digo con comentarios numero = $1 echo \" $numero es un numero\" if (( $numero > 10 )) then echo \" $numero es mayor a 10\" else echo \" $numero es menor o igual a 10\" fi numero = $1 echo \" $numero es un numero\" if (( $numero > 10 )) then # Ahora si la condici\u00f3n es verdad se va a ejecutar el c\u00f3digo entre *then* y *else* y luego va a # seguir a partir de *fi* echo \" $numero es mayor a 10\" else # El c\u00f3digo entre *else* y *fi* se ejecuta solo cuando la condici\u00f3n no es verdad echo \" $numero es menor o igual a 10\" fi Hay bastante m\u00e1s para hablar de los ifs . Hay muchos m\u00e1s comparadores y son diferentes si estoy comparando n\u00fameros o strings . Hay formas de poner m\u00e1s de una condici\u00f3n por if y hay otras estructuras como son los case que cumplen una funci\u00f3n similar. Sin embargo, lo que acabamos de aprender es la base y va a ser suficiente por ahora. M\u00e1s informaci\u00f3n sobre los condicionales en Bash, incluyendo una lista m\u00e1s detallada de los comparadores, se puede ver en esta p\u00e1gina y en esta p\u00e1gina (en Bash las condiciones pueden estar rodeadas por par\u00e9ntesis o corchetes y en cada caso los comparadores se comportan diferente, ojo con esto).","title":"Condicionales"},{"location":"practicos/TP01_Linux/#ciclos","text":"Digamos que por alguna extra\u00f1a raz\u00f3n quieren imprimir los numeros del 1 al 10 en la consola, tendr\u00edan que hacer echo 1 , echo 2 , etc, hasta llegar a echo 10 . \u00bfQu\u00e9 pasa si ahora les pido del 1 al 100, o al 1000?. Por suerte existen los ciclos , que son estructuras que nos permiten repetir algo varias veces y al usar variables podemos hacer que cada vez sea ligeramente diferente a la anterior. C\u00f3digo C\u00f3digo con comentarios for (( i = 1 ; i< = 1000 ; i++ )) do echo $i done # *for* es una de las estructuras m\u00e1s usadas para hacer ciclos # *i* es el nombre de la variable que va a cambiar de valor en cada ciclo. Se le podria poner cualquier nombre a # \u00e9sta variable, por ejemplo *numero* en nuestro caso, pero es costumbre ponele *i* # i=1 indica que el primer valor de $i es 1 # i<=1000 indica que el ciclo se va a repetir mientras $i sea menor o igual a 1000 # i++ indica que al final de cada ciclo el valor de $i va a subir en 1 for (( i = 1 ; i< = 1000 ; i++ )) do # El c\u00f3digo entre *do* y *done* se va a ejecutar una vez para cada posible $i en el rango echo $i done Hay otra versi\u00f3n del for que comunmente se denomina for each . En este caso $i no representa n\u00fameros que aumentan, sino diferentes elementos en una lista. Por ejemplo: C\u00f3digo C\u00f3digo con comentarios for color in rojo amarillo verde do echo \"Este es el color $color \" done # Como ahora la variable son elementos de una lista le pongo el nombre *color* para que se sepa que es, # pero podr\u00eda ser *i* # Esta es una forma bastante mala de usar listas de elementos, donde la estoy declarando en el mismo *for*; # comunmente las listas existen de antes en el programa o las obtengo de un archivo o comando de Lubuntu for color in rojo amarillo verde do echo \"Este es el color $color \" done Hay bastante m\u00e1s para hablar de los ciclos . Se pueden hacer ciclos que aumenten de 2 en 2 o hacer ciclos que disminuyan. Hay otros dos tipos de ciclos comunmente den\u00f3minados while y until (tambien llamado do ) y hay formas de forzar salir del ciclo o pasar a la pr\u00f3xima iteraci\u00f3n con break y continue (tambien llamado next ). Sin embargo, lo que acabamos de aprender es la base y va a ser suficiente por ahora. M\u00e1s informaci\u00f3n sobre los ciclos en Bash se puede ver en esta p\u00e1gina .","title":"Ciclos"},{"location":"practicos/TP01_Linux/#ejercicio-3-programacion-en-bash","text":"El objetivo de este ejercicio es hacer un script que: Use por lo menos un for y un if Recorra los n\u00fameros del 1 al 10 Por cada uno de esos n\u00fameros cree un archivo llamado archivo_NUMERO , d\u00f3nde hay que reemplazar NUMERO por el n\u00famero correspondiente (de 1 a 10) En los primeros 5 archivos ( archivo_1 a archivo_5 ) escriba el texto: Primera parte. Este es el archivo NUMERO. Donde hay que reemplazar NUMERO por el n\u00famero correspondiente (de 1 a 5) En los \u00faltimos 5 archivos ( archivo_6 a archivo_10 ) escriba el texto: Segunda parte. Este es el archivo NUMERO. Donde hay que reemplazar NUMERO por el n\u00famero correspondiente (de 6 a 10). Noten que ambas oraciones est\u00e1n en lineas diferentes Ahora que sabemos nuestro objetivo vayan a Documentos y creen una nueva carpeta donde vamos a trabajar llamada TP01_EJ3 . Dentro de ella creen un archivo vacio llamado crear_archivos.sh que va a ser nuestro script. Al momento de hacer programas complejos, especialmente en un lenguaje que reci\u00e9n aprenden, es recomendado ir por partes e ir probando en el medio. Unos posibles pasos a seguir son: Info La idea de hacerlo as\u00ed es ir probando de a poco si aparece algun error. \u00a1Prueben el script entre cada paso! Modifiquen el script para que cree un archivo llamado archivo_1 que adentro tenga el texto: Primera parte. Este es el archivo 1. Agreguen un for que vaya de 1 a 5 y cree los archivos archivo_1 a archivo_5 que adentro tengan el texto: Primera parte. Este es el archivo NUMERO. Donde hay que reemplazar NUMERO por el n\u00famero correspondiente (de 1 a 5). Expandan el for para que vaya de 1 a 10. Agreguen un if adentro del for que haga que los archivos se creen solo para los primeros 5 ciclos. Tip Aca les puede venir bien el comparador <= , que significa \"menor o igual\". Un ejemplo de <= seria: if (( $1 < = 7 )) Que en este caso es verdadero cuando el par\u00e1metro $1 es menor o igual a 7. Agreguen un else al if , recordando que los comandos adentro del else se van a ejecutar cuando la condici\u00f3n no sea verdadera. Asumiendo que usaron <= en la condici\u00f3n del if , modifiquen los comandos adentro del else para que en ese caso se creen los archivos archivo_6 a archivo_10 que adentro tengan el texto: Segunda parte. Este es el archivo NUMERO. Donde hay que reemplazar NUMERO por el n\u00famero correspondiente (de 6 a 10). \u00a1Y listo, deber\u00edan tener su programa andando!","title":"Ejercicio 3"},{"location":"practicos/TP01_Linux/#bash-tablas","text":"Lo ultimo que vamos a aprender hoy es un peque\u00f1o vistazo a como se pueden manipular tablas desde la consola de Lubuntu. Descarguen el archivo mtcars que se encuentra en los materiales del TP (boton al principio de todo) y ponganlo en Documentos . Esta tabla viene por defecto con el lenguaje de programaci\u00f3n R y nos va a servir para aprender como manipular tablas en Bash. Abran el archivo con Leafpad (doble click). Podemos ver que es una tabla en formato texto, donde la primera l\u00ednea es el encabezado o header de la tabla y en cada l\u00ed\u0144ea las columnas est\u00e1n separadas entre ellas con un Tab (a estos archivos se los conoce como TSV o \"Tab-Separated Values\"). Es bioinform\u00e1tica es muy com\u00fan querer seleccionar columnas espec\u00edficas en una tabla, o filtrar filas debido al valor de una de sus columnas; esto es lo que vamos a aprender a continuaci\u00f3n. Columnas de mtcars mtcars es una tabla que viene por defecto con el lenguaje de programaci\u00f3n R , sus columnas son: Nombre Descripci\u00f3n car_name Name of the car mpg Miles/(US) gallon cyl Number of cylinders disp Displacement (cu.in.) hp Gross horsepower drat Rear axle ratio wt Weight (1000 lbs) qsec 1/4 mile time vs Engine (0 = V-shaped, 1 = straight) am Transmission (0 = automatic, 1 = manual) gear Number of forward gears carb Number of carburetors","title":"Bash: Tablas"},{"location":"practicos/TP01_Linux/#awk","text":"El comando awk (que recibe su nombre de las iniciales de los apellidos de las 3 personas que lo crearon) es uno de los comandos mas usados en Bash para manipular tablas por su gran flexibilidad, hasta el punto que es posible incorporar condicionales y ciclos dentro de \u00e9l. La forma m\u00e1s simple del comando es: awk -opciones 'instrucciones' ARCHIVO_TABLA Donde ARCHIVO_TABLA es el archivo que contiene a la tabla e instrucciones es que hacer con ese archivo una vez que se abra (las instrucciones siempre tienen que estar delimitadas por comillas simples, o ' ). Colocando a nuestra terminal en Documentos podemos correr: awk -F \"\\t\" '{print}' mtcars Donde -F es la opci\u00f3n que le dice a awk cual es el caracter que separa las diferentes columnas (en este caso es \\t , que es el s\u00edmbolo de Tab ) y {print} es la instrucci\u00f3n que simplemente dice que imprima en pantalla la tabla. Lo importante de awk es que nos permite trabajar con columnas individuales. Por ejemplo si ponemos: awk -F \"\\t\" '{print $1}' mtcars Vemos que awk imprime solo la primera columna, que en este caso es el nombre de los autos. Podemos asumir entonces que cada columna se puede referir con $1 , $2 , etc. Probemos imprimir muchas columnas corriendo: awk -F \"\\t\" '{print $1 $3 $5}' mtcars \u00bfQu\u00e9 ven que pasa aca? Debido a como funciona print , las diferentes columnas se imprimeron una pegada a la otra sin dejar espacios. Si quisieramos imprimir las columnas separadas con Tab como la tabla original tenemos que hacer: awk -F \"\\t\" '{print $1 \"\\t\" $3 \"\\t\" $5}' mtcars Ahora bien, una actividad normal cuando se tienen tablas con muchos datos es filtrar mis datos por alguna columna, o dicho de otra forma, usar condicionales. Un ejemplo de esto en awk seria: awk -F \"\\t\" '{if ($3 == 6) {print}}' mtcars \u00bfQu\u00e9 les parece que hace ese comando? Piensen que estan viendo una estructura de if que no vieron antes, pero aun as\u00ed probablemente puedan inferir que va a hacer el comando pensando en como funcionaba el if de Bash que aprendimos arriba. Esto es super normal en la programaci\u00f3n, donde la estructura exacta cambia, pero la l\u00f3gica detr\u00e1s se mantiene constante. Entonces, aca le estan diciendo a awk que imprima en la pantalla todas las filas que tengan un valor de 6 en la columna 3 (que si se fijan es cyl , o el n\u00famero de cilindros). Como siempre hay mucho m\u00e1s para decir sobre awk , pero por hoy estamos bien. Sepan sin embargo que awk tiene su propio grep y su propio for , que se pueden declarar variables dentro de \u00e9l y que tiene hasta una lista de comandos propios. Pueden ver mucha m\u00e1s informaci\u00f3n de awk en esta p\u00e1gina .","title":"AWK"},{"location":"practicos/TP01_Linux/#ejercicio-adicional-1-programacion-en-bash-v2","text":"Info Algunas guias van a tener ejercicios adicionales, que son ejercicios que pueden hacer si quieren practicar m\u00e1s el tema, pero no son obligatorios. Estos ejercicios pueden llegar a ser un poco m\u00e1s complicados que los ejercicios de la gu\u00eda. El objetivo de este Ejercicio va a ser hacer un script que: Reciba un n\u00famero por consola (vamos a asumir que dicho n\u00famero va a ser siempre un n\u00famero entero entre 1 y 1000) Recorra todos los n\u00fameros entre 1 y el n\u00famero que recibi\u00f3 por consola Para cada uno de esos n\u00fameros vea si es par Imprima los n\u00fameros pares por consola Dos cosas que van a necesitar para hacer esto son: # El operador % calcula el resto entre 2 n\u00fameros # En este caso $resto va a contener el resto de dividir 5 por 2 (que es 1) # Una forma muy usada en programac\u00edon para ver si un n\u00famero es par es ver si su resto al dividirlo por 2 es 0 # Los par\u00e9ntesis y signo $ bordeando a la operaci\u00f3n son necesarios para que funcione bien en Bash resto = $(( 5 % 2 )) # == es el comparador para igualdad usado en los *ifs* # Va a ser verdadero solo si lo de la izquierda es identico a lo de la derecha. if (( $1 == 2 )) Para hacer este ejercicio pueden usar como base el c\u00f3digo creado en el Ejercicio 3 que ambos tienen una estructura general bastante similar.","title":"Ejercicio Adicional 1"},{"location":"practicos/TP01_Linux/#bibliografia","text":"","title":"Bibliograf\u00eda"},{"location":"practicos/TP01_Linux/#consola","text":"Comando man","title":" Consola"},{"location":"practicos/TP01_Linux/88_BU/","text":"TP1. Titulo del Trabajo Pr\u00e1ctico Materiales Software a usar Programa 1 www.donde.lo.bajo.com Programa 2 www.donde.lo.bajo2.com Recursos Online Recurso 1 www.webAusar.com Recurso 2 www.webAusar.com Objetivos Introduccion al Tema Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non onsequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Existen distintos de Admonitions Atenci\u00f3n esto es un admonition!! Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Admonition desplegable (Esto est\u00e1 bueno para ver las soluciones a las cosas o tipo los ayuda memoria, c\u00f3digo de amino\u00e1cidos de una letra, etc) Atenci\u00f3n !! Sin desplegar Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Definici\u00f3n de Inline Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Esto en teor\u00eda ser\u00eda para que me entre ac\u00e1 y me quede a la izquierda LO QUE EST\u00c1 PUESTO ARRIBA ladito Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Todos los tipos disponibles ac\u00e1 Todo lo que sea c\u00f3digo y se muestre la soluci\u00f3n se recomienda usar las tabs C\u00f3digo Ouput Esto es una prueba Y esta es la otra prueba Ejercicio 1. Titulo del Ejercicio a realizar probado el titulo en codigo 1 2 3 4 5 6 import tensorflow as tf def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Ejercicio 2. Titulo del Ejercicio a realizar The range() function is used to generate a sequence of numbers. >seq1 ARTPLKMNSDADASDASDASJFGDAKJFGKJDAHGFKJDHALFKDHFLKJHAKF DLKFJHALKDFHKLJHDLFKJHDAKFHLKADJHFLKJHALDKFHLAKDHFLKHA DSDADSSA Ctrl + Alt + Del Ctrl + V Bibliograf\u00eda Libros Libro 1 Libro 2 Online Material 1 Material 2","title":"Index"},{"location":"practicos/TP01_Linux/88_BU/#tp1-titulo-del-trabajo-practico","text":"Materiales","title":"Label que aparece en Table Of Contents"},{"location":"practicos/TP01_Linux/88_BU/#software-a-usar","text":"Programa 1 www.donde.lo.bajo.com Programa 2 www.donde.lo.bajo2.com","title":"Software a usar"},{"location":"practicos/TP01_Linux/88_BU/#recursos-online","text":"Recurso 1 www.webAusar.com Recurso 2 www.webAusar.com","title":"Recursos Online"},{"location":"practicos/TP01_Linux/88_BU/#objetivos","text":"","title":"Objetivos"},{"location":"practicos/TP01_Linux/88_BU/#introduccion-al-tema","text":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non onsequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Existen distintos de Admonitions Atenci\u00f3n esto es un admonition!! Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Admonition desplegable (Esto est\u00e1 bueno para ver las soluciones a las cosas o tipo los ayuda memoria, c\u00f3digo de amino\u00e1cidos de una letra, etc) Atenci\u00f3n !! Sin desplegar Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Definici\u00f3n de Inline Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Esto en teor\u00eda ser\u00eda para que me entre ac\u00e1 y me quede a la izquierda LO QUE EST\u00c1 PUESTO ARRIBA ladito Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Todos los tipos disponibles ac\u00e1 Todo lo que sea c\u00f3digo y se muestre la soluci\u00f3n se recomienda usar las tabs C\u00f3digo Ouput Esto es una prueba Y esta es la otra prueba","title":"Introduccion al Tema"},{"location":"practicos/TP01_Linux/88_BU/#ejercicio-1-titulo-del-ejercicio-a-realizar","text":"probado el titulo en codigo 1 2 3 4 5 6 import tensorflow as tf def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ]","title":"Ejercicio 1"},{"location":"practicos/TP01_Linux/88_BU/#ejercicio-2-titulo-del-ejercicio-a-realizar","text":"The range() function is used to generate a sequence of numbers. >seq1 ARTPLKMNSDADASDASDASJFGDAKJFGKJDAHGFKJDHALFKDHFLKJHAKF DLKFJHALKDFHKLJHDLFKJHDAKFHLKADJHFLKJHALDKFHLAKDHFLKHA DSDADSSA Ctrl + Alt + Del Ctrl + V","title":"Ejercicio 2"},{"location":"practicos/TP01_Linux/88_BU/#bibliografia","text":"","title":"Bibliograf\u00eda"},{"location":"practicos/TP01_Linux/88_BU/#libros","text":"Libro 1 Libro 2","title":" Libros"},{"location":"practicos/TP01_Linux/88_BU/#online","text":"Material 1 Material 2","title":" Online"},{"location":"practicos/TP02_EMBOSS/","text":"TP 2 . EMBOSS Materiales Slides mostrados en la clase Cierre TP Videos de la clase grabada Introducci\u00f3n al TP Cierre TP Software a usar EMBOSS (ya instalado en la VM). Objetivos Familiarizarse con el uso de herramientas bioinform\u00e1ticas por l\u00ednea de comandos. Familiarizarse con los formatos caracter\u00edsticos de datos biol\u00f3gicos. Practicar conceptos aprendidos en el TP 1. Introduccion al Tema EMBOSS es una suite bioinform\u00e1tica creada y mantenida por EMBnet que incluye una multitud de herramientas elementales en biolog\u00eda molecular y gen\u00e9tica. Algunas ventajas de EMBOSS son: Maneja informaci\u00f3n biol\u00f3gica en varios formatos para realizar distintos tipos de tareas. Es muy r\u00e1pida, lo cual significa que es computacionalmente escalable. Si bien cada uno de sus programas individuales podr\u00edan ser reemplazados por otros softwares o un script propio, EMBOSS agrupa todos estos programas en un solo paquete y le provee al usuario una interfaz unificada para todas las aplicaciones. A continuaci\u00f3n se encuentra una lista de 256 programas que contiene EMBOSS y un resumen corto de lo que hace cada uno: Programas de EMBOSS Program name Description aaindexextract Extract amino acid property data from AAINDEX abiview Display the trace in an ABI sequencer file acdc Test an application ACD file acdpretty Correctly reformat an application ACD file acdtable Generate an HTML table of parameters from an application ACD file acdtrace Trace processing of an application ACD file (for testing) acdvalid Validate an application ACD file aligncopy Read and write alignments aligncopypair Read and write pairs from alignments antigenic Find antigenic sites in proteins assemblyget Get assembly of sequence reads backtranambig Back-translate a protein sequence to ambiguous nucleotide sequence backtranseq Back-translate a protein sequence to a nucleotide sequence banana Plot bending and curvature data for B-DNA biosed Replace or delete sequence sections btwisted Calculate the twisting in a B-DNA sequence cachedas Generate server cache file for DAS servers or for the DAS registry cachedbfetch Generate server cache file for Dbfetch/WSDbfetch data sources cacheebeyesearch Generate server cache file for EB-eye search domains cacheensembl Generate server cache file for an Ensembl server cai Calculate codon adaptation index chaos Draw a chaos game representation plot for a nucleotide sequence charge Draw a protein charge plot checktrans Report STOP codons and ORF statistics of a protein chips Calculate Nc codon usage statistic cirdna Draw circular map of DNA constructs codcmp Codon usage table comparison codcopy Copy and reformat a codon usage table coderet Extract CDS, mRNA and translations from feature tables compseq Calculate the composition of unique words in sequences cons Create a consensus sequence from a multiple alignment consambig Create an ambiguous consensus sequence from a multiple alignment cpgplot Identify and plot CpG islands in nucleotide sequence(s) cpgreport Identify and report CpG-rich regions in nucleotide sequence(s) cusp Create a codon usage table from nucleotide sequence(s) cutgextract Extract codon usage tables from CUTG database cutseq Remove a section from a sequence dan Calculate nucleic acid melting temperature dbiblast Index a BLAST database dbifasta Index a fasta file database dbiflat Index a flat file database dbigcg Index a GCG formatted database dbtell Display information about a public database dbxcompress Compress an uncompressed dbx index dbxedam Index the EDAM ontology using b+tree indices dbxfasta Index a fasta file database using b+tree indices dbxflat Index a flat file database using b+tree indices dbxgcg Index a GCG formatted database using b+tree indices dbxobo Index an obo ontology using b+tree indices dbxreport Validate index and report internals for dbx databases dbxresource Index a data resource catalogue using b+tree indices dbxstat Dump statistics for dbx databases dbxtax Index NCBI taxonomy using b+tree indices dbxuncompress Uncompress a compressed dbx index degapseq Remove non-alphabetic (e.g. gap) characters from sequences density Draw a nucleic acid density plot descseq Alter the name or description of a sequence diffseq Compare and report features of two similar sequences distmat Create a distance matrix from a multiple sequence alignment dotmatcher Draw a threshold dotplot of two sequences dotpath Draw a non-overlapping wordmatch dotplot of two sequences dottup Display a wordmatch dotplot of two sequences dreg Regular expression search of nucleotide sequence(s) drfinddata Find public databases by data type drfindformat Find public databases by format drfindid Find public databases by identifier drfindresource Find public databases by resource drget Get data resource entries drtext Get data resource entries complete text edamdef Find EDAM ontology terms by definition edamhasinput Find EDAM ontology terms by has_input relation edamhasoutput Find EDAM ontology terms by has_output relation edamisformat Find EDAM ontology terms by is_format_of relation edamisid Find EDAM ontology terms by is_identifier_of relation edamname Find EDAM ontology terms by name edialign Local multiple alignment of sequences einverted Find inverted repeats in nucleotide sequences embossdata Find and retrieve EMBOSS data files embossupdate Checks for more recent updates to EMBOSS embossversion Report the current EMBOSS version number emma Multiple sequence alignment (ClustalW wrapper) emowse Search protein sequences by digest fragment molecular weight entret Retrieve sequence entries from flatfile databases and files epestfind Find PEST motifs as potential proteolytic cleavage sites eprimer3 Pick PCR primers and hybridization oligos eprimer32 Pick PCR primers and hybridization oligos equicktandem Find tandem repeats in nucleotide sequences est2genome Align EST sequences to genomic DNA sequence etandem Find tandem repeats in a nucleotide sequence extractalign Extract regions from a sequence alignment extractfeat Extract features from sequence(s) extractseq Extract regions from a sequence featcopy Read and write a feature table featmerge Merge two overlapping feature tables featreport Read and write a feature table feattext Return a feature table original text findkm Calculate and plot enzyme reaction data freak Generate residue/base frequency table or plot fuzznuc Search for patterns in nucleotide sequences fuzzpro Search for patterns in protein sequences fuzztran Search for patterns in protein sequences (translated) garnier Predict protein secondary structure using GOR method geecee Calculate fractional GC content of nucleic acid sequences getorf Find and extract open reading frames (ORFs) godef Find GO ontology terms by definition goname Find GO ontology terms by name helixturnhelix Identify nucleic acid-binding motifs in protein sequences hmoment Calculate and plot hydrophobic moment for protein sequence(s) iep Calculate the isoelectric point of proteins infoalign Display basic information about a multiple sequence alignment infoassembly Display information about assemblies infobase Return information on a given nucleotide base inforesidue Return information on a given amino acid residue infoseq Display basic information about sequences isochore Plot isochores in DNA sequences jaspextract Extract data from JASPAR jaspscan Scan DNA sequences for transcription factors lindna Draw linear maps of DNA constructs listor Write a list file of the logical OR of two sets of sequences makenucseq Create random nucleotide sequences makeprotseq Create random protein sequences marscan Find matrix/scaffold recognition (MRS) signatures in DNA sequences maskambignuc Mask all ambiguity characters in nucleotide sequences with N maskambigprot Mask all ambiguity characters in protein sequences with X maskfeat Write a sequence with masked features maskseq Write a sequence with masked regions matcher Waterman-Eggert local alignment of two sequences megamerger Merge two large overlapping DNA sequences merger Merge two overlapping sequences msbar Mutate a sequence mwcontam Find weights common to multiple molecular weights files mwfilter Filter noisy data from molecular weights file needle Needleman-Wunsch global alignment of two sequences needleall Many-to-many pairwise alignments of two sequence sets newcpgreport Identify CpG islands in nucleotide sequence(s) newcpgseek Identify and report CpG-rich regions in nucleotide sequence(s) newseq Create a sequence file from a typed-in sequence nohtml Remove mark-up (e.g. HTML tags) from an ASCII text file noreturn Remove carriage return from ASCII files nospace Remove whitespace from an ASCII text file notab Replace tabs with spaces in an ASCII text file notseq Write to file a subset of an input stream of sequences nthseq Write to file a single sequence from an input stream of sequences nthseqset Read and write (return) one set of sequences from many octanol Draw a White-Wimley protein hydropathy plot oddcomp Identify proteins with specified sequence word composition ontocount Count ontology term(s) ontoget Get ontology term(s) ontogetcommon Get common ancestor for terms ontogetdown Get ontology term(s) by parent id ontogetobsolete Get ontology ontology terms ontogetroot Get ontology root terms by child identifier ontogetsibs Get ontology term(s) by id with common parent ontogetup Get ontology term(s) by id of child ontoisobsolete Report whether an ontology term id is obsolete ontotext Get ontology term(s) original full text palindrome Find inverted repeats in nucleotide sequence(s) pasteseq Insert one sequence into another patmatdb Search protein sequences with a sequence motif patmatmotifs Scan a protein sequence with motifs from the PROSITE database pepcoil Predict coiled coil regions in protein sequences pepdigest Report on protein proteolytic enzyme or reagent cleavage sites pepinfo Plot amino acid properties of a protein sequence in parallel pepnet Draw a helical net for a protein sequence pepstats Calculate statistics of protein properties pepwheel Draw a helical wheel diagram for a protein sequence pepwindow Draw a hydropathy plot for a protein sequence pepwindowall Draw Kyte-Doolittle hydropathy plot for a protein alignment plotcon Plot conservation of a sequence alignment plotorf Plot potential open reading frames in a nucleotide sequence polydot Draw dotplots for all-against-all comparison of a sequence set preg Regular expression search of protein sequence(s) prettyplot Draw a sequence alignment with pretty formatting prettyseq Write a nucleotide sequence and its translation to file primersearch Search DNA sequences for matches with primer pairs printsextract Extract data from PRINTS database for use by pscan profit Scan one or more sequences with a simple frequency matrix prophecy Create frequency matrix or profile from a multiple alignment prophet Scan one or more sequences with a Gribskov or Henikoff profile prosextract Process the PROSITE motif database for use by patmatmotifs pscan Scan protein sequence(s) with fingerprints from the PRINTS database psiphi Calculates phi and psi torsion angles from protein coordinates rebaseextract Process the REBASE database for use by restriction enzyme applications recoder Find restriction sites to remove (mutate) with no translation change redata Retrieve information from REBASE restriction enzyme database refseqget Get reference sequence remap Display restriction enzyme binding sites in a nucleotide sequence restover Find restriction enzymes producing a specific overhang restrict Report restriction enzyme cleavage sites in a nucleotide sequence revseq Reverse and complement a nucleotide sequence seealso Find programs with similar function to a specified program seqcount Read and count sequences seqmatchall All-against-all word comparison of a sequence set seqret Read and write (return) sequences seqretsetall Read and write (return) many sets of sequences seqretsplit Read sequences and write them to individual files seqxref Retrieve all database cross-references for a sequence entry seqxrefget Retrieve all cross-referenced data for a sequence entry servertell Display information about a public server showalign Display a multiple sequence alignment in pretty format showdb Display information on configured databases showfeat Display features of a sequence in pretty format showorf Display a nucleotide sequence and translation in pretty format showpep Display protein sequences with features in pretty format showseq Display sequences with features in pretty format showserver Display information on configured servers shuffleseq Shuffle a set of sequences maintaining composition sigcleave Report on signal cleavage sites in a protein sequence silent Find restriction sites to insert (mutate) with no translation change sirna Find siRNA duplexes in mRNA sixpack Display a DNA sequence with 6-frame translation and ORFs sizeseq Sort sequences by size skipredundant Remove redundant sequences from an input set skipseq Read and write (return) sequences, skipping first few splitsource Split sequence(s) into original source sequences splitter Split sequence(s) into smaller sequences stretcher Needleman-Wunsch rapid global alignment of two sequences stssearch Search a DNA database for matches with a set of STS primers supermatcher Calculate approximate local pair-wise alignments of larger sequences syco Draw synonymous codon usage statistic plot for a nucleotide sequence taxget Get taxon(s) taxgetdown Get descendants of taxon(s) taxgetrank Get parents of taxon(s) taxgetspecies Get all species under taxon(s) taxgetup Get parents of taxon(s) tcode Identify protein-coding regions using Fickett TESTCODE statistic textget Get text data entries textsearch Search the textual description of sequence(s) tfextract Process TRANSFAC transcription factor database for use by tfscan tfm Display full documentation for an application tfscan Identify transcription factor binding sites in DNA sequences tmap Predict and plot transmembrane segments in protein sequences tranalign Generate an alignment of nucleic coding regions from aligned proteins transeq Translate nucleic acid sequences trimest Remove poly-A tails from nucleotide sequences trimseq Remove unwanted characters from start and end of sequence(s) trimspace Remove extra whitespace from an ASCII text file twofeat Find neighbouring pairs of features in sequence(s) union Concatenate multiple sequences into a single sequence urlget Get URLs of data resources variationget Get sequence variations vectorstrip Remove vectors from the ends of nucleotide sequence(s) water Smith-Waterman local alignment of sequences whichdb Search all sequence databases for an entry and retrieve it wobble Plot third base position variability in a nucleotide sequence wordcount Count and extract unique words in molecular sequence(s) wordfinder Match large sequences against one or more other sequences wordmatch Find regions of identity (exact matches) of two sequences wossdata Find programs by EDAM data wossinput Find programs by EDAM input data wossname Find programs by keywords in their short description wossoperation Find programs by EDAM operation wossoutput Find programs by EDAM output data wossparam Find programs by EDAM parameter wosstopic Find programs by EDAM topic yank Add a sequence reference (a full USA) to a list file Como obviamente es imposible acordarse de todos estos programas, EMBOSS tiene un comando llamado wossname que permite listar comandos que tengan cierta palabra en su descripci\u00f3n (en ingl\u00e9s). Abran la consola y prueben correr: wossname dna Por otro lado, una vez que encuentran un programa que les interesa pueden leer detalladamente como funciona usando el comando tfm ( The Funny? Full? Manual ). Por ejemplo pueden ejecutar: tfm jaspscan El texto que aparece funciona similar al comando less que vimos en el TP 1, donde Space pasa a la pr\u00f3xima p\u00e1gina y apretando Q deja de leerlo. Como mencionamos antes es posible hacer bioinform\u00e1tica sin usar EMBOSS, ya sea porque queremos controlar hasta el \u00faltimo detalle que hace nuestro programa, porque queremos agregar alguna opci\u00f3n que EMBOSS no tiene, o simplemente porque era una tarea simple y no quer\u00edamos aprender a usar un programa de EMBOSS para hacerla. Son todas razones v\u00e1lidas. Lo que queremos que se lleven hoy es que EMBOSS existe y que puede hacer algunas tareas que les van a resultar \u00fatiles en el d\u00eda a d\u00eda de hacer bioinform\u00e1tica. Si no estan usando la Maquina Virtual de Introducci\u00f3n a la Bioinform\u00e1tica lean esto: EMBOSS y su documentaci\u00f3n est\u00e1 ya instalado en la m\u00e1quina virtual que les pasamos. Si no estas usando la m\u00e1quina virtual tenes que instalarlo usando: sudo apt-get install emboss emboss-data emboss-doc Aplicaciones en Biotecnolog\u00eda En el TP de hoy vamos a familiarizarnos con EMBOSS y algunas herramientas del paquete, aplic\u00e1ndolas al dise\u00f1o de una estrategia de clonado, puntualmente para dise\u00f1ar/optimizar prote\u00ednas para expresi\u00f3n recombinante heter\u00f3loga. En los \u00faltimos a\u00f1os se ha simplificado considerablemente la ejecuci\u00f3n del proceso de clonado/expresi\u00f3n. Esto se debe a la aparici\u00f3n de m\u00faltiples herramientas de Ingenieria Gen\u00e9tica y a la posibilidad de sintetizar largas secuencias de \u00e1cidos nucleicos in vitro , lo que quita el peso de levantar un gen de inter\u00e9s o el riesgo de meter errores durante la PCR que ejecutamos para hacerlo. Una de las industrias biotecnol\u00f3gicas m\u00e1s antigua es la industria alimenticia. Centenares de microorganismos distintos y decenas de enzimas son utilizados en esta industria para distintos procesos. Algunos de estos procesos son muy complejos, como la fermentaci\u00f3n de un vino, mientras que otros son simples y puntuales, como la degradaci\u00f3n de lactosa en productos l\u00e1cteos para personas intolerantes a este az\u00facar. Los procesos enzim\u00e1ticos simples pueden resolverse f\u00e1cilmente mediante la producci\u00f3n de la enzima de inter\u00e9s en forma heter\u00f3loga. Con el fin de dar rienda suelta a nuestro emprendedor interior, montaremos las bases de una empresa biotecnol\u00f3gica: vamos a producir enzimas. La primera enzima que queremos producir es la VpVan , la cual es la encargada de convertir el \u00e1cido fer\u00falico en vanillina . La vainillina es un compuesto de alto inter\u00e9s econ\u00f3mico debido a su uso como saborizante (a que no adivinan que sabor tiene). Archivos FASTA Esta enzima ha sido aislada (y secuenciada) a partir de Vanilla planifolia . Encontrar\u00e1n la secuencia correspondiente entre sus materiales de trabajo ( VpVAN.fasta ) y m\u00e1s informaci\u00f3n sobre el descubrimiento en este paper . Por si no lo saben o no lo recuerdan, el formato FASTA es la forma m\u00e1s usada para trabajar secuencias biol\u00f3gicas (ADN, ARN, amino\u00e1cidos) en forma digital. Son archivos de texto plano, donde se asume un formato muy sencillo de interpretar para el ojo humano: Un archivo FASTA tiene dos elementos importantes: Header : Est\u00e1 indicado con un > . Es la l\u00ednea con el nombre o identificador de la secuencia. Puede contener informaci\u00f3n adicional como alguna descripci\u00f3n extra sobre la secuencia, tal como las condiciones en que fue obtenida u otra descripci\u00f3n opcional. Secuencia : El resto de las l\u00edneas que contin\u00faan contienen la secuencia propiamente dicha. El largo de cada fila de la secuencia no significa nada; una secuencia de 800 amino\u00e1cidos puede ser escrita en una sola l\u00ednea de 800 amino\u00e1cidos o en 10 l\u00edneas de 80 amino\u00e1cidos cada una. La secuencia sigue hasta el pr\u00f3ximo > o hasta el final del archivo, lo que pase primero. Info Cuando un FASTA tiene m\u00e1s de una secuencia se lo denomina multiFASTA . En los archivos multiFASTA cada secuencia tiene su header y su secuencia propiamente dicha. Repaso biol\u00f3gico Nuestro objetivo en esta gu\u00eda va a ser dise\u00f1ar una secuencia de ADN sint\u00e9tico que: Exprese VpVan Tenga sitios de corte para enzimas de restricci\u00f3n para que pueda ser insertado en un pl\u00e1smido o vector de expresi\u00f3n de un organismo hu\u00e9sped. En este caso, dichos sitios de corte van a pertenecer a diferentes enzimas de restricci\u00f3n para facilitar la inserci\u00f3n del gen en el sentido correcto Marque a VpVan de alguna forma para facilitar su posterior purificaci\u00f3n A continuaci\u00f3n vamos a dar una versi\u00f3n super resumida de los conceptos anteriores. Si ya saben como funciona todo lo mencionado pueden ir a la pr\u00f3xima secci\u00f3n ( Bases del experimento ). Repaso biol\u00f3gico - Pl\u00e1smidos Pl\u00e1smidos Los pl\u00e1smidos son mol\u00e9culas de ADN de forma circular presentes principalmente en bacterias, arqueas y levaduras. Estas mol\u00e9culas se encuentran fuera de los cromosomas y se replican de manera aut\u00f3noma. Debido a estas caracter\u00edsticas, es posible generar pl\u00e1smidos artificiales con el objetivo de amplificar ( vector de clonaci\u00f3n ) o de expresar ( vector de expresi\u00f3n ) un gen de inter\u00e9s. Esto generalmente se realiza cuando la expresi\u00f3n de dicho gen en su organismo original no es factible, ya sea por problemas de volumen, log\u00edstica o \u00e9tica. Los principales componentes de vector de expresi\u00f3n son: Origen de la replicaci\u00f3n: punto inicial para la replicaci\u00f3n del pl\u00e1smido Gen de resistencia a antibi\u00f3ticos: gen que se expresa y da resistencia al organismo hu\u00e9sped, permite quedarnos solo con los organismos que tienen el pl\u00e1smido dentro de ellos Promotor: controla la transcripci\u00f3n de una determinada secuencia (en este caso el gen insertado) Sitio de restricci\u00f3n: secuencia que es cortada por una enzima de restricci\u00f3n y donde ser\u00e1 insertado el gen de inter\u00e9s (m\u00e1s de esto a continuaci\u00f3n) Repaso biol\u00f3gico - Enzimas de Restricci\u00f3n Enzimas de Restricci\u00f3n Las enzimas de restricci\u00f3n son prote\u00ednas que reconocen una secuencia espec\u00edfica de nucle\u00f3tidos dentro de una mol\u00e9cula de ADN y cortan el ADN en ese punto en concreto o en un punto cercano. A esas secuencias de ADN se las denomina sitios de restricci\u00f3n y tienen entre cuatro a seis pares de bases. Hay dos grandes grupos de enzimas de restricci\u00f3n, aquellas que dejan extremos cohesivos y aquellas que dejan extremos romos: Al momento de insertar genes en pl\u00e1smidos se usan generalmente enzimas de restricci\u00f3n que dejan extremos cohesivos ya que facilitan la inserci\u00f3n del gen debido a su especificidad y a que pueden volverse a unir espontaneamente. La idea detr\u00e1s de su uso es colocar un sitio de restricci\u00f3n en el pl\u00e1smido y colocar el mismo sitio de restricci\u00f3n a cada lado del gen de inter\u00e9s (en el ADN que uno sintetiza). Luego los pl\u00e1smidos vacios se colocan en una soluci\u00f3n con el ADN sint\u00e9tico y se les agrega la enzima de restricci\u00f3n correspondiente que va a cortar el ADN dejando los extremos cohesivos en cada sitio de restricci\u00f3n. Como el sitio de restricci\u00f3n es el mismo en el pl\u00e1stido y en la secuencia de ADN, es posible entonces que el ADN sint\u00e9tico se insert\u00e9 en el pl\u00e1smido, ya sea espontaneamente o ayudado por una ligasa. Esta p\u00e1gina tiene muy buenos esquemas sobre el proceso. En el experimento anterior, luego de cortar el sitio de restricci\u00f3n con la enzima, pueden pasar tres cosas: El pl\u00e1smido se vuelve a cerrar sin ningun inserto Se inserta el gen de inter\u00e9s en la direcci\u00f3n correcta (respecto al promotor en el pl\u00e1smido) Se inserta el gen de inter\u00e9s en la direcci\u00f3n contraria (respecto al promotor en el pl\u00e1smido) Es posible evitar el caso donde el gen se inserta en la direcci\u00f3n contraria combinando 2 enzimas de restricci\u00f3n diferentes, donde ahora va a haber 2 sitios de restricci\u00f3n en el pl\u00e1smido (uno para cada enzima) y los dos sitios de restricci\u00f3n en el ADN sint\u00e9tico van a ser diferentes (uno para cada enzima, en el mismo orden que en el pl\u00e1smido). Si bien en esta versi\u00f3n no es posible que el gen sea insertado en la direcci\u00f3n contraria, s\u00ed es posible que se vuelva a insertar el fragmento de pl\u00e1smido entre los sitios de restricci\u00f3n, pero hay formas de controlar estos casos. Cuando usamos 2 enzimas de reestricci\u00f3n en esta forma decimos que estamos \"clonando en forma direccional\". Danger Es importante cuando se usan enzimas de restricci\u00f3n asegurarse que no haya ning\u00fan sitio de corte para las enzimas elegidas en el pl\u00e1smido ni en el ADN sint\u00e9tico fuera de los sitios involucrados en el proceso de inserci\u00f3n (ya que de existir tambi\u00e9n ser\u00e1n cortados y la inserci\u00f3n fracasar\u00e1). Repaso biol\u00f3gico - Purificaci\u00f3n y Tags Purificaci\u00f3n y Tags Una vez que nuestros organismos hu\u00e9sped tienen el vector de expresi\u00f3n con el gen de inter\u00e9s, se los deja crecer, reproducirse y expresar la prote\u00edna de inter\u00e9s en grandes cantidades. Una vez hecho esto, es necesario extraer esa prote\u00edna de la soluci\u00f3n, lo que no es trivial. Hay varias formas de purificar prote\u00ednas y una de ellas es la cromatograf\u00eda por afinidad, la cual se basa en la uni\u00f3n reversible entre el analito de inter\u00e9s (en nuestro caso la VpVan ) y un ligando espec\u00edfico, inmovilizado en un soporte s\u00f3lido inerte. Cuando la muestra pasa por la columna, s\u00f3lo son retenidas las mol\u00e9culas que se unen de manera selectiva al ligando por afinidad y las que no se unen avanzan con la fase m\u00f3vil. La figura a continuaci\u00f3n muestra un ejemplo donde se usan anticuerpos inmovilizados en una columna para purificar a la prote\u00edna roja del resto de la soluci\u00f3n: Uno podr\u00eda asumir entonces que para poder construir estas columnas es necesario conseguir un ligando que reconozca a nuestra prote\u00edna de inter\u00e9s. Si bien esto es te\u00f3ricamente cierto, como nosotros estamos sintetizando el ADN desde cero podemos pensar lateralmente y agregarle a nuestra prote\u00edna una secuenc\u00eda aminoac\u00eddica en uno de sus extremos para la cual ya conozcamos ligandos. Estas secuencias pueden ser desde pocos amino\u00e1cidos hasta a prote\u00ednas peque\u00f1as y son denominadas tags . Bases del experimento Volviendo a nuestro experimento, queremos insertar el gen de VpVan en un vector de expresi\u00f3n. Nuestro organismo hu\u00e9sped es: E. coli BL21 Como queremos clonar en forma direccional tenemos que usar dos enzimas de restricci\u00f3n . Ellas son: BamHI HindIII Al momento de purificar necesitamos agregarle un tag a la prote\u00edna. Vamos a probar 3 tags diferentes: FLAG-tag His-tag MBP-tag Por cuestiones de practicidad, todos los tags van a estar en el C-terminal. En los siguientes ejercicios vamos a: Ejercicio 1: Generar secuencias quim\u00e9ricas VpVan-Tag agregando diferentes tags de inter\u00e9s a la secuencia prote\u00edca de VpVan Ejercicio 2: Obtener el genoma del organismo hu\u00e9sped E. coli BL21 (necesario para el Ejercicio 3 ) Ejercicio 3: Generar una tabla de frecuencia de uso de codones del organismo hu\u00e9sped Ejercicio 4: Generar la secuencia nucleot\u00eddica VpVan-Tag con los codones optimizados para el organismo hu\u00e9sped Ejercicio 5: Verificar que no hayan quedado sitios de corte para nuestras enzimas de restricci\u00f3n dentro de la secuencia VpVan-Tag optimizada y luego agregar los sitios de restricci\u00f3n en los bordes de la secuencia Ejercicio 1. Secuencias aminoac\u00eddicas VpVan-Tag Vamos a generar las secuencias de amino\u00e1cidos quim\u00e9ricas VpVan-Tag (donde Tag = FLAG/His/MBP). Para esto van a necesitar los siguientes archivos que se encuentras en sus materiales de trabajo: VpVan.fasta FLAG-tag.fasta His-tag.fasta MBP-tag.fasta Es altamente recomendado que creen diferentes carpetas para los diferentes TPs y en algunos casos para los diferentes ejercicios (especialemente en este). El nombre y la ubicaci\u00f3n lo pueden decidir ustedes, pero un ejemplo para este ejercicio ser\u00eda ~/Documentos/TP_02/EJ_1 . Una vez creada la carpeta para este ejercicio, muevan los cuatro archivos anteriores a dicha carpeta. Tip Recuerden que es preferible no usar espacios al crear directorios o archivos Nuestro objetivo ahora es crear 3 nuevos archivos FASTA que contengan las diferentes construcciones ( VpVan + cada uno de los tags). Vamos a llamarlos VpVan-FLAG-tag.fasta y similar (reemplazando el nombre del tag en cada caso). Ahora bien, como son solo 3 tags esto se podr\u00eda hacer a mano copiando y pegando, pero es un buen momento para profundizar en dos conceptos que aprendimos la clase pasada: scripts y ciclos . Creen un archivo vacio de texto en esa carpeta y llamenl\u00f3 agregar_tags.sh . Dentr\u00f3 del archivo pongan lo siguiente: C\u00f3digo C\u00f3digo con comentarios vpvan_sequence = ` cat VpVAN.fasta | grep -v \">\" ` lista_de_archivos_tags = ` ls *-tag.fasta ` for archivo_tag in $lista_de_archivos_tags do tag_sequence = ` cat $archivo_tag | grep -v \">\" ` new_header = \">VpVAN- $archivo_tag \" combined_sequence = \" $vpvan_sequence$tag_sequence \" echo \" $new_header \" > VpVAN- $archivo_tag echo \" $combined_sequence \" >> VpVAN- $archivo_tag done # Aca estamos ejecutando comandos de Linux y guardando su output en una variable # En estos casos hay que rodear a los comandos con ` (acento grave o comilla invertida) # Leemos el FASTA de VpVAN y nos quedamos solo con la secuencia # (estamos removiendo con grep cualquier linea que tenga >, que aca es solo el header) vpvan_sequence = ` cat VpVAN.fasta | grep -v \">\" ` # Creamos una lista que contiene a todos los archivos que terminan con -tag.fasta # (esto va a mirar solo archivos que est\u00e9n en la carpeta donde se corre el script) lista_de_archivos_tags = ` ls *-tag.fasta ` # Este es una estructura a la que llamamos *for each* en el TP 1. Es un *for*, pero en vez de tener # una cantidad determinada de ciclos, recorre cada uno de los elementos de una lista for archivo_tag in $lista_de_archivos_tags do # Leemos el FASTA del tag y nos quedamos solo con la secuencia tag_sequence = ` cat $archivo_tag | grep -v \">\" ` # Creamos una variable que almacene el nuevo header para la secuencia de VpVAN + tag new_header = \">VpVAN- $archivo_tag \" # Calculamos la nueva secuencia VpVAN + tag combined_sequence = \" $vpvan_sequence$tag_sequence \" # Escribimos el nuevo header y la nueva secuencia en un nuevo archivo echo \" $new_header \" > VpVAN- $archivo_tag echo \" $combined_sequence \" >> VpVAN- $archivo_tag done Como recordatorio del TP 1: cat lee archivos de texto y los escribe en la consola | desvia la salida de un programa para que funcione como entrada del siguiente grep filtra texto, quedandos\u00e9 solo con aquellas l\u00edneas que contengan un texto dado (y de usar la opci\u00f3n -v se queda solo con aquellas que no lo contengan) ls lista los archivos y carpetas dentro del directorio actual echo escribe un texto por consola > desvia la salida que \u00edria a consola hacia un archivo de texto, sobrescribiendolo >> desvia la salida que \u00edria a consola hacia un archivo de texto, sin sobreescribirlo (agrega lineas al final) for , in , do y done son todas partes del ciclo for each . El c\u00f3digo entre do y done se va a repetir por cada elemento en $lista_de_archivos_tags , donde en cada iteraci\u00f3n la variable $archivo_tag toma el valor de uno de esos elementos Hay dos cosas en este script que no vimos en el TP 1. La primera es que estamos ejecutando comandos de Bash y guardando su salida en variables. En estos casos es necesario rodear el comando con ` , llamado acento grave o comilla invertida. Por ejemplo: variable = ` comando -opciones parametro1 parametro2 ` La segunda novedad es el uso de * con el comando ls . En todo lo que es Linux el caracter * funciona como comod\u00edn, tomando cualquier valor. Esto quiere decir que ls *-tag.fasta va a listar todos los archivos cuyos nombres terminen con \"-tag.fasta\" , sin importar como empiecen (pueden probar correr el comando ls *-tag.fasta a mano en la consola y ver que devuelve). \u00bfEntienden ahora lo que hace el script? Lean la pesta\u00f1a C\u00f3digo con comentarios para aclarar cualquier duda que tengan sobre \u00e9l (y si todav\u00eda no se entiende no duden en preguntar). Ahora abran la consola y corran el script que acabamos de crear, generando as\u00ed los nuevos 3 archivos. Tip Recuerden que los script se corren con bash ARCHIVO_SCRIPT \u00a1Ya tenemos nuestras secuencias quim\u00e9ricas! Tip Este script va a dar problemas si se lo corre multiples veces. Esto se debe a que al correrlo la primera vez estamos creando m\u00e1s archivos que terminan con \"-tag.fasta\", que en una segunda corrida van a ser detectados por el ls . Si no quieren tener problemas con esto pueden agregar el siguiente c\u00f3digo luego de dicho comando: | grep -v \"VpVAN\" Ejercicio 2. Genoma de E. coli Nosotros queremos expresar el gen de un organismo en otro organismo. Si bien el c\u00f3digo gen\u00e9tico es practicamente universal, diferentes organismos pueden tener preferencia para diferentes codones que generan un mismo amino\u00e1cido. Por esta raz\u00f3n, al hacer expresi\u00f3n recombinante heter\u00f3loga es una buena idea cambiar los codones del gen de inter\u00e9s para que matcheen mejor con los codones que prefiere el organismo hu\u00e9sped (se modifica el ADN pero se sigue produciendo la misma prote\u00edna). El primer paso para realizar esta modificaci\u00f3n es conocer cuales son los codones preferidos por dicho organismo. Busquen usando el comando wossname que programas de EMBOSS trabajan con codones (recuerden que est\u00e1 en ingl\u00e9s, asi que tienen que buscar \"codon\"). Lean la descripci\u00f3n de dichos programas, \u00bfcual les parece que vamos a usar para calcular la tabla de uso de codones? Respuesta cusp , cuya descripci\u00f3n es \"Create a codon usage table from nucleotide sequence(s)\" Si leen la descripci\u00f3n del programa, ver\u00e1n que pide una secuencia de nucle\u00f3tidos, es decir, que necesitamos un FASTA del genoma completo de E. coli (ya que \u00e9ste es nuestro organismo hu\u00e9sped). Un buen lugar para obtener informaci\u00f3n de genomas, genes, y prote\u00ednas es RefSeq , que es una colecci\u00f3n curada de secuencias nucleot\u00eddicas y sus productos. En su FAQ ( Frequently Asked Questions , o preguntas frecuentes ) hay una pregunta que es b\u00e1sicamente lo que queremos hacer nosotros: How can I download RefSeq data for all complete bacterial genomes? Si bien los comandos que ellos sugieren son un poco complejos, vamos a utilizarlos y tratar de explicarlos lo mejor posible. Tip Antes de seguir les recomendamos crear una carpeta nueva para este ejercicio, por ejemplo ~/Documentos/TP_02/EJ_2 . RefSeq - Paso 1 - Bajar y filtrar la tabla con los genomas El primer paso indicado en el FAQ es descargar el archivo assembly_summary.txt y ponerlo en la carpeta de este ejercicio. Esto lo pueden hacer desde la p\u00e1gina de RefSeq a mano o abriendo la consola en la carpeta de este ejercicio y corriendo: wget ftp://ftp.ncbi.nlm.nih.gov/genomes/refseq/bacteria/assembly_summary.txt Question \u00bfQu\u00e9 piensan que hace wget ? \u00bfC\u00f3mo pueden averiguarlo si no lo saben? Warning Si el comando wget tarda mucho o ven que tiene errores bajens\u00e9 este archivo desde este link Una vez descargado ese archivo (que pesa bastante) queremos ver sus contenidos. Sabiendo que es un archivo que tiene m\u00e1s de 250.000 lineas: \u00bfQu\u00e9 comando usar\u00edan para ver que tipo de datos tiene adentro? Pruebenlo. Dado que es un archivo con muchas columnas, probablemente les cueste entender lo que est\u00e1n viendo aunque hayan usado el comando correcto. Para entender la estructura de nuestro archivo vamos a crear un archivo temporal que tenga solo las primeras 20 filas de este archivo: head -20 assembly_summary.txt > assembly_summary_temporal.tsv Lo \u00fanico que les deber\u00eda llamar la atenci\u00f3n del comando anterior es que el nuevo archivo tiene la extensi\u00f3n tsv . Esto lo mencionamos por arriba en el TP 1, pero los archivos TSV o \"Tab-Separated Values\" son archivos de texto que contienen una tabla donde sus columnas est\u00e1n separadas entre ellas por un Tab , lo cual es exactamente el caso de la tabla actual. Hagan doble click sobre el archivo assembly_summary_temporal.tsv . La extensi\u00f3n tsv en nuestra m\u00e1quina virtual est\u00e1 asociada al programa Gnumeric (similar a Excell o a Google Sheets). Gnumeric va a detectar autom\u00e1ticamente que las columnas est\u00e1n separadas por Tab . Identifiquen la columna correspondiente a la especie (son solo las primeras 20 filas, no van a encontrar a E. coli ), la cepa y el link a la ubicaci\u00f3n del genoma. Ahora que conocen la estructura de la tabla, y sabiendo que tiene muchos mas organismos que E. coli , tenemos que filtrar el archivo y quedarnos solo con nuestro organismo y cepa de inter\u00e9s. Para esto, corran los siguientes comandos uno a la vez: C\u00f3digo C\u00f3digo con comentarios head -2 assembly_summary.txt > assembly_summary_coli.tsv grep \"Escherichia coli\" assembly_summary.txt | grep \"BL21\" >> assembly_summary_coli.tsv # Generamos un nuevo archivo con el header de la tabla (que en este caso son 2 filas) head -2 assembly_summary.txt > assembly_summary_coli.tsv # Buscamos dentro del archivo las filas que contengan \"Escherichia coli\" y \"BL21\" y # las agregamos a la nuevo archivo grep \"Escherichia coli\" assembly_summary.txt | grep \"BL21\" >> assembly_summary_coli.tsv RefSeq - Paso 2 - Crear un archivo con links a las carpetas de los genomas Ahora que tenemos y entendemos la tabla con nuestros datos de E. coli la podemos abrir en Gnumeric haciendo doble click. Van a ver que no hay solo un genoma de E. coli BL21, sino varios, por lo cual nuestro objetivo de crear una tabla de codones acaba de volverse un poco m\u00e1s complicado. Lo que vamos a hacer entonces es bajar todos los genomas de E. coli BL21 que vemos en la tabla, as\u00ed que continuamos al segundo paso en el FAQ de RefSeq : awk -F \"\\t\" '{if ($12==\"Complete Genome\" && $11==\"latest\") {print $20}}' assembly_summary_coli.tsv > ftpdirpaths Al comando awk lo vimos brevemente al final del TP 1 y sirve para trabajar con tablas en Bash (entre otras cosas). Las diferentes partes de este comando son: -F \"\\t\" indica que el separador de columnas es \\t , o sea, Tab $12==\"Complete Genome\" es una condici\u00f3n que filtra las filas, qued\u00e1ndose solo con aquellas donde la columna 12 ( assembly_level ) es \"Complete Genome\" $11==\"latest\" es una condici\u00f3n que filtra las filas, qued\u00e1ndose solo con aquellas donde la columna 11 ( version_status ) es \"latest\" && se denomina and y une ambas condiciones, pidiendo que ambas se cumplan para que la condici\u00f3n total se cumpla {print $20} indica que se va a devolver la columna 20 ( ftp_path , contiene el path del genoma, o sea, la carpeta) Este comando va a crear el archivo ftpdirpaths , que contiene links a las carpetas que contienen los genomas. Investiguen cuantos links quedaron en ftpdirpaths . \u00bfEntienden por qu\u00e9? Sino consulten. RefSeq - Paso 3 - Crear un archivo con links a los genomas Los links que tenemos de momento tienen el formato: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/833/145/GCF_000833145.1_ASM83314v1 Sin embargo, estos son links a las carpetas que contienen los genomas. Siguiendo las instrucciones del FAQ de RefSeq podemos crear el link de los genomas, que para el ejemplo anterior ser\u00eda: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/833/145/GCF_000833145.1_ASM83314v1/GCF_000833145.1_ASM83314v1_cds_from_genomic.fna.gz Donde el nombre del archivo es el nombre de la \u00faltima carpeta + \"_cds_from_genomic.fna.gz\" Los archivos terminados en .fna.gz son secuencias en formato FASTA ( f ) de nucle\u00f3tidos ( na ) comprimidas ( gz ). Hay varias formas de crear estos nuevos links. Nosotros lo vamos a hacer de la siguiente manera: awk -F \"/\" '{print $0 \"/\" $10 \"_cds_from_genomic.fna.gz\"}' ftpdirpaths > ftpfilepaths Donde: -F \"/\" indica que el separador de columnas es / . Lo que est\u00e1 haciendo este c\u00f3digo es leer nuestros paths como si fueran tablas de varias columnas, haciendo que cada carpeta quede en su propia columna. $0 parecer\u00eda indicar la columna 0, pero las columnas en awk van de 1 en adelante ( $1 , $2 , etc). El \u00edndice $0 es un \u00edndice especial que devuelve toda la fila (que en este caso es todo el path a la carpeta del genoma). $10 es la columna 10, la cual contiene el nombre del genoma (es el nombre de la \u00faltima carpeta en el path ). print va a concatenar $0 (el path a la carpeta del genoma), \"/\" (una barra para separar los directorios), $10 (la primera parte del nombre del archivo a descargar) y \"_cds_from_genomic.fna.gz\" (la segunda parte del nombre del archivo a descargar). awk va a hacer esto por cada fila del archivo ftpdirpaths . Una vez que entienden lo que hace este comando abran la terminal y corranl\u00f3. Por si se quedaron con curiosidad de el comando que propon\u00eda el FAQ de RefSeq El comando awk que sugeria el FAQ de RefSeq es un poco m\u00e1s complejo, pero llegaba al mismo resultado. Noten que en este comando el archivo tiene la extensi\u00f3n .gbff.gz que hace referencia al formato de GenBank , que no es el con el que vamos a trabajar. Hay que cambiarlo por \"cds_from_genomic.fna.gz\" awk 'BEGIN{FS=OFS=\"/\";filesuffix=\"genomic.gbff.gz\"}{ftpdir=$0;asm=$10;file=asm\"_\"filesuffix;print ftpdir,file}' ftpdirpaths > ftpfilepaths No es necesario que lo entiendan 100%, pero vamos a aclarar algunas cosas: BEGIN significa que las cosas entre las primeras llaves se van a ejecutar solo una vez, y no una vez por fila (como el resto). FS es una variable interna de awk que indica como se separan las columnas en la tabla a leer (es equivalente a usar -F ). La variable OFS indica lo mismo, pero para la salida de awk . Con FS=OFS=\"/\" estamos indicando que ambos ser\u00e1n la barra / . Lo que est\u00e1 haciendo este c\u00f3digo es leer nuestros paths como si fueran tablas de varias columnas, haciendo que cada carpeta quede en su propia columna. En filesuffix=\"cds_from_genomic.fna.gz\" est\u00e1 definiendo una variable en la que va a almacenar la cadena de texto que queremos agregar al final de cada link. En ftpdir=$0 est\u00e1 definiendo una variable en la que parece almacenar la columna 0. Ahora bien, las columnas en awk van de 1 en adelante ( $1 , $2 , etc), pero el \u00edndice $0 es un \u00edndice especial que devuelve toda la fila (que en este caso es todo el path a la carpeta del genoma). En asm=$10 est\u00e1 definiendo una variable en la que va a almacenar la columna 10, la cual contiene el nombre del genoma (es el nombre de la \u00faltima carpeta en el path ). En file=asm\"_\"filesuffix est\u00e1 definiendo una nueva variable como la concatenaci\u00f3n de asm , un gui\u00f3n bajo y filesuffix . Este va a ser el nombre del archivo a descargar (pero todav\u00eda le falta el path ). print ftpdir,file va a imprimir el valor de ftpdir (el path a la carpeta del genoma) seguido por el valor de file (el nombre del archivo a descargar) por cada fila del archivo ftpdirpaths . La barra entre ambos ( / ) es agregada automaticamente debido a que declaramos OFS=\"/\" al principio. RefSeq - Paso 4 - Descargar genomas de E. coli Ya falta poco para tener nuestros genomas, solo hay que descargar todos los links que tenemos adentro del archivo ftpfilepaths . Esto se puede hacer usando el comando wget . Ahora bien, por defecto a wget hay que pasarle un link de descarga como hicimos arriba, pero por suerte existe una opci\u00f3n que permite pasarle un archivo de entrada y que descargue todos los links que se encuentran en \u00e9l. Usen wget -h (mas conciso) o man wget (mas extenso) para ver las diferentes opciones de wget , encuentren la que se usa para pasarle un archivo de entrada (o fichero o input file ) con links (o URLs ) y usen wget con ftpfilepaths para bajar todos los genomas que seleccionamos. Tip wget tiene bastantes opciones, asi que para hacerla un poco m\u00e1s f\u00e1cil sepan que la opci\u00f3n que necesitan es una de las 15 primeras y est\u00e1 en la secci\u00f3n Ficheros de registro y de entrada (o Logging and input file ) Este comando puede tardar un rato en descargar todo y va a bajar 11 archivos con extensi\u00f3n .fna.gz donde .fna es una extensi\u00f3n que hace referencia a que el archivo contiene informaci\u00f3n de secuencia (similar a FASTA) y .gz es la extensi\u00f3n de los archivos comprimidos de Linux. Ejercicio 3. Construir tabla de frecuencias de uso de codones Tras lo que parece una eternidad por fin tenemos nuestros genomas. Ahora es momento de usar el comando cusp del que hablamos al principio del ejercicio anterior para transformar nuestros genomas en tablas con frecuencias de uso de codones. Como tenemos varios archivos .fna.gz vamos a tener que correr el comando cusp varias veces, y la mejor forma de hacer esto es creando un script con un ciclo for each que lo haga por nosotros. Este ciclo va a recorrer todos los archivos .fna.gz que acabamos de descargar, los va a descomprimir y va a ejecutar el comando cusp para cada uno. Reemplacen los REEMPLAZAR en el pr\u00f3ximo c\u00f3digo por lo que sea adecuado para conseguir nuestro objetivo: REEMPLAZAR for REEMPLAZAR in REEMPLAZAR do REEMPLAZAR done Sabiendo que un REEMPLAZAR es: # Creamos una lista que contiene a todos los archivos que empiezan con \"GCF\" y terminan con \".gz\" lista_de_archivos_genomas = ` ls GCF*.gz ` y otro es: # Descomprimimos el archivo \".gz\" y corremos el comando *cusp* para cada $archivo_genoma de la lista zcat $archivo_genoma | cusp -auto -sequence \"stdin\" -outfile \" ${ archivo_genoma } .cusp\" zcat es un comando que descomprime archivos .gz y devuelve su contenido por consola (similar a cat ). -auto hace que cusp use los par\u00e1metros por defecto y no nos consulte cuales usar. -sequence \"stdin\" le esta diciendo a cusp que el genoma se lo estamos dando por la consola (mediante el pipe o | ). -outfile \"${archivo_genoma}.cusp\" define el nombre del archivo de salida de cusp , que en este caso es el nombre del genoma seguido de .cusp . Si bien las llaves no son necesarias en este caso, ayudan a entender donde termina la variable y empieza el string . Idealmente habria que sacarle la extensi\u00f3n anterior al archivo (ya que ahora va a quedar .fna.gz.cusp ), pero ya tenemos bastante que hacer. Tip Si no les sale pueden ver el for each del Ejercicio 1 para usarlo como base (si bien ese es m\u00e1s complicado) Una vez creado el script, corranl\u00f3. Si ven que este script tarda mucho tiempo en correr (varios minutos sin indicar que avanza) lean esto: Cancelen la corrida apretando Ctrl + C en la terminal Usen para la pr\u00f3xima seccion los archivos ecoli_BL21_codon_table_1.cusp y ecoli_BL21_codon_table_2.cusp que se encuentra en sus materiales de trabajo Comparar tablas de codones Recordando nuestro objetivo, nosotros quer\u00edamos una tabla de codones de E. coli para saber como modificar el ADN de nuestra prote\u00edna de inter\u00e9s ( VpVan ) para que use aquellos codones preferidos por el organismo hu\u00e9sped. En este momento tenemos varias tablas de codones, asi que tenemos que elegir alguna. Abran uno de los archivos .cusp que acabamos de crear y vean que informaci\u00f3n tiene: Si en la tabla dentro del archivo .cusp las columnas no est\u00e1n alineadas lean esto: Por defecto Leafpad usa una fuente llamada \"Ubuntu\" , que si bien sirve para escribir cuentos, nos va a dar problemas al momento de ver ciertos archivos que vamos a usar en esta materia. En Leafpad vayan a Opciones Tipograf\u00eda... , seleccionen la fuente \"Ubuntu Mono\" y aprieten Aceptar . Las fuentes que tienen Mono en su nombre estan indicando que son monoespaciadas, o sea, que todos sus caracteres tienen el mismo ancho. Esto es ideal para cuando se quieren ver tablas o alineamientos con Leafpad , cosa que vamos a hacer bastante en esta materia. Ayuda-memoria con amino\u00e1cidos y sus abreviaturas Full Name Abbreviation (3 Letter) Abbreviation (1 Letter) Alanine Ala A Arginine Arg R Asparagine Asn N Aspartate Asp D Aspartate or Asparagine Asx B Cysteine Cys C Glutamate Glu E Glutamine Gln Q Glutamate or Glutamine Glx Z Glycine Gly G Histidine His H Isoleucine Ile I Leucine Leu L Lysine Lys K Methionine Met M Phenylalanine Phe F Proline Pro P Serine Ser S Threonine Thr T Tryptophans Trp W Tyrosine Tyr Y Valine Val V \u00bfPor qu\u00e9 hay m\u00e1s de un cod\u00f3n para cada amino\u00e1cido? \u00bfQu\u00e9 indica la columna Fraction ? \u00bfQu\u00e9 indica la columna Frequency ? (pueden encontra la respuesta usando tfm cusp , pero est\u00e1 mas claro en la ayuda online ) Ahora abran otro archivo .cusp , \u00bfnotan diferencias entre las frecuencias de uso de codones de los distintos proyectos genoma de E.Coli BL21? En un principio pareceria que ambos archivos .cusp son bastante parecidos, pero queremos estar seguros. EMBOSS tiene un programa llamado codcmp que permite comparar tablas de codones, calculando ciertos estad\u00edsticos. El programa se usa: codcmp ARCHIVO_CUSP_1 ARCHIVO_CUSP_2 ARCHIVO_SALIDA Usen este comando para comparar los dos archivos .cusp que miraron previamente y guarden la comparaci\u00f3n en un archivo llamado cusp_comparison.out . Abran cusp_comparison.out y vean los estad\u00edsticos calculados. \u00bfSon compatibles estos resultados con nuestras observaciones previas de que ambos archivos .cusp son muy parecidos? Hay entoces una noticia buena y una mala: Noticia Buena Todos las tablas de frecuencias de codones son casi id\u00e9nticas, asi que podemos usar cualquiera de ellas y va a funcionar bien. Aclaraci\u00f3n 1: Los resultados de codcmp no alcanzan para decir que las diferencias no son \"estadisticamente signficativas\" (aunque en este caso es bastante obvio). En el manual de codcmp dan algunas ideas para calcular esto. Aclaraci\u00f3n 2: Otra forma de resolver el \"problema\" de tener muchas tablas de codones podr\u00eda haber sido calcular una nueva tabla de frecuencias de codones que sea un promedio de todas las anteriores, pero esto es un trabajo complejo y no se amerita hacerlo para este caso debido a los similar que son las diferentes tablas entre s\u00ed. Noticia Mala Todos las tablas de frecuencias de codones son casi id\u00e9nticas, asi que podr\u00edamos haber bajado solo una de ellas y ahorrarnos bastante trabajo (aunque no ten\u00edamos forma de saber esto previamente). Ejercicio 4. Optimizar secuencia a insertar en base a la tabla de codones Ya casi estamos. En este momento tenemos la tabla de frecuencia de uso de codones para E. coli BL21 y queremos aplicar dichos codones a las 3 secuencias quim\u00e9ricas que creamos en el Ejercicio 1 , es decir, codificar una secuencia amionac\u00eddica de planta en la forma m\u00e1s \u00f3ptima para su traducci\u00f3n en E. coli . Para organizar un poco los archivos volvemos a recomendar crear una carpeta para este ejercicio, por ejemplo ~/Documentos/TP_02/EJ_4 . Dentro de la carpeta copien los siguientes archivos: VpVAN-FLAG-tag.fasta (creado en el Ejercicio 1) VpVAN-His-tag.fasta (creado en el Ejercicio 1) VpVAN-MBP-tag.fasta (creado en el Ejercicio 1) Elijan alguno de los archivos .cusp creados en el Ejercicio 3, copienlo a la nueva carpeta y cambienl\u00e9 el nombre a ecoli_BL21_codon_table.cusp . Ahora bien, para hacer esta optimizaci\u00f3n de secuencias podemos usar otro de los programas de EMBOSS llamado backtranseq . Este programa toma una secuencia de amino\u00e1cidos correspondiente a una prote\u00edna de inter\u00e9s y una tabla de frecuencia de uso de codones y usa ambos para hacer una traducci\u00f3n inversa desde la secuencia prote\u00edca hacia la secuencia de ADN que, con mayor probabilidad, le dio origen. Es decir, backtranseq devuelve una secuencia de ADN a partir de una secuencia de amino\u00e1cidos. Este comando se usa: backtranseq -auto -sequence ARCHIVO_PROTEINA_FASTA -cfile ARCHIVO_CUSP -outfile ARCHIVO_SALIDA_ADN_FASTA Corran este comando 3 veces pas\u00e1ndole los archivos correctos y creen los siguientes archivos (si quieren pueden hacer script con un for each , pero no hace falta): Ecoli-DNA-VpVAN-FLAG-tag.fasta Ecoli-DNA-VpVAN-His-tag.fasta Ecoli-DNA-VpVAN-MBP-tag.fasta Tip De hacerlo a mano, aca van a tener que ejecutar tres comandos muy similares. Recuerden que pueden usar Up y Down en su terminal para navegar por los ultimos comandos utilizados y modificar lo necesario, as\u00ed como Tab para autocompletar nombres de archivos. Tambi\u00e9n puede serles \u00fatiles la tecla Home ( Inicio ) y End ( Fin ) para moverse al principio o al final del comando que est\u00e1n editando. Ejercicio 5. Agregar enzimas de restricci\u00f3n El \u00faltimo paso es agregar los sitios de corte de enzimas de restricci\u00f3n a los costados de mi secuencia quim\u00e9rica, pero antes de eso tengo que asegurarme que dichas enzimas no tengan sitios de corte dentro de mi secuencia. Probablemente ya no les sorprenda que existe un programa de EMBOSS para hacer esto llamado remap ; sin embargo, dicho programa necesita que previamente le hayamos pasado a EMBOSS una base de datos de enzimas de restricci\u00f3n. En los materiales de trabajo van a encontrar dos archivos llamados proto.207 y withrefm.207 que contienen la informaci\u00f3n para crear la base de datos de enzimas de restricci\u00f3n. Copienlos a la carpeta donde estan trabajando y corran el comando: rebaseextract -infile withrefm.207 -protofile proto.207 Este comando les va a tirar un error, pero no porque est\u00e9 mal escrito. El problema es que este comando quiere editar archivos que no son del usuario ibioinfo , por lo que en un principio no tenemos permisos para editarlos. En estos casos hay que agregar el prefijo sudo y puede ser que Lubuntu les pida la contrase\u00f1a (parece que no escribe nada, pero eso es por seguridad, si se las pide escriban \"unsam\" y aprieten Enter ). Asi que corran: sudo rebaseextract -infile withrefm.207 -protofile proto.207 Info Solo para que sepan, los archivos proto.207 y withrefm.207 se pueden descargar de aca o aca usando wget (con los links anteriores van a bajar un \u00edndice general y luego tienen que pasarle a wget el link de los archivos que quieran). Dependiendo de cuando vayan a esa p\u00e1gina puede ser que encuentren versiones incluso mas recientes. Ahora que ya tenemos la base de datos configurada podemos usar remap , pero antes veamos un poco mas informaci\u00f3n sobre nuestras enzimas de restricci\u00f3n. Usando grep busquen dentro del archivo proto.207 a nuestras enzimas de restricci\u00f3n de inter\u00e9s ( BamHI y HindIII ). \u00bfQu\u00e9 longitud tienen los sitios de restricci\u00f3n de BamHI y HindIII ? \u00bfQu\u00e9 piensan que significa el s\u00edmbolo ^ en el sitio de restricci\u00f3n? (pueden buscar informaci\u00f3n sobre dichas enzimas online y se van a dar cuenta enseguida) Ahora que sabemos un poco m\u00e1s sobre nuestras enzimas vamos a usar el comando remap con las siguientes opciones: remap -auto -sequence ARCHIVO_ADN_FASTA -width 80 -commercial -sitelen 6 -frame 1 -enzymes all -outfile ARCHIVO_SALIDA_REMAP Donde: -auto hace que remap use los par\u00e1metros por defecto y no nos consulte cuales usar. -width indica el ancho de secuencia a mostrar en el archivo de salida. -commercial analiza solo las enzimas de restricci\u00f3n de uso comercial (entre las que se encuentran nuestras enzimas de inter\u00e9s). -sitelen indica el m\u00ednimo de longitud del sitio de restricci\u00f3n (como sabemos que los sitios de restricci\u00f3n de nuestras enzimas de inter\u00e9s tienen 6 amino\u00e1cidos ponemos ese n\u00famero). frame indica el marco de lectura a traducir (ya que el output tambien va a dar informaci\u00f3n a nivel prote\u00edna). En nuestro caso el frame es 1 (estamos en la hebra codificante y hay que traducir a partir del primer nucle\u00f3tido). enzymes indica los nombres de las enzimas a probar. Si bien podr\u00edamos haber puesto nuestras enzimas de inter\u00e9s, ponemos all para ver m\u00e1s informaci\u00f3n del output. Corran este comando 3 veces pas\u00e1ndole los archivos correctos y creen los siguientes archivos: enzimas_FLAG.out enzimas_His.out enzimas_MBP.out Una vez creados, abran los archivos con Leafpad . \u00bfEntienden lo que simboliza el archivo? (es necesario que esten usando la fuente Ubuntu Mono en Leafpad para verlo bien) Busquen nuestras enzimas de restricci\u00f3n de inter\u00e9s. \u00bfLas encuentran? \u00bfEn que categor\u00eda est\u00e1n? \u00bfSe pueden usar entonces estas enzimas de restricci\u00f3n para insertar nuestra secuencia en un pl\u00e1smido? \u00bfHay alg\u00fan tag de los tres que estabamos considerando que no se pueda usar debido a las enzimas de restricci\u00f3n que elegimos? Elijan el tag que quieren usar, copien su construcci\u00f3n Ecoli-DNA-VpVAN-???-tag.fasta a un nuevo archivo y luego cambienl\u00e9 el nombre a secuencia_final.fasta . Abran secuencia_final.fasta en Leafpad y agreguen a mano el sitio de restricci\u00f3n de BamHI al principio y el de HindIII al final. \u00a1Felicitaciones, tenemos nuestra secuencia lista para mandar a secuenciar! Bibliograf\u00eda Online Insertar secuencias de ADN en pl\u00e1smidos Cromatograf\u00eda de afinidad","title":"TP 2 - EMBOSS"},{"location":"practicos/TP02_EMBOSS/#tp-2-emboss","text":"Materiales","title":"TP 2"},{"location":"practicos/TP02_EMBOSS/#slides-mostrados-en-la-clase","text":"Cierre TP","title":"Slides mostrados en la clase"},{"location":"practicos/TP02_EMBOSS/#videos-de-la-clase-grabada","text":"Introducci\u00f3n al TP Cierre TP","title":"Videos de la clase grabada"},{"location":"practicos/TP02_EMBOSS/#software-a-usar","text":"EMBOSS (ya instalado en la VM).","title":"Software a usar"},{"location":"practicos/TP02_EMBOSS/#objetivos","text":"Familiarizarse con el uso de herramientas bioinform\u00e1ticas por l\u00ednea de comandos. Familiarizarse con los formatos caracter\u00edsticos de datos biol\u00f3gicos. Practicar conceptos aprendidos en el TP 1.","title":"Objetivos"},{"location":"practicos/TP02_EMBOSS/#introduccion-al-tema","text":"EMBOSS es una suite bioinform\u00e1tica creada y mantenida por EMBnet que incluye una multitud de herramientas elementales en biolog\u00eda molecular y gen\u00e9tica. Algunas ventajas de EMBOSS son: Maneja informaci\u00f3n biol\u00f3gica en varios formatos para realizar distintos tipos de tareas. Es muy r\u00e1pida, lo cual significa que es computacionalmente escalable. Si bien cada uno de sus programas individuales podr\u00edan ser reemplazados por otros softwares o un script propio, EMBOSS agrupa todos estos programas en un solo paquete y le provee al usuario una interfaz unificada para todas las aplicaciones. A continuaci\u00f3n se encuentra una lista de 256 programas que contiene EMBOSS y un resumen corto de lo que hace cada uno: Programas de EMBOSS Program name Description aaindexextract Extract amino acid property data from AAINDEX abiview Display the trace in an ABI sequencer file acdc Test an application ACD file acdpretty Correctly reformat an application ACD file acdtable Generate an HTML table of parameters from an application ACD file acdtrace Trace processing of an application ACD file (for testing) acdvalid Validate an application ACD file aligncopy Read and write alignments aligncopypair Read and write pairs from alignments antigenic Find antigenic sites in proteins assemblyget Get assembly of sequence reads backtranambig Back-translate a protein sequence to ambiguous nucleotide sequence backtranseq Back-translate a protein sequence to a nucleotide sequence banana Plot bending and curvature data for B-DNA biosed Replace or delete sequence sections btwisted Calculate the twisting in a B-DNA sequence cachedas Generate server cache file for DAS servers or for the DAS registry cachedbfetch Generate server cache file for Dbfetch/WSDbfetch data sources cacheebeyesearch Generate server cache file for EB-eye search domains cacheensembl Generate server cache file for an Ensembl server cai Calculate codon adaptation index chaos Draw a chaos game representation plot for a nucleotide sequence charge Draw a protein charge plot checktrans Report STOP codons and ORF statistics of a protein chips Calculate Nc codon usage statistic cirdna Draw circular map of DNA constructs codcmp Codon usage table comparison codcopy Copy and reformat a codon usage table coderet Extract CDS, mRNA and translations from feature tables compseq Calculate the composition of unique words in sequences cons Create a consensus sequence from a multiple alignment consambig Create an ambiguous consensus sequence from a multiple alignment cpgplot Identify and plot CpG islands in nucleotide sequence(s) cpgreport Identify and report CpG-rich regions in nucleotide sequence(s) cusp Create a codon usage table from nucleotide sequence(s) cutgextract Extract codon usage tables from CUTG database cutseq Remove a section from a sequence dan Calculate nucleic acid melting temperature dbiblast Index a BLAST database dbifasta Index a fasta file database dbiflat Index a flat file database dbigcg Index a GCG formatted database dbtell Display information about a public database dbxcompress Compress an uncompressed dbx index dbxedam Index the EDAM ontology using b+tree indices dbxfasta Index a fasta file database using b+tree indices dbxflat Index a flat file database using b+tree indices dbxgcg Index a GCG formatted database using b+tree indices dbxobo Index an obo ontology using b+tree indices dbxreport Validate index and report internals for dbx databases dbxresource Index a data resource catalogue using b+tree indices dbxstat Dump statistics for dbx databases dbxtax Index NCBI taxonomy using b+tree indices dbxuncompress Uncompress a compressed dbx index degapseq Remove non-alphabetic (e.g. gap) characters from sequences density Draw a nucleic acid density plot descseq Alter the name or description of a sequence diffseq Compare and report features of two similar sequences distmat Create a distance matrix from a multiple sequence alignment dotmatcher Draw a threshold dotplot of two sequences dotpath Draw a non-overlapping wordmatch dotplot of two sequences dottup Display a wordmatch dotplot of two sequences dreg Regular expression search of nucleotide sequence(s) drfinddata Find public databases by data type drfindformat Find public databases by format drfindid Find public databases by identifier drfindresource Find public databases by resource drget Get data resource entries drtext Get data resource entries complete text edamdef Find EDAM ontology terms by definition edamhasinput Find EDAM ontology terms by has_input relation edamhasoutput Find EDAM ontology terms by has_output relation edamisformat Find EDAM ontology terms by is_format_of relation edamisid Find EDAM ontology terms by is_identifier_of relation edamname Find EDAM ontology terms by name edialign Local multiple alignment of sequences einverted Find inverted repeats in nucleotide sequences embossdata Find and retrieve EMBOSS data files embossupdate Checks for more recent updates to EMBOSS embossversion Report the current EMBOSS version number emma Multiple sequence alignment (ClustalW wrapper) emowse Search protein sequences by digest fragment molecular weight entret Retrieve sequence entries from flatfile databases and files epestfind Find PEST motifs as potential proteolytic cleavage sites eprimer3 Pick PCR primers and hybridization oligos eprimer32 Pick PCR primers and hybridization oligos equicktandem Find tandem repeats in nucleotide sequences est2genome Align EST sequences to genomic DNA sequence etandem Find tandem repeats in a nucleotide sequence extractalign Extract regions from a sequence alignment extractfeat Extract features from sequence(s) extractseq Extract regions from a sequence featcopy Read and write a feature table featmerge Merge two overlapping feature tables featreport Read and write a feature table feattext Return a feature table original text findkm Calculate and plot enzyme reaction data freak Generate residue/base frequency table or plot fuzznuc Search for patterns in nucleotide sequences fuzzpro Search for patterns in protein sequences fuzztran Search for patterns in protein sequences (translated) garnier Predict protein secondary structure using GOR method geecee Calculate fractional GC content of nucleic acid sequences getorf Find and extract open reading frames (ORFs) godef Find GO ontology terms by definition goname Find GO ontology terms by name helixturnhelix Identify nucleic acid-binding motifs in protein sequences hmoment Calculate and plot hydrophobic moment for protein sequence(s) iep Calculate the isoelectric point of proteins infoalign Display basic information about a multiple sequence alignment infoassembly Display information about assemblies infobase Return information on a given nucleotide base inforesidue Return information on a given amino acid residue infoseq Display basic information about sequences isochore Plot isochores in DNA sequences jaspextract Extract data from JASPAR jaspscan Scan DNA sequences for transcription factors lindna Draw linear maps of DNA constructs listor Write a list file of the logical OR of two sets of sequences makenucseq Create random nucleotide sequences makeprotseq Create random protein sequences marscan Find matrix/scaffold recognition (MRS) signatures in DNA sequences maskambignuc Mask all ambiguity characters in nucleotide sequences with N maskambigprot Mask all ambiguity characters in protein sequences with X maskfeat Write a sequence with masked features maskseq Write a sequence with masked regions matcher Waterman-Eggert local alignment of two sequences megamerger Merge two large overlapping DNA sequences merger Merge two overlapping sequences msbar Mutate a sequence mwcontam Find weights common to multiple molecular weights files mwfilter Filter noisy data from molecular weights file needle Needleman-Wunsch global alignment of two sequences needleall Many-to-many pairwise alignments of two sequence sets newcpgreport Identify CpG islands in nucleotide sequence(s) newcpgseek Identify and report CpG-rich regions in nucleotide sequence(s) newseq Create a sequence file from a typed-in sequence nohtml Remove mark-up (e.g. HTML tags) from an ASCII text file noreturn Remove carriage return from ASCII files nospace Remove whitespace from an ASCII text file notab Replace tabs with spaces in an ASCII text file notseq Write to file a subset of an input stream of sequences nthseq Write to file a single sequence from an input stream of sequences nthseqset Read and write (return) one set of sequences from many octanol Draw a White-Wimley protein hydropathy plot oddcomp Identify proteins with specified sequence word composition ontocount Count ontology term(s) ontoget Get ontology term(s) ontogetcommon Get common ancestor for terms ontogetdown Get ontology term(s) by parent id ontogetobsolete Get ontology ontology terms ontogetroot Get ontology root terms by child identifier ontogetsibs Get ontology term(s) by id with common parent ontogetup Get ontology term(s) by id of child ontoisobsolete Report whether an ontology term id is obsolete ontotext Get ontology term(s) original full text palindrome Find inverted repeats in nucleotide sequence(s) pasteseq Insert one sequence into another patmatdb Search protein sequences with a sequence motif patmatmotifs Scan a protein sequence with motifs from the PROSITE database pepcoil Predict coiled coil regions in protein sequences pepdigest Report on protein proteolytic enzyme or reagent cleavage sites pepinfo Plot amino acid properties of a protein sequence in parallel pepnet Draw a helical net for a protein sequence pepstats Calculate statistics of protein properties pepwheel Draw a helical wheel diagram for a protein sequence pepwindow Draw a hydropathy plot for a protein sequence pepwindowall Draw Kyte-Doolittle hydropathy plot for a protein alignment plotcon Plot conservation of a sequence alignment plotorf Plot potential open reading frames in a nucleotide sequence polydot Draw dotplots for all-against-all comparison of a sequence set preg Regular expression search of protein sequence(s) prettyplot Draw a sequence alignment with pretty formatting prettyseq Write a nucleotide sequence and its translation to file primersearch Search DNA sequences for matches with primer pairs printsextract Extract data from PRINTS database for use by pscan profit Scan one or more sequences with a simple frequency matrix prophecy Create frequency matrix or profile from a multiple alignment prophet Scan one or more sequences with a Gribskov or Henikoff profile prosextract Process the PROSITE motif database for use by patmatmotifs pscan Scan protein sequence(s) with fingerprints from the PRINTS database psiphi Calculates phi and psi torsion angles from protein coordinates rebaseextract Process the REBASE database for use by restriction enzyme applications recoder Find restriction sites to remove (mutate) with no translation change redata Retrieve information from REBASE restriction enzyme database refseqget Get reference sequence remap Display restriction enzyme binding sites in a nucleotide sequence restover Find restriction enzymes producing a specific overhang restrict Report restriction enzyme cleavage sites in a nucleotide sequence revseq Reverse and complement a nucleotide sequence seealso Find programs with similar function to a specified program seqcount Read and count sequences seqmatchall All-against-all word comparison of a sequence set seqret Read and write (return) sequences seqretsetall Read and write (return) many sets of sequences seqretsplit Read sequences and write them to individual files seqxref Retrieve all database cross-references for a sequence entry seqxrefget Retrieve all cross-referenced data for a sequence entry servertell Display information about a public server showalign Display a multiple sequence alignment in pretty format showdb Display information on configured databases showfeat Display features of a sequence in pretty format showorf Display a nucleotide sequence and translation in pretty format showpep Display protein sequences with features in pretty format showseq Display sequences with features in pretty format showserver Display information on configured servers shuffleseq Shuffle a set of sequences maintaining composition sigcleave Report on signal cleavage sites in a protein sequence silent Find restriction sites to insert (mutate) with no translation change sirna Find siRNA duplexes in mRNA sixpack Display a DNA sequence with 6-frame translation and ORFs sizeseq Sort sequences by size skipredundant Remove redundant sequences from an input set skipseq Read and write (return) sequences, skipping first few splitsource Split sequence(s) into original source sequences splitter Split sequence(s) into smaller sequences stretcher Needleman-Wunsch rapid global alignment of two sequences stssearch Search a DNA database for matches with a set of STS primers supermatcher Calculate approximate local pair-wise alignments of larger sequences syco Draw synonymous codon usage statistic plot for a nucleotide sequence taxget Get taxon(s) taxgetdown Get descendants of taxon(s) taxgetrank Get parents of taxon(s) taxgetspecies Get all species under taxon(s) taxgetup Get parents of taxon(s) tcode Identify protein-coding regions using Fickett TESTCODE statistic textget Get text data entries textsearch Search the textual description of sequence(s) tfextract Process TRANSFAC transcription factor database for use by tfscan tfm Display full documentation for an application tfscan Identify transcription factor binding sites in DNA sequences tmap Predict and plot transmembrane segments in protein sequences tranalign Generate an alignment of nucleic coding regions from aligned proteins transeq Translate nucleic acid sequences trimest Remove poly-A tails from nucleotide sequences trimseq Remove unwanted characters from start and end of sequence(s) trimspace Remove extra whitespace from an ASCII text file twofeat Find neighbouring pairs of features in sequence(s) union Concatenate multiple sequences into a single sequence urlget Get URLs of data resources variationget Get sequence variations vectorstrip Remove vectors from the ends of nucleotide sequence(s) water Smith-Waterman local alignment of sequences whichdb Search all sequence databases for an entry and retrieve it wobble Plot third base position variability in a nucleotide sequence wordcount Count and extract unique words in molecular sequence(s) wordfinder Match large sequences against one or more other sequences wordmatch Find regions of identity (exact matches) of two sequences wossdata Find programs by EDAM data wossinput Find programs by EDAM input data wossname Find programs by keywords in their short description wossoperation Find programs by EDAM operation wossoutput Find programs by EDAM output data wossparam Find programs by EDAM parameter wosstopic Find programs by EDAM topic yank Add a sequence reference (a full USA) to a list file Como obviamente es imposible acordarse de todos estos programas, EMBOSS tiene un comando llamado wossname que permite listar comandos que tengan cierta palabra en su descripci\u00f3n (en ingl\u00e9s). Abran la consola y prueben correr: wossname dna Por otro lado, una vez que encuentran un programa que les interesa pueden leer detalladamente como funciona usando el comando tfm ( The Funny? Full? Manual ). Por ejemplo pueden ejecutar: tfm jaspscan El texto que aparece funciona similar al comando less que vimos en el TP 1, donde Space pasa a la pr\u00f3xima p\u00e1gina y apretando Q deja de leerlo. Como mencionamos antes es posible hacer bioinform\u00e1tica sin usar EMBOSS, ya sea porque queremos controlar hasta el \u00faltimo detalle que hace nuestro programa, porque queremos agregar alguna opci\u00f3n que EMBOSS no tiene, o simplemente porque era una tarea simple y no quer\u00edamos aprender a usar un programa de EMBOSS para hacerla. Son todas razones v\u00e1lidas. Lo que queremos que se lleven hoy es que EMBOSS existe y que puede hacer algunas tareas que les van a resultar \u00fatiles en el d\u00eda a d\u00eda de hacer bioinform\u00e1tica. Si no estan usando la Maquina Virtual de Introducci\u00f3n a la Bioinform\u00e1tica lean esto: EMBOSS y su documentaci\u00f3n est\u00e1 ya instalado en la m\u00e1quina virtual que les pasamos. Si no estas usando la m\u00e1quina virtual tenes que instalarlo usando: sudo apt-get install emboss emboss-data emboss-doc","title":"Introduccion al Tema"},{"location":"practicos/TP02_EMBOSS/#aplicaciones-en-biotecnologia","text":"En el TP de hoy vamos a familiarizarnos con EMBOSS y algunas herramientas del paquete, aplic\u00e1ndolas al dise\u00f1o de una estrategia de clonado, puntualmente para dise\u00f1ar/optimizar prote\u00ednas para expresi\u00f3n recombinante heter\u00f3loga. En los \u00faltimos a\u00f1os se ha simplificado considerablemente la ejecuci\u00f3n del proceso de clonado/expresi\u00f3n. Esto se debe a la aparici\u00f3n de m\u00faltiples herramientas de Ingenieria Gen\u00e9tica y a la posibilidad de sintetizar largas secuencias de \u00e1cidos nucleicos in vitro , lo que quita el peso de levantar un gen de inter\u00e9s o el riesgo de meter errores durante la PCR que ejecutamos para hacerlo. Una de las industrias biotecnol\u00f3gicas m\u00e1s antigua es la industria alimenticia. Centenares de microorganismos distintos y decenas de enzimas son utilizados en esta industria para distintos procesos. Algunos de estos procesos son muy complejos, como la fermentaci\u00f3n de un vino, mientras que otros son simples y puntuales, como la degradaci\u00f3n de lactosa en productos l\u00e1cteos para personas intolerantes a este az\u00facar. Los procesos enzim\u00e1ticos simples pueden resolverse f\u00e1cilmente mediante la producci\u00f3n de la enzima de inter\u00e9s en forma heter\u00f3loga. Con el fin de dar rienda suelta a nuestro emprendedor interior, montaremos las bases de una empresa biotecnol\u00f3gica: vamos a producir enzimas. La primera enzima que queremos producir es la VpVan , la cual es la encargada de convertir el \u00e1cido fer\u00falico en vanillina . La vainillina es un compuesto de alto inter\u00e9s econ\u00f3mico debido a su uso como saborizante (a que no adivinan que sabor tiene).","title":"Aplicaciones en Biotecnolog\u00eda"},{"location":"practicos/TP02_EMBOSS/#archivos-fasta","text":"Esta enzima ha sido aislada (y secuenciada) a partir de Vanilla planifolia . Encontrar\u00e1n la secuencia correspondiente entre sus materiales de trabajo ( VpVAN.fasta ) y m\u00e1s informaci\u00f3n sobre el descubrimiento en este paper . Por si no lo saben o no lo recuerdan, el formato FASTA es la forma m\u00e1s usada para trabajar secuencias biol\u00f3gicas (ADN, ARN, amino\u00e1cidos) en forma digital. Son archivos de texto plano, donde se asume un formato muy sencillo de interpretar para el ojo humano: Un archivo FASTA tiene dos elementos importantes: Header : Est\u00e1 indicado con un > . Es la l\u00ednea con el nombre o identificador de la secuencia. Puede contener informaci\u00f3n adicional como alguna descripci\u00f3n extra sobre la secuencia, tal como las condiciones en que fue obtenida u otra descripci\u00f3n opcional. Secuencia : El resto de las l\u00edneas que contin\u00faan contienen la secuencia propiamente dicha. El largo de cada fila de la secuencia no significa nada; una secuencia de 800 amino\u00e1cidos puede ser escrita en una sola l\u00ednea de 800 amino\u00e1cidos o en 10 l\u00edneas de 80 amino\u00e1cidos cada una. La secuencia sigue hasta el pr\u00f3ximo > o hasta el final del archivo, lo que pase primero. Info Cuando un FASTA tiene m\u00e1s de una secuencia se lo denomina multiFASTA . En los archivos multiFASTA cada secuencia tiene su header y su secuencia propiamente dicha.","title":"Archivos FASTA"},{"location":"practicos/TP02_EMBOSS/#repaso-biologico","text":"Nuestro objetivo en esta gu\u00eda va a ser dise\u00f1ar una secuencia de ADN sint\u00e9tico que: Exprese VpVan Tenga sitios de corte para enzimas de restricci\u00f3n para que pueda ser insertado en un pl\u00e1smido o vector de expresi\u00f3n de un organismo hu\u00e9sped. En este caso, dichos sitios de corte van a pertenecer a diferentes enzimas de restricci\u00f3n para facilitar la inserci\u00f3n del gen en el sentido correcto Marque a VpVan de alguna forma para facilitar su posterior purificaci\u00f3n A continuaci\u00f3n vamos a dar una versi\u00f3n super resumida de los conceptos anteriores. Si ya saben como funciona todo lo mencionado pueden ir a la pr\u00f3xima secci\u00f3n ( Bases del experimento ). Repaso biol\u00f3gico - Pl\u00e1smidos","title":"Repaso biol\u00f3gico"},{"location":"practicos/TP02_EMBOSS/#plasmidos","text":"Los pl\u00e1smidos son mol\u00e9culas de ADN de forma circular presentes principalmente en bacterias, arqueas y levaduras. Estas mol\u00e9culas se encuentran fuera de los cromosomas y se replican de manera aut\u00f3noma. Debido a estas caracter\u00edsticas, es posible generar pl\u00e1smidos artificiales con el objetivo de amplificar ( vector de clonaci\u00f3n ) o de expresar ( vector de expresi\u00f3n ) un gen de inter\u00e9s. Esto generalmente se realiza cuando la expresi\u00f3n de dicho gen en su organismo original no es factible, ya sea por problemas de volumen, log\u00edstica o \u00e9tica. Los principales componentes de vector de expresi\u00f3n son: Origen de la replicaci\u00f3n: punto inicial para la replicaci\u00f3n del pl\u00e1smido Gen de resistencia a antibi\u00f3ticos: gen que se expresa y da resistencia al organismo hu\u00e9sped, permite quedarnos solo con los organismos que tienen el pl\u00e1smido dentro de ellos Promotor: controla la transcripci\u00f3n de una determinada secuencia (en este caso el gen insertado) Sitio de restricci\u00f3n: secuencia que es cortada por una enzima de restricci\u00f3n y donde ser\u00e1 insertado el gen de inter\u00e9s (m\u00e1s de esto a continuaci\u00f3n) Repaso biol\u00f3gico - Enzimas de Restricci\u00f3n","title":"Pl\u00e1smidos"},{"location":"practicos/TP02_EMBOSS/#enzimas-de-restriccion","text":"Las enzimas de restricci\u00f3n son prote\u00ednas que reconocen una secuencia espec\u00edfica de nucle\u00f3tidos dentro de una mol\u00e9cula de ADN y cortan el ADN en ese punto en concreto o en un punto cercano. A esas secuencias de ADN se las denomina sitios de restricci\u00f3n y tienen entre cuatro a seis pares de bases. Hay dos grandes grupos de enzimas de restricci\u00f3n, aquellas que dejan extremos cohesivos y aquellas que dejan extremos romos: Al momento de insertar genes en pl\u00e1smidos se usan generalmente enzimas de restricci\u00f3n que dejan extremos cohesivos ya que facilitan la inserci\u00f3n del gen debido a su especificidad y a que pueden volverse a unir espontaneamente. La idea detr\u00e1s de su uso es colocar un sitio de restricci\u00f3n en el pl\u00e1smido y colocar el mismo sitio de restricci\u00f3n a cada lado del gen de inter\u00e9s (en el ADN que uno sintetiza). Luego los pl\u00e1smidos vacios se colocan en una soluci\u00f3n con el ADN sint\u00e9tico y se les agrega la enzima de restricci\u00f3n correspondiente que va a cortar el ADN dejando los extremos cohesivos en cada sitio de restricci\u00f3n. Como el sitio de restricci\u00f3n es el mismo en el pl\u00e1stido y en la secuencia de ADN, es posible entonces que el ADN sint\u00e9tico se insert\u00e9 en el pl\u00e1smido, ya sea espontaneamente o ayudado por una ligasa. Esta p\u00e1gina tiene muy buenos esquemas sobre el proceso. En el experimento anterior, luego de cortar el sitio de restricci\u00f3n con la enzima, pueden pasar tres cosas: El pl\u00e1smido se vuelve a cerrar sin ningun inserto Se inserta el gen de inter\u00e9s en la direcci\u00f3n correcta (respecto al promotor en el pl\u00e1smido) Se inserta el gen de inter\u00e9s en la direcci\u00f3n contraria (respecto al promotor en el pl\u00e1smido) Es posible evitar el caso donde el gen se inserta en la direcci\u00f3n contraria combinando 2 enzimas de restricci\u00f3n diferentes, donde ahora va a haber 2 sitios de restricci\u00f3n en el pl\u00e1smido (uno para cada enzima) y los dos sitios de restricci\u00f3n en el ADN sint\u00e9tico van a ser diferentes (uno para cada enzima, en el mismo orden que en el pl\u00e1smido). Si bien en esta versi\u00f3n no es posible que el gen sea insertado en la direcci\u00f3n contraria, s\u00ed es posible que se vuelva a insertar el fragmento de pl\u00e1smido entre los sitios de restricci\u00f3n, pero hay formas de controlar estos casos. Cuando usamos 2 enzimas de reestricci\u00f3n en esta forma decimos que estamos \"clonando en forma direccional\". Danger Es importante cuando se usan enzimas de restricci\u00f3n asegurarse que no haya ning\u00fan sitio de corte para las enzimas elegidas en el pl\u00e1smido ni en el ADN sint\u00e9tico fuera de los sitios involucrados en el proceso de inserci\u00f3n (ya que de existir tambi\u00e9n ser\u00e1n cortados y la inserci\u00f3n fracasar\u00e1). Repaso biol\u00f3gico - Purificaci\u00f3n y Tags","title":"Enzimas de Restricci\u00f3n"},{"location":"practicos/TP02_EMBOSS/#purificacion-y-tags","text":"Una vez que nuestros organismos hu\u00e9sped tienen el vector de expresi\u00f3n con el gen de inter\u00e9s, se los deja crecer, reproducirse y expresar la prote\u00edna de inter\u00e9s en grandes cantidades. Una vez hecho esto, es necesario extraer esa prote\u00edna de la soluci\u00f3n, lo que no es trivial. Hay varias formas de purificar prote\u00ednas y una de ellas es la cromatograf\u00eda por afinidad, la cual se basa en la uni\u00f3n reversible entre el analito de inter\u00e9s (en nuestro caso la VpVan ) y un ligando espec\u00edfico, inmovilizado en un soporte s\u00f3lido inerte. Cuando la muestra pasa por la columna, s\u00f3lo son retenidas las mol\u00e9culas que se unen de manera selectiva al ligando por afinidad y las que no se unen avanzan con la fase m\u00f3vil. La figura a continuaci\u00f3n muestra un ejemplo donde se usan anticuerpos inmovilizados en una columna para purificar a la prote\u00edna roja del resto de la soluci\u00f3n: Uno podr\u00eda asumir entonces que para poder construir estas columnas es necesario conseguir un ligando que reconozca a nuestra prote\u00edna de inter\u00e9s. Si bien esto es te\u00f3ricamente cierto, como nosotros estamos sintetizando el ADN desde cero podemos pensar lateralmente y agregarle a nuestra prote\u00edna una secuenc\u00eda aminoac\u00eddica en uno de sus extremos para la cual ya conozcamos ligandos. Estas secuencias pueden ser desde pocos amino\u00e1cidos hasta a prote\u00ednas peque\u00f1as y son denominadas tags .","title":"Purificaci\u00f3n y Tags"},{"location":"practicos/TP02_EMBOSS/#bases-del-experimento","text":"Volviendo a nuestro experimento, queremos insertar el gen de VpVan en un vector de expresi\u00f3n. Nuestro organismo hu\u00e9sped es: E. coli BL21 Como queremos clonar en forma direccional tenemos que usar dos enzimas de restricci\u00f3n . Ellas son: BamHI HindIII Al momento de purificar necesitamos agregarle un tag a la prote\u00edna. Vamos a probar 3 tags diferentes: FLAG-tag His-tag MBP-tag Por cuestiones de practicidad, todos los tags van a estar en el C-terminal. En los siguientes ejercicios vamos a: Ejercicio 1: Generar secuencias quim\u00e9ricas VpVan-Tag agregando diferentes tags de inter\u00e9s a la secuencia prote\u00edca de VpVan Ejercicio 2: Obtener el genoma del organismo hu\u00e9sped E. coli BL21 (necesario para el Ejercicio 3 ) Ejercicio 3: Generar una tabla de frecuencia de uso de codones del organismo hu\u00e9sped Ejercicio 4: Generar la secuencia nucleot\u00eddica VpVan-Tag con los codones optimizados para el organismo hu\u00e9sped Ejercicio 5: Verificar que no hayan quedado sitios de corte para nuestras enzimas de restricci\u00f3n dentro de la secuencia VpVan-Tag optimizada y luego agregar los sitios de restricci\u00f3n en los bordes de la secuencia","title":"Bases del experimento"},{"location":"practicos/TP02_EMBOSS/#ejercicio-1-secuencias-aminoacidicas-vpvan-tag","text":"Vamos a generar las secuencias de amino\u00e1cidos quim\u00e9ricas VpVan-Tag (donde Tag = FLAG/His/MBP). Para esto van a necesitar los siguientes archivos que se encuentras en sus materiales de trabajo: VpVan.fasta FLAG-tag.fasta His-tag.fasta MBP-tag.fasta Es altamente recomendado que creen diferentes carpetas para los diferentes TPs y en algunos casos para los diferentes ejercicios (especialemente en este). El nombre y la ubicaci\u00f3n lo pueden decidir ustedes, pero un ejemplo para este ejercicio ser\u00eda ~/Documentos/TP_02/EJ_1 . Una vez creada la carpeta para este ejercicio, muevan los cuatro archivos anteriores a dicha carpeta. Tip Recuerden que es preferible no usar espacios al crear directorios o archivos Nuestro objetivo ahora es crear 3 nuevos archivos FASTA que contengan las diferentes construcciones ( VpVan + cada uno de los tags). Vamos a llamarlos VpVan-FLAG-tag.fasta y similar (reemplazando el nombre del tag en cada caso). Ahora bien, como son solo 3 tags esto se podr\u00eda hacer a mano copiando y pegando, pero es un buen momento para profundizar en dos conceptos que aprendimos la clase pasada: scripts y ciclos . Creen un archivo vacio de texto en esa carpeta y llamenl\u00f3 agregar_tags.sh . Dentr\u00f3 del archivo pongan lo siguiente: C\u00f3digo C\u00f3digo con comentarios vpvan_sequence = ` cat VpVAN.fasta | grep -v \">\" ` lista_de_archivos_tags = ` ls *-tag.fasta ` for archivo_tag in $lista_de_archivos_tags do tag_sequence = ` cat $archivo_tag | grep -v \">\" ` new_header = \">VpVAN- $archivo_tag \" combined_sequence = \" $vpvan_sequence$tag_sequence \" echo \" $new_header \" > VpVAN- $archivo_tag echo \" $combined_sequence \" >> VpVAN- $archivo_tag done # Aca estamos ejecutando comandos de Linux y guardando su output en una variable # En estos casos hay que rodear a los comandos con ` (acento grave o comilla invertida) # Leemos el FASTA de VpVAN y nos quedamos solo con la secuencia # (estamos removiendo con grep cualquier linea que tenga >, que aca es solo el header) vpvan_sequence = ` cat VpVAN.fasta | grep -v \">\" ` # Creamos una lista que contiene a todos los archivos que terminan con -tag.fasta # (esto va a mirar solo archivos que est\u00e9n en la carpeta donde se corre el script) lista_de_archivos_tags = ` ls *-tag.fasta ` # Este es una estructura a la que llamamos *for each* en el TP 1. Es un *for*, pero en vez de tener # una cantidad determinada de ciclos, recorre cada uno de los elementos de una lista for archivo_tag in $lista_de_archivos_tags do # Leemos el FASTA del tag y nos quedamos solo con la secuencia tag_sequence = ` cat $archivo_tag | grep -v \">\" ` # Creamos una variable que almacene el nuevo header para la secuencia de VpVAN + tag new_header = \">VpVAN- $archivo_tag \" # Calculamos la nueva secuencia VpVAN + tag combined_sequence = \" $vpvan_sequence$tag_sequence \" # Escribimos el nuevo header y la nueva secuencia en un nuevo archivo echo \" $new_header \" > VpVAN- $archivo_tag echo \" $combined_sequence \" >> VpVAN- $archivo_tag done Como recordatorio del TP 1: cat lee archivos de texto y los escribe en la consola | desvia la salida de un programa para que funcione como entrada del siguiente grep filtra texto, quedandos\u00e9 solo con aquellas l\u00edneas que contengan un texto dado (y de usar la opci\u00f3n -v se queda solo con aquellas que no lo contengan) ls lista los archivos y carpetas dentro del directorio actual echo escribe un texto por consola > desvia la salida que \u00edria a consola hacia un archivo de texto, sobrescribiendolo >> desvia la salida que \u00edria a consola hacia un archivo de texto, sin sobreescribirlo (agrega lineas al final) for , in , do y done son todas partes del ciclo for each . El c\u00f3digo entre do y done se va a repetir por cada elemento en $lista_de_archivos_tags , donde en cada iteraci\u00f3n la variable $archivo_tag toma el valor de uno de esos elementos Hay dos cosas en este script que no vimos en el TP 1. La primera es que estamos ejecutando comandos de Bash y guardando su salida en variables. En estos casos es necesario rodear el comando con ` , llamado acento grave o comilla invertida. Por ejemplo: variable = ` comando -opciones parametro1 parametro2 ` La segunda novedad es el uso de * con el comando ls . En todo lo que es Linux el caracter * funciona como comod\u00edn, tomando cualquier valor. Esto quiere decir que ls *-tag.fasta va a listar todos los archivos cuyos nombres terminen con \"-tag.fasta\" , sin importar como empiecen (pueden probar correr el comando ls *-tag.fasta a mano en la consola y ver que devuelve). \u00bfEntienden ahora lo que hace el script? Lean la pesta\u00f1a C\u00f3digo con comentarios para aclarar cualquier duda que tengan sobre \u00e9l (y si todav\u00eda no se entiende no duden en preguntar). Ahora abran la consola y corran el script que acabamos de crear, generando as\u00ed los nuevos 3 archivos. Tip Recuerden que los script se corren con bash ARCHIVO_SCRIPT \u00a1Ya tenemos nuestras secuencias quim\u00e9ricas! Tip Este script va a dar problemas si se lo corre multiples veces. Esto se debe a que al correrlo la primera vez estamos creando m\u00e1s archivos que terminan con \"-tag.fasta\", que en una segunda corrida van a ser detectados por el ls . Si no quieren tener problemas con esto pueden agregar el siguiente c\u00f3digo luego de dicho comando: | grep -v \"VpVAN\"","title":"Ejercicio 1 - Tags"},{"location":"practicos/TP02_EMBOSS/#ejercicio-2-genoma-de-e-coli","text":"Nosotros queremos expresar el gen de un organismo en otro organismo. Si bien el c\u00f3digo gen\u00e9tico es practicamente universal, diferentes organismos pueden tener preferencia para diferentes codones que generan un mismo amino\u00e1cido. Por esta raz\u00f3n, al hacer expresi\u00f3n recombinante heter\u00f3loga es una buena idea cambiar los codones del gen de inter\u00e9s para que matcheen mejor con los codones que prefiere el organismo hu\u00e9sped (se modifica el ADN pero se sigue produciendo la misma prote\u00edna). El primer paso para realizar esta modificaci\u00f3n es conocer cuales son los codones preferidos por dicho organismo. Busquen usando el comando wossname que programas de EMBOSS trabajan con codones (recuerden que est\u00e1 en ingl\u00e9s, asi que tienen que buscar \"codon\"). Lean la descripci\u00f3n de dichos programas, \u00bfcual les parece que vamos a usar para calcular la tabla de uso de codones? Respuesta cusp , cuya descripci\u00f3n es \"Create a codon usage table from nucleotide sequence(s)\" Si leen la descripci\u00f3n del programa, ver\u00e1n que pide una secuencia de nucle\u00f3tidos, es decir, que necesitamos un FASTA del genoma completo de E. coli (ya que \u00e9ste es nuestro organismo hu\u00e9sped). Un buen lugar para obtener informaci\u00f3n de genomas, genes, y prote\u00ednas es RefSeq , que es una colecci\u00f3n curada de secuencias nucleot\u00eddicas y sus productos. En su FAQ ( Frequently Asked Questions , o preguntas frecuentes ) hay una pregunta que es b\u00e1sicamente lo que queremos hacer nosotros: How can I download RefSeq data for all complete bacterial genomes? Si bien los comandos que ellos sugieren son un poco complejos, vamos a utilizarlos y tratar de explicarlos lo mejor posible. Tip Antes de seguir les recomendamos crear una carpeta nueva para este ejercicio, por ejemplo ~/Documentos/TP_02/EJ_2 .","title":"Ejercicio 2 - Genoma de E. coli"},{"location":"practicos/TP02_EMBOSS/#refseq-paso-1-bajar-y-filtrar-la-tabla-con-los-genomas","text":"El primer paso indicado en el FAQ es descargar el archivo assembly_summary.txt y ponerlo en la carpeta de este ejercicio. Esto lo pueden hacer desde la p\u00e1gina de RefSeq a mano o abriendo la consola en la carpeta de este ejercicio y corriendo: wget ftp://ftp.ncbi.nlm.nih.gov/genomes/refseq/bacteria/assembly_summary.txt Question \u00bfQu\u00e9 piensan que hace wget ? \u00bfC\u00f3mo pueden averiguarlo si no lo saben? Warning Si el comando wget tarda mucho o ven que tiene errores bajens\u00e9 este archivo desde este link Una vez descargado ese archivo (que pesa bastante) queremos ver sus contenidos. Sabiendo que es un archivo que tiene m\u00e1s de 250.000 lineas: \u00bfQu\u00e9 comando usar\u00edan para ver que tipo de datos tiene adentro? Pruebenlo. Dado que es un archivo con muchas columnas, probablemente les cueste entender lo que est\u00e1n viendo aunque hayan usado el comando correcto. Para entender la estructura de nuestro archivo vamos a crear un archivo temporal que tenga solo las primeras 20 filas de este archivo: head -20 assembly_summary.txt > assembly_summary_temporal.tsv Lo \u00fanico que les deber\u00eda llamar la atenci\u00f3n del comando anterior es que el nuevo archivo tiene la extensi\u00f3n tsv . Esto lo mencionamos por arriba en el TP 1, pero los archivos TSV o \"Tab-Separated Values\" son archivos de texto que contienen una tabla donde sus columnas est\u00e1n separadas entre ellas por un Tab , lo cual es exactamente el caso de la tabla actual. Hagan doble click sobre el archivo assembly_summary_temporal.tsv . La extensi\u00f3n tsv en nuestra m\u00e1quina virtual est\u00e1 asociada al programa Gnumeric (similar a Excell o a Google Sheets). Gnumeric va a detectar autom\u00e1ticamente que las columnas est\u00e1n separadas por Tab . Identifiquen la columna correspondiente a la especie (son solo las primeras 20 filas, no van a encontrar a E. coli ), la cepa y el link a la ubicaci\u00f3n del genoma. Ahora que conocen la estructura de la tabla, y sabiendo que tiene muchos mas organismos que E. coli , tenemos que filtrar el archivo y quedarnos solo con nuestro organismo y cepa de inter\u00e9s. Para esto, corran los siguientes comandos uno a la vez: C\u00f3digo C\u00f3digo con comentarios head -2 assembly_summary.txt > assembly_summary_coli.tsv grep \"Escherichia coli\" assembly_summary.txt | grep \"BL21\" >> assembly_summary_coli.tsv # Generamos un nuevo archivo con el header de la tabla (que en este caso son 2 filas) head -2 assembly_summary.txt > assembly_summary_coli.tsv # Buscamos dentro del archivo las filas que contengan \"Escherichia coli\" y \"BL21\" y # las agregamos a la nuevo archivo grep \"Escherichia coli\" assembly_summary.txt | grep \"BL21\" >> assembly_summary_coli.tsv","title":"RefSeq - Paso 1"},{"location":"practicos/TP02_EMBOSS/#refseq-paso-2-crear-un-archivo-con-links-a-las-carpetas-de-los-genomas","text":"Ahora que tenemos y entendemos la tabla con nuestros datos de E. coli la podemos abrir en Gnumeric haciendo doble click. Van a ver que no hay solo un genoma de E. coli BL21, sino varios, por lo cual nuestro objetivo de crear una tabla de codones acaba de volverse un poco m\u00e1s complicado. Lo que vamos a hacer entonces es bajar todos los genomas de E. coli BL21 que vemos en la tabla, as\u00ed que continuamos al segundo paso en el FAQ de RefSeq : awk -F \"\\t\" '{if ($12==\"Complete Genome\" && $11==\"latest\") {print $20}}' assembly_summary_coli.tsv > ftpdirpaths Al comando awk lo vimos brevemente al final del TP 1 y sirve para trabajar con tablas en Bash (entre otras cosas). Las diferentes partes de este comando son: -F \"\\t\" indica que el separador de columnas es \\t , o sea, Tab $12==\"Complete Genome\" es una condici\u00f3n que filtra las filas, qued\u00e1ndose solo con aquellas donde la columna 12 ( assembly_level ) es \"Complete Genome\" $11==\"latest\" es una condici\u00f3n que filtra las filas, qued\u00e1ndose solo con aquellas donde la columna 11 ( version_status ) es \"latest\" && se denomina and y une ambas condiciones, pidiendo que ambas se cumplan para que la condici\u00f3n total se cumpla {print $20} indica que se va a devolver la columna 20 ( ftp_path , contiene el path del genoma, o sea, la carpeta) Este comando va a crear el archivo ftpdirpaths , que contiene links a las carpetas que contienen los genomas. Investiguen cuantos links quedaron en ftpdirpaths . \u00bfEntienden por qu\u00e9? Sino consulten.","title":"RefSeq - Paso 2"},{"location":"practicos/TP02_EMBOSS/#refseq-paso-3-crear-un-archivo-con-links-a-los-genomas","text":"Los links que tenemos de momento tienen el formato: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/833/145/GCF_000833145.1_ASM83314v1 Sin embargo, estos son links a las carpetas que contienen los genomas. Siguiendo las instrucciones del FAQ de RefSeq podemos crear el link de los genomas, que para el ejemplo anterior ser\u00eda: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/833/145/GCF_000833145.1_ASM83314v1/GCF_000833145.1_ASM83314v1_cds_from_genomic.fna.gz Donde el nombre del archivo es el nombre de la \u00faltima carpeta + \"_cds_from_genomic.fna.gz\" Los archivos terminados en .fna.gz son secuencias en formato FASTA ( f ) de nucle\u00f3tidos ( na ) comprimidas ( gz ). Hay varias formas de crear estos nuevos links. Nosotros lo vamos a hacer de la siguiente manera: awk -F \"/\" '{print $0 \"/\" $10 \"_cds_from_genomic.fna.gz\"}' ftpdirpaths > ftpfilepaths Donde: -F \"/\" indica que el separador de columnas es / . Lo que est\u00e1 haciendo este c\u00f3digo es leer nuestros paths como si fueran tablas de varias columnas, haciendo que cada carpeta quede en su propia columna. $0 parecer\u00eda indicar la columna 0, pero las columnas en awk van de 1 en adelante ( $1 , $2 , etc). El \u00edndice $0 es un \u00edndice especial que devuelve toda la fila (que en este caso es todo el path a la carpeta del genoma). $10 es la columna 10, la cual contiene el nombre del genoma (es el nombre de la \u00faltima carpeta en el path ). print va a concatenar $0 (el path a la carpeta del genoma), \"/\" (una barra para separar los directorios), $10 (la primera parte del nombre del archivo a descargar) y \"_cds_from_genomic.fna.gz\" (la segunda parte del nombre del archivo a descargar). awk va a hacer esto por cada fila del archivo ftpdirpaths . Una vez que entienden lo que hace este comando abran la terminal y corranl\u00f3. Por si se quedaron con curiosidad de el comando que propon\u00eda el FAQ de RefSeq El comando awk que sugeria el FAQ de RefSeq es un poco m\u00e1s complejo, pero llegaba al mismo resultado. Noten que en este comando el archivo tiene la extensi\u00f3n .gbff.gz que hace referencia al formato de GenBank , que no es el con el que vamos a trabajar. Hay que cambiarlo por \"cds_from_genomic.fna.gz\" awk 'BEGIN{FS=OFS=\"/\";filesuffix=\"genomic.gbff.gz\"}{ftpdir=$0;asm=$10;file=asm\"_\"filesuffix;print ftpdir,file}' ftpdirpaths > ftpfilepaths No es necesario que lo entiendan 100%, pero vamos a aclarar algunas cosas: BEGIN significa que las cosas entre las primeras llaves se van a ejecutar solo una vez, y no una vez por fila (como el resto). FS es una variable interna de awk que indica como se separan las columnas en la tabla a leer (es equivalente a usar -F ). La variable OFS indica lo mismo, pero para la salida de awk . Con FS=OFS=\"/\" estamos indicando que ambos ser\u00e1n la barra / . Lo que est\u00e1 haciendo este c\u00f3digo es leer nuestros paths como si fueran tablas de varias columnas, haciendo que cada carpeta quede en su propia columna. En filesuffix=\"cds_from_genomic.fna.gz\" est\u00e1 definiendo una variable en la que va a almacenar la cadena de texto que queremos agregar al final de cada link. En ftpdir=$0 est\u00e1 definiendo una variable en la que parece almacenar la columna 0. Ahora bien, las columnas en awk van de 1 en adelante ( $1 , $2 , etc), pero el \u00edndice $0 es un \u00edndice especial que devuelve toda la fila (que en este caso es todo el path a la carpeta del genoma). En asm=$10 est\u00e1 definiendo una variable en la que va a almacenar la columna 10, la cual contiene el nombre del genoma (es el nombre de la \u00faltima carpeta en el path ). En file=asm\"_\"filesuffix est\u00e1 definiendo una nueva variable como la concatenaci\u00f3n de asm , un gui\u00f3n bajo y filesuffix . Este va a ser el nombre del archivo a descargar (pero todav\u00eda le falta el path ). print ftpdir,file va a imprimir el valor de ftpdir (el path a la carpeta del genoma) seguido por el valor de file (el nombre del archivo a descargar) por cada fila del archivo ftpdirpaths . La barra entre ambos ( / ) es agregada automaticamente debido a que declaramos OFS=\"/\" al principio.","title":"RefSeq - Paso 3"},{"location":"practicos/TP02_EMBOSS/#refseq-paso-4-descargar-genomas-de-e-coli","text":"Ya falta poco para tener nuestros genomas, solo hay que descargar todos los links que tenemos adentro del archivo ftpfilepaths . Esto se puede hacer usando el comando wget . Ahora bien, por defecto a wget hay que pasarle un link de descarga como hicimos arriba, pero por suerte existe una opci\u00f3n que permite pasarle un archivo de entrada y que descargue todos los links que se encuentran en \u00e9l. Usen wget -h (mas conciso) o man wget (mas extenso) para ver las diferentes opciones de wget , encuentren la que se usa para pasarle un archivo de entrada (o fichero o input file ) con links (o URLs ) y usen wget con ftpfilepaths para bajar todos los genomas que seleccionamos. Tip wget tiene bastantes opciones, asi que para hacerla un poco m\u00e1s f\u00e1cil sepan que la opci\u00f3n que necesitan es una de las 15 primeras y est\u00e1 en la secci\u00f3n Ficheros de registro y de entrada (o Logging and input file ) Este comando puede tardar un rato en descargar todo y va a bajar 11 archivos con extensi\u00f3n .fna.gz donde .fna es una extensi\u00f3n que hace referencia a que el archivo contiene informaci\u00f3n de secuencia (similar a FASTA) y .gz es la extensi\u00f3n de los archivos comprimidos de Linux.","title":"RefSeq - Paso 4"},{"location":"practicos/TP02_EMBOSS/#ejercicio-3-construir-tabla-de-frecuencias-de-uso-de-codones","text":"Tras lo que parece una eternidad por fin tenemos nuestros genomas. Ahora es momento de usar el comando cusp del que hablamos al principio del ejercicio anterior para transformar nuestros genomas en tablas con frecuencias de uso de codones. Como tenemos varios archivos .fna.gz vamos a tener que correr el comando cusp varias veces, y la mejor forma de hacer esto es creando un script con un ciclo for each que lo haga por nosotros. Este ciclo va a recorrer todos los archivos .fna.gz que acabamos de descargar, los va a descomprimir y va a ejecutar el comando cusp para cada uno. Reemplacen los REEMPLAZAR en el pr\u00f3ximo c\u00f3digo por lo que sea adecuado para conseguir nuestro objetivo: REEMPLAZAR for REEMPLAZAR in REEMPLAZAR do REEMPLAZAR done Sabiendo que un REEMPLAZAR es: # Creamos una lista que contiene a todos los archivos que empiezan con \"GCF\" y terminan con \".gz\" lista_de_archivos_genomas = ` ls GCF*.gz ` y otro es: # Descomprimimos el archivo \".gz\" y corremos el comando *cusp* para cada $archivo_genoma de la lista zcat $archivo_genoma | cusp -auto -sequence \"stdin\" -outfile \" ${ archivo_genoma } .cusp\" zcat es un comando que descomprime archivos .gz y devuelve su contenido por consola (similar a cat ). -auto hace que cusp use los par\u00e1metros por defecto y no nos consulte cuales usar. -sequence \"stdin\" le esta diciendo a cusp que el genoma se lo estamos dando por la consola (mediante el pipe o | ). -outfile \"${archivo_genoma}.cusp\" define el nombre del archivo de salida de cusp , que en este caso es el nombre del genoma seguido de .cusp . Si bien las llaves no son necesarias en este caso, ayudan a entender donde termina la variable y empieza el string . Idealmente habria que sacarle la extensi\u00f3n anterior al archivo (ya que ahora va a quedar .fna.gz.cusp ), pero ya tenemos bastante que hacer. Tip Si no les sale pueden ver el for each del Ejercicio 1 para usarlo como base (si bien ese es m\u00e1s complicado) Una vez creado el script, corranl\u00f3. Si ven que este script tarda mucho tiempo en correr (varios minutos sin indicar que avanza) lean esto: Cancelen la corrida apretando Ctrl + C en la terminal Usen para la pr\u00f3xima seccion los archivos ecoli_BL21_codon_table_1.cusp y ecoli_BL21_codon_table_2.cusp que se encuentra en sus materiales de trabajo","title":"Ejercicio 3 - Tablas de codones"},{"location":"practicos/TP02_EMBOSS/#comparar-tablas-de-codones","text":"Recordando nuestro objetivo, nosotros quer\u00edamos una tabla de codones de E. coli para saber como modificar el ADN de nuestra prote\u00edna de inter\u00e9s ( VpVan ) para que use aquellos codones preferidos por el organismo hu\u00e9sped. En este momento tenemos varias tablas de codones, asi que tenemos que elegir alguna. Abran uno de los archivos .cusp que acabamos de crear y vean que informaci\u00f3n tiene: Si en la tabla dentro del archivo .cusp las columnas no est\u00e1n alineadas lean esto: Por defecto Leafpad usa una fuente llamada \"Ubuntu\" , que si bien sirve para escribir cuentos, nos va a dar problemas al momento de ver ciertos archivos que vamos a usar en esta materia. En Leafpad vayan a Opciones Tipograf\u00eda... , seleccionen la fuente \"Ubuntu Mono\" y aprieten Aceptar . Las fuentes que tienen Mono en su nombre estan indicando que son monoespaciadas, o sea, que todos sus caracteres tienen el mismo ancho. Esto es ideal para cuando se quieren ver tablas o alineamientos con Leafpad , cosa que vamos a hacer bastante en esta materia. Ayuda-memoria con amino\u00e1cidos y sus abreviaturas Full Name Abbreviation (3 Letter) Abbreviation (1 Letter) Alanine Ala A Arginine Arg R Asparagine Asn N Aspartate Asp D Aspartate or Asparagine Asx B Cysteine Cys C Glutamate Glu E Glutamine Gln Q Glutamate or Glutamine Glx Z Glycine Gly G Histidine His H Isoleucine Ile I Leucine Leu L Lysine Lys K Methionine Met M Phenylalanine Phe F Proline Pro P Serine Ser S Threonine Thr T Tryptophans Trp W Tyrosine Tyr Y Valine Val V \u00bfPor qu\u00e9 hay m\u00e1s de un cod\u00f3n para cada amino\u00e1cido? \u00bfQu\u00e9 indica la columna Fraction ? \u00bfQu\u00e9 indica la columna Frequency ? (pueden encontra la respuesta usando tfm cusp , pero est\u00e1 mas claro en la ayuda online ) Ahora abran otro archivo .cusp , \u00bfnotan diferencias entre las frecuencias de uso de codones de los distintos proyectos genoma de E.Coli BL21? En un principio pareceria que ambos archivos .cusp son bastante parecidos, pero queremos estar seguros. EMBOSS tiene un programa llamado codcmp que permite comparar tablas de codones, calculando ciertos estad\u00edsticos. El programa se usa: codcmp ARCHIVO_CUSP_1 ARCHIVO_CUSP_2 ARCHIVO_SALIDA Usen este comando para comparar los dos archivos .cusp que miraron previamente y guarden la comparaci\u00f3n en un archivo llamado cusp_comparison.out . Abran cusp_comparison.out y vean los estad\u00edsticos calculados. \u00bfSon compatibles estos resultados con nuestras observaciones previas de que ambos archivos .cusp son muy parecidos? Hay entoces una noticia buena y una mala: Noticia Buena Todos las tablas de frecuencias de codones son casi id\u00e9nticas, asi que podemos usar cualquiera de ellas y va a funcionar bien. Aclaraci\u00f3n 1: Los resultados de codcmp no alcanzan para decir que las diferencias no son \"estadisticamente signficativas\" (aunque en este caso es bastante obvio). En el manual de codcmp dan algunas ideas para calcular esto. Aclaraci\u00f3n 2: Otra forma de resolver el \"problema\" de tener muchas tablas de codones podr\u00eda haber sido calcular una nueva tabla de frecuencias de codones que sea un promedio de todas las anteriores, pero esto es un trabajo complejo y no se amerita hacerlo para este caso debido a los similar que son las diferentes tablas entre s\u00ed. Noticia Mala Todos las tablas de frecuencias de codones son casi id\u00e9nticas, asi que podr\u00edamos haber bajado solo una de ellas y ahorrarnos bastante trabajo (aunque no ten\u00edamos forma de saber esto previamente).","title":"Comparar tablas de codones"},{"location":"practicos/TP02_EMBOSS/#ejercicio-4-optimizar-secuencia-a-insertar-en-base-a-la-tabla-de-codones","text":"Ya casi estamos. En este momento tenemos la tabla de frecuencia de uso de codones para E. coli BL21 y queremos aplicar dichos codones a las 3 secuencias quim\u00e9ricas que creamos en el Ejercicio 1 , es decir, codificar una secuencia amionac\u00eddica de planta en la forma m\u00e1s \u00f3ptima para su traducci\u00f3n en E. coli . Para organizar un poco los archivos volvemos a recomendar crear una carpeta para este ejercicio, por ejemplo ~/Documentos/TP_02/EJ_4 . Dentro de la carpeta copien los siguientes archivos: VpVAN-FLAG-tag.fasta (creado en el Ejercicio 1) VpVAN-His-tag.fasta (creado en el Ejercicio 1) VpVAN-MBP-tag.fasta (creado en el Ejercicio 1) Elijan alguno de los archivos .cusp creados en el Ejercicio 3, copienlo a la nueva carpeta y cambienl\u00e9 el nombre a ecoli_BL21_codon_table.cusp . Ahora bien, para hacer esta optimizaci\u00f3n de secuencias podemos usar otro de los programas de EMBOSS llamado backtranseq . Este programa toma una secuencia de amino\u00e1cidos correspondiente a una prote\u00edna de inter\u00e9s y una tabla de frecuencia de uso de codones y usa ambos para hacer una traducci\u00f3n inversa desde la secuencia prote\u00edca hacia la secuencia de ADN que, con mayor probabilidad, le dio origen. Es decir, backtranseq devuelve una secuencia de ADN a partir de una secuencia de amino\u00e1cidos. Este comando se usa: backtranseq -auto -sequence ARCHIVO_PROTEINA_FASTA -cfile ARCHIVO_CUSP -outfile ARCHIVO_SALIDA_ADN_FASTA Corran este comando 3 veces pas\u00e1ndole los archivos correctos y creen los siguientes archivos (si quieren pueden hacer script con un for each , pero no hace falta): Ecoli-DNA-VpVAN-FLAG-tag.fasta Ecoli-DNA-VpVAN-His-tag.fasta Ecoli-DNA-VpVAN-MBP-tag.fasta Tip De hacerlo a mano, aca van a tener que ejecutar tres comandos muy similares. Recuerden que pueden usar Up y Down en su terminal para navegar por los ultimos comandos utilizados y modificar lo necesario, as\u00ed como Tab para autocompletar nombres de archivos. Tambi\u00e9n puede serles \u00fatiles la tecla Home ( Inicio ) y End ( Fin ) para moverse al principio o al final del comando que est\u00e1n editando.","title":"Ejercicio 4 - Optimizar ADN"},{"location":"practicos/TP02_EMBOSS/#ejercicio-5-agregar-enzimas-de-restriccion","text":"El \u00faltimo paso es agregar los sitios de corte de enzimas de restricci\u00f3n a los costados de mi secuencia quim\u00e9rica, pero antes de eso tengo que asegurarme que dichas enzimas no tengan sitios de corte dentro de mi secuencia. Probablemente ya no les sorprenda que existe un programa de EMBOSS para hacer esto llamado remap ; sin embargo, dicho programa necesita que previamente le hayamos pasado a EMBOSS una base de datos de enzimas de restricci\u00f3n. En los materiales de trabajo van a encontrar dos archivos llamados proto.207 y withrefm.207 que contienen la informaci\u00f3n para crear la base de datos de enzimas de restricci\u00f3n. Copienlos a la carpeta donde estan trabajando y corran el comando: rebaseextract -infile withrefm.207 -protofile proto.207 Este comando les va a tirar un error, pero no porque est\u00e9 mal escrito. El problema es que este comando quiere editar archivos que no son del usuario ibioinfo , por lo que en un principio no tenemos permisos para editarlos. En estos casos hay que agregar el prefijo sudo y puede ser que Lubuntu les pida la contrase\u00f1a (parece que no escribe nada, pero eso es por seguridad, si se las pide escriban \"unsam\" y aprieten Enter ). Asi que corran: sudo rebaseextract -infile withrefm.207 -protofile proto.207 Info Solo para que sepan, los archivos proto.207 y withrefm.207 se pueden descargar de aca o aca usando wget (con los links anteriores van a bajar un \u00edndice general y luego tienen que pasarle a wget el link de los archivos que quieran). Dependiendo de cuando vayan a esa p\u00e1gina puede ser que encuentren versiones incluso mas recientes. Ahora que ya tenemos la base de datos configurada podemos usar remap , pero antes veamos un poco mas informaci\u00f3n sobre nuestras enzimas de restricci\u00f3n. Usando grep busquen dentro del archivo proto.207 a nuestras enzimas de restricci\u00f3n de inter\u00e9s ( BamHI y HindIII ). \u00bfQu\u00e9 longitud tienen los sitios de restricci\u00f3n de BamHI y HindIII ? \u00bfQu\u00e9 piensan que significa el s\u00edmbolo ^ en el sitio de restricci\u00f3n? (pueden buscar informaci\u00f3n sobre dichas enzimas online y se van a dar cuenta enseguida) Ahora que sabemos un poco m\u00e1s sobre nuestras enzimas vamos a usar el comando remap con las siguientes opciones: remap -auto -sequence ARCHIVO_ADN_FASTA -width 80 -commercial -sitelen 6 -frame 1 -enzymes all -outfile ARCHIVO_SALIDA_REMAP Donde: -auto hace que remap use los par\u00e1metros por defecto y no nos consulte cuales usar. -width indica el ancho de secuencia a mostrar en el archivo de salida. -commercial analiza solo las enzimas de restricci\u00f3n de uso comercial (entre las que se encuentran nuestras enzimas de inter\u00e9s). -sitelen indica el m\u00ednimo de longitud del sitio de restricci\u00f3n (como sabemos que los sitios de restricci\u00f3n de nuestras enzimas de inter\u00e9s tienen 6 amino\u00e1cidos ponemos ese n\u00famero). frame indica el marco de lectura a traducir (ya que el output tambien va a dar informaci\u00f3n a nivel prote\u00edna). En nuestro caso el frame es 1 (estamos en la hebra codificante y hay que traducir a partir del primer nucle\u00f3tido). enzymes indica los nombres de las enzimas a probar. Si bien podr\u00edamos haber puesto nuestras enzimas de inter\u00e9s, ponemos all para ver m\u00e1s informaci\u00f3n del output. Corran este comando 3 veces pas\u00e1ndole los archivos correctos y creen los siguientes archivos: enzimas_FLAG.out enzimas_His.out enzimas_MBP.out Una vez creados, abran los archivos con Leafpad . \u00bfEntienden lo que simboliza el archivo? (es necesario que esten usando la fuente Ubuntu Mono en Leafpad para verlo bien) Busquen nuestras enzimas de restricci\u00f3n de inter\u00e9s. \u00bfLas encuentran? \u00bfEn que categor\u00eda est\u00e1n? \u00bfSe pueden usar entonces estas enzimas de restricci\u00f3n para insertar nuestra secuencia en un pl\u00e1smido? \u00bfHay alg\u00fan tag de los tres que estabamos considerando que no se pueda usar debido a las enzimas de restricci\u00f3n que elegimos? Elijan el tag que quieren usar, copien su construcci\u00f3n Ecoli-DNA-VpVAN-???-tag.fasta a un nuevo archivo y luego cambienl\u00e9 el nombre a secuencia_final.fasta . Abran secuencia_final.fasta en Leafpad y agreguen a mano el sitio de restricci\u00f3n de BamHI al principio y el de HindIII al final. \u00a1Felicitaciones, tenemos nuestra secuencia lista para mandar a secuenciar!","title":"Ejercicio 5 - Enzimas"},{"location":"practicos/TP02_EMBOSS/#bibliografia","text":"","title":"Bibliograf\u00eda"},{"location":"practicos/TP02_EMBOSS/#online","text":"Insertar secuencias de ADN en pl\u00e1smidos Cromatograf\u00eda de afinidad","title":" Online"},{"location":"practicos/TP03_Alineamientos/","text":"TP 3 . Alineamientos de secuencias de a pares Materiales Atenci\u00f3n: Este TP tiene informe. Slides mostrados en la clase Cierre TP Videos de la clase grabada Introducci\u00f3n al TP Cierre TP Objetivos Entender el funcionamiento b\u00e1sico del algoritmo de alineamiento de pares de secuencias de Needleman-Wunsch. Aprender a interpretar un Dot-Plot, pudiendo identificar las regiones relevantes que contienen patrones. Comprender los conceptos de similitud y homolog\u00eda de secuencias, y establecer una clara diferencia entre los mismos. Realizar un alineamiento m\u00faltiple de secuencias e interpretar qu\u00e9 informaci\u00f3n importante se puede extraer del mismo. Introducci\u00f3n El alineamiento de secuencias de a pares comprende la asignaci\u00f3n uno-a-uno de correspondencias entre los elementos que componen dichas secuencias sin alterar su orden. En dicho proceso tres eventos principales pueden tener lugar: Match (M) : Cuando los elementos enfrentados son equivalentes. Mismatch (m) : Cuando los elementos correspondientes son diferentes. Gap (g): Cuando un elemento de una secuencia no tiene par en la otra y se enfrenta a un espacio, caracterizado por un gui\u00f3n (-). Gap open: Cuando se abre un gap. Gap extend: Cuando se agregan gaps a continuaci\u00f3n de otro gap. Por ejemplo, si alineamos las secuencias AFGIVHKLIVS y AFGIHKIVS un posible resultado ser\u00eda: A F G I V H K L I V S A F G I - H K - I V S Los gaps no existen en la realidad. NO son un amino\u00e1cido o nucle\u00f3tido m\u00e1s, sino una herramienta que utilizamos para poder alinear. La principal funci\u00f3n de los alineamientos es establecer una medida de similitud entre las secuencias que participan en el mismo. Para ello es necesario definir un sistema de puntuaci\u00f3n que pese cada uno de los eventos que tienen lugar en la construcci\u00f3n del alineamiento. Asimismo, este esquema de puntajes o scoring nos permitir\u00e1 optimizar el alineamiento de forma tal que los algoritmos empleados elijan la correspondencia entre secuencias que maximice el puntaje o score global. Existen varios algoritmos de alineamiento: Los alineamientos globales (o de Needleman-Wunsch por sus creadores), se realizan apareando todos los elementos de una secuencia con todos los elementos de la otra. Este tipo de alineamientos se utiliza principalmente para comparar dos secuencias que son similares en longitud. Los alineamientos locales (o de Smith-Waterman), parean \u00fanicamente parte de las secuencias y son \u00fatiles para identificar, por ejemplo, dominios en com\u00fan. Los alineamientos mixtos , que combinan los dos anteriores. Dynamic programming Dado un par de secuencias y un sistema de puntuaci\u00f3n o scoring se pueden aplicar diversos algoritmos para encontrar el alineamiento que d\u00e9 el mejor puntaje. El algoritmo m\u00e1s popular utiliza un m\u00e9todo matem\u00e1tico llamado dynamic programming . El mismo consiste en comparar ambas secuencias construyendo una matriz del alineamiento. Brevemente: Se comienza en el extremo superior izquierdo de la matriz, con un puntaje inicial de 0. En cada paso, se calcula el costo que tiene aparejado desplazarse de una celda a la otra, dado el sistema de puntajes pre-establecido, y se elige la opci\u00f3n m\u00e1s favorable, es decir aquella que maximice el puntaje global del alineamiento. En cada iteraci\u00f3n se guarda el puntaje con el que se lleg\u00f3 a una celda dada y el movimiento que origin\u00f3 dicho camino o path , indicado t\u00edpicamente con una flecha. Una vez que la matriz est\u00e1 completa en su totalidad se puede recorrer hacia atr\u00e1s o realizar un traceback , desde el extremo inferior derecho al superior izquierdo, para reconstruir el alineamiento. La principal ventaja de este m\u00e9todo es que siempre encuentra el alineamiento \u00f3ptimo entre las secuencias dadas. Sin embargo, una desventaja es pueden existir varios alineamientos que satisfagan esta condici\u00f3n. Otra desventaja es de origen t\u00e9cnica: la exhaustividad con la que el algoritmo realiza la b\u00fasqueda hace que su velocidad dependa de la longitud de las secuencias implicadas, haciendo poco eficiente la b\u00fasqueda de similitud de una secuencia contra una base de datos. Para esto existen diferentes adaptaciones del algoritmo que se ver\u00e1n m\u00e1s adelante. Ejemplo Imaginen que queremos alinear las secuencias TCGCA y TCCA utilizando un esquema de scoring de: Match: M=1 Mismatch: m=-1 Gap: g=-2 Para eso ubicamos las secuencias en una matriz, donde cada una de sus dimensiones corresponda a una de las secuencias, tal como se muestra en la siguiente figura. Si observamos los paths 1 y 2 dibujados en las matrices de la figura podemos ver que se emplearon distintas estrategias para alinear este par de secuencias. En 1 se eligi\u00f3 alinear los dos primeros nucle\u00f3tidos TC por la diagonal, luego colocar un gap en la secuencia vertical TCCA y para finalizar se alinearon los nucle\u00f3tidos CA restantes por la diagonal. En 2 el primer nucle\u00f3tido T de ambas secuencias se aline\u00f3 por la diagonal, luego se coloc\u00f3 un gap en la secuencia vertical TCCA y finalmente se alinearon los 3 nucle\u00f3tidos GCA y CCA restantes por la diagonal. Si computamos los puntajes de ambos alineamientos, obtenemos que: La opci\u00f3n 1 tiene un puntaje de 2. Se propone colocar un \u00fanico gap permitiendo alinear al resto de los nucle\u00f3tidos en ambas secuencias con eventos de match . La opci\u00f3n 2 tiene un puntaje de 0. Las secuencias estudiadas se alinean con 1 gap , 1 mismatch y 3 matches . La estrategia es sub\u00f3ptima en relaci\u00f3n a 1 . Pregunta Si hubi\u00e9semos aplicado la metodolog\u00eda de dynamic programming para realizar un alineamiento global de estas secuencias, \u00bfcu\u00e1l ser\u00eda el path \u00f3ptimo resultante? A priori uno pensar\u00eda que es el path 1 , pero hagamos el ejercicio para corroborar si esto es efectivamente as\u00ed. Para comenzar, refresquemos c\u00f3mo funcionaba el m\u00e9todo de dynamic programming . Para llegar desde el extremo superior izquierdo (= inicio) de la matriz del alineamiento a la posici\u00f3n marcada con una x podr\u00edamos, hipot\u00e9ticamente, tomar cualquiera de los caminos dibujados en la figura de m\u00e1s arriba. Estos paths dar\u00edan alinemientos diferentes de las secuencias TC con TC . Pregunta Pero... \u00bfcu\u00e1l es el procedimiento iterativo empleado por el m\u00e9todo de dynamic programming para obtener el alineamiento \u00f3ptimo entre dos secuencias? Para llegar a cualquier celda de la matriz, uno puede acceder por, como m\u00e1ximo, 3 direcciones. La idea es siempre moverse en la direcci\u00f3n que maximice el score o puntaje. Veamos que : un movimiento en la direcci\u00f3n horizontal , de la posici\u00f3n (i, j-1) a la posici\u00f3n (i, j) , supone introducir un gap en la secuencia del eje vertical i un movimiento en la direcci\u00f3n diagonal , de la posici\u00f3n (i-1, j-1) a la posici\u00f3n (i, j) , supone un match o un mismatch entre los nucle\u00f3tidos enfrentados un movimiento en la direcci\u00f3n vertical , de la posici\u00f3n (i-1, j) a la posici\u00f3n (i, j) , supone introducir un gap en la secuencia del eje horizontal j Teniendo en cuenta la f\u00f3rmula para obtener el score enunciada m\u00e1s arriba, podemos comenzar con nuestro ejercicio! Recordemos que la matriz se llenar\u00e1 iterativamente, comenzando por la celda del extremo superior izquierdo, que tiene un puntaje de 0. Para moverse del (0, 0) al (0, 1), hay una s\u00f3la opci\u00f3n, moverse en forma horizontal . Esto significa alinear T con un gap , lo cual da un score de 0 + (-2) = -2. eje j: T eje i: - Lo mismo pasa al moverse del (0, 0) al (1, 0), hay una s\u00f3la opci\u00f3n, moverse en forma vertical . Esto significa alinear T con un gap , lo cual tambi\u00e9n da un score de 0 + (-2) = -2. eje j: - eje i: T Para moverse del (0, 0) al (1, 1) hay 3 maneras: 1. Hacer un movimiento vertical , lo cual da un score de -2 + (-2) = -4 -2 es el puntaje de la celda inicial (0, 1) El movimiento vertical implica colocar un gap : -2 Resultado: eje j: T - eje i: - T 2. Hacer un movimiento horizontal , lo cual da un score de -2 + (-2) = -4. Similar al caso anterior: -2 es el puntaje de la celda inicial (1, 0) El movimiento horizontal implica colocar un gap : -2 Resultado: eje j: - T eje i: T - 3. Hacer un movimiento diagonal , lo cual da un score de 0 + (+1). Implica alinear ambos nucl\u00e9otidos! 0 es el puntaje de la celda inicial (0, 0) Hay T en las ambas secuencias. Es un match : +1 Resultado: eje j: T eje i: T Para decidir qu\u00e9 valor ubicamos en la celda simplemente optamos por el que nos d\u00e9 el mayor score , en este caso 1, y se marca el movimiento que lo produjo: un movimiento diagonal. De esta manera podemos seguir completando la matriz, Obsevando la \u00faltima celda computada, podemos ver que hay nuevamente 3 maneras de llegar a la misma, Hacer un movimiento vertical , de (1, 3) a (2, 3): Es decir, introducir un gap en la secuencia horizontal j. Si (1, 3) tiene un score de -3, el nuevo score es: -3 + gap penalty = -3 + (-2) = -5 (flecha en direcci\u00f3n vertical). Hacer un movimiento horizontal , de (2, 2) a (2, 3). Es decir, introducir un gap en la secuencia vertical i. Si (2, 2) tiene un score de 2, el nuevo score es: 2 + gap penalty = 2 + (-2) = 0 (flecha en direcci\u00f3n horizontal). Hacer un movimiento diagonal , de (1, 2) a (2, 3). Es decir, alinear los nucle\u00f3tidos G y C. Si (1, 2) tiene un score de -1, el nuevo score es: -1 + mismatch = -1 + (-1) = -2 (flecha en direcci\u00f3n diagonal). El m\u00e1ximo de los 3 scores calculados es: max(-5, 0, -2) = 0, que corresponde al puntaje del movimiento horizontal . Entonces colocamos 0 en la celda (2, 3) y una flecha horizontal que indique el movimiento de (2, 2) a (2, 3). Al completar todas las celdas de la matriz, podemos saber cu\u00e1l es el puntaje de la celda ubicada en extremo inferior derecho, que en este caso result\u00f3 ser +2. Este tambi\u00e9n es el puntaje final del alineamiento. Para reconstruir el mismo, se parte de la celda ubicada en extremo inferior derecho y se siguen las flechas hasta llegar a la celda de inicio, en el extremo superior izquierdo. Las flechas en rojo resaltan el path del alineamiento, eje j: T C G C A eje i: T C - C A que podemos corroborar que es id\u00e9ntico al path 1 del ejemplo que se plante\u00f3 inicialmente. Ejercicio 1 1.1 En grupo, realiz\u00e1 el alineamiento de las secuencias ATTGG con AGATGG , usando el esquema de puntajes: M=1, m=-1, g=-2. Para esto, abr\u00ed el siguiente Google Jamboard , guard\u00e1 una copia local del mismo en tu Google Drive y compart\u00ed el GJamboard a tus compa\u00f1eros de equipo. Atenci\u00f3n Para guardar una copia local del GJamboard en tu GDrive, clique\u00e1 en el \u00edcono con 3 puntitos, en el extremo superior derecho (M\u00e1s acciones). Luego seleccion\u00e1 la opci\u00f3n \"Hacer una copia\". Eleg\u00ed la carpeta adonde deseas guardarlo dentro de tu unidad y clique\u00e1 aceptar. \u00a1Ahora est\u00e1s listo para empezar! Record\u00e1 rellenar la matriz con todos los puntajes y flechas faltantes. Cuando termines, reconstru\u00ed el path del alineamiento. 1.2 Cuando termines el ejercicio anterior pod\u00e9s corrobar la soluci\u00f3n que hallaste ingresando en UniFreiburg-FreiburgRNATools . Segu\u00ed las siguientes instrucciones para usar este recurso web: a. Ingres\u00e1 las dos secuencias que quer\u00e9s alinear en los recuadros de Input Sequence a y Sequence b . Record\u00e1 que la secuencia que figura en tu matriz en sentido horizontal debe ser ingresada como Sequence b y la que figura en sentido vertical debe ser ingresada como Sequence a . b. Seleccion\u00e1 optimizaci\u00f3n de Similarity. c. Complet\u00e1 los valores de tu esquema de scoring . En el output podr\u00e1s apreciar dos salidas: A la izquierda, los valores de la matriz de alineamiento. Si cliqueas sobre los valores de la matriz, vas a observar que el valor sobre el que te paraste se colorea en verde, mientras que las celdas que dieron origen a ese valor se colorean en rosa. A la derecha, se observa el alineamiento final, donde un match se esquematiza en con *, un mismatch con | y un gap con _. 1.3 Respond\u00e9 a las siguientes preguntas: 1.3.1 Reproduc\u00ed el alineamiento que vimos como ejemplo al inicio ( TCGCA con TCCA , esquema de puntajes: M=1, m=-1, g=-2) en la web de la UniFreiburg-FreiburgRNATools \u00bfCu\u00e1ntas soluciones \u00f3ptimas hay para este alineamiento? \u00bfSucede lo mismo para el alineamiento que realizaste en el Ejercicio 1.1 ? \u00bfPor qu\u00e9? 1.3.2 Observ\u00e1 con detenimiento el output del panel de la izquierda (la matriz) Seleccion\u00e1 una celda. \u00bfQu\u00e9 sucede cuando clique\u00e1s en una celda y se colorea en verde y la celda aleda\u00f1a a la misma en rosa ? \u00bfA qu\u00e9 corresponde este coloreado o resaltado de las celdas? Observ\u00e1 nuevamente la matriz del alineamiento que obtuviste en 1.2 . Cliqu\u00e9a en la celda con puntaje -2 en la posici\u00f3n (A3, T2). Observ\u00e1 que se colorea en verde y dos celdas aleda\u00f1as a la misma en rosa . \u00bfEntend\u00e9s qu\u00e9 significa esto? \u00bfPod\u00e9s relacionarlo con los dos caminos \u00f3ptimos posibles que existen para este alineamiento? 1.3.3 Finalmente te propongo que realices el siguiente alineamiento: Sequence a: AGATGG y Sequence b: ATTGGG . Seleccion\u00e1 optimizaci\u00f3n de Similarity. Esquema de puntajes: M:1, m:-1, g:-5 . Registr\u00e1 con atenci\u00f3n el resultado. Ahora cambiemos el esquema de scoring , dejando el mismo valor para match, pero intercambiando los puntajes de gap y mismatch. \u00bfC\u00f3mo cambi\u00f3 el output? \u00bfQu\u00e9 observ\u00e1s ahora en las secuencias halladas como soluci\u00f3n \u00f3ptima en comparaci\u00f3n a lo que arrojaba el algoritmo con los par\u00e1metros anteriores? Dot-Plots Los dot-plots son representaciones gr\u00e1ficas que dan un pantallazo sobre la similitud entre dos secuencias. En ellos se pueden identificar patrones que aporten informaci\u00f3n sobre la relaci\u00f3n entre ambas secuencias. La forma de obtener uno es muy sencilla: se establece una matriz donde cada elemento de una de las secuencias se corresponde con una fila y los de la otra con una columna. Acto seguido se procede a colorear cada celda donde los caracteres correspondientes a fila y columna sean equivalentes. Por ejemplo: Nosotros podemos utilizar la herramienta de EMBOSS dotmatcher para generar nuestros propios plots. Recordatorio Para ver qu\u00e9 par\u00e1metros toma de entrada la funci\u00f3n, correr en la terminal dotmatcher -h . Ejercicio 2 2.1 Utiliz\u00e1 la secuencia HS-ch11-fragment.fasta que se encuentra en la carpeta data para compararla contra s\u00ed misma. Esta secuencia es un peque\u00f1o fragmento del cromosoma 1 de Homo sapiens y la vamos a utilizar \u00fanicamente para ver algunos de los patrones que podemos encontrar en un dotplot. Gener\u00e1 un dotplot utilizando la secuencia HS-ch11-fragment.fasta contra s\u00ed misma. dotmatcher -graph X11 HS-ch1-fragment.fasta HS-ch1-fragment.fasta Atenci\u00f3n Recuerden abrir el archivo HS-ch11-fragment.fasta y chequear que la secuencia es de ADN. Es una buena pr\u00e1ctica conocer qu\u00e9 hay en los archivos que vamos a utilizar. \u00bfQu\u00e9 pod\u00e9s interpretar de este dotplot? La verdad es que el plot es bastante ruidoso, esto sucede muy a menudo en secuencias gen\u00f3micas ya que la cantidad de caracteres que componen las secuencias es muy limitada (solo 4) y por ello hay muchas ocurrencias y por lo tanto muchos puntos. Para limpiar el plot y quedarnos con los matches m\u00e1s significativos podemos jugar con dos par\u00e1metros: windowsize : Tama\u00f1o de ventana threshold : Umbral de ocurrencia Esto quiere decir que dotmatcher s\u00f3lo va a poner un punto cuando un fragmento del largo windowsize contenga un score mayor a threshold . Por ejemplo: dotmatcher -graph X11 -windowsize 50 -threshold 20 HS-ch1-fragment.fasta HS-ch1-fragment.fasta Si aument\u00e1s estos par\u00e1metros pod\u00e9s ir eliminando fragmentos que corresponden a secciones compartidas m\u00e1s cortas, sin embargo existe una relaci\u00f3n de compromiso, utilizar tama\u00f1o de ventana y umbral muy grandes nos llevan a perder informaci\u00f3n por lo que hay que seleccionarlos con cuidado. Aqui hay algunos patrones con los que te pod\u00e9s encontrar en este tipo de plots: a) Match perfecto. b) Repeticiones. c) Pal\u00edndromo. d) Repeticiones invertidas. e) Zonas de baja complejidad (microsatelites). f) Zonas altamente repetitivas (minisatelites). g) Secuencias con alta conservaci\u00f3n. h) Inserci\u00f3n o deleci\u00f3n. 2.2 Cambi\u00e1 los par\u00e1metros windowsize y threshold hasta obtener un plot que te parezca adecuado. \u00bfQu\u00e9 pod\u00e9s interpretar del mismo? Identific\u00e1 patrones. Similitud y Homolog\u00eda Los t\u00e9rminos similitud y homolog\u00eda se suelen utilizar como sin\u00f3nimos por muchos investigadores, sin embargo no lo son. La similitud es una caracter\u00edstica cuantitativa de un par de secuencias, donde se establece en qu\u00e9 grado estas se parecen (por ejemplo aplicando los algoritmos antes vistos, utilizando un sistema de puntaje). La homolog\u00eda , por otro lado, es una caracter\u00edstica cualitativa, dos secuencias SON o NO SON hom\u00f3logas. Homolog\u00eda implica espec\u00edficamente que el par de secuencias estudiadas provienen de un mismo ancestro com\u00fan. Esta afirmaci\u00f3n es completamente hipot\u00e9tica, ya que, salvo en contados casos, no se puede corroborar. Uno puede inferir que este es el caso dado la similitud observada en las secuencias actuales, sin tener acceso a las secuencias ancestrales. Atenci\u00f3n Decir que un par de secuencias tiene N% de homolog\u00eda es TOTALMENTE incorrecto. A partir de esta relaci\u00f3n entre similitud y homolog\u00eda se puede aplicar para inferir relaciones entre diferentes especies, buscar posibles funciones de una secuencia desconocida, etc. Ejercicio 3 3.1 Determinar qu\u00e9 especies est\u00e1n m\u00e1s relacionadas utilizando la ribonucleasa pancre\u00e1tica de caballo ( Equus caballus ), ballena enana ( Balaenoptera acutorostrata ) y canguro rojo ( Macropus rufus ). 3.1.1 Descarg\u00e1 las secuencias antes mencionadas de la carpeta del TP. 3.1.2 Utiliz\u00e1 la herramienta de alineamiento global de EMBOSS needle (pueden leer el manual para ver que opciones admite) para comparar las tres secuencias. needle -gapopen 10 -gapextend 1 -asequence *secuencia_1* -bsequence *secuencia_2* -outfile *salida* 3.1.3 Observ\u00e1 e interpret\u00e1 las salidas obtenidas. \u00bfQu\u00e9 secuencias son m\u00e1s similares? \u00bfTiene sentido el resultado obtenido? 3.1.4 Analiz\u00e1 \u00e1rbol filogen\u00e9tico de la Fig. 1 del paper de O'Leary et al. , 2013. Sabiendo que los caballos y las ballenas pertenecen al clado Euungulata y los canguros al clado Marsupialia , ubic\u00e1 estos clado en el \u00e1rbol. \u00bfEsta informaci\u00f3n coincide con los resultados que obtuviste en 3.1.3 ? 3.2 Realiz\u00e1 el mismo procedimiento pero esta vez para determinar si los mamuts ( Mammuthus primigenius ) son m\u00e1s cercanos a los elefantes africanos ( Loxodonta africana ) o asi\u00e1ticos ( Elephas maximus ) utilizando la secuencia de la cadena alfa de la hemoglobina. 3.2.1 \u00bfQu\u00e9 te sugieren los resultados obtenidos? 3.2.2 \u00bfEs relevante la diferencia hallada? 3.2.3 \u00bfC\u00f3mo har\u00edas para sacar conclusiones m\u00e1s fuertes sobre las relaciones filogen\u00e9ticas entre los organismos estudiados en los ejercicios 3.1 y 3.2? Alineamientos m\u00faltiples Un alineamiento m\u00faltiple (MSA) involucra tres o m\u00e1s secuencias biol\u00f3gicas. Debido a que la tarea de alinear m\u00faltiples secuencias de largos biol\u00f3gicamente significativos suele ser muy demandante en t\u00e9rminos de recursos computacionales y tiempos de ejecuci\u00f3n estos requieren metodolog\u00edas m\u00e1s sofisticadas para llevarse a cabo. Por ello la mayor\u00eda de los programas disponibles para realizar MSA utiliza heur\u00edsticas en vez de algoritmos de optimizaci\u00f3n global. Heur\u00edstica Es una estrategia que busca resolver un problema m\u00e1s simple cuya soluci\u00f3n se interseca con la soluci\u00f3n de un problema m\u00e1s complejo. Generalmente esto implica que no es seguro encontrar el mejor resultado pero s\u00ed una soluci\u00f3n que sea aceptable. Las heur\u00edsticas se aplican con frecuencia en computaci\u00f3n para poder resolver problemas que, por su complejidad, ser\u00edan imposibles de abordar dados los limitados recursos con los que se cuentan. Dadas las secuencias de amino\u00e1cidos de un set de prote\u00ednas que se quieren comparar, el MSA muestra los residuos de cada prote\u00edna en una fila junto con los gaps que le correspondan de tal manera que todos los residuos \"equivalentes\" se encuentren en la misma columna. La utilidad de esta equivalencia depende de quien mire el alineamiento: Alguien que hace una filogenia puede enfocarse en que comparten un ancestro com\u00fan; Alguien que hace biolog\u00eda estructural puede enfocarse en que son residuos en posiciones an\u00e1logas de una estructura proteica; Alguien que hace biolog\u00eda molecular puede enfocarse en el rol funcional de esos residuos en la prote\u00edna. En cada caso un MSA provee un pantallazo sobre las restricciones evolutivas, estructurales o funcionales que caracterizan un set de prote\u00ednas de una manera visual e intuitiva. Un pipeline t\u00edpico para realizar un MSA ser\u00eda: Formular la pregunta que se quiere contestar. Por ejemplo, \"\u00bfQu\u00e9 estructura secundaria adopta X regi\u00f3n de mi prote\u00edna de inter\u00e9s?\" Obtener secuencias que puedan contestar a mi pregunta. Por ejemplo, secuencias que est\u00e9n relacionadas a mi prote\u00edna de inter\u00e9s. Utilizar alguno de los programas disponibles para llevar a cabo el MSA. Por ej. EMBOSS Realizar ajustes manuales para corregir posibles errores de los algoritmos de alineamiento. Ejercicio 4 (Adicional) Atenci\u00f3n Antes de comenzar a resolver los ejercicios, instal\u00e1 ClustalW en tu VM, escribiendo el siguiente comando en la terminal: sudo apt install clustalw La gp120 es una prote\u00edna que recubre al virus del HIV y facilita su uni\u00f3n e ingreso a la c\u00e9lula que infecta (linfocitos CD4+) Entre nuestros archivos contamos con un multifasta (gp120.fasta) que contiene 27 secuencias de gp120 de HIV-1, HIV-2 y SIV. Estas prote\u00ednas contienen 9 puentes disulfuro conservados. Tambi\u00e9n es de inter\u00e9s el loop V3, una porci\u00f3n expuesta de la prote\u00edna, conocido target de anticuerpos el cual constituye una regi\u00f3n hipervariable dada la presi\u00f3n selectiva a la que se ve sometido. Pueden ver la disposici\u00f3n de las distintas regiones de la gp120 en el siguiente esquema: Mathys L, Balzarini J. Several N-Glycans on the HIV Envelope Glycoprotein gp120 Preferentially Locate Near Disulphide Bridges and Are Required for Efficient Infectivity and Virus Transmission. PLoS One. 2015 Jun 29;10(6):e0130621. doi: 10.1371/journal.pone.0130621. PMID: 26121645; PMCID: PMC4488071. Figure 1. 4.1 Utiliz\u00e1 las herramientas de EMBOSS para realizar un alineamiento m\u00faltiple con las secuencias de gp120 (recuerden que para buscar herramientas pueden usar wossname ) Pista El comando a utilizar es emma . Para ver la ayuda, tipe\u00e1 emma -help en la terminal. 4.2 Utiliz\u00e1 el comando showalign de EMBOSS para obtener una mejor visualizaci\u00f3n del alineamiento. Otra alternativa Para visualizar el alineamiento correctamente le sugerimos usar el comando cat en la consola. Si desea ver el archivo con Leafpad recuerde ingresar a Opciones > Tipograf\u00eda y seleccionar Ubuntu Mono. 4.3 Observ\u00e1 el alineamiento, como primer control podemos corroborar que las 18 Ciste\u00ednas ( C ) est\u00e9n bien alineadas. 4.4 Utiliz\u00e1 el esquema de gp120 para identificar diversas regiones ya sea conservadas o muy variables (Estructuras, loops, etc.) Tip Not\u00e1 que las posiciones en el alineamiento cuentan gaps por lo que no se corresponden exactamente con el esquema. Utiliz\u00e1 las posiciones de las ciste\u00ednas conservadas para identificar diferentes regiones. Ejercicio a informar Info Fecha l\u00edmite de entrega: Domingo, 28 de Agosto 2022, 23:59hs. Materiales Enunciado Usted trabaja en un laboratorio que estudia distintos aspectos del coronavirus. Desde el comienzo de la pandemia trabaja en colaboraci\u00f3n con la agencia de vigilancia epidemiol\u00f3gica nacional de agentes infecciosos (AVENAI). Como parte de la colaboraci\u00f3n, todos los d\u00edas se obtienen clones y secuencias de nuevos aislamientos. AVENAI comparte con su jefe un nuevo aislamiento. Su jefe lo pone a cargo de analizar dicho aislamiento para extraer toda la informaci\u00f3n bioinform\u00e1tica posible de su colecci\u00f3n de datos. Breve descripci\u00f3n de la Familia Coronaviridae Los coronavirus son virus envueltos ARN simple cadena positivos (es decir que su genoma puede ser traducido directamente a prote\u00ednas virales por los ribosomas del hospedador). En la envoltura viral se encuentra la prote\u00edna E y la prote\u00edna Spike. En el interior, se encuentra el genoma ARN asociado con la prote\u00edna N formando la nucleoc\u00e1pside. La subfamilia Coronavirinae est\u00e1 formada por cuatro g\u00e9neros: Alphacoronavirus , Betacoronavirus , Gammacoronavirus y Deltacoronavirus . Cada g\u00e9nero agrupa distintas especies. Cada especie agrupa distintos tipos virales y cada tipo viral posee distintas variantes (algunos eligen llamarlas cepas o aislamientos, pero ac\u00e1 las llamamos variantes). En particular, SARS-CoV2 tambi\u00e9n conocido como COVID-19, se encuentra dentro del g\u00e9nero Betacoronavirus . Ahora si ... Usted cuenta con un conjunto de secuencias que utiliza normalmente en su laboratorio que guarda en el archivo All_Sequences.fasta , el record en All_Sequences.gb y datos de inter\u00e9s propio en conjunto_de_secuencias.xlsx . Pero\u2026 Cuando usted recibe los datos ( sequence_incognito.fasta ) se da cuenta que se olvidaron de nombrar correctamente un archivo! AVENAI trabaja con tantas secuencias que de vez en cuando se producen errores comunes como este. Para solucionarlo decide utilizar las herramientas que aprendi\u00f3 en el trabajo pr\u00e1ctico N3 de bioinform\u00e1tica cuando era estudiante y decide: Comparar la secuencia del nuevo aislamiento con la que crea m\u00e1s conveniente de su conjunto de secuencias. \u00bfPertenece el nuevo aislamiento a un coronavirus? Para responder a esta pregunta le sugerimos que realice un dotplot que le permita visualizar el alineamiento entre su secuencia inc\u00f3gnita y la(s) secuencias de su inter\u00e9s. Identifique y reporte qu\u00e9 patrones observa en el dotplot. Ahora quisiera saber a qu\u00e9 coronavirus se parece m\u00e1s, para esto decide determinar el % de similitud que posee su secuencia con el conjunto de secuencias con las que usted trabaja com\u00fanmente. Tip Si necesitan dividir el archivo All_Sequences.fasta en archivos individuales pueden buscar wossname split . Extra! (y por ende opcional) Para resolver el punto 2 pueden hacer un script de bash usando entre otras cosas un ciclo for . Si lo logran (o si lo intentan), los invito a incluirlo en el trabajo pr\u00e1ctico (incl\u00fayanlo a\u00fan si no les sali\u00f3 bien).","title":"TP 3 - Alineamientos de a pares"},{"location":"practicos/TP03_Alineamientos/#tp-3-alineamientos-de-secuencias-de-a-pares","text":"Materiales Atenci\u00f3n: Este TP tiene informe.","title":"data-toc-label"},{"location":"practicos/TP03_Alineamientos/#slides-mostrados-en-la-clase","text":"Cierre TP","title":"Slides mostrados en la clase"},{"location":"practicos/TP03_Alineamientos/#videos-de-la-clase-grabada","text":"Introducci\u00f3n al TP Cierre TP","title":"Videos de la clase grabada"},{"location":"practicos/TP03_Alineamientos/#objetivos","text":"Entender el funcionamiento b\u00e1sico del algoritmo de alineamiento de pares de secuencias de Needleman-Wunsch. Aprender a interpretar un Dot-Plot, pudiendo identificar las regiones relevantes que contienen patrones. Comprender los conceptos de similitud y homolog\u00eda de secuencias, y establecer una clara diferencia entre los mismos. Realizar un alineamiento m\u00faltiple de secuencias e interpretar qu\u00e9 informaci\u00f3n importante se puede extraer del mismo.","title":"Objetivos"},{"location":"practicos/TP03_Alineamientos/#introduccion","text":"El alineamiento de secuencias de a pares comprende la asignaci\u00f3n uno-a-uno de correspondencias entre los elementos que componen dichas secuencias sin alterar su orden. En dicho proceso tres eventos principales pueden tener lugar: Match (M) : Cuando los elementos enfrentados son equivalentes. Mismatch (m) : Cuando los elementos correspondientes son diferentes. Gap (g): Cuando un elemento de una secuencia no tiene par en la otra y se enfrenta a un espacio, caracterizado por un gui\u00f3n (-). Gap open: Cuando se abre un gap. Gap extend: Cuando se agregan gaps a continuaci\u00f3n de otro gap. Por ejemplo, si alineamos las secuencias AFGIVHKLIVS y AFGIHKIVS un posible resultado ser\u00eda: A F G I V H K L I V S A F G I - H K - I V S Los gaps no existen en la realidad. NO son un amino\u00e1cido o nucle\u00f3tido m\u00e1s, sino una herramienta que utilizamos para poder alinear. La principal funci\u00f3n de los alineamientos es establecer una medida de similitud entre las secuencias que participan en el mismo. Para ello es necesario definir un sistema de puntuaci\u00f3n que pese cada uno de los eventos que tienen lugar en la construcci\u00f3n del alineamiento. Asimismo, este esquema de puntajes o scoring nos permitir\u00e1 optimizar el alineamiento de forma tal que los algoritmos empleados elijan la correspondencia entre secuencias que maximice el puntaje o score global. Existen varios algoritmos de alineamiento: Los alineamientos globales (o de Needleman-Wunsch por sus creadores), se realizan apareando todos los elementos de una secuencia con todos los elementos de la otra. Este tipo de alineamientos se utiliza principalmente para comparar dos secuencias que son similares en longitud. Los alineamientos locales (o de Smith-Waterman), parean \u00fanicamente parte de las secuencias y son \u00fatiles para identificar, por ejemplo, dominios en com\u00fan. Los alineamientos mixtos , que combinan los dos anteriores.","title":"Introducci\u00f3n"},{"location":"practicos/TP03_Alineamientos/#dynamic-programming","text":"Dado un par de secuencias y un sistema de puntuaci\u00f3n o scoring se pueden aplicar diversos algoritmos para encontrar el alineamiento que d\u00e9 el mejor puntaje. El algoritmo m\u00e1s popular utiliza un m\u00e9todo matem\u00e1tico llamado dynamic programming . El mismo consiste en comparar ambas secuencias construyendo una matriz del alineamiento. Brevemente: Se comienza en el extremo superior izquierdo de la matriz, con un puntaje inicial de 0. En cada paso, se calcula el costo que tiene aparejado desplazarse de una celda a la otra, dado el sistema de puntajes pre-establecido, y se elige la opci\u00f3n m\u00e1s favorable, es decir aquella que maximice el puntaje global del alineamiento. En cada iteraci\u00f3n se guarda el puntaje con el que se lleg\u00f3 a una celda dada y el movimiento que origin\u00f3 dicho camino o path , indicado t\u00edpicamente con una flecha. Una vez que la matriz est\u00e1 completa en su totalidad se puede recorrer hacia atr\u00e1s o realizar un traceback , desde el extremo inferior derecho al superior izquierdo, para reconstruir el alineamiento. La principal ventaja de este m\u00e9todo es que siempre encuentra el alineamiento \u00f3ptimo entre las secuencias dadas. Sin embargo, una desventaja es pueden existir varios alineamientos que satisfagan esta condici\u00f3n. Otra desventaja es de origen t\u00e9cnica: la exhaustividad con la que el algoritmo realiza la b\u00fasqueda hace que su velocidad dependa de la longitud de las secuencias implicadas, haciendo poco eficiente la b\u00fasqueda de similitud de una secuencia contra una base de datos. Para esto existen diferentes adaptaciones del algoritmo que se ver\u00e1n m\u00e1s adelante.","title":"Dynamic programming"},{"location":"practicos/TP03_Alineamientos/#ejemplo","text":"Imaginen que queremos alinear las secuencias TCGCA y TCCA utilizando un esquema de scoring de: Match: M=1 Mismatch: m=-1 Gap: g=-2 Para eso ubicamos las secuencias en una matriz, donde cada una de sus dimensiones corresponda a una de las secuencias, tal como se muestra en la siguiente figura. Si observamos los paths 1 y 2 dibujados en las matrices de la figura podemos ver que se emplearon distintas estrategias para alinear este par de secuencias. En 1 se eligi\u00f3 alinear los dos primeros nucle\u00f3tidos TC por la diagonal, luego colocar un gap en la secuencia vertical TCCA y para finalizar se alinearon los nucle\u00f3tidos CA restantes por la diagonal. En 2 el primer nucle\u00f3tido T de ambas secuencias se aline\u00f3 por la diagonal, luego se coloc\u00f3 un gap en la secuencia vertical TCCA y finalmente se alinearon los 3 nucle\u00f3tidos GCA y CCA restantes por la diagonal. Si computamos los puntajes de ambos alineamientos, obtenemos que: La opci\u00f3n 1 tiene un puntaje de 2. Se propone colocar un \u00fanico gap permitiendo alinear al resto de los nucle\u00f3tidos en ambas secuencias con eventos de match . La opci\u00f3n 2 tiene un puntaje de 0. Las secuencias estudiadas se alinean con 1 gap , 1 mismatch y 3 matches . La estrategia es sub\u00f3ptima en relaci\u00f3n a 1 . Pregunta Si hubi\u00e9semos aplicado la metodolog\u00eda de dynamic programming para realizar un alineamiento global de estas secuencias, \u00bfcu\u00e1l ser\u00eda el path \u00f3ptimo resultante? A priori uno pensar\u00eda que es el path 1 , pero hagamos el ejercicio para corroborar si esto es efectivamente as\u00ed. Para comenzar, refresquemos c\u00f3mo funcionaba el m\u00e9todo de dynamic programming . Para llegar desde el extremo superior izquierdo (= inicio) de la matriz del alineamiento a la posici\u00f3n marcada con una x podr\u00edamos, hipot\u00e9ticamente, tomar cualquiera de los caminos dibujados en la figura de m\u00e1s arriba. Estos paths dar\u00edan alinemientos diferentes de las secuencias TC con TC . Pregunta Pero... \u00bfcu\u00e1l es el procedimiento iterativo empleado por el m\u00e9todo de dynamic programming para obtener el alineamiento \u00f3ptimo entre dos secuencias? Para llegar a cualquier celda de la matriz, uno puede acceder por, como m\u00e1ximo, 3 direcciones. La idea es siempre moverse en la direcci\u00f3n que maximice el score o puntaje. Veamos que : un movimiento en la direcci\u00f3n horizontal , de la posici\u00f3n (i, j-1) a la posici\u00f3n (i, j) , supone introducir un gap en la secuencia del eje vertical i un movimiento en la direcci\u00f3n diagonal , de la posici\u00f3n (i-1, j-1) a la posici\u00f3n (i, j) , supone un match o un mismatch entre los nucle\u00f3tidos enfrentados un movimiento en la direcci\u00f3n vertical , de la posici\u00f3n (i-1, j) a la posici\u00f3n (i, j) , supone introducir un gap en la secuencia del eje horizontal j Teniendo en cuenta la f\u00f3rmula para obtener el score enunciada m\u00e1s arriba, podemos comenzar con nuestro ejercicio! Recordemos que la matriz se llenar\u00e1 iterativamente, comenzando por la celda del extremo superior izquierdo, que tiene un puntaje de 0. Para moverse del (0, 0) al (0, 1), hay una s\u00f3la opci\u00f3n, moverse en forma horizontal . Esto significa alinear T con un gap , lo cual da un score de 0 + (-2) = -2. eje j: T eje i: - Lo mismo pasa al moverse del (0, 0) al (1, 0), hay una s\u00f3la opci\u00f3n, moverse en forma vertical . Esto significa alinear T con un gap , lo cual tambi\u00e9n da un score de 0 + (-2) = -2. eje j: - eje i: T Para moverse del (0, 0) al (1, 1) hay 3 maneras: 1. Hacer un movimiento vertical , lo cual da un score de -2 + (-2) = -4 -2 es el puntaje de la celda inicial (0, 1) El movimiento vertical implica colocar un gap : -2 Resultado: eje j: T - eje i: - T 2. Hacer un movimiento horizontal , lo cual da un score de -2 + (-2) = -4. Similar al caso anterior: -2 es el puntaje de la celda inicial (1, 0) El movimiento horizontal implica colocar un gap : -2 Resultado: eje j: - T eje i: T - 3. Hacer un movimiento diagonal , lo cual da un score de 0 + (+1). Implica alinear ambos nucl\u00e9otidos! 0 es el puntaje de la celda inicial (0, 0) Hay T en las ambas secuencias. Es un match : +1 Resultado: eje j: T eje i: T Para decidir qu\u00e9 valor ubicamos en la celda simplemente optamos por el que nos d\u00e9 el mayor score , en este caso 1, y se marca el movimiento que lo produjo: un movimiento diagonal. De esta manera podemos seguir completando la matriz, Obsevando la \u00faltima celda computada, podemos ver que hay nuevamente 3 maneras de llegar a la misma, Hacer un movimiento vertical , de (1, 3) a (2, 3): Es decir, introducir un gap en la secuencia horizontal j. Si (1, 3) tiene un score de -3, el nuevo score es: -3 + gap penalty = -3 + (-2) = -5 (flecha en direcci\u00f3n vertical). Hacer un movimiento horizontal , de (2, 2) a (2, 3). Es decir, introducir un gap en la secuencia vertical i. Si (2, 2) tiene un score de 2, el nuevo score es: 2 + gap penalty = 2 + (-2) = 0 (flecha en direcci\u00f3n horizontal). Hacer un movimiento diagonal , de (1, 2) a (2, 3). Es decir, alinear los nucle\u00f3tidos G y C. Si (1, 2) tiene un score de -1, el nuevo score es: -1 + mismatch = -1 + (-1) = -2 (flecha en direcci\u00f3n diagonal). El m\u00e1ximo de los 3 scores calculados es: max(-5, 0, -2) = 0, que corresponde al puntaje del movimiento horizontal . Entonces colocamos 0 en la celda (2, 3) y una flecha horizontal que indique el movimiento de (2, 2) a (2, 3). Al completar todas las celdas de la matriz, podemos saber cu\u00e1l es el puntaje de la celda ubicada en extremo inferior derecho, que en este caso result\u00f3 ser +2. Este tambi\u00e9n es el puntaje final del alineamiento. Para reconstruir el mismo, se parte de la celda ubicada en extremo inferior derecho y se siguen las flechas hasta llegar a la celda de inicio, en el extremo superior izquierdo. Las flechas en rojo resaltan el path del alineamiento, eje j: T C G C A eje i: T C - C A que podemos corroborar que es id\u00e9ntico al path 1 del ejemplo que se plante\u00f3 inicialmente.","title":"Ejemplo"},{"location":"practicos/TP03_Alineamientos/#ejercicio-1","text":"1.1 En grupo, realiz\u00e1 el alineamiento de las secuencias ATTGG con AGATGG , usando el esquema de puntajes: M=1, m=-1, g=-2. Para esto, abr\u00ed el siguiente Google Jamboard , guard\u00e1 una copia local del mismo en tu Google Drive y compart\u00ed el GJamboard a tus compa\u00f1eros de equipo. Atenci\u00f3n Para guardar una copia local del GJamboard en tu GDrive, clique\u00e1 en el \u00edcono con 3 puntitos, en el extremo superior derecho (M\u00e1s acciones). Luego seleccion\u00e1 la opci\u00f3n \"Hacer una copia\". Eleg\u00ed la carpeta adonde deseas guardarlo dentro de tu unidad y clique\u00e1 aceptar. \u00a1Ahora est\u00e1s listo para empezar! Record\u00e1 rellenar la matriz con todos los puntajes y flechas faltantes. Cuando termines, reconstru\u00ed el path del alineamiento. 1.2 Cuando termines el ejercicio anterior pod\u00e9s corrobar la soluci\u00f3n que hallaste ingresando en UniFreiburg-FreiburgRNATools . Segu\u00ed las siguientes instrucciones para usar este recurso web: a. Ingres\u00e1 las dos secuencias que quer\u00e9s alinear en los recuadros de Input Sequence a y Sequence b . Record\u00e1 que la secuencia que figura en tu matriz en sentido horizontal debe ser ingresada como Sequence b y la que figura en sentido vertical debe ser ingresada como Sequence a . b. Seleccion\u00e1 optimizaci\u00f3n de Similarity. c. Complet\u00e1 los valores de tu esquema de scoring . En el output podr\u00e1s apreciar dos salidas: A la izquierda, los valores de la matriz de alineamiento. Si cliqueas sobre los valores de la matriz, vas a observar que el valor sobre el que te paraste se colorea en verde, mientras que las celdas que dieron origen a ese valor se colorean en rosa. A la derecha, se observa el alineamiento final, donde un match se esquematiza en con *, un mismatch con | y un gap con _. 1.3 Respond\u00e9 a las siguientes preguntas: 1.3.1 Reproduc\u00ed el alineamiento que vimos como ejemplo al inicio ( TCGCA con TCCA , esquema de puntajes: M=1, m=-1, g=-2) en la web de la UniFreiburg-FreiburgRNATools \u00bfCu\u00e1ntas soluciones \u00f3ptimas hay para este alineamiento? \u00bfSucede lo mismo para el alineamiento que realizaste en el Ejercicio 1.1 ? \u00bfPor qu\u00e9? 1.3.2 Observ\u00e1 con detenimiento el output del panel de la izquierda (la matriz) Seleccion\u00e1 una celda. \u00bfQu\u00e9 sucede cuando clique\u00e1s en una celda y se colorea en verde y la celda aleda\u00f1a a la misma en rosa ? \u00bfA qu\u00e9 corresponde este coloreado o resaltado de las celdas? Observ\u00e1 nuevamente la matriz del alineamiento que obtuviste en 1.2 . Cliqu\u00e9a en la celda con puntaje -2 en la posici\u00f3n (A3, T2). Observ\u00e1 que se colorea en verde y dos celdas aleda\u00f1as a la misma en rosa . \u00bfEntend\u00e9s qu\u00e9 significa esto? \u00bfPod\u00e9s relacionarlo con los dos caminos \u00f3ptimos posibles que existen para este alineamiento? 1.3.3 Finalmente te propongo que realices el siguiente alineamiento: Sequence a: AGATGG y Sequence b: ATTGGG . Seleccion\u00e1 optimizaci\u00f3n de Similarity. Esquema de puntajes: M:1, m:-1, g:-5 . Registr\u00e1 con atenci\u00f3n el resultado. Ahora cambiemos el esquema de scoring , dejando el mismo valor para match, pero intercambiando los puntajes de gap y mismatch. \u00bfC\u00f3mo cambi\u00f3 el output? \u00bfQu\u00e9 observ\u00e1s ahora en las secuencias halladas como soluci\u00f3n \u00f3ptima en comparaci\u00f3n a lo que arrojaba el algoritmo con los par\u00e1metros anteriores?","title":"Ejercicio 1"},{"location":"practicos/TP03_Alineamientos/#dot-plots","text":"Los dot-plots son representaciones gr\u00e1ficas que dan un pantallazo sobre la similitud entre dos secuencias. En ellos se pueden identificar patrones que aporten informaci\u00f3n sobre la relaci\u00f3n entre ambas secuencias. La forma de obtener uno es muy sencilla: se establece una matriz donde cada elemento de una de las secuencias se corresponde con una fila y los de la otra con una columna. Acto seguido se procede a colorear cada celda donde los caracteres correspondientes a fila y columna sean equivalentes. Por ejemplo: Nosotros podemos utilizar la herramienta de EMBOSS dotmatcher para generar nuestros propios plots. Recordatorio Para ver qu\u00e9 par\u00e1metros toma de entrada la funci\u00f3n, correr en la terminal dotmatcher -h .","title":"Dot-Plots"},{"location":"practicos/TP03_Alineamientos/#ejercicio-2","text":"2.1 Utiliz\u00e1 la secuencia HS-ch11-fragment.fasta que se encuentra en la carpeta data para compararla contra s\u00ed misma. Esta secuencia es un peque\u00f1o fragmento del cromosoma 1 de Homo sapiens y la vamos a utilizar \u00fanicamente para ver algunos de los patrones que podemos encontrar en un dotplot. Gener\u00e1 un dotplot utilizando la secuencia HS-ch11-fragment.fasta contra s\u00ed misma. dotmatcher -graph X11 HS-ch1-fragment.fasta HS-ch1-fragment.fasta Atenci\u00f3n Recuerden abrir el archivo HS-ch11-fragment.fasta y chequear que la secuencia es de ADN. Es una buena pr\u00e1ctica conocer qu\u00e9 hay en los archivos que vamos a utilizar. \u00bfQu\u00e9 pod\u00e9s interpretar de este dotplot? La verdad es que el plot es bastante ruidoso, esto sucede muy a menudo en secuencias gen\u00f3micas ya que la cantidad de caracteres que componen las secuencias es muy limitada (solo 4) y por ello hay muchas ocurrencias y por lo tanto muchos puntos. Para limpiar el plot y quedarnos con los matches m\u00e1s significativos podemos jugar con dos par\u00e1metros: windowsize : Tama\u00f1o de ventana threshold : Umbral de ocurrencia Esto quiere decir que dotmatcher s\u00f3lo va a poner un punto cuando un fragmento del largo windowsize contenga un score mayor a threshold . Por ejemplo: dotmatcher -graph X11 -windowsize 50 -threshold 20 HS-ch1-fragment.fasta HS-ch1-fragment.fasta Si aument\u00e1s estos par\u00e1metros pod\u00e9s ir eliminando fragmentos que corresponden a secciones compartidas m\u00e1s cortas, sin embargo existe una relaci\u00f3n de compromiso, utilizar tama\u00f1o de ventana y umbral muy grandes nos llevan a perder informaci\u00f3n por lo que hay que seleccionarlos con cuidado. Aqui hay algunos patrones con los que te pod\u00e9s encontrar en este tipo de plots: a) Match perfecto. b) Repeticiones. c) Pal\u00edndromo. d) Repeticiones invertidas. e) Zonas de baja complejidad (microsatelites). f) Zonas altamente repetitivas (minisatelites). g) Secuencias con alta conservaci\u00f3n. h) Inserci\u00f3n o deleci\u00f3n. 2.2 Cambi\u00e1 los par\u00e1metros windowsize y threshold hasta obtener un plot que te parezca adecuado. \u00bfQu\u00e9 pod\u00e9s interpretar del mismo? Identific\u00e1 patrones.","title":"Ejercicio 2"},{"location":"practicos/TP03_Alineamientos/#similitud-y-homologia","text":"Los t\u00e9rminos similitud y homolog\u00eda se suelen utilizar como sin\u00f3nimos por muchos investigadores, sin embargo no lo son. La similitud es una caracter\u00edstica cuantitativa de un par de secuencias, donde se establece en qu\u00e9 grado estas se parecen (por ejemplo aplicando los algoritmos antes vistos, utilizando un sistema de puntaje). La homolog\u00eda , por otro lado, es una caracter\u00edstica cualitativa, dos secuencias SON o NO SON hom\u00f3logas. Homolog\u00eda implica espec\u00edficamente que el par de secuencias estudiadas provienen de un mismo ancestro com\u00fan. Esta afirmaci\u00f3n es completamente hipot\u00e9tica, ya que, salvo en contados casos, no se puede corroborar. Uno puede inferir que este es el caso dado la similitud observada en las secuencias actuales, sin tener acceso a las secuencias ancestrales. Atenci\u00f3n Decir que un par de secuencias tiene N% de homolog\u00eda es TOTALMENTE incorrecto. A partir de esta relaci\u00f3n entre similitud y homolog\u00eda se puede aplicar para inferir relaciones entre diferentes especies, buscar posibles funciones de una secuencia desconocida, etc.","title":"Similitud y Homolog\u00eda"},{"location":"practicos/TP03_Alineamientos/#ejercicio-3","text":"3.1 Determinar qu\u00e9 especies est\u00e1n m\u00e1s relacionadas utilizando la ribonucleasa pancre\u00e1tica de caballo ( Equus caballus ), ballena enana ( Balaenoptera acutorostrata ) y canguro rojo ( Macropus rufus ). 3.1.1 Descarg\u00e1 las secuencias antes mencionadas de la carpeta del TP. 3.1.2 Utiliz\u00e1 la herramienta de alineamiento global de EMBOSS needle (pueden leer el manual para ver que opciones admite) para comparar las tres secuencias. needle -gapopen 10 -gapextend 1 -asequence *secuencia_1* -bsequence *secuencia_2* -outfile *salida* 3.1.3 Observ\u00e1 e interpret\u00e1 las salidas obtenidas. \u00bfQu\u00e9 secuencias son m\u00e1s similares? \u00bfTiene sentido el resultado obtenido? 3.1.4 Analiz\u00e1 \u00e1rbol filogen\u00e9tico de la Fig. 1 del paper de O'Leary et al. , 2013. Sabiendo que los caballos y las ballenas pertenecen al clado Euungulata y los canguros al clado Marsupialia , ubic\u00e1 estos clado en el \u00e1rbol. \u00bfEsta informaci\u00f3n coincide con los resultados que obtuviste en 3.1.3 ? 3.2 Realiz\u00e1 el mismo procedimiento pero esta vez para determinar si los mamuts ( Mammuthus primigenius ) son m\u00e1s cercanos a los elefantes africanos ( Loxodonta africana ) o asi\u00e1ticos ( Elephas maximus ) utilizando la secuencia de la cadena alfa de la hemoglobina. 3.2.1 \u00bfQu\u00e9 te sugieren los resultados obtenidos? 3.2.2 \u00bfEs relevante la diferencia hallada? 3.2.3 \u00bfC\u00f3mo har\u00edas para sacar conclusiones m\u00e1s fuertes sobre las relaciones filogen\u00e9ticas entre los organismos estudiados en los ejercicios 3.1 y 3.2?","title":"Ejercicio 3"},{"location":"practicos/TP03_Alineamientos/#alineamientos-multiples","text":"Un alineamiento m\u00faltiple (MSA) involucra tres o m\u00e1s secuencias biol\u00f3gicas. Debido a que la tarea de alinear m\u00faltiples secuencias de largos biol\u00f3gicamente significativos suele ser muy demandante en t\u00e9rminos de recursos computacionales y tiempos de ejecuci\u00f3n estos requieren metodolog\u00edas m\u00e1s sofisticadas para llevarse a cabo. Por ello la mayor\u00eda de los programas disponibles para realizar MSA utiliza heur\u00edsticas en vez de algoritmos de optimizaci\u00f3n global. Heur\u00edstica Es una estrategia que busca resolver un problema m\u00e1s simple cuya soluci\u00f3n se interseca con la soluci\u00f3n de un problema m\u00e1s complejo. Generalmente esto implica que no es seguro encontrar el mejor resultado pero s\u00ed una soluci\u00f3n que sea aceptable. Las heur\u00edsticas se aplican con frecuencia en computaci\u00f3n para poder resolver problemas que, por su complejidad, ser\u00edan imposibles de abordar dados los limitados recursos con los que se cuentan. Dadas las secuencias de amino\u00e1cidos de un set de prote\u00ednas que se quieren comparar, el MSA muestra los residuos de cada prote\u00edna en una fila junto con los gaps que le correspondan de tal manera que todos los residuos \"equivalentes\" se encuentren en la misma columna. La utilidad de esta equivalencia depende de quien mire el alineamiento: Alguien que hace una filogenia puede enfocarse en que comparten un ancestro com\u00fan; Alguien que hace biolog\u00eda estructural puede enfocarse en que son residuos en posiciones an\u00e1logas de una estructura proteica; Alguien que hace biolog\u00eda molecular puede enfocarse en el rol funcional de esos residuos en la prote\u00edna. En cada caso un MSA provee un pantallazo sobre las restricciones evolutivas, estructurales o funcionales que caracterizan un set de prote\u00ednas de una manera visual e intuitiva. Un pipeline t\u00edpico para realizar un MSA ser\u00eda: Formular la pregunta que se quiere contestar. Por ejemplo, \"\u00bfQu\u00e9 estructura secundaria adopta X regi\u00f3n de mi prote\u00edna de inter\u00e9s?\" Obtener secuencias que puedan contestar a mi pregunta. Por ejemplo, secuencias que est\u00e9n relacionadas a mi prote\u00edna de inter\u00e9s. Utilizar alguno de los programas disponibles para llevar a cabo el MSA. Por ej. EMBOSS Realizar ajustes manuales para corregir posibles errores de los algoritmos de alineamiento.","title":"Alineamientos m\u00faltiples"},{"location":"practicos/TP03_Alineamientos/#ejercicio-4-adicional","text":"Atenci\u00f3n Antes de comenzar a resolver los ejercicios, instal\u00e1 ClustalW en tu VM, escribiendo el siguiente comando en la terminal: sudo apt install clustalw La gp120 es una prote\u00edna que recubre al virus del HIV y facilita su uni\u00f3n e ingreso a la c\u00e9lula que infecta (linfocitos CD4+) Entre nuestros archivos contamos con un multifasta (gp120.fasta) que contiene 27 secuencias de gp120 de HIV-1, HIV-2 y SIV. Estas prote\u00ednas contienen 9 puentes disulfuro conservados. Tambi\u00e9n es de inter\u00e9s el loop V3, una porci\u00f3n expuesta de la prote\u00edna, conocido target de anticuerpos el cual constituye una regi\u00f3n hipervariable dada la presi\u00f3n selectiva a la que se ve sometido. Pueden ver la disposici\u00f3n de las distintas regiones de la gp120 en el siguiente esquema: Mathys L, Balzarini J. Several N-Glycans on the HIV Envelope Glycoprotein gp120 Preferentially Locate Near Disulphide Bridges and Are Required for Efficient Infectivity and Virus Transmission. PLoS One. 2015 Jun 29;10(6):e0130621. doi: 10.1371/journal.pone.0130621. PMID: 26121645; PMCID: PMC4488071. Figure 1. 4.1 Utiliz\u00e1 las herramientas de EMBOSS para realizar un alineamiento m\u00faltiple con las secuencias de gp120 (recuerden que para buscar herramientas pueden usar wossname ) Pista El comando a utilizar es emma . Para ver la ayuda, tipe\u00e1 emma -help en la terminal. 4.2 Utiliz\u00e1 el comando showalign de EMBOSS para obtener una mejor visualizaci\u00f3n del alineamiento. Otra alternativa Para visualizar el alineamiento correctamente le sugerimos usar el comando cat en la consola. Si desea ver el archivo con Leafpad recuerde ingresar a Opciones > Tipograf\u00eda y seleccionar Ubuntu Mono. 4.3 Observ\u00e1 el alineamiento, como primer control podemos corroborar que las 18 Ciste\u00ednas ( C ) est\u00e9n bien alineadas. 4.4 Utiliz\u00e1 el esquema de gp120 para identificar diversas regiones ya sea conservadas o muy variables (Estructuras, loops, etc.) Tip Not\u00e1 que las posiciones en el alineamiento cuentan gaps por lo que no se corresponden exactamente con el esquema. Utiliz\u00e1 las posiciones de las ciste\u00ednas conservadas para identificar diferentes regiones.","title":"Ejercicio 4 (Adicional)"},{"location":"practicos/TP03_Alineamientos/#ejercicio-a-informar","text":"Info Fecha l\u00edmite de entrega: Domingo, 28 de Agosto 2022, 23:59hs. Materiales","title":"Ejercicio a informar"},{"location":"practicos/TP03_Alineamientos/#enunciado","text":"Usted trabaja en un laboratorio que estudia distintos aspectos del coronavirus. Desde el comienzo de la pandemia trabaja en colaboraci\u00f3n con la agencia de vigilancia epidemiol\u00f3gica nacional de agentes infecciosos (AVENAI). Como parte de la colaboraci\u00f3n, todos los d\u00edas se obtienen clones y secuencias de nuevos aislamientos. AVENAI comparte con su jefe un nuevo aislamiento. Su jefe lo pone a cargo de analizar dicho aislamiento para extraer toda la informaci\u00f3n bioinform\u00e1tica posible de su colecci\u00f3n de datos.","title":"Enunciado"},{"location":"practicos/TP03_Alineamientos/#breve-descripcion-de-la-familia-coronaviridae","text":"Los coronavirus son virus envueltos ARN simple cadena positivos (es decir que su genoma puede ser traducido directamente a prote\u00ednas virales por los ribosomas del hospedador). En la envoltura viral se encuentra la prote\u00edna E y la prote\u00edna Spike. En el interior, se encuentra el genoma ARN asociado con la prote\u00edna N formando la nucleoc\u00e1pside. La subfamilia Coronavirinae est\u00e1 formada por cuatro g\u00e9neros: Alphacoronavirus , Betacoronavirus , Gammacoronavirus y Deltacoronavirus . Cada g\u00e9nero agrupa distintas especies. Cada especie agrupa distintos tipos virales y cada tipo viral posee distintas variantes (algunos eligen llamarlas cepas o aislamientos, pero ac\u00e1 las llamamos variantes). En particular, SARS-CoV2 tambi\u00e9n conocido como COVID-19, se encuentra dentro del g\u00e9nero Betacoronavirus .","title":"Breve descripci\u00f3n de la Familia Coronaviridae"},{"location":"practicos/TP03_Alineamientos/#ahora-si","text":"Usted cuenta con un conjunto de secuencias que utiliza normalmente en su laboratorio que guarda en el archivo All_Sequences.fasta , el record en All_Sequences.gb y datos de inter\u00e9s propio en conjunto_de_secuencias.xlsx . Pero\u2026 Cuando usted recibe los datos ( sequence_incognito.fasta ) se da cuenta que se olvidaron de nombrar correctamente un archivo! AVENAI trabaja con tantas secuencias que de vez en cuando se producen errores comunes como este. Para solucionarlo decide utilizar las herramientas que aprendi\u00f3 en el trabajo pr\u00e1ctico N3 de bioinform\u00e1tica cuando era estudiante y decide: Comparar la secuencia del nuevo aislamiento con la que crea m\u00e1s conveniente de su conjunto de secuencias. \u00bfPertenece el nuevo aislamiento a un coronavirus? Para responder a esta pregunta le sugerimos que realice un dotplot que le permita visualizar el alineamiento entre su secuencia inc\u00f3gnita y la(s) secuencias de su inter\u00e9s. Identifique y reporte qu\u00e9 patrones observa en el dotplot. Ahora quisiera saber a qu\u00e9 coronavirus se parece m\u00e1s, para esto decide determinar el % de similitud que posee su secuencia con el conjunto de secuencias con las que usted trabaja com\u00fanmente. Tip Si necesitan dividir el archivo All_Sequences.fasta en archivos individuales pueden buscar wossname split . Extra! (y por ende opcional) Para resolver el punto 2 pueden hacer un script de bash usando entre otras cosas un ciclo for . Si lo logran (o si lo intentan), los invito a incluirlo en el trabajo pr\u00e1ctico (incl\u00fayanlo a\u00fan si no les sali\u00f3 bien).","title":"Ahora si ..."},{"location":"practicos/TP04_Busqueda_por_similitud/","text":"TP 4 . B\u00fasqueda de secuencias por similitud Materiales Slides mostrados en la clase Cierre TP Videos de la clase grabada Introducci\u00f3n al TP Cierre TP Objetivos Familiarizarse con el uso de programas de b\u00fasqueda de secuencias en bases de datos (BLAST y FASTA), y en particular con el uso de estos programas en la l\u00ednea de comando. Familiarizarse con la visualizaci\u00f3n de histogramas que arroja FASTA. Familiarizarse con el uso de par\u00e1metros estad\u00edsticos en relaci\u00f3n a la b\u00fasqueda en bases de datos. \u00a1Antes de comenzar! Para realizar este TP tienen que estar frente a una terminal UNIX. Los programas que vamos a utilizar son: blastall, blastcl3, formatdb y fastacmd (NCBI-Toolkit), fasta, tfasta, fastx, tfastx, fasty, tfasty, ssearch, prss ( FASTA program package). Para instalarlos, descarguemos el archivo install.sh de la carpeta de trabajo provista y ejecutemos el comando. bash install.sh Introducci\u00f3n a Bases de Datos de Prote\u00ednas La mayor base de datos de Uniprot es UniProtKB (UniProt KnowledgeBase) que est\u00e1 dividida en dos secciones: TrEMBL y Swiss-Prot. TrEMBL es una recolecci\u00f3n de prote\u00ednas anotadas autom\u00e1ticamente que en su mayor\u00eda, aunque no de manera exclusiva, fueron obtenidas a partir de la traducci\u00f3n de secuencias nucleot\u00eddicas codificantes (CoDing Sequences, CDS) disponibles en GenBank. Recordatorio Una secuencia codificante (CDS) es una regi\u00f3n de ADN o ARN cuya secuencia determina la secuencia de amino\u00e1cidos en una prote\u00edna. No se debe confundir con un marco abierto de lectura (Open Reading Frame, ORF) que es una regi\u00f3n continua de codones de ADN que empiezan con un cod\u00f3n de inicio y termina con un cod\u00f3n stop. Todos los CDS son ORFs pero no todos los ORFs son CDS, por ejemplo, los ORFs incluye a los intrones. Swiss-Prot es una base de datos de prote\u00ednas que fueron revisadas y anotadas manualmente por un curador/a experto/a. Por lo tanto, Swiss-Prot contiene la informaci\u00f3n de m\u00e1s alta calidad para secuencias de prote\u00ednas. TrEMBL brinda los datos crudos para que los curadores de Swiss-Prot los revisen. Por lo tanto, TrEMBL tiene m\u00e1s entradas que Swiss-Prot, pero carece de la anotaci\u00f3n manual de un experto. En este TP trabajaremos con Swiss-Prot . Introducci\u00f3n a BLAST BLAST busca secuencias similares a una secuencia query en una base de datos de secuencias, utilizando distintas estrategias de b\u00fasqueda: BLASTn : compara una secuencia nucleot\u00eddica query contra una base de datos de secuencias nucleot\u00eddicas. BLASTx : compara una secuencia nucleot\u00eddica query , que es traducida en los 6 posibles marcos de lectura (resultando en 6 secuencias proteicas), contra una base de datos de secuencias proteicas. tBLASTn : compara una secuencia proteica query contra las traducciones (6 posibles marcos de lectura) de una base de datos de secuencias nucleot\u00eddicas. BLASTp : compara una secuencia proteica query contra una base de datos de secuencias proteicas. BLAST , tal como es distribu\u00eddo por el NCBI , se encuentra disponible mediante el comando blastall . Este comando necesita como m\u00ednimo tres argumentos para realizar una b\u00fasqueda: -i una secuencia query (recordar, i = input) -d una base de datos con secuencias (recordar, d = database) -p el tipo de busqueda (p = programa: blastp , blastn , blastx , etc.) Tip Para ver una lista de los argumentos que acepta blastall prueben correr el comando sin argumentos. Si esto no les funciona pueden ver todos los argumentos haciendo click aqu\u00ed . Recordatorio: Estad\u00edstica de los Alineamientos \u00bfQu\u00e9 es un Expect value o E-value ? El E-value (E) es un par\u00e1metro que describe el n\u00famero de hits que uno espera encontrar por azar cuando est\u00e1 buscando en una base de datos de un tama\u00f1o particular. Este disminuye exponencialmente a medida que el Score (S) del alineamiento aumenta. Esencialmente el E-value describe el ruido de fondo aleatorio que est\u00e1 presente al realizar una b\u00fasqueda en una base de datos de secuencias. Cuanto m\u00e1s peque\u00f1o sea el E-value, o m\u00e1s cercano a 0, m\u00e1s significativo resulta ser nuestro hit. Sin embargo, siempre hay que tener en cuenta que los alineamientos cortos tienen E-values relativamente altos, y esto es debido a que el E-value tiene en cuenta el largo de la secuencia query . Estos E-values tienen sentido porque las secuencias cortas tienen una probabilidad m\u00e1s alta de estar presentes en una base de datos puramente por azar. El E-value es un par\u00e1metro conveniente para establecer un umbral de significancia a la hora de reportar los resultados de una b\u00fasqueda en una base de datos. Uno puede cambiar el E-value umbral al listar los resultados de una b\u00fasqueda con BLAST. Recordemos la f\u00f3rmula para calcular el E-value (E) de la te\u00f3rica. Ejercicio 1 1.1 Como primer ejemplo podemos usar la secuencia xlrhodop.pep para realizar una b\u00fasqueda contra Swiss-Prot . Como estamos trabajando con una secuencia y una base de datos de prote\u00ednas, usamos blastp para realizar la busqueda: blastall -p blastp -i xlrhodop.pep -d ~/Swissprot_db/Swissprot.fasta Atenci\u00f3n Este comando no se ejecutar\u00e1 correctamente si uno mueve de lugar el archivo de la base de datos Swiss-Prot luego de ejecutar install.sh . Si este es el caso, especifique el camino o path completo. En este ejemplo, el resultado de la b\u00fasqueda es volcado en la pantalla (stdout). Para que el resultado aparezca en un archivo, podemos redireccionar stdout (usando > , ver TP01-Linux) o usar la opcion -o (output). blastall -p blastp -i xlrhodop.pep -d ~/Swissprot_db/Swissprot.fasta -o xlrhodop.blastp Pueden ver el resultado del blastp , por ejemplo paginando el archivo: less xlrhodop.blastp \u00bfQu\u00e9 indican las \u00faltimas l\u00edneas de este archivo? Si recuerda c\u00f3mo se computa el E-value, \u00bfentiende la relevancia de reportar el tama\u00f1o de la base de datos ( number of letters , number of sequences )? Nota El t\u00e9rmino neighboring words refiere a palabras \"vecinas\" o \"cercanas\", es decir con alta similitud de secuencia. Atenci\u00f3n Si corren blastp s\u00f3lo, es decir sin invocar primero al comando blastall , van a poder realizar las mismas b\u00fasquedas pero los nombres de los argumentos del comando blastp s\u00f3lo difieren de los de blastall -p blastp . Por lo tanto, no les recomendamos correrlo de esta forma. 1.2 Explore las siguientes opciones del programa blastp : -G Costo del gap open ( default : 11) -E Costo del gap extend ( default : 1) -W Tama\u00f1o de la ktupla. ( default : 3, puede variar entre 2 y 7) Atenci\u00f3n Hay tuplas de valores permitidos para los argumentos -G y -E , no cualquier combinaci\u00f3n de costos es v\u00e1lida. Pruebe con distintas combinaciones de estos par\u00e1metros y preste atenci\u00f3n al impacto que esto tiene en los alineamientos reportados. 1.2.1 Responda a las siguientes preguntas: a. Si observa los primeros 20 hits de su b\u00fasqueda, \u00bfpuede detectar alguna diferencia en los alineamientos reportados si cambia los par\u00e1metros indicados m\u00e1s arriba? b. A medida que va descendendiendo en la lista de los hits reportados (menor Score, mayor E-value), \u00bfqu\u00e9 patrones puede observar en los alineamientos que arroja BLAST? c. Tome como ejemplo dos de los siguientes hits: - OPSD_CARAU - OPN4A_DANRE - OPN4_RUTRU y complete para cada uno de los alinemientos reportados la siguiente tabla, teniendo en cuenta los diferentes costos de gap open y gap extend propuestos. N\u00famero total de gaps Extensi\u00f3n de la regiones con gaps Gap open: 6 + gap extend: 2 Gap open: 13 + gap extend: 1 1.2.2 Opcional : Evaluando el impacto del par\u00e1metro longitud de la k-tupla. Responda a las siguientes preguntas: Para una misma combinaci\u00f3n de costos para gap open y gap extend (pueden usar los valores default): a. \u00bfQu\u00e9 sucede con los valores de ktupla=2 y ktupla=7 ? b. \u00bfCu\u00e1l b\u00fasqueda es la que tarda m\u00e1s? \u00bfCu\u00e1l menos? c. \u00bfCu\u00e1ntas secuencias devuelven? Para los m\u00e1s curiosos, las respuestas a estas preguntas pueden hallarlas en el siguiente link . Introducci\u00f3n a FASTA Curiosidad El nombre FASTA proviene de \"FAST-All\" porque funciona con cualquier alfabeto, esto significa que es una extensi\u00f3n de las herramientas originales para realizar alineamientos \"FAST-P\" (prote\u00ednas) y \"FAST-N\" (nucle\u00f3tidos). El formato \".fasta\" para almacenar secuencias de prote\u00ednas o nucle\u00f3tidos se origina con el software FASTA , es por esto que llevan el mismo nombre. Al igual que BLAST , FASTA necesita los mismos tres argumentos obligatorios. Sin embargo, el paquete FASTA provee un comando ejecutable para cada tipo de b\u00fasqueda. Comparaci\u00f3n de programas en el paquete FASTA FASTA permite comparar una secuencia proteica contra una base de datos de prote\u00ednas o una secuencia de ADN contra una base de datos de ADN ( Pearson and Lipman, 1988, Pearson, 1996 ). La velocidad de la b\u00fasqueda y la selectividad est\u00e1n controladas por el par\u00e1metro ktup ( word size ). Para comparaciones entre prote\u00ednas, ktup=2 es el default, ktup=1 es m\u00e1s sensible pero m\u00e1s lento. Para comparaciones entre secuencias de ADN, ktup=6 es el default, ktup=3 o ktup=4 proveen una mayor sensibilidad, ktup=1 debe ser utilizado para oligonucle\u00f3tidos (secuencias query de ADN de longitud < 20). ssearch Compara una secuencia proteica contra una base de datos de prote\u00ednas o una secuencia de ADN contra una base de datos de ADN usando el algoritmo de Smith-Waterman (Smith and Waterman, 1981). fastx y fasty Compara una secuencia de ADN contra una base de datos de prote\u00ednas. fasty compara la secuencia de ADN traducida en 3 marcos de lectura, permitiendo gaps y frameshifts. Es m\u00e1s lento que fastx pero produce mejores alineamientos para secuencias de baja calidad ya que los frameshifts se admiten entre codones. fastx usa un algoritmo m\u00e1s simple y r\u00e1pido para alineamientos que permiten frameshifts s\u00f3lo entre codones. tfastx Compara una secuencia proteica a una base de datos de ADN, calculando las similaridades con frameshifts para las orientaciones forward y reverse. tfasta Compara una secuencia proteica a una base de datos de ADN, calculando las similaridades (sin frameshifts) para los 3 forward y los 3 reverse ORFs. tfastx es preferido debido a que calcula las similaridades teniendo en cuenta frameshifts. fasts Compara un set peque\u00f1o de p\u00e9ptidos, obtenidos por ejemplo de un experimento de espectrometr\u00eda de masas, contra una base de datos de prote\u00ednas ( fasts ) o de ADN ( tfasts ). Ejercicio 2 Ahora corramos la misma b\u00fasqueda del ejemplo anterior usando FASTA: fasta -H xlrhodop.pep ~/Swissprot_db/Swissprot.fasta > xlrhodop.fasta Para interpretar correctamente el histograma que FASTA da como output tenemos que pensar que est\u00e1 apaisado (o rotado 90 grados en sentido horario) con respecto al t\u00edpico histograma que muestra la distribuci\u00f3n de scores para todas las secuencias halladas. Esto se ilustra en la siguiente figura. 2.1 Responda a las siguientes preguntas con respecto al histograma apaisado que obtuvo como output: a. \u00bfQu\u00e9 valores se representan en el eje y (vertical)? b. \u00bfQu\u00e9 valores se representan en el eje x (horizontal)? c. \u00bfQu\u00e9 representan los asteriscos \"*\" ? d. \u00bfQu\u00e9 representan los iguales \"=\" ? \u00bfCu\u00e1nto representa el \"=\" ? e. \u00bfQu\u00e9 es la primera columna de n\u00fameros?, \u00bfpor qu\u00e9 hay un \"<\" en la primera l\u00ednea? y \u00bfpor qu\u00e9 hay un \">\" en la \u00faltima? f. \u00bfQu\u00e9 es la segunda columna de n\u00fameros? (Pista: mir\u00e1 el n\u00fameros de iguales que hay en esa l\u00ednea) g. \u00bfQu\u00e9 es la tercera columna de n\u00fameros? h. \u00bfQu\u00e9 es un inset? \u00bfQu\u00e9 regi\u00f3n del histograma est\u00e1 representada en el inset? \u00bfCu\u00e1nto representa el \"=\" en el inset? i. \u00bfEl valor del \u201c=\u201d en el inset es mayor o menor que en el resto del histograma? \u00bfTiene sentido? 2.2 \u00bfPor qu\u00e9 le parece que es relevante que se reporte el tama\u00f1o de la base de datos ( \"x residues in y sequences\" ) en el header del archivo de salida? 2.3 \u00bfQu\u00e9 par\u00e1metros se utilizaron en esta corrida con FASTA? 2.4 \u00bfEn qu\u00e9 se diferencian las distribuciones esperadas y observadas? \u00bfQu\u00e9 implica? 2.5 \u00bfEn qu\u00e9 regi\u00f3n del histograma se ubican los puntajes de los alineamientos que consideramos m\u00e1s significativos ( hits con mejor puntaje)? 2.6 \u00bfQu\u00e9 representa el n\u00famero que est\u00e1 entre par\u00e9ntesis en el E (ver figura m\u00e1s abajo)? \u00bfCu\u00e1l es el E-value para el mejor hit ? Diferencias entre BLAST y FASTA ktup: Tanto FASTA como BLAST usan una estrategia de b\u00fasqueda inicial basada en palabras cortas. ktup en FASTA es el par\u00e1metro que indica el tama\u00f1o de la palabra utilizada en esta b\u00fasqueda inicial. FASTA utiliza por default ktup=2, mientras que BLAST utiliza ktup=3. Sin embargo, FASTA s\u00f3lo considera identidades respecto a la palabra, mientras que BLAST utiliza identidades y sustituciones conservativas. Por lo tanto BLAST con ktup=3 es en general m\u00e1s sensible que FASTA con ktup=2. FASTA con ktup=1 es m\u00e1s sensible, pero es tambi\u00e9n m\u00e1s lento. Matrices y scores: BLAST y FASTA usan distintas matrices de scoring y gap penalties por default (BLAST: BLOSUM62, gap open:-11, gap extend:-1; FASTA: BLOSUM50, gap open:-10, gap extend:-2). Estad\u00edsticas Los par\u00e1metros kappa y lambda son centrales para estimar scores en BLAST y en FASTA. FASTA calcula estos par\u00e1metros on the fly a partir de la base de datos (se tiene en cuenta el tama\u00f1o) y la matriz de scoring . Esto produce estad\u00edsticas m\u00e1s representativas, pero puede ser problem\u00e1tico para bases de datos peque\u00f1as. Si la base de datos es de menos de 10 secuencias, FASTA no estima estos par\u00e1metros. BLAST usa valores pre-calculados para estos par\u00e1metros, que fueron derivados a partir de simulaciones. Alineamientos: BLAST puede mostrar varios alineamientos por cada par de secuencias (varios high-scoring pairs o HSPs) aunque por default s\u00f3lo muestra el mejor, FASTA \u00fanicamente reporta un alineamiento posible. Filtrado de secuencias de baja complejidad: Por default, BLAST filtra secuencias de baja complejidad o repeticiones, \u00a1FASTA no! Esto puede afectar la capacidad de discriminar falsos positivos, aunque FASTA provee otro tipo de opciones para manejar este tipo de casos. Ver la secci\u00f3n espec\u00edfica sobre este punto m\u00e1s abajo. Traducciones: blastx hace 6 b\u00fasquedas independientes (una en cada marco de lectura) mientras que fastx3 y fasty3 hacen una \u00fanica b\u00fasqueda forward (o reverse usando -i ) que permite frameshifts . Estos \u00faltimos son m\u00e1s sensibles y pueden producir mejores alineamientos que blastx cuando se usan secuencias de baja calidad (lo mismo es cierto para tblastn vs tfastx3 y tfasty3 ). Hom\u00f3logos distantes: Existe una opci\u00f3n en FASTA ( -F ) que les permite ignorar (i.e. que no aparezcan en el output) secuencias altamente similares al query . Esto es \u00fatil, por ejemplo, para focalizar una b\u00fasqueda en las secuencias m\u00e1s divergentes. No existe una opci\u00f3n similar en BLAST . Secuencias cortas: Ya sea que busquen un primer o un p\u00e9ptido, si quieren utilizar BLAST o FASTA para esto, tengan en cuenta que BLAST es generalmente in\u00fatil al respecto. Esto es porque BLAST tiene un l\u00edmite inferior sobre la longitud que puede tener una palabra (ktup). En el caso de nucle\u00f3tidos, el l\u00edmite inferior es 7 (el default es 11). En este sentido FASTA es mejor, porque siempre pueden usar ktup=1. Por otra parte, en el caso espec\u00edfico de p\u00e9ptidos, FASTA provee algunos algoritmos particulares de b\u00fasqueda ( fastf , fasts y tfasf , tfasts ). Tip Usar un cuchillo en lugar de un destornillador, a veces puede funcionar, pero no deja de ser cierto que cada herramienta fue dise\u00f1ada para un fin distinto. Si quieren realizar b\u00fasquedas de secuencias cortas prueben primero con fuzznuc , fuzzpro o findpatterns (todos parte de EMBOSS ). Filtrado de secuencias de baja complejidad Muchas secuencias son altamente repetitivas. Si la secuencia query contiene regiones de baja complejidad o repeticiones, es posible que una b\u00fasqueda encuentre muchas secuencias no relacionadas, con altos scores (por ej. hits contra colas de poly-A o regiones ricas en Prolina). En otros casos, la secuencia puede contener un vector (pl\u00e1smido) o repeticiones Alu, que ustedes pueden querer omitir en la b\u00fasqueda. BLAST permite filtrar el primer tipo de casos, mediante la opci\u00f3n -F . FASTA en cambio no provee esta alternativa. Es el usuario el que tiene que filtrar el query antes de realizar una b\u00fasqueda. Ejercicio 3 3.1 Usar la prote\u00edna Groucho de Drosophila (grou_drome) para buscar secuencias similares en Swiss-Prot usando BLAST . Comparar los resultados obtenidos usando ( -F T ) o sin usar ( -F F ) la opci\u00f3n de filtrado que provee BLAST . Observen el primer hit en las lista de los alineamientos resultantes. \u00bfQu\u00e9 pueden detectar de diferencia entre los dos comandos que corrieron? 3.2 Ahora para repetir el mismo ejercicio con FASTA , tenemos que detectar y marcar las regiones de baja complejidad. Para esto se utiliza segmasker : segmasker -in grou_drome.fasta -outfmt fasta > grou_drome_lc.fasta 3.3 Comparen las secuencias grou_drome.fasta y grou_drome_lc.fasta e identifiquen las diferencias. \u00bfQu\u00e9 hizo segmasker con la secuencia? Ahora, podemos buscar secuencias similares en Swiss-Prot usando grou_drome.fasta (con opciones standard) y grou_drome_lc.fasta (usando la opci\u00f3n -S ). fasta -H grou_drome.fasta ~/Swissprot_db/Swissprot.fasta fasta -H -S grou_drome_lc.fasta ~/Swissprot_db/Swissprot.fasta \u00bfQu\u00e9 diferencias encuentran en los histogramas de cada b\u00fasqueda? Bases de datos propias Tener acceso a BLAST o FASTA en la l\u00ednea de comando les da la posibilidad de crear sus propias bases de datos para realizar b\u00fasquedas. FASTA puede realizar b\u00fasquedas sobre un archivo en formato fasta conteniendo varias secuencias sin ning\u00fan otro tipo de tratamiento. BLAST , sin embargo necesita contar con una base de datos indexada. formatdb es el comando que vamos a utilizar para generar los \u00edndices que BLAST necesita. Adicional: Ejercicio 4 4.1 Primero, vamos a generar un archivo fasta m\u00faltiple con algunas secuencias. Por ejemplo, para construir una base de datos con secuencias de opsinas podemos empezar con: seqret \"~/Swissprot_db/Swissprot.fasta:ops*\" fasta::ops Esto deber\u00eda generar un archivo FASTA m\u00faltiple conteniendo secuencias de opsinas. 4.2 \u00bfCu\u00e1ntas secuencias tiene nuestra base de datos? Ahora para indexar el archivo ops (en formato fasta ), usamos formatdb , indic\u00e1ndole el archivo que contiene las secuencias ( -i ) y si el archivo contiene secuencias de ADN ( -p F ) o de prote\u00ednas ( -p T ). formatdb -i ops -p T 4.3 Una vez indexada la base de datos, podemos hacer una b\u00fasqueda, por ejemplo, con nuestra ya conocida xlrhodop.pep blastall -p blastp -d ./ops -i xlrhodop.pep > xlrhodop.ops.blastp Pueden ver las opciones que acepta el comando formatdb pidiendo ayuda: #formatdb --help ... (en versiones viejas de blast se pod\u00eda usar este comando... pero ya no) makeblastdb -help BLAST con m\u00faltiples secuencias Si tienen un archivo con m\u00faltiples secuencias en formato fasta , pueden usarlo como query en una b\u00fasqueda, usando BLAST . Adicional: Ejercicio 5 5.1 El archivo opsv.fasta contiene la secuencia de 4 fotorreceptores, usen este archivo para realizar una b\u00fasqueda, usando blastp , contra la base de datos ops que crearon en el ejercicio anterior. 5.2 El output generado consiste en 4 reportes de BLAST , concatenados en un \u00fanico archivo. \u00bfC\u00f3mo pueden navegar f\u00e1cilmente dentro del documento usando less ? Tip Tip: \u00bfqu\u00e9 palabras o conjunto de palabras ocurren una sola vez en cada reporte? 5.3 Ahora puedo leer el reporte y manejarme bien dentro de \u00e9l. Si quiero partirlo en 4 reportes individuales \u00bfC\u00f3mo hago? Para esto pueden usar el comando de Unix split que puede partir un archivo en otros m\u00e1s peque\u00f1os, ya sea por tama\u00f1o o cada vez que encuentre una palabra o pattern (patr\u00f3n, expresi\u00f3n regular). Usando la opci\u00f3n -p pueden especificar un pattern . Info La opci\u00f3n -p s\u00f3lo est\u00e1 disponible en el comando split de sistemas operativos del tipo BSD ( FreeBSD , NetBSD ). Linux usa el comando split de GNU, donde esta opci\u00f3n no existe. man split Tanto en Linux como en cualquier Unix, una manera de partir un archivo en varios usando un pattern es usando el comando awk : Dado un archivo llamado blast.out , podemos partirlo en varios usando la siguiente invocaci\u00f3n: awk -v i = 0 '/pattern/{i++}{print > \"blast.\"i}' blast.out Atenci\u00f3n Recuerden reemplazar \" pattern \" por el patr\u00f3n que quieren utilizar para dividir el archivo. \u00bfLo lograron? Bibliograf\u00eda Tutorial de BLAST en la web del NCBI: The Statistics of Sequence Similarity Scores","title":"TP 4 - B\u00fasqueda por similitud"},{"location":"practicos/TP04_Busqueda_por_similitud/#tp-4-busqueda-de-secuencias-por-similitud","text":"Materiales","title":"data-toc-label"},{"location":"practicos/TP04_Busqueda_por_similitud/#slides-mostrados-en-la-clase","text":"Cierre TP","title":"Slides mostrados en la clase"},{"location":"practicos/TP04_Busqueda_por_similitud/#videos-de-la-clase-grabada","text":"Introducci\u00f3n al TP Cierre TP","title":"Videos de la clase grabada"},{"location":"practicos/TP04_Busqueda_por_similitud/#objetivos","text":"Familiarizarse con el uso de programas de b\u00fasqueda de secuencias en bases de datos (BLAST y FASTA), y en particular con el uso de estos programas en la l\u00ednea de comando. Familiarizarse con la visualizaci\u00f3n de histogramas que arroja FASTA. Familiarizarse con el uso de par\u00e1metros estad\u00edsticos en relaci\u00f3n a la b\u00fasqueda en bases de datos. \u00a1Antes de comenzar! Para realizar este TP tienen que estar frente a una terminal UNIX. Los programas que vamos a utilizar son: blastall, blastcl3, formatdb y fastacmd (NCBI-Toolkit), fasta, tfasta, fastx, tfastx, fasty, tfasty, ssearch, prss ( FASTA program package). Para instalarlos, descarguemos el archivo install.sh de la carpeta de trabajo provista y ejecutemos el comando. bash install.sh","title":"Objetivos"},{"location":"practicos/TP04_Busqueda_por_similitud/#introduccion-a-bases-de-datos-de-proteinas","text":"La mayor base de datos de Uniprot es UniProtKB (UniProt KnowledgeBase) que est\u00e1 dividida en dos secciones: TrEMBL y Swiss-Prot. TrEMBL es una recolecci\u00f3n de prote\u00ednas anotadas autom\u00e1ticamente que en su mayor\u00eda, aunque no de manera exclusiva, fueron obtenidas a partir de la traducci\u00f3n de secuencias nucleot\u00eddicas codificantes (CoDing Sequences, CDS) disponibles en GenBank. Recordatorio Una secuencia codificante (CDS) es una regi\u00f3n de ADN o ARN cuya secuencia determina la secuencia de amino\u00e1cidos en una prote\u00edna. No se debe confundir con un marco abierto de lectura (Open Reading Frame, ORF) que es una regi\u00f3n continua de codones de ADN que empiezan con un cod\u00f3n de inicio y termina con un cod\u00f3n stop. Todos los CDS son ORFs pero no todos los ORFs son CDS, por ejemplo, los ORFs incluye a los intrones. Swiss-Prot es una base de datos de prote\u00ednas que fueron revisadas y anotadas manualmente por un curador/a experto/a. Por lo tanto, Swiss-Prot contiene la informaci\u00f3n de m\u00e1s alta calidad para secuencias de prote\u00ednas. TrEMBL brinda los datos crudos para que los curadores de Swiss-Prot los revisen. Por lo tanto, TrEMBL tiene m\u00e1s entradas que Swiss-Prot, pero carece de la anotaci\u00f3n manual de un experto. En este TP trabajaremos con Swiss-Prot .","title":"Introducci\u00f3n a Bases de Datos de Prote\u00ednas"},{"location":"practicos/TP04_Busqueda_por_similitud/#introduccion-a-blast","text":"BLAST busca secuencias similares a una secuencia query en una base de datos de secuencias, utilizando distintas estrategias de b\u00fasqueda: BLASTn : compara una secuencia nucleot\u00eddica query contra una base de datos de secuencias nucleot\u00eddicas. BLASTx : compara una secuencia nucleot\u00eddica query , que es traducida en los 6 posibles marcos de lectura (resultando en 6 secuencias proteicas), contra una base de datos de secuencias proteicas. tBLASTn : compara una secuencia proteica query contra las traducciones (6 posibles marcos de lectura) de una base de datos de secuencias nucleot\u00eddicas. BLASTp : compara una secuencia proteica query contra una base de datos de secuencias proteicas. BLAST , tal como es distribu\u00eddo por el NCBI , se encuentra disponible mediante el comando blastall . Este comando necesita como m\u00ednimo tres argumentos para realizar una b\u00fasqueda: -i una secuencia query (recordar, i = input) -d una base de datos con secuencias (recordar, d = database) -p el tipo de busqueda (p = programa: blastp , blastn , blastx , etc.) Tip Para ver una lista de los argumentos que acepta blastall prueben correr el comando sin argumentos. Si esto no les funciona pueden ver todos los argumentos haciendo click aqu\u00ed . Recordatorio: Estad\u00edstica de los Alineamientos \u00bfQu\u00e9 es un Expect value o E-value ? El E-value (E) es un par\u00e1metro que describe el n\u00famero de hits que uno espera encontrar por azar cuando est\u00e1 buscando en una base de datos de un tama\u00f1o particular. Este disminuye exponencialmente a medida que el Score (S) del alineamiento aumenta. Esencialmente el E-value describe el ruido de fondo aleatorio que est\u00e1 presente al realizar una b\u00fasqueda en una base de datos de secuencias. Cuanto m\u00e1s peque\u00f1o sea el E-value, o m\u00e1s cercano a 0, m\u00e1s significativo resulta ser nuestro hit. Sin embargo, siempre hay que tener en cuenta que los alineamientos cortos tienen E-values relativamente altos, y esto es debido a que el E-value tiene en cuenta el largo de la secuencia query . Estos E-values tienen sentido porque las secuencias cortas tienen una probabilidad m\u00e1s alta de estar presentes en una base de datos puramente por azar. El E-value es un par\u00e1metro conveniente para establecer un umbral de significancia a la hora de reportar los resultados de una b\u00fasqueda en una base de datos. Uno puede cambiar el E-value umbral al listar los resultados de una b\u00fasqueda con BLAST. Recordemos la f\u00f3rmula para calcular el E-value (E) de la te\u00f3rica.","title":"Introducci\u00f3n a BLAST"},{"location":"practicos/TP04_Busqueda_por_similitud/#ejercicio-1","text":"1.1 Como primer ejemplo podemos usar la secuencia xlrhodop.pep para realizar una b\u00fasqueda contra Swiss-Prot . Como estamos trabajando con una secuencia y una base de datos de prote\u00ednas, usamos blastp para realizar la busqueda: blastall -p blastp -i xlrhodop.pep -d ~/Swissprot_db/Swissprot.fasta Atenci\u00f3n Este comando no se ejecutar\u00e1 correctamente si uno mueve de lugar el archivo de la base de datos Swiss-Prot luego de ejecutar install.sh . Si este es el caso, especifique el camino o path completo. En este ejemplo, el resultado de la b\u00fasqueda es volcado en la pantalla (stdout). Para que el resultado aparezca en un archivo, podemos redireccionar stdout (usando > , ver TP01-Linux) o usar la opcion -o (output). blastall -p blastp -i xlrhodop.pep -d ~/Swissprot_db/Swissprot.fasta -o xlrhodop.blastp Pueden ver el resultado del blastp , por ejemplo paginando el archivo: less xlrhodop.blastp \u00bfQu\u00e9 indican las \u00faltimas l\u00edneas de este archivo? Si recuerda c\u00f3mo se computa el E-value, \u00bfentiende la relevancia de reportar el tama\u00f1o de la base de datos ( number of letters , number of sequences )? Nota El t\u00e9rmino neighboring words refiere a palabras \"vecinas\" o \"cercanas\", es decir con alta similitud de secuencia. Atenci\u00f3n Si corren blastp s\u00f3lo, es decir sin invocar primero al comando blastall , van a poder realizar las mismas b\u00fasquedas pero los nombres de los argumentos del comando blastp s\u00f3lo difieren de los de blastall -p blastp . Por lo tanto, no les recomendamos correrlo de esta forma. 1.2 Explore las siguientes opciones del programa blastp : -G Costo del gap open ( default : 11) -E Costo del gap extend ( default : 1) -W Tama\u00f1o de la ktupla. ( default : 3, puede variar entre 2 y 7) Atenci\u00f3n Hay tuplas de valores permitidos para los argumentos -G y -E , no cualquier combinaci\u00f3n de costos es v\u00e1lida. Pruebe con distintas combinaciones de estos par\u00e1metros y preste atenci\u00f3n al impacto que esto tiene en los alineamientos reportados. 1.2.1 Responda a las siguientes preguntas: a. Si observa los primeros 20 hits de su b\u00fasqueda, \u00bfpuede detectar alguna diferencia en los alineamientos reportados si cambia los par\u00e1metros indicados m\u00e1s arriba? b. A medida que va descendendiendo en la lista de los hits reportados (menor Score, mayor E-value), \u00bfqu\u00e9 patrones puede observar en los alineamientos que arroja BLAST? c. Tome como ejemplo dos de los siguientes hits: - OPSD_CARAU - OPN4A_DANRE - OPN4_RUTRU y complete para cada uno de los alinemientos reportados la siguiente tabla, teniendo en cuenta los diferentes costos de gap open y gap extend propuestos. N\u00famero total de gaps Extensi\u00f3n de la regiones con gaps Gap open: 6 + gap extend: 2 Gap open: 13 + gap extend: 1 1.2.2 Opcional : Evaluando el impacto del par\u00e1metro longitud de la k-tupla. Responda a las siguientes preguntas: Para una misma combinaci\u00f3n de costos para gap open y gap extend (pueden usar los valores default): a. \u00bfQu\u00e9 sucede con los valores de ktupla=2 y ktupla=7 ? b. \u00bfCu\u00e1l b\u00fasqueda es la que tarda m\u00e1s? \u00bfCu\u00e1l menos? c. \u00bfCu\u00e1ntas secuencias devuelven? Para los m\u00e1s curiosos, las respuestas a estas preguntas pueden hallarlas en el siguiente link .","title":"Ejercicio 1"},{"location":"practicos/TP04_Busqueda_por_similitud/#introduccion-a-fasta","text":"Curiosidad El nombre FASTA proviene de \"FAST-All\" porque funciona con cualquier alfabeto, esto significa que es una extensi\u00f3n de las herramientas originales para realizar alineamientos \"FAST-P\" (prote\u00ednas) y \"FAST-N\" (nucle\u00f3tidos). El formato \".fasta\" para almacenar secuencias de prote\u00ednas o nucle\u00f3tidos se origina con el software FASTA , es por esto que llevan el mismo nombre. Al igual que BLAST , FASTA necesita los mismos tres argumentos obligatorios. Sin embargo, el paquete FASTA provee un comando ejecutable para cada tipo de b\u00fasqueda. Comparaci\u00f3n de programas en el paquete FASTA FASTA permite comparar una secuencia proteica contra una base de datos de prote\u00ednas o una secuencia de ADN contra una base de datos de ADN ( Pearson and Lipman, 1988, Pearson, 1996 ). La velocidad de la b\u00fasqueda y la selectividad est\u00e1n controladas por el par\u00e1metro ktup ( word size ). Para comparaciones entre prote\u00ednas, ktup=2 es el default, ktup=1 es m\u00e1s sensible pero m\u00e1s lento. Para comparaciones entre secuencias de ADN, ktup=6 es el default, ktup=3 o ktup=4 proveen una mayor sensibilidad, ktup=1 debe ser utilizado para oligonucle\u00f3tidos (secuencias query de ADN de longitud < 20). ssearch Compara una secuencia proteica contra una base de datos de prote\u00ednas o una secuencia de ADN contra una base de datos de ADN usando el algoritmo de Smith-Waterman (Smith and Waterman, 1981). fastx y fasty Compara una secuencia de ADN contra una base de datos de prote\u00ednas. fasty compara la secuencia de ADN traducida en 3 marcos de lectura, permitiendo gaps y frameshifts. Es m\u00e1s lento que fastx pero produce mejores alineamientos para secuencias de baja calidad ya que los frameshifts se admiten entre codones. fastx usa un algoritmo m\u00e1s simple y r\u00e1pido para alineamientos que permiten frameshifts s\u00f3lo entre codones. tfastx Compara una secuencia proteica a una base de datos de ADN, calculando las similaridades con frameshifts para las orientaciones forward y reverse. tfasta Compara una secuencia proteica a una base de datos de ADN, calculando las similaridades (sin frameshifts) para los 3 forward y los 3 reverse ORFs. tfastx es preferido debido a que calcula las similaridades teniendo en cuenta frameshifts. fasts Compara un set peque\u00f1o de p\u00e9ptidos, obtenidos por ejemplo de un experimento de espectrometr\u00eda de masas, contra una base de datos de prote\u00ednas ( fasts ) o de ADN ( tfasts ).","title":"Introducci\u00f3n a FASTA"},{"location":"practicos/TP04_Busqueda_por_similitud/#ejercicio-2","text":"Ahora corramos la misma b\u00fasqueda del ejemplo anterior usando FASTA: fasta -H xlrhodop.pep ~/Swissprot_db/Swissprot.fasta > xlrhodop.fasta Para interpretar correctamente el histograma que FASTA da como output tenemos que pensar que est\u00e1 apaisado (o rotado 90 grados en sentido horario) con respecto al t\u00edpico histograma que muestra la distribuci\u00f3n de scores para todas las secuencias halladas. Esto se ilustra en la siguiente figura. 2.1 Responda a las siguientes preguntas con respecto al histograma apaisado que obtuvo como output: a. \u00bfQu\u00e9 valores se representan en el eje y (vertical)? b. \u00bfQu\u00e9 valores se representan en el eje x (horizontal)? c. \u00bfQu\u00e9 representan los asteriscos \"*\" ? d. \u00bfQu\u00e9 representan los iguales \"=\" ? \u00bfCu\u00e1nto representa el \"=\" ? e. \u00bfQu\u00e9 es la primera columna de n\u00fameros?, \u00bfpor qu\u00e9 hay un \"<\" en la primera l\u00ednea? y \u00bfpor qu\u00e9 hay un \">\" en la \u00faltima? f. \u00bfQu\u00e9 es la segunda columna de n\u00fameros? (Pista: mir\u00e1 el n\u00fameros de iguales que hay en esa l\u00ednea) g. \u00bfQu\u00e9 es la tercera columna de n\u00fameros? h. \u00bfQu\u00e9 es un inset? \u00bfQu\u00e9 regi\u00f3n del histograma est\u00e1 representada en el inset? \u00bfCu\u00e1nto representa el \"=\" en el inset? i. \u00bfEl valor del \u201c=\u201d en el inset es mayor o menor que en el resto del histograma? \u00bfTiene sentido? 2.2 \u00bfPor qu\u00e9 le parece que es relevante que se reporte el tama\u00f1o de la base de datos ( \"x residues in y sequences\" ) en el header del archivo de salida? 2.3 \u00bfQu\u00e9 par\u00e1metros se utilizaron en esta corrida con FASTA? 2.4 \u00bfEn qu\u00e9 se diferencian las distribuciones esperadas y observadas? \u00bfQu\u00e9 implica? 2.5 \u00bfEn qu\u00e9 regi\u00f3n del histograma se ubican los puntajes de los alineamientos que consideramos m\u00e1s significativos ( hits con mejor puntaje)? 2.6 \u00bfQu\u00e9 representa el n\u00famero que est\u00e1 entre par\u00e9ntesis en el E (ver figura m\u00e1s abajo)? \u00bfCu\u00e1l es el E-value para el mejor hit ? Diferencias entre BLAST y FASTA ktup: Tanto FASTA como BLAST usan una estrategia de b\u00fasqueda inicial basada en palabras cortas. ktup en FASTA es el par\u00e1metro que indica el tama\u00f1o de la palabra utilizada en esta b\u00fasqueda inicial. FASTA utiliza por default ktup=2, mientras que BLAST utiliza ktup=3. Sin embargo, FASTA s\u00f3lo considera identidades respecto a la palabra, mientras que BLAST utiliza identidades y sustituciones conservativas. Por lo tanto BLAST con ktup=3 es en general m\u00e1s sensible que FASTA con ktup=2. FASTA con ktup=1 es m\u00e1s sensible, pero es tambi\u00e9n m\u00e1s lento. Matrices y scores: BLAST y FASTA usan distintas matrices de scoring y gap penalties por default (BLAST: BLOSUM62, gap open:-11, gap extend:-1; FASTA: BLOSUM50, gap open:-10, gap extend:-2). Estad\u00edsticas Los par\u00e1metros kappa y lambda son centrales para estimar scores en BLAST y en FASTA. FASTA calcula estos par\u00e1metros on the fly a partir de la base de datos (se tiene en cuenta el tama\u00f1o) y la matriz de scoring . Esto produce estad\u00edsticas m\u00e1s representativas, pero puede ser problem\u00e1tico para bases de datos peque\u00f1as. Si la base de datos es de menos de 10 secuencias, FASTA no estima estos par\u00e1metros. BLAST usa valores pre-calculados para estos par\u00e1metros, que fueron derivados a partir de simulaciones. Alineamientos: BLAST puede mostrar varios alineamientos por cada par de secuencias (varios high-scoring pairs o HSPs) aunque por default s\u00f3lo muestra el mejor, FASTA \u00fanicamente reporta un alineamiento posible. Filtrado de secuencias de baja complejidad: Por default, BLAST filtra secuencias de baja complejidad o repeticiones, \u00a1FASTA no! Esto puede afectar la capacidad de discriminar falsos positivos, aunque FASTA provee otro tipo de opciones para manejar este tipo de casos. Ver la secci\u00f3n espec\u00edfica sobre este punto m\u00e1s abajo. Traducciones: blastx hace 6 b\u00fasquedas independientes (una en cada marco de lectura) mientras que fastx3 y fasty3 hacen una \u00fanica b\u00fasqueda forward (o reverse usando -i ) que permite frameshifts . Estos \u00faltimos son m\u00e1s sensibles y pueden producir mejores alineamientos que blastx cuando se usan secuencias de baja calidad (lo mismo es cierto para tblastn vs tfastx3 y tfasty3 ). Hom\u00f3logos distantes: Existe una opci\u00f3n en FASTA ( -F ) que les permite ignorar (i.e. que no aparezcan en el output) secuencias altamente similares al query . Esto es \u00fatil, por ejemplo, para focalizar una b\u00fasqueda en las secuencias m\u00e1s divergentes. No existe una opci\u00f3n similar en BLAST . Secuencias cortas: Ya sea que busquen un primer o un p\u00e9ptido, si quieren utilizar BLAST o FASTA para esto, tengan en cuenta que BLAST es generalmente in\u00fatil al respecto. Esto es porque BLAST tiene un l\u00edmite inferior sobre la longitud que puede tener una palabra (ktup). En el caso de nucle\u00f3tidos, el l\u00edmite inferior es 7 (el default es 11). En este sentido FASTA es mejor, porque siempre pueden usar ktup=1. Por otra parte, en el caso espec\u00edfico de p\u00e9ptidos, FASTA provee algunos algoritmos particulares de b\u00fasqueda ( fastf , fasts y tfasf , tfasts ). Tip Usar un cuchillo en lugar de un destornillador, a veces puede funcionar, pero no deja de ser cierto que cada herramienta fue dise\u00f1ada para un fin distinto. Si quieren realizar b\u00fasquedas de secuencias cortas prueben primero con fuzznuc , fuzzpro o findpatterns (todos parte de EMBOSS ).","title":"Ejercicio 2"},{"location":"practicos/TP04_Busqueda_por_similitud/#filtrado-de-secuencias-de-baja-complejidad","text":"Muchas secuencias son altamente repetitivas. Si la secuencia query contiene regiones de baja complejidad o repeticiones, es posible que una b\u00fasqueda encuentre muchas secuencias no relacionadas, con altos scores (por ej. hits contra colas de poly-A o regiones ricas en Prolina). En otros casos, la secuencia puede contener un vector (pl\u00e1smido) o repeticiones Alu, que ustedes pueden querer omitir en la b\u00fasqueda. BLAST permite filtrar el primer tipo de casos, mediante la opci\u00f3n -F . FASTA en cambio no provee esta alternativa. Es el usuario el que tiene que filtrar el query antes de realizar una b\u00fasqueda.","title":"Filtrado de secuencias de baja complejidad"},{"location":"practicos/TP04_Busqueda_por_similitud/#ejercicio-3","text":"3.1 Usar la prote\u00edna Groucho de Drosophila (grou_drome) para buscar secuencias similares en Swiss-Prot usando BLAST . Comparar los resultados obtenidos usando ( -F T ) o sin usar ( -F F ) la opci\u00f3n de filtrado que provee BLAST . Observen el primer hit en las lista de los alineamientos resultantes. \u00bfQu\u00e9 pueden detectar de diferencia entre los dos comandos que corrieron? 3.2 Ahora para repetir el mismo ejercicio con FASTA , tenemos que detectar y marcar las regiones de baja complejidad. Para esto se utiliza segmasker : segmasker -in grou_drome.fasta -outfmt fasta > grou_drome_lc.fasta 3.3 Comparen las secuencias grou_drome.fasta y grou_drome_lc.fasta e identifiquen las diferencias. \u00bfQu\u00e9 hizo segmasker con la secuencia? Ahora, podemos buscar secuencias similares en Swiss-Prot usando grou_drome.fasta (con opciones standard) y grou_drome_lc.fasta (usando la opci\u00f3n -S ). fasta -H grou_drome.fasta ~/Swissprot_db/Swissprot.fasta fasta -H -S grou_drome_lc.fasta ~/Swissprot_db/Swissprot.fasta \u00bfQu\u00e9 diferencias encuentran en los histogramas de cada b\u00fasqueda?","title":"Ejercicio 3"},{"location":"practicos/TP04_Busqueda_por_similitud/#bases-de-datos-propias","text":"Tener acceso a BLAST o FASTA en la l\u00ednea de comando les da la posibilidad de crear sus propias bases de datos para realizar b\u00fasquedas. FASTA puede realizar b\u00fasquedas sobre un archivo en formato fasta conteniendo varias secuencias sin ning\u00fan otro tipo de tratamiento. BLAST , sin embargo necesita contar con una base de datos indexada. formatdb es el comando que vamos a utilizar para generar los \u00edndices que BLAST necesita.","title":"Bases de datos propias"},{"location":"practicos/TP04_Busqueda_por_similitud/#adicional-ejercicio-4","text":"4.1 Primero, vamos a generar un archivo fasta m\u00faltiple con algunas secuencias. Por ejemplo, para construir una base de datos con secuencias de opsinas podemos empezar con: seqret \"~/Swissprot_db/Swissprot.fasta:ops*\" fasta::ops Esto deber\u00eda generar un archivo FASTA m\u00faltiple conteniendo secuencias de opsinas. 4.2 \u00bfCu\u00e1ntas secuencias tiene nuestra base de datos? Ahora para indexar el archivo ops (en formato fasta ), usamos formatdb , indic\u00e1ndole el archivo que contiene las secuencias ( -i ) y si el archivo contiene secuencias de ADN ( -p F ) o de prote\u00ednas ( -p T ). formatdb -i ops -p T 4.3 Una vez indexada la base de datos, podemos hacer una b\u00fasqueda, por ejemplo, con nuestra ya conocida xlrhodop.pep blastall -p blastp -d ./ops -i xlrhodop.pep > xlrhodop.ops.blastp Pueden ver las opciones que acepta el comando formatdb pidiendo ayuda: #formatdb --help ... (en versiones viejas de blast se pod\u00eda usar este comando... pero ya no) makeblastdb -help","title":"Adicional: Ejercicio 4"},{"location":"practicos/TP04_Busqueda_por_similitud/#blast-con-multiples-secuencias","text":"Si tienen un archivo con m\u00faltiples secuencias en formato fasta , pueden usarlo como query en una b\u00fasqueda, usando BLAST .","title":"BLAST con m\u00faltiples secuencias"},{"location":"practicos/TP04_Busqueda_por_similitud/#adicional-ejercicio-5","text":"5.1 El archivo opsv.fasta contiene la secuencia de 4 fotorreceptores, usen este archivo para realizar una b\u00fasqueda, usando blastp , contra la base de datos ops que crearon en el ejercicio anterior. 5.2 El output generado consiste en 4 reportes de BLAST , concatenados en un \u00fanico archivo. \u00bfC\u00f3mo pueden navegar f\u00e1cilmente dentro del documento usando less ? Tip Tip: \u00bfqu\u00e9 palabras o conjunto de palabras ocurren una sola vez en cada reporte? 5.3 Ahora puedo leer el reporte y manejarme bien dentro de \u00e9l. Si quiero partirlo en 4 reportes individuales \u00bfC\u00f3mo hago? Para esto pueden usar el comando de Unix split que puede partir un archivo en otros m\u00e1s peque\u00f1os, ya sea por tama\u00f1o o cada vez que encuentre una palabra o pattern (patr\u00f3n, expresi\u00f3n regular). Usando la opci\u00f3n -p pueden especificar un pattern . Info La opci\u00f3n -p s\u00f3lo est\u00e1 disponible en el comando split de sistemas operativos del tipo BSD ( FreeBSD , NetBSD ). Linux usa el comando split de GNU, donde esta opci\u00f3n no existe. man split Tanto en Linux como en cualquier Unix, una manera de partir un archivo en varios usando un pattern es usando el comando awk : Dado un archivo llamado blast.out , podemos partirlo en varios usando la siguiente invocaci\u00f3n: awk -v i = 0 '/pattern/{i++}{print > \"blast.\"i}' blast.out Atenci\u00f3n Recuerden reemplazar \" pattern \" por el patr\u00f3n que quieren utilizar para dividir el archivo. \u00bfLo lograron?","title":"Adicional: Ejercicio 5"},{"location":"practicos/TP04_Busqueda_por_similitud/#bibliografia","text":"Tutorial de BLAST en la web del NCBI: The Statistics of Sequence Similarity Scores","title":"Bibliograf\u00eda"},{"location":"practicos/TP05_PSI-BLAST/","text":"TP 5 . Perfiles de secuencias y PSI-BLAST Materiales Atenci\u00f3n: Este TP tiene informe. Videos de la clase grabada Introducci\u00f3n al TP Cierre TP Construcci\u00f3n de Logos y Matrices peso-espec\u00edficas Objetivos Familiarizarse con la construcci\u00f3n de matrices peso-espec\u00edficas o PSSM. Familiarizarse con la visualizaci\u00f3n de logos de secuencias, y el uso del contenido de informaci\u00f3n. Utilizar las matrices peso-espec\u00edficas como m\u00e9todos predictivos, y entender las m\u00e9tricas PCC (Pearson correlation coefficient) y Aroc (Area under the Receiver Operating Characteristic curve) empleadas para evaluar la calidad de los modelos. Introducci\u00f3n En este TP utilizaremos herramientas bioinform\u00e1ticas para predecir la uni\u00f3n de p\u00e9ptidos a MHC, o por sus siglas en ingl\u00e9s Major Histocompatibility Complex , y seleccionaremos potenciales ep\u00edtopes como candidatos para desarrollar una vacuna. Los pasos a seguir ser\u00e1n: Identificaci\u00f3n de motivos de uni\u00f3n a MHC. Visualizaci\u00f3n de motivos utilizando logos de secuencias. Entrenamiento de m\u00e9todos de predicci\u00f3n de uni\u00f3n a MHC. Utilizaci\u00f3n de los m\u00e9todos desarrollados para la selecci\u00f3n de candidatos vacunales. La uni\u00f3n de p\u00e9ptidos a MHC es el paso m\u00e1s selectivo en el camino de procesamiento y presentaci\u00f3n antig\u00e9nica. Este evento es crucial ya que solamente 1 de cada 200 p\u00e9ptidos forma un complejo con el MHC. Existe una gran variedad de MHC diferentes, cada uno con una alta especificidad. El motivo de uni\u00f3n de los MHC de la v\u00eda de clase I es, en la mayor\u00eda de los casos, de 9 amino\u00e1cidos de longitud. Estos est\u00e1n caracterizados por una marcada preferencia por ciertos amino\u00e1cidos en determinadas posiciones del motivo. Estas posiciones son llamadas \"anclas\" o, en ingl\u00e9s, anchor positions . Para una gran cantidad de complejos de MHC de clase I estas anclas se encuentran en las posiciones P2 y P9. Sin embargo, este no es siempre el caso. Existe una gran cantidad de datos que describen las diferentes especificidades de las mol\u00e9culas de MHC. Una base de datos muy conocida que almacena esta informaci\u00f3n es SYFPEITHI . En ella se puede encontrar informacion de ligandos y motivos de MHC. Con este tipo de informaci\u00f3n es posible desarrollar un modelo de predicci\u00f3n de uni\u00f3n de p\u00e9ptidos a MHC y usarlo para descubrir nuevos ep\u00edtopes con los cuales dise\u00f1ar vacunas. Esto puede ser aplicado a nivel de proteomas enteros para ahorrar tanto tiempo como recursos. A continuaci\u00f3n vamos a: Visualizar motivos de uni\u00f3n utilizando logos de secuencias. Entrenar un modelo predictivo utilizando el servidor de EasyPred . Aplicar el modelo para seleccionar p\u00e9ptidos con potencial inmunog\u00e9nico de prote\u00ednas de SARS-CoV-2. Identificaci\u00f3n de motivos de uni\u00f3n a MHC Dir\u00edjanse a la p\u00e1gina web de SYFPEITHI . All\u00ed, una vez que hagan click en el logo, pueden buscar motivos con el bot\u00f3n Find your motif, Ligand or Epitope . All\u00ed seleccionen con el men\u00fa de la izquierda el alelo de MHC HLA-A*02:01 y presionen Do Query . Nota El resto de las opciones se pueden usar para refinar la b\u00fasqueda, limit\u00e1ndola a ligandos de prote\u00ednas determinadas o por referencia bibliogr\u00e1fica. En este caso queremos obtener TODOS los ligandos para poder ver qu\u00e9 caracter\u00edsticas comparten. En el resultado de la b\u00fasqueda podemos ver las posiciones anchor principales y auxiliares, y tambi\u00e9n otras posiciones con residuos preferidos. Tambi\u00e9n tenemos una lista de otros amino\u00e1cidos que se ven con frecuencia en los ligandos del alelo que estamos estudiando. Por \u00faltimo, m\u00e1s abajo, se muestra la lista de los ligandos que existen en esta base de datos, junto a su proteina de procedencia, la referencia del trabajo donde se lo identific\u00f3 y alguna nota como la asociaci\u00f3n de un p\u00e9ptido dado con una enfermedad. 1. Respondan a las siguientes preguntas : a. \u00bfQu\u00e9 posiciones identifican como anchors ? \u00bfQu\u00e9 residuos son preferidos en estas posiciones? \u00bfY en los auxiliary anchors ? b. \u00bfQu\u00e9 otras posiciones muestran preferencias de residuos? \u00bfQu\u00e9 residuos son preferidos en estas posiciones? c. \u00bfQu\u00e9 caracter\u00edstica del conjunto de p\u00e9ptidos creen que puede estar diferenciando a las posiciones anchor del resto de las posiciones de los p\u00e9ptidos? Recu\u00e9rdenla para el ejercicio de logos de secuencia. 2. Repitan el mismo an\u00e1lisis para el alelo HLA-B*27 . \u00bfCoinciden las posiciones anchor con las del alelo HLA-A*02:01 ?, \u00bfy los residuos preferidos? Logos de secuencias Los logos son una herramienta muy \u00fatil para visualizar motivos de uni\u00f3n. En un logo de secuencia se grafica en el eje y el contenido de informaci\u00f3n de cada posici\u00f3n del motivo, generalmente expresado en bits . A su vez, la frecuencia con la que aparece una letra (nucle\u00f3tido u aminino\u00e1cido) en una dada posici\u00f3n se grafica con un tama\u00f1o proporcional a dicha magnitud. Un servidor que nos permite generar facilmente logos de secuencia es Seq2Logo . Este m\u00e9todo nos da la opci\u00f3n de ingresar un alineamiento m\u00faltiple (MSA), una lista de p\u00e9ptidos o una matriz peso-espec\u00edfica con la cual realizar el gr\u00e1fico. La informaci\u00f3n puede pegarse directamente en el cuadro de texto que provee la web, o subiendo directamente un archivo local utilizando la opci\u00f3n Switch to file upload que se encuentra debajo del cuadro. Dentro de las opciones que nos permite cambiar tenemos: Logo type: Esto refiere a la magnitud que se calcular\u00e1 para cada posici\u00f3n y se graficar\u00e1 en el eje y (Kullback-Leiber, Shannon, etc.). Clustering method: Agrupa las secuencias que son muy similares para no sesgar el resultado, se pueden optar por diferentes m\u00e9todos. Weight on prior: Es el valor que le asignamos al par\u00e1metro beta en la ecuacion del c\u00e1lculo del contenido de informaci\u00f3n . Recuerden que la relaci\u00f3n entre alfa y beta es determinante para este c\u00e1lculo. Information content units: Generalmente se expresa en bits , pero en algunos casos se opta por half-bits . Output format: El tipo de archivo de imagen adonde se guardar\u00e1 el logo. Tambi\u00e9n tenemos la opci\u00f3n de realizar cambios avanzados, como modificar las frecuencias de background o la matriz de scoring , limitar la regi\u00f3n del alineamiento que queremos graficar, etc. y opciones gr\u00e1ficas, como el tama\u00f1o de la imagen y los colores con los que se representa cada amino\u00e1cido. Por convenci\u00f3n los colores que se utilizan son: Rojo : Amino\u00e1cidos \u00e1cidos [DE] Azul : Amino\u00e1cidos b\u00e1sicos [HKR] Negro : Amino\u00e1cidos hidrof\u00f3bicos [ACFILMPVW] Verde : Amino\u00e1cidos neutros [GNQSTY] Atenci\u00f3n Recuerden guardar los logos de secuencia generados. 3. En Materiales pueden encontrar los archivos HLA-A0201 y HLA-B27 , los cuales contienen ligandos de cada uno de estos alelos de MHC. \u00dasenlos para generar logos que muestren sus motivos de preferencia. Utilicen como opci\u00f3n de clustering Heuristics. Usamos para el resto de las opciones los valores default .Identifiquen las posiciones ancla y las preferencias de cada alelo. a. \u00bfEl logo obtenido para HLA-A02:01 y HLA-B27 se condice con lo que encontr\u00f3 en la base de datos en el punto anterior? b. \u00bfQu\u00e9 magnitud es la que est\u00e1 diferenciando a las posiciones anchor del resto? \u00bfEn qu\u00e9 unidad aparece representada en el logo? \u00bfCoincide con lo supuesto en el punto 1.c ? Construcci\u00f3n de matrices peso-espec\u00edficas (PSSM) Para este punto vamos a utilizar el servidor de EasyPred . Esta herramienta nos permite construir tanto matrices peso-espec\u00edficas, o PSSM (Position-Specific Scoring Matrix) , como aplicarlas a un set de datos para calcular su score . El servidor consta de dos cuadros de texto, el de la izquierda en el cual se ingresan datos para construir la matriz, y el de la derecha donde uno puede ingresar secuencias sobre las cuales quiere realizar una predicci\u00f3n. Para explorar un poco la construcci\u00f3n de matrices solo utilizaremos el recuadro de la izquierda donde ingresaremos las siguientes secuencias: VFAAA VHYWW VLQPK LREWQ LPYIH Las opciones que tenemos aqu\u00ed son muy similares a las que habiamos visto en el servidor de Seq2Logo debido a que ambos realizan c\u00e1lculos del contenido de informaci\u00f3n. En este caso vamos a seleccionar Clustering method: No clustering y Weight on prior: 10000 . Usamos para el resto de las opciones los valores default . 4. Antes de generar la PSSM, reflexionen un poco acerca de los par\u00e1metros empleados para la construcci\u00f3n de la misma. a. \u00bfPor qu\u00e9 consideran que no estamos usando ning\u00fan m\u00e9todo de clustering? b. \u00bfPor qu\u00e9 creen que es tan alto el valor sugerido para el weight on prior (\u03b2) ? Recordatorio La ecuaci\u00f3n utilizada para estimar la frecuencia p a , para una dada posici\u00f3n, en una matriz peso-espec\u00edfica es, donde \u03b1 es el n\u00famero de secuencias en el MSA-1, \u03b2 es el weight on prior o weight on pseudocounts , f a es la frecuencia observada para el amino\u00e1cido a en esa posici\u00f3n y g a es la pseudo frecuencia para el amino\u00e1cido a en esa misma posici\u00f3n. Hagan Submit query y observen la salida. All\u00ed podr\u00e1n encontrar informaci\u00f3n sobre los par\u00e1metros utilizados y un logo que representa el set de datos que ingresamos. Observando el logo generado: 5. \u00bfQu\u00e9 amino\u00e1cidos es m\u00e1s probable hallar en la posici\u00f3n P1? Pista Son los que est\u00e1n por encima de y=0. 6. \u00bfCu\u00e1ntos amino\u00e1cidos diferentes hay en P1 (en y>=0)? \u00bfCu\u00e1les se encuentran datos de entrada? \u00bfCu\u00e1les en el logo generado? 7. \u00bfA qu\u00e9 se debe esta diferencia? 8. Realice el mismo ejercicio pero ahora elija un weight on prior \u03b2=0. \u00bfCambian sus respuestas para los puntos 5. , 6. y 7. ? Predicci\u00f3n de uni\u00f3n a MHC Habi\u00e9ndonos familiarizado con la interfaz de EasyPred vamos a utilizarla para entrenar un modelo con m\u00e1s datos y ponerlo a prueba. Para eso utilizaremos dos sets de entrenamiento que poseen p\u00e9ptidos fueron testeados con el alelo HLA-A02:01. Cada uno tiene un valor asociado que denota si son positivos (1) o negativos (0.1). A lo largo del proceso iremos variando diferentes par\u00e1metros para observar qu\u00e9 efectos esto tiene sobre el poder predictivo del modelo, al ser testeado en un set de evaluaci\u00f3n con valores de afinidad ( binding affinity ) de uni\u00f3n a MHC reales (reescalados entre 0 y 1). Los datos que utilizaremos est\u00e1n en los archivos: Entrenamiento_chico.set que contiene 110 p\u00e9ptidos de los cuales s\u00f3lo 10 son positivos. Entrenamiento_grande.set contiene 232 p\u00e9ptidos de los cuales todos son positivos. Para evaluar el desempe\u00f1o de nuestro modelo utilizaremos el archivo Evaluacion.set , el cual contiene 1266 peptidos con valores de afinidad convertidos al rango 0-1 mediante la formula 1-log(x)/log(50000). Utilizando esta transformaci\u00f3n, valores mayores a 0.638 (equivalente a 50nM) representan una uni\u00f3n fuerte, entre 0.638 y 0.426 (equivalente a 500nM) una uni\u00f3n d\u00e9bil y p\u00e9ptidos con valores menores a 0.426 no se consideran ligandos. Atenci\u00f3n Una buena pr\u00e1ctica antes de comezar a hacer cualquier cosa con nuestros datos es observarlos y entender el formato en el que est\u00e1n almacenados. Por ejemplo, si hacemos un cat del archivo Entrenamiento_chico.set , nos encontramos con lo siguiente: Este es un archivo con dos columnas, la primera contiene a los p\u00e9ptidos y la segunda a los valores de afinidad de uni\u00f3n o binding affinity de los mismos. (\u00bfEn qu\u00e9 escala est\u00e1n los valores de binding affinity ? \u00bfEst\u00e1n normalizados entre 0 y 1?) Para analizar el desempe\u00f1o de nuestros modelos vamos a tener en cuenta dos m\u00e9tricas: Aroc (Area under the Receiver Operator Curve): este valor var\u00eda entre 0 y 1, siendo 1 el puntaje perfecto y 0.5 el valor aleatorio. Por regla general, valores mayores a 0.85 son altamente deseables. Coeficiente de correlaci\u00f3n de Pearson (PCC): tambi\u00e9n oscila entre 0 y 1, siendo 1 una correlaci\u00f3n perfecta entre las dos variables de estudio, y -1 una anticorrelaci\u00f3n perfecta. En este caso el valor que implica aleatoriedad total o no correlaci\u00f3n entre las dos variables es 0. Estas m\u00e9tricas nos van a ayudar a seleccionar el mejor de nuestros modelos, siendo \u00e9ste el que alcance los mejores valores de Aroc y Coeficiente de Pearson . Note A continuaci\u00f3n vamos a entrenar varios modelos y comparar sus resultados. Haga cada prueba en una ventana nueva o guarde las salidas de alguna manera que crea conveniente. Primera prueba Atenci\u00f3n Volvamos a abrir EasyPred o recarguemos la p\u00e1gina para que todas las opciones vuelvan a estar por defecto. Realicemos los siguientes cambios: los datos del archivo Entrenamiento_chico.set en el recuadro de entrenamiento y los de Evaluacion.set en el recuadro de evaluaci\u00f3n . Coloquemos el umbral de corte para positivos ( Cutoff for counting an example as a positive example ) en 0 y apretemos el bot\u00f3n Submit query . La salida consta de varias partes: Al principio tenemos una peque\u00f1a descripci\u00f3n de los par\u00e1metros con los que se llev\u00f3 a cabo el entrenamiento, tanto de los datos como del m\u00e9todo. Esto es siempre \u00fatil para poder reproducir los resultados. Luego tenemos un logo constru\u00eddo a partir de los datos de entrenamiento. Esto nos puede ayudar a identificar (como hicimos anteriormente) la preferencia de la mol\u00e9cula que se une a nuestro set de p\u00e9ptidos. A continuaci\u00f3n sigue la informaci\u00f3n sobre la evaluaci\u00f3n. All\u00ed podemos encontrar los valores del coeficiente de Pearson y Aroc y la lista de predicciones sobre el set de evaluaci\u00f3n. F\u00edjense que Assignment se refiere al valor medido o real que est\u00e1 en el archivo de evaluaci\u00f3n y va de 0 a 1, sin embargo la predicci\u00f3n puede adoptar otros valores, incluso negativos. Tip Las m\u00e9tricas que utilizamos no se enfocan en reportar la precisi\u00f3n del m\u00e9todo (proporci\u00f3n de verdaderos positivos entre todos los p\u00e9ptidos predichos como positivos) sino que muestran: la habilidad del m\u00e9todo para distinguir instancias positivas de negativas (Aroc) y la correlaci\u00f3n entre los valores predichos y los valores reales u observados (PCC). Revisando la salida contesten: 9. \u00bfQu\u00e9 valores de Aroc y PCC obtuvieron? \u00bfQu\u00e9 implica esto? 10. Viendo el logo resultante, \u00bfEntienden por qu\u00e9 el modelo tiene tan mal desempe\u00f1o? 11. \u00bfCu\u00e1ntos de los 110 p\u00e9ptidos se utilizaron para la construcci\u00f3n de la matriz? \u00bfPor qu\u00e9 se us\u00f3 ese n\u00famero de p\u00e9ptidos? Pista Mire el archivo de entrada Entrenamiento_chico.set y vea cu\u00e1les son los valores de afinidad para los p\u00e9ptidos all\u00ed listados. Segunda prueba Volvamos a la p\u00e1gina principal de EasyPred . Esta vez coloquemos el umbral de positivos en 0.5 pero especifiquemos que no haya clustering y pongamos un weight on prior de 0.0. 12. \u00bfQu\u00e9 valores de desempe\u00f1o tienen ahora? \u00bfQu\u00e9 implican estos valores? \u00bfSon mejores o peores que en la primera prueba? \u00bfPor qu\u00e9 cree que cambiaron? 13. \u00bfCu\u00e1ntos de los 110 p\u00e9ptidos se utilizaron en este caso para la construcci\u00f3n de la matriz? 14. Mirando el logo, \u00bfSe parece al motivo de uni\u00f3n de HLA-A*02:01 que hab\u00edan visto antes? \u00bfPor qu\u00e9 cree que ocurre esto? Pista Tenga en cuenta el n\u00famero de secuencias que se usaron para construir la matriz y recuerde que siempre es una buena pr\u00e1ctica revisar las instrucciones de la gu\u00eda y los archivos de entrada. Tercera prueba Volvamos atr\u00e1s y repitamos el caso anterior pero seleccionando Clustering at 62% identity . Mantengamos el weight on prior en 0.0 y el resto de los par\u00e1metros como se hab\u00edan seteado en la segunda prueba. 15. \u00bfCu\u00e1l es el desempe\u00f1o ahora? 16. \u00bfCambi\u00f3 el logo con respecto al anterior? Si es as\u00ed\u2026 \u00bfA qu\u00e9 cree que se debe el cambio? Pista De nuevo, es una buena pr\u00e1ctica revisar qu\u00e9 contienen los archivos de entrada, es decir los datos crudos. Miren con atenci\u00f3n las secuencias de los positivos. Cuarta prueba Volvamos una vez m\u00e1s, manteniendo Clustering at 62% identity pero utilicemos como weight on prior un valor de 200, y el umbral de positivos en 0.5. 17. Una vez m\u00e1s revisen las m\u00e9tricas de desempe\u00f1o. 18. Mirando el logo, \u00bfCu\u00e1l es la gran diferencia con aquellos que ven\u00edan viendo? \u00bfCu\u00e1l es la raz\u00f3n de este cambio? \u00bfEmpieza ahora a parecerse a los motivos que hab\u00edan visto antes? Quinta (y \u00faltima) prueba Hasta ahora ven\u00edamos utilizando un set de datos sumamente reducido, con solo 10 p\u00e9ptidos positivos para entrenar. A\u00fan asi hemos conseguido valores de desempe\u00f1o bastante aceptables. Sin embargo, estos m\u00e9todos suelen utilizar muchas m\u00e1s informaci\u00f3n para su entrenamiento. A continuaci\u00f3n recarguen la p\u00e1gina de EasyPred y carguen para entrenar el archivo Entrenamiento_grande.set . En el cuadro de evaluaci\u00f3n vuelvan a cargar Evaluacion.set . Seleccionen una vez m\u00e1s Clustering at 62% identity , pongan el weight on prior en 200 y el umbral de positivos en 0.5. Tilden tambi\u00e9n la opci\u00f3n Sort output on predicted values para ver la tabla de p\u00e9ptidos ordenada por los valores de predicci\u00f3n. 19. Revisen una vez m\u00e1s los valores de desempe\u00f1o. 20. Vean el logo, \u00bfqu\u00e9 les parece? 21. Mirando la tabla de predicciones, \u00bfCu\u00e1ntos falsos positivos encuentran entre los primeros 20 p\u00e9ptidos? (con Assignment menor a 0.426) Atenci\u00f3n Antes de cerrar la ventana haga click en Parameters for prediction method luego del logo. All\u00ed podr\u00e1 descargar la matriz calculada a partir de los datos de entrenamiento (Se descarga con el nombre para.dat, es un archivo de texto plano). Esta puede ser utilizada luego para llevar a cabo predicciones. PSI-BLAST Objetivos Comprender el funcionamiento del algoritmo PSI-BLAST, aplicando el mismo en un caso de estudio en el que BLAST no funciona. Generar y reutilizar la PSSM que arroja PSI-BLAST, para encontrar hits en otras bases de datos relevantes tales como PDB. Entender la informaci\u00f3n que nos otorga la PSSM constru\u00edda por PSI-BLAST en relaci\u00f3n a los residuos o dominios conservados de una prote\u00edna. Introducci\u00f3n PSI-BLAST (o Position Specific Iterated BLAST) es un algoritmo alternativo de BLAST que construye iterativamente una matriz de puntajes posici\u00f3n espec\u00edfica, o PSSM (Position-Specific Scoring Matrix) , para calcular el score de los alineamientos. En su forma b\u00e1sica de funcionamiento lo que hace es realizar un simple BLAST con una secuencia query y, a partir de los resultados o hits que obtiene, construye un perfil o PSSM. Entonces, la siguiente b\u00fasqueda la realiza con ese perfil, lo que permitir\u00e1 encontrar, idealmente, nuevos hits , correspondientes a secuencias m\u00e1s distantes de la secuencia query . Con esos nuevos hits genera un nuevo perfil, el cual, idealmente, contendr\u00e1 mayor cantidad de informaci\u00f3n y con el que se podr\u00e1 realizar otra b\u00fasqueda. Es un proceso iterativo. En resumen, a partir de la segunda iteraci\u00f3n los puntajes de la matriz variar\u00e1n acorde a la conservaci\u00f3n de los amino\u00e1cidos o nucle\u00f3tidos en cada posici\u00f3n permitiendo refinar nuestra b\u00fasqueda y as\u00ed recuperando secuencias distantes que comparten motivos o dominios con nuestra secuencia query original. Cuando BLAST falla Digamos que se tiene una secuencia query (abajo) y se quiere predecir su estructura y funci\u00f3n. Como vimos anteriormente uno recurre generalmente a BLAST para este tipo de tareas. Si logramos identificar una prote\u00edna suficientemente similar podr\u00edamos hipotetizar que comparten dichas caracteristicas. >QUERY1 MKDTDLSTLLSIIRLTELKESKRNALLSLIFQLSVAYFIALVIVSRFVRYVNYITYNNLV EFIIVLSLIMLIIVTDIFIKKYISKFSNILLETLNLKINSDNNFRREIINASKNHNDKNK LYDLINKTFEKDNIEIKQLGLFIISSVINNFAYIILLSIGFILLNEVYSNLFSSRYTTIS IFTLIVSYMLFIRNKIISSEEEEQIEYEKVATSYISSLINRILNTKFTENTTTIGQDKQL YDSFKTPKIQYGAKVPVKLEEIKEVAKNIEHIPSKAYFVLLAESGLRPGELLNVSIENID LKARIIWINKETQTKRAYFSFFSRKTAEFLEKVYLPAREEFIRANEKNIAKLAAANENQE IDLEKWKAKLFPYKDDVLRRKIYEAMDRALGKRFELYALRRHFATYMQLKKVPPLAINIL QGRVGPNEFRILKENYTVFTIEDLRKLYDEAGLVVLE Vayan a la pagina de BLAST y utilicen el algoritmo de Protein BLAST para buscar secuencias similares. En el campo de base de datos seleccione pdb que es la base que contiene estructuras . Tip Pueden correr la b\u00fasqueda eligiendo el par\u00e1metro \"Show results in a new window\". 1. \u00bfCu\u00e1ntos hits con E-value < 0.005 encuentran? Vuelvan atr\u00e1s y, en Program selection: Algorithm , seleccionen PSI-BLAST. \u00bfCambi\u00f3 el resultado en comparaci\u00f3n a lo que hab\u00edan obtenido anteriormente? Usando PSI-BLAST Atenci\u00f3n Realicen cada corrida de BLAST (e iteraci\u00f3n de PSI-BLAST) en una ventana diferente, en varios casos van a necesitar comparar las salidas. Vuelvan atr\u00e1s a la p\u00e1gina de alineamiento de prote\u00ednas, pero esta vez seleccionen la base de datos Non-redundant protein sequences (nr) y en la secci\u00f3n de algoritmos seleccionen PSI-BLAST. Teniendo en cuenta que el primer hit es nuestro query y por lo tanto vamos a ignorarlo: 2. Ahora, \u00bfCu\u00e1ntos hits significativos encuentran (E-value < 0.005)? 3. \u00bfQu\u00e9 significa la variable Query Cover ? Una manera visual para entender el query coverage es mirar el Graphic Summary . Dentro de la pesta\u00f1a Descriptions , coloquen la pesta\u00f1a Show en 100. Luego cliqueen en la pesta\u00f1a Graphic Summary . \u00bfCu\u00e1l es la cobertura de los hits obtenidos? Construyendo la PSSM Si se fijan debajo de los hits significativos van a tener la opci\u00f3n de seguir iterando PSI-BLAST: All\u00ed pueden especificar cuantas secuencias queremos utilizar para refinar nuestras PSSM ( Position-Specific Scoring Matrix ). Conservando el valor por defecto corramos la siguiente iteraci\u00f3n. 4. \u00bfCu\u00e1ntos hits significativos pueden encontrar ahora (E-value < 0.005)? 5. \u00bfC\u00f3mo se modific\u00f3 el coverage de estos hits ? Vuelvan a mirar el Graphic Summary , colocando previamente en Descriptions la pesta\u00f1a Show en 250. 6. \u00bfPor qu\u00e9 creen que PSI-BLAST puede identificar ahora m\u00e1s hits significativos y que es lo que est\u00e1 afectando el query coverage ? 7. \u00bfQu\u00e9 significan que los hits est\u00e9n resaltados en amarillo, y qu\u00e9 significa que est\u00e9n en blanco con un tick verde? Nota Antes de proseguir realicen una o dos iteraciones m\u00e1s y observen la aparici\u00f3n de nuevas prote\u00ednas identificadas (marcadas con amarillo). Guardando y reutilizando la PSSM Ahora podemos utilizar la PSSM que est\u00e1 ajustada con los resultados obtenidos de PSI-BLAST para realizar b\u00fasquedas m\u00e1s significativas en otras bases de datos. Para obtener la PSSM descarguenla arriba donde dice \" Donwload All \" Volvamos una vez m\u00e1s a la p\u00e1gina para realizar la b\u00fasqueda. Sin ingresar ninguna secuencia query seleccionemos otra vez la base de datos de estructuras Protein Data Bank (pdb) y como algoritmo PSI-BLAST. Por \u00faltimo, justo debajo del bot\u00f3n de BLAST, abramos el men\u00fa de Algorithm parameters y carguemos nuestra PSSM (justo al final). Ahora s\u00ed corramos la b\u00fasqueda. 8. \u00bfPueden encontrar hits significativos de PDB ahora? 9. \u00bfQu\u00e9 funci\u00f3n pueden identificar en los primeros hits? Identificando residuos conservados Ahora (si tuvimos suerte) habremos podido identificar una relaci\u00f3n estructural entre nuestra secuencia query y las secuencias de la base de datos de estructuras proteicas PDB. Digamos que, en este punto, nos gustar\u00eda validar esa relaci\u00f3n. Para identificar los residuos conservados en nuestra secuencia query vayan al servidor de Blast2logo y suban dicha secuencia. Seleccionen BLAST Database NR70 y denle Submit (esto puede llevar un tiempito). En caso de que algo falle puede encontrar la salida ac\u00e1 . Cuando esto termine deber\u00edan tener un logo de toda la secuencia. Atenci\u00f3n Si les resulta dif\u00edcil de leer pueden hacer click en el bot\u00f3n Customize visualization using Seq2Logo . Al hacer esto los transfiere al servidor de Seq2logo y all\u00ed, sin tocar ninguna opci\u00f3n, denle Submit . Arriba les va a aparecer la opci\u00f3n de descargar cada imagen por separado (JPEG(1), JPEG(2), etc.) o en un s\u00f3lo archivo EPS (similar a PDF). Se recomienda esto \u00faltimo. 10. Viendo el logo: \u00bfPor qu\u00e9 creen que las primeras ~150 posiciones se ven bastante planas (Bits<1)? \u00bfCu\u00e1les son las posiciones con contenido de informaci\u00f3n m\u00e1s alto? \u00bfPueden identificar el dominio conservado que hab\u00edan visto en el ejercicio anterior? Para probar qu\u00e9 residuos dentro del dominio m\u00e1s conservado son los m\u00e1s relevantes para la estructura y/o funci\u00f3n de nuestra prote\u00edna, podr\u00edamos realizar un ensayo de mutag\u00e9nesis en el laboratorio. Debido a que la secuencia de nuestra prote\u00edna es larga (m\u00e1s de 400 amino\u00e1cidos), un estudio completo de mutag\u00e9nesis podr\u00eda resultar extremadamente costoso. Por esta raz\u00f3n, teniendo en cuenta lo realizado con el servidor Blast2logo, vamos a seleccionar (guiados por la conservaci\u00f3n de los residuos) 4 de los siguientes 8 residuos para llevar a cabo nuestro hipot\u00e9tico ensayo de mutag\u00e9nesis: (a): H271 (b): R287 (c): E290 (d): Y334 (e): F371 (f): R379 (g): R400 (h): Y436 11. \u00bfCu\u00e1les creen que son los 4 residuos que podr\u00edamos mutar de la lista para generar un impacto en la estructura de nuestra prote\u00edna query ? Ejercicio a informar Info Fecha l\u00edmite de entrega: Viernes, 16 de Septiembre 2022, 23:59hs. Enunciado Una vez que usted hizo el an\u00e1lisis (informado en el TP3), se comunic\u00f3 con el laboratorio AVENAI y le indican que una vez secuenciado el aislamiento, tienen como pol\u00edtica hacer todas sus secuencias de dominio p\u00fablico, esto significa que su secuencia de estudio ya figura en las bases de datos (Usted suspira, de haberlo sabido antes...). Para poder identificarla, y sabiendo que es un Betacoronavirus , usted decide utilizar la herramienta provista por NCBI y hacer un BLASTn de su secuencia inc\u00f3gnita contra la base de datos genomic/Viruses/Betacoronavirus . 1. \u00bfCu\u00e1l es el resultado de realizar el BLASTn? \u00bfObtiene alg\u00fan hit con 100% de cobertura y E-value=0.0? Si obtiene m\u00e1s de un hit, recupere el primero. 2. \u00bfA qu\u00e9 aislamiento corresponde su secuencia? Para recolectar m\u00e1s informaci\u00f3n de su secuencia, decide acceder al GenBank yendo a la pesta\u00f1a Alignments de la salida del BLASTn y cliqueando en el accession number correspondiente. Su jefe est\u00e1 muy interesado en estudiar qu\u00e9 prote\u00ednas de esta variante de coronavirus contienen ligandos del alelo HLA-A*02:01 . Para eso a usted se le ocurre realizar predicciones utilizando la matriz peso-espec\u00edfica del alelo correspondiente que ya hab\u00eda generado en un curso de Bioinform\u00e1tica (TP5) tiempo atr\u00e1s y que sabe que funciona muy bien. Puede encontrar una descripci\u00f3n de coronavirus y sus prote\u00ednas en ViralZone de Expasy . Usted decide trabajar con las prote\u00ednas S (spike o prote\u00edna de glicoprote\u00edna de superficie), E (prote\u00edna de la envoltura), M (prote\u00edna de membrana) y N (fosfoprote\u00edna de la nucleoc\u00e1pside) de esta variante de coronavirus (ex secuencia inc\u00f3gnito) ya que cree, adem\u00e1s, que son las que podr\u00edan llegar a contener los p\u00e9ptidos m\u00e1s inmunog\u00e9nicos. Para obtener las secuencias de las prote\u00ednas en estudio decide recurrir al registro del GenBank que afortunadamente guard\u00f3 despu\u00e9s de hacer el BLASTn. Decide adem\u00e1s utilizar la herramienta EasyPred que ya us\u00f3 tiempo atr\u00e1s para generar su matriz peso-espec\u00edfica, pero esta vez la usar\u00e1 para realizar una predicci\u00f3n. Por lo tanto, deja el recuadro de entrenamiento vac\u00edo e ingresa el archivo con la secuencia de la prote\u00edna a evaluar en el recuadro de evaluaci\u00f3n. Por \u00faltimo, sube el archivo con la matriz en la secci\u00f3n Load saved prediction method . Selecciona Sort output on predicted values y aprieta el bot\u00f3n Submit query. Atenci\u00f3n Importante: En la salida no hay logos ni m\u00e9tricas porque ya no se est\u00e1 entrenando ni testeando el modelo. En este punto se est\u00e1 utilizando un modelo ya entrenado (su matriz) para hacer predicciones en datos que nunca vi\u00f3. La lista de p\u00e9ptidos son todas aquellas secuencias de 9 amino\u00e1cidos que se pueden obtener de la secuencia proteica que se le administra al servidor, junto con el valor de predicci\u00f3n. 3. Describa lo que observa en el output de EasyPred. \u00bfQu\u00e9 operaci\u00f3n realiza el servidor para obtener las predicciones para cada p\u00e9ptido? 4. \u00bfQu\u00e9 p\u00e9ptidos de cada una de las prote\u00ednas analizadas elegir\u00eda para testear en el laboratorio? Para analizar en forma conjunta los mejores ligandos que obtuvo seg\u00fan los puntajes predichos por su PSSM decide realizar un logo con todos los p\u00e9ptidos de las prote\u00ednas M , E , S y N que contengan un valor de predicci\u00f3n mayor a 1. Extra (y por ende opcional) Puede realizar un for loop junto con un awk para seleccionar los p\u00e9ptidos relevantes de cada una de las prote\u00ednas (recuerde que en un TP se realiz\u00f3 un awk para seleccionar columnas). Para realizar el logo, utiliza Seq2Logo y genera un logo con todos estos p\u00e9ptidos ajustando los par\u00e1metros seg\u00fan su criterio. 5. En base a los conocimientos adquiridos en su curso de Bioinform\u00e1tica, \u00bfle parece razonable el motivo hallado para el alelo HLA-A*02:01? \u00bfPuede ver claramente las posiciones ancla? \u00bfQu\u00e9 amino\u00e1cidos son los preferidos para estas posiciones? 6. \u00bfObserva algo raro en el logo obtenido? \u00bfC\u00f3mo har\u00eda para modificarlo?","title":"TP 5 - Perfiles de secuencias"},{"location":"practicos/TP05_PSI-BLAST/#tp-5-perfiles-de-secuencias-y-psi-blast","text":"Materiales Atenci\u00f3n: Este TP tiene informe.","title":"data-toc-label"},{"location":"practicos/TP05_PSI-BLAST/#videos-de-la-clase-grabada","text":"Introducci\u00f3n al TP Cierre TP","title":"Videos de la clase grabada"},{"location":"practicos/TP05_PSI-BLAST/#construccion-de-logos-y-matrices-peso-especificas","text":"","title":"Construcci\u00f3n de Logos y Matrices peso-espec\u00edficas"},{"location":"practicos/TP05_PSI-BLAST/#objetivos","text":"Familiarizarse con la construcci\u00f3n de matrices peso-espec\u00edficas o PSSM. Familiarizarse con la visualizaci\u00f3n de logos de secuencias, y el uso del contenido de informaci\u00f3n. Utilizar las matrices peso-espec\u00edficas como m\u00e9todos predictivos, y entender las m\u00e9tricas PCC (Pearson correlation coefficient) y Aroc (Area under the Receiver Operating Characteristic curve) empleadas para evaluar la calidad de los modelos.","title":"Objetivos"},{"location":"practicos/TP05_PSI-BLAST/#introduccion","text":"En este TP utilizaremos herramientas bioinform\u00e1ticas para predecir la uni\u00f3n de p\u00e9ptidos a MHC, o por sus siglas en ingl\u00e9s Major Histocompatibility Complex , y seleccionaremos potenciales ep\u00edtopes como candidatos para desarrollar una vacuna. Los pasos a seguir ser\u00e1n: Identificaci\u00f3n de motivos de uni\u00f3n a MHC. Visualizaci\u00f3n de motivos utilizando logos de secuencias. Entrenamiento de m\u00e9todos de predicci\u00f3n de uni\u00f3n a MHC. Utilizaci\u00f3n de los m\u00e9todos desarrollados para la selecci\u00f3n de candidatos vacunales. La uni\u00f3n de p\u00e9ptidos a MHC es el paso m\u00e1s selectivo en el camino de procesamiento y presentaci\u00f3n antig\u00e9nica. Este evento es crucial ya que solamente 1 de cada 200 p\u00e9ptidos forma un complejo con el MHC. Existe una gran variedad de MHC diferentes, cada uno con una alta especificidad. El motivo de uni\u00f3n de los MHC de la v\u00eda de clase I es, en la mayor\u00eda de los casos, de 9 amino\u00e1cidos de longitud. Estos est\u00e1n caracterizados por una marcada preferencia por ciertos amino\u00e1cidos en determinadas posiciones del motivo. Estas posiciones son llamadas \"anclas\" o, en ingl\u00e9s, anchor positions . Para una gran cantidad de complejos de MHC de clase I estas anclas se encuentran en las posiciones P2 y P9. Sin embargo, este no es siempre el caso. Existe una gran cantidad de datos que describen las diferentes especificidades de las mol\u00e9culas de MHC. Una base de datos muy conocida que almacena esta informaci\u00f3n es SYFPEITHI . En ella se puede encontrar informacion de ligandos y motivos de MHC. Con este tipo de informaci\u00f3n es posible desarrollar un modelo de predicci\u00f3n de uni\u00f3n de p\u00e9ptidos a MHC y usarlo para descubrir nuevos ep\u00edtopes con los cuales dise\u00f1ar vacunas. Esto puede ser aplicado a nivel de proteomas enteros para ahorrar tanto tiempo como recursos. A continuaci\u00f3n vamos a: Visualizar motivos de uni\u00f3n utilizando logos de secuencias. Entrenar un modelo predictivo utilizando el servidor de EasyPred . Aplicar el modelo para seleccionar p\u00e9ptidos con potencial inmunog\u00e9nico de prote\u00ednas de SARS-CoV-2.","title":"Introducci\u00f3n"},{"location":"practicos/TP05_PSI-BLAST/#identificacion-de-motivos-de-union-a-mhc","text":"Dir\u00edjanse a la p\u00e1gina web de SYFPEITHI . All\u00ed, una vez que hagan click en el logo, pueden buscar motivos con el bot\u00f3n Find your motif, Ligand or Epitope . All\u00ed seleccionen con el men\u00fa de la izquierda el alelo de MHC HLA-A*02:01 y presionen Do Query . Nota El resto de las opciones se pueden usar para refinar la b\u00fasqueda, limit\u00e1ndola a ligandos de prote\u00ednas determinadas o por referencia bibliogr\u00e1fica. En este caso queremos obtener TODOS los ligandos para poder ver qu\u00e9 caracter\u00edsticas comparten. En el resultado de la b\u00fasqueda podemos ver las posiciones anchor principales y auxiliares, y tambi\u00e9n otras posiciones con residuos preferidos. Tambi\u00e9n tenemos una lista de otros amino\u00e1cidos que se ven con frecuencia en los ligandos del alelo que estamos estudiando. Por \u00faltimo, m\u00e1s abajo, se muestra la lista de los ligandos que existen en esta base de datos, junto a su proteina de procedencia, la referencia del trabajo donde se lo identific\u00f3 y alguna nota como la asociaci\u00f3n de un p\u00e9ptido dado con una enfermedad. 1. Respondan a las siguientes preguntas : a. \u00bfQu\u00e9 posiciones identifican como anchors ? \u00bfQu\u00e9 residuos son preferidos en estas posiciones? \u00bfY en los auxiliary anchors ? b. \u00bfQu\u00e9 otras posiciones muestran preferencias de residuos? \u00bfQu\u00e9 residuos son preferidos en estas posiciones? c. \u00bfQu\u00e9 caracter\u00edstica del conjunto de p\u00e9ptidos creen que puede estar diferenciando a las posiciones anchor del resto de las posiciones de los p\u00e9ptidos? Recu\u00e9rdenla para el ejercicio de logos de secuencia. 2. Repitan el mismo an\u00e1lisis para el alelo HLA-B*27 . \u00bfCoinciden las posiciones anchor con las del alelo HLA-A*02:01 ?, \u00bfy los residuos preferidos?","title":"Identificaci\u00f3n de motivos de uni\u00f3n a MHC"},{"location":"practicos/TP05_PSI-BLAST/#logos-de-secuencias","text":"Los logos son una herramienta muy \u00fatil para visualizar motivos de uni\u00f3n. En un logo de secuencia se grafica en el eje y el contenido de informaci\u00f3n de cada posici\u00f3n del motivo, generalmente expresado en bits . A su vez, la frecuencia con la que aparece una letra (nucle\u00f3tido u aminino\u00e1cido) en una dada posici\u00f3n se grafica con un tama\u00f1o proporcional a dicha magnitud. Un servidor que nos permite generar facilmente logos de secuencia es Seq2Logo . Este m\u00e9todo nos da la opci\u00f3n de ingresar un alineamiento m\u00faltiple (MSA), una lista de p\u00e9ptidos o una matriz peso-espec\u00edfica con la cual realizar el gr\u00e1fico. La informaci\u00f3n puede pegarse directamente en el cuadro de texto que provee la web, o subiendo directamente un archivo local utilizando la opci\u00f3n Switch to file upload que se encuentra debajo del cuadro. Dentro de las opciones que nos permite cambiar tenemos: Logo type: Esto refiere a la magnitud que se calcular\u00e1 para cada posici\u00f3n y se graficar\u00e1 en el eje y (Kullback-Leiber, Shannon, etc.). Clustering method: Agrupa las secuencias que son muy similares para no sesgar el resultado, se pueden optar por diferentes m\u00e9todos. Weight on prior: Es el valor que le asignamos al par\u00e1metro beta en la ecuacion del c\u00e1lculo del contenido de informaci\u00f3n . Recuerden que la relaci\u00f3n entre alfa y beta es determinante para este c\u00e1lculo. Information content units: Generalmente se expresa en bits , pero en algunos casos se opta por half-bits . Output format: El tipo de archivo de imagen adonde se guardar\u00e1 el logo. Tambi\u00e9n tenemos la opci\u00f3n de realizar cambios avanzados, como modificar las frecuencias de background o la matriz de scoring , limitar la regi\u00f3n del alineamiento que queremos graficar, etc. y opciones gr\u00e1ficas, como el tama\u00f1o de la imagen y los colores con los que se representa cada amino\u00e1cido. Por convenci\u00f3n los colores que se utilizan son: Rojo : Amino\u00e1cidos \u00e1cidos [DE] Azul : Amino\u00e1cidos b\u00e1sicos [HKR] Negro : Amino\u00e1cidos hidrof\u00f3bicos [ACFILMPVW] Verde : Amino\u00e1cidos neutros [GNQSTY] Atenci\u00f3n Recuerden guardar los logos de secuencia generados. 3. En Materiales pueden encontrar los archivos HLA-A0201 y HLA-B27 , los cuales contienen ligandos de cada uno de estos alelos de MHC. \u00dasenlos para generar logos que muestren sus motivos de preferencia. Utilicen como opci\u00f3n de clustering Heuristics. Usamos para el resto de las opciones los valores default .Identifiquen las posiciones ancla y las preferencias de cada alelo. a. \u00bfEl logo obtenido para HLA-A02:01 y HLA-B27 se condice con lo que encontr\u00f3 en la base de datos en el punto anterior? b. \u00bfQu\u00e9 magnitud es la que est\u00e1 diferenciando a las posiciones anchor del resto? \u00bfEn qu\u00e9 unidad aparece representada en el logo? \u00bfCoincide con lo supuesto en el punto 1.c ?","title":"Logos de secuencias"},{"location":"practicos/TP05_PSI-BLAST/#construccion-de-matrices-peso-especificas-pssm","text":"Para este punto vamos a utilizar el servidor de EasyPred . Esta herramienta nos permite construir tanto matrices peso-espec\u00edficas, o PSSM (Position-Specific Scoring Matrix) , como aplicarlas a un set de datos para calcular su score . El servidor consta de dos cuadros de texto, el de la izquierda en el cual se ingresan datos para construir la matriz, y el de la derecha donde uno puede ingresar secuencias sobre las cuales quiere realizar una predicci\u00f3n. Para explorar un poco la construcci\u00f3n de matrices solo utilizaremos el recuadro de la izquierda donde ingresaremos las siguientes secuencias: VFAAA VHYWW VLQPK LREWQ LPYIH Las opciones que tenemos aqu\u00ed son muy similares a las que habiamos visto en el servidor de Seq2Logo debido a que ambos realizan c\u00e1lculos del contenido de informaci\u00f3n. En este caso vamos a seleccionar Clustering method: No clustering y Weight on prior: 10000 . Usamos para el resto de las opciones los valores default . 4. Antes de generar la PSSM, reflexionen un poco acerca de los par\u00e1metros empleados para la construcci\u00f3n de la misma. a. \u00bfPor qu\u00e9 consideran que no estamos usando ning\u00fan m\u00e9todo de clustering? b. \u00bfPor qu\u00e9 creen que es tan alto el valor sugerido para el weight on prior (\u03b2) ? Recordatorio La ecuaci\u00f3n utilizada para estimar la frecuencia p a , para una dada posici\u00f3n, en una matriz peso-espec\u00edfica es, donde \u03b1 es el n\u00famero de secuencias en el MSA-1, \u03b2 es el weight on prior o weight on pseudocounts , f a es la frecuencia observada para el amino\u00e1cido a en esa posici\u00f3n y g a es la pseudo frecuencia para el amino\u00e1cido a en esa misma posici\u00f3n. Hagan Submit query y observen la salida. All\u00ed podr\u00e1n encontrar informaci\u00f3n sobre los par\u00e1metros utilizados y un logo que representa el set de datos que ingresamos. Observando el logo generado: 5. \u00bfQu\u00e9 amino\u00e1cidos es m\u00e1s probable hallar en la posici\u00f3n P1? Pista Son los que est\u00e1n por encima de y=0. 6. \u00bfCu\u00e1ntos amino\u00e1cidos diferentes hay en P1 (en y>=0)? \u00bfCu\u00e1les se encuentran datos de entrada? \u00bfCu\u00e1les en el logo generado? 7. \u00bfA qu\u00e9 se debe esta diferencia? 8. Realice el mismo ejercicio pero ahora elija un weight on prior \u03b2=0. \u00bfCambian sus respuestas para los puntos 5. , 6. y 7. ?","title":"Construcci\u00f3n de matrices peso-espec\u00edficas (PSSM)"},{"location":"practicos/TP05_PSI-BLAST/#prediccion-de-union-a-mhc","text":"Habi\u00e9ndonos familiarizado con la interfaz de EasyPred vamos a utilizarla para entrenar un modelo con m\u00e1s datos y ponerlo a prueba. Para eso utilizaremos dos sets de entrenamiento que poseen p\u00e9ptidos fueron testeados con el alelo HLA-A02:01. Cada uno tiene un valor asociado que denota si son positivos (1) o negativos (0.1). A lo largo del proceso iremos variando diferentes par\u00e1metros para observar qu\u00e9 efectos esto tiene sobre el poder predictivo del modelo, al ser testeado en un set de evaluaci\u00f3n con valores de afinidad ( binding affinity ) de uni\u00f3n a MHC reales (reescalados entre 0 y 1). Los datos que utilizaremos est\u00e1n en los archivos: Entrenamiento_chico.set que contiene 110 p\u00e9ptidos de los cuales s\u00f3lo 10 son positivos. Entrenamiento_grande.set contiene 232 p\u00e9ptidos de los cuales todos son positivos. Para evaluar el desempe\u00f1o de nuestro modelo utilizaremos el archivo Evaluacion.set , el cual contiene 1266 peptidos con valores de afinidad convertidos al rango 0-1 mediante la formula 1-log(x)/log(50000). Utilizando esta transformaci\u00f3n, valores mayores a 0.638 (equivalente a 50nM) representan una uni\u00f3n fuerte, entre 0.638 y 0.426 (equivalente a 500nM) una uni\u00f3n d\u00e9bil y p\u00e9ptidos con valores menores a 0.426 no se consideran ligandos. Atenci\u00f3n Una buena pr\u00e1ctica antes de comezar a hacer cualquier cosa con nuestros datos es observarlos y entender el formato en el que est\u00e1n almacenados. Por ejemplo, si hacemos un cat del archivo Entrenamiento_chico.set , nos encontramos con lo siguiente: Este es un archivo con dos columnas, la primera contiene a los p\u00e9ptidos y la segunda a los valores de afinidad de uni\u00f3n o binding affinity de los mismos. (\u00bfEn qu\u00e9 escala est\u00e1n los valores de binding affinity ? \u00bfEst\u00e1n normalizados entre 0 y 1?) Para analizar el desempe\u00f1o de nuestros modelos vamos a tener en cuenta dos m\u00e9tricas: Aroc (Area under the Receiver Operator Curve): este valor var\u00eda entre 0 y 1, siendo 1 el puntaje perfecto y 0.5 el valor aleatorio. Por regla general, valores mayores a 0.85 son altamente deseables. Coeficiente de correlaci\u00f3n de Pearson (PCC): tambi\u00e9n oscila entre 0 y 1, siendo 1 una correlaci\u00f3n perfecta entre las dos variables de estudio, y -1 una anticorrelaci\u00f3n perfecta. En este caso el valor que implica aleatoriedad total o no correlaci\u00f3n entre las dos variables es 0. Estas m\u00e9tricas nos van a ayudar a seleccionar el mejor de nuestros modelos, siendo \u00e9ste el que alcance los mejores valores de Aroc y Coeficiente de Pearson . Note A continuaci\u00f3n vamos a entrenar varios modelos y comparar sus resultados. Haga cada prueba en una ventana nueva o guarde las salidas de alguna manera que crea conveniente.","title":"Predicci\u00f3n de uni\u00f3n a MHC"},{"location":"practicos/TP05_PSI-BLAST/#primera-prueba","text":"Atenci\u00f3n Volvamos a abrir EasyPred o recarguemos la p\u00e1gina para que todas las opciones vuelvan a estar por defecto. Realicemos los siguientes cambios: los datos del archivo Entrenamiento_chico.set en el recuadro de entrenamiento y los de Evaluacion.set en el recuadro de evaluaci\u00f3n . Coloquemos el umbral de corte para positivos ( Cutoff for counting an example as a positive example ) en 0 y apretemos el bot\u00f3n Submit query . La salida consta de varias partes: Al principio tenemos una peque\u00f1a descripci\u00f3n de los par\u00e1metros con los que se llev\u00f3 a cabo el entrenamiento, tanto de los datos como del m\u00e9todo. Esto es siempre \u00fatil para poder reproducir los resultados. Luego tenemos un logo constru\u00eddo a partir de los datos de entrenamiento. Esto nos puede ayudar a identificar (como hicimos anteriormente) la preferencia de la mol\u00e9cula que se une a nuestro set de p\u00e9ptidos. A continuaci\u00f3n sigue la informaci\u00f3n sobre la evaluaci\u00f3n. All\u00ed podemos encontrar los valores del coeficiente de Pearson y Aroc y la lista de predicciones sobre el set de evaluaci\u00f3n. F\u00edjense que Assignment se refiere al valor medido o real que est\u00e1 en el archivo de evaluaci\u00f3n y va de 0 a 1, sin embargo la predicci\u00f3n puede adoptar otros valores, incluso negativos. Tip Las m\u00e9tricas que utilizamos no se enfocan en reportar la precisi\u00f3n del m\u00e9todo (proporci\u00f3n de verdaderos positivos entre todos los p\u00e9ptidos predichos como positivos) sino que muestran: la habilidad del m\u00e9todo para distinguir instancias positivas de negativas (Aroc) y la correlaci\u00f3n entre los valores predichos y los valores reales u observados (PCC). Revisando la salida contesten: 9. \u00bfQu\u00e9 valores de Aroc y PCC obtuvieron? \u00bfQu\u00e9 implica esto? 10. Viendo el logo resultante, \u00bfEntienden por qu\u00e9 el modelo tiene tan mal desempe\u00f1o? 11. \u00bfCu\u00e1ntos de los 110 p\u00e9ptidos se utilizaron para la construcci\u00f3n de la matriz? \u00bfPor qu\u00e9 se us\u00f3 ese n\u00famero de p\u00e9ptidos? Pista Mire el archivo de entrada Entrenamiento_chico.set y vea cu\u00e1les son los valores de afinidad para los p\u00e9ptidos all\u00ed listados.","title":"Primera prueba"},{"location":"practicos/TP05_PSI-BLAST/#segunda-prueba","text":"Volvamos a la p\u00e1gina principal de EasyPred . Esta vez coloquemos el umbral de positivos en 0.5 pero especifiquemos que no haya clustering y pongamos un weight on prior de 0.0. 12. \u00bfQu\u00e9 valores de desempe\u00f1o tienen ahora? \u00bfQu\u00e9 implican estos valores? \u00bfSon mejores o peores que en la primera prueba? \u00bfPor qu\u00e9 cree que cambiaron? 13. \u00bfCu\u00e1ntos de los 110 p\u00e9ptidos se utilizaron en este caso para la construcci\u00f3n de la matriz? 14. Mirando el logo, \u00bfSe parece al motivo de uni\u00f3n de HLA-A*02:01 que hab\u00edan visto antes? \u00bfPor qu\u00e9 cree que ocurre esto? Pista Tenga en cuenta el n\u00famero de secuencias que se usaron para construir la matriz y recuerde que siempre es una buena pr\u00e1ctica revisar las instrucciones de la gu\u00eda y los archivos de entrada.","title":"Segunda prueba"},{"location":"practicos/TP05_PSI-BLAST/#tercera-prueba","text":"Volvamos atr\u00e1s y repitamos el caso anterior pero seleccionando Clustering at 62% identity . Mantengamos el weight on prior en 0.0 y el resto de los par\u00e1metros como se hab\u00edan seteado en la segunda prueba. 15. \u00bfCu\u00e1l es el desempe\u00f1o ahora? 16. \u00bfCambi\u00f3 el logo con respecto al anterior? Si es as\u00ed\u2026 \u00bfA qu\u00e9 cree que se debe el cambio? Pista De nuevo, es una buena pr\u00e1ctica revisar qu\u00e9 contienen los archivos de entrada, es decir los datos crudos. Miren con atenci\u00f3n las secuencias de los positivos.","title":"Tercera prueba"},{"location":"practicos/TP05_PSI-BLAST/#cuarta-prueba","text":"Volvamos una vez m\u00e1s, manteniendo Clustering at 62% identity pero utilicemos como weight on prior un valor de 200, y el umbral de positivos en 0.5. 17. Una vez m\u00e1s revisen las m\u00e9tricas de desempe\u00f1o. 18. Mirando el logo, \u00bfCu\u00e1l es la gran diferencia con aquellos que ven\u00edan viendo? \u00bfCu\u00e1l es la raz\u00f3n de este cambio? \u00bfEmpieza ahora a parecerse a los motivos que hab\u00edan visto antes?","title":"Cuarta prueba"},{"location":"practicos/TP05_PSI-BLAST/#quinta-y-ultima-prueba","text":"Hasta ahora ven\u00edamos utilizando un set de datos sumamente reducido, con solo 10 p\u00e9ptidos positivos para entrenar. A\u00fan asi hemos conseguido valores de desempe\u00f1o bastante aceptables. Sin embargo, estos m\u00e9todos suelen utilizar muchas m\u00e1s informaci\u00f3n para su entrenamiento. A continuaci\u00f3n recarguen la p\u00e1gina de EasyPred y carguen para entrenar el archivo Entrenamiento_grande.set . En el cuadro de evaluaci\u00f3n vuelvan a cargar Evaluacion.set . Seleccionen una vez m\u00e1s Clustering at 62% identity , pongan el weight on prior en 200 y el umbral de positivos en 0.5. Tilden tambi\u00e9n la opci\u00f3n Sort output on predicted values para ver la tabla de p\u00e9ptidos ordenada por los valores de predicci\u00f3n. 19. Revisen una vez m\u00e1s los valores de desempe\u00f1o. 20. Vean el logo, \u00bfqu\u00e9 les parece? 21. Mirando la tabla de predicciones, \u00bfCu\u00e1ntos falsos positivos encuentran entre los primeros 20 p\u00e9ptidos? (con Assignment menor a 0.426) Atenci\u00f3n Antes de cerrar la ventana haga click en Parameters for prediction method luego del logo. All\u00ed podr\u00e1 descargar la matriz calculada a partir de los datos de entrenamiento (Se descarga con el nombre para.dat, es un archivo de texto plano). Esta puede ser utilizada luego para llevar a cabo predicciones.","title":"Quinta (y \u00faltima) prueba"},{"location":"practicos/TP05_PSI-BLAST/#psi-blast","text":"","title":"PSI-BLAST"},{"location":"practicos/TP05_PSI-BLAST/#objetivos_1","text":"Comprender el funcionamiento del algoritmo PSI-BLAST, aplicando el mismo en un caso de estudio en el que BLAST no funciona. Generar y reutilizar la PSSM que arroja PSI-BLAST, para encontrar hits en otras bases de datos relevantes tales como PDB. Entender la informaci\u00f3n que nos otorga la PSSM constru\u00edda por PSI-BLAST en relaci\u00f3n a los residuos o dominios conservados de una prote\u00edna.","title":"Objetivos"},{"location":"practicos/TP05_PSI-BLAST/#introduccion_1","text":"PSI-BLAST (o Position Specific Iterated BLAST) es un algoritmo alternativo de BLAST que construye iterativamente una matriz de puntajes posici\u00f3n espec\u00edfica, o PSSM (Position-Specific Scoring Matrix) , para calcular el score de los alineamientos. En su forma b\u00e1sica de funcionamiento lo que hace es realizar un simple BLAST con una secuencia query y, a partir de los resultados o hits que obtiene, construye un perfil o PSSM. Entonces, la siguiente b\u00fasqueda la realiza con ese perfil, lo que permitir\u00e1 encontrar, idealmente, nuevos hits , correspondientes a secuencias m\u00e1s distantes de la secuencia query . Con esos nuevos hits genera un nuevo perfil, el cual, idealmente, contendr\u00e1 mayor cantidad de informaci\u00f3n y con el que se podr\u00e1 realizar otra b\u00fasqueda. Es un proceso iterativo. En resumen, a partir de la segunda iteraci\u00f3n los puntajes de la matriz variar\u00e1n acorde a la conservaci\u00f3n de los amino\u00e1cidos o nucle\u00f3tidos en cada posici\u00f3n permitiendo refinar nuestra b\u00fasqueda y as\u00ed recuperando secuencias distantes que comparten motivos o dominios con nuestra secuencia query original.","title":"Introducci\u00f3n"},{"location":"practicos/TP05_PSI-BLAST/#cuando-blast-falla","text":"Digamos que se tiene una secuencia query (abajo) y se quiere predecir su estructura y funci\u00f3n. Como vimos anteriormente uno recurre generalmente a BLAST para este tipo de tareas. Si logramos identificar una prote\u00edna suficientemente similar podr\u00edamos hipotetizar que comparten dichas caracteristicas. >QUERY1 MKDTDLSTLLSIIRLTELKESKRNALLSLIFQLSVAYFIALVIVSRFVRYVNYITYNNLV EFIIVLSLIMLIIVTDIFIKKYISKFSNILLETLNLKINSDNNFRREIINASKNHNDKNK LYDLINKTFEKDNIEIKQLGLFIISSVINNFAYIILLSIGFILLNEVYSNLFSSRYTTIS IFTLIVSYMLFIRNKIISSEEEEQIEYEKVATSYISSLINRILNTKFTENTTTIGQDKQL YDSFKTPKIQYGAKVPVKLEEIKEVAKNIEHIPSKAYFVLLAESGLRPGELLNVSIENID LKARIIWINKETQTKRAYFSFFSRKTAEFLEKVYLPAREEFIRANEKNIAKLAAANENQE IDLEKWKAKLFPYKDDVLRRKIYEAMDRALGKRFELYALRRHFATYMQLKKVPPLAINIL QGRVGPNEFRILKENYTVFTIEDLRKLYDEAGLVVLE Vayan a la pagina de BLAST y utilicen el algoritmo de Protein BLAST para buscar secuencias similares. En el campo de base de datos seleccione pdb que es la base que contiene estructuras . Tip Pueden correr la b\u00fasqueda eligiendo el par\u00e1metro \"Show results in a new window\". 1. \u00bfCu\u00e1ntos hits con E-value < 0.005 encuentran? Vuelvan atr\u00e1s y, en Program selection: Algorithm , seleccionen PSI-BLAST. \u00bfCambi\u00f3 el resultado en comparaci\u00f3n a lo que hab\u00edan obtenido anteriormente?","title":"Cuando BLAST falla"},{"location":"practicos/TP05_PSI-BLAST/#usando-psi-blast","text":"Atenci\u00f3n Realicen cada corrida de BLAST (e iteraci\u00f3n de PSI-BLAST) en una ventana diferente, en varios casos van a necesitar comparar las salidas. Vuelvan atr\u00e1s a la p\u00e1gina de alineamiento de prote\u00ednas, pero esta vez seleccionen la base de datos Non-redundant protein sequences (nr) y en la secci\u00f3n de algoritmos seleccionen PSI-BLAST. Teniendo en cuenta que el primer hit es nuestro query y por lo tanto vamos a ignorarlo: 2. Ahora, \u00bfCu\u00e1ntos hits significativos encuentran (E-value < 0.005)? 3. \u00bfQu\u00e9 significa la variable Query Cover ? Una manera visual para entender el query coverage es mirar el Graphic Summary . Dentro de la pesta\u00f1a Descriptions , coloquen la pesta\u00f1a Show en 100. Luego cliqueen en la pesta\u00f1a Graphic Summary . \u00bfCu\u00e1l es la cobertura de los hits obtenidos?","title":"Usando PSI-BLAST"},{"location":"practicos/TP05_PSI-BLAST/#construyendo-la-pssm","text":"Si se fijan debajo de los hits significativos van a tener la opci\u00f3n de seguir iterando PSI-BLAST: All\u00ed pueden especificar cuantas secuencias queremos utilizar para refinar nuestras PSSM ( Position-Specific Scoring Matrix ). Conservando el valor por defecto corramos la siguiente iteraci\u00f3n. 4. \u00bfCu\u00e1ntos hits significativos pueden encontrar ahora (E-value < 0.005)? 5. \u00bfC\u00f3mo se modific\u00f3 el coverage de estos hits ? Vuelvan a mirar el Graphic Summary , colocando previamente en Descriptions la pesta\u00f1a Show en 250. 6. \u00bfPor qu\u00e9 creen que PSI-BLAST puede identificar ahora m\u00e1s hits significativos y que es lo que est\u00e1 afectando el query coverage ? 7. \u00bfQu\u00e9 significan que los hits est\u00e9n resaltados en amarillo, y qu\u00e9 significa que est\u00e9n en blanco con un tick verde? Nota Antes de proseguir realicen una o dos iteraciones m\u00e1s y observen la aparici\u00f3n de nuevas prote\u00ednas identificadas (marcadas con amarillo).","title":"Construyendo la PSSM"},{"location":"practicos/TP05_PSI-BLAST/#guardando-y-reutilizando-la-pssm","text":"Ahora podemos utilizar la PSSM que est\u00e1 ajustada con los resultados obtenidos de PSI-BLAST para realizar b\u00fasquedas m\u00e1s significativas en otras bases de datos. Para obtener la PSSM descarguenla arriba donde dice \" Donwload All \" Volvamos una vez m\u00e1s a la p\u00e1gina para realizar la b\u00fasqueda. Sin ingresar ninguna secuencia query seleccionemos otra vez la base de datos de estructuras Protein Data Bank (pdb) y como algoritmo PSI-BLAST. Por \u00faltimo, justo debajo del bot\u00f3n de BLAST, abramos el men\u00fa de Algorithm parameters y carguemos nuestra PSSM (justo al final). Ahora s\u00ed corramos la b\u00fasqueda. 8. \u00bfPueden encontrar hits significativos de PDB ahora? 9. \u00bfQu\u00e9 funci\u00f3n pueden identificar en los primeros hits?","title":"Guardando y reutilizando la PSSM"},{"location":"practicos/TP05_PSI-BLAST/#identificando-residuos-conservados","text":"Ahora (si tuvimos suerte) habremos podido identificar una relaci\u00f3n estructural entre nuestra secuencia query y las secuencias de la base de datos de estructuras proteicas PDB. Digamos que, en este punto, nos gustar\u00eda validar esa relaci\u00f3n. Para identificar los residuos conservados en nuestra secuencia query vayan al servidor de Blast2logo y suban dicha secuencia. Seleccionen BLAST Database NR70 y denle Submit (esto puede llevar un tiempito). En caso de que algo falle puede encontrar la salida ac\u00e1 . Cuando esto termine deber\u00edan tener un logo de toda la secuencia. Atenci\u00f3n Si les resulta dif\u00edcil de leer pueden hacer click en el bot\u00f3n Customize visualization using Seq2Logo . Al hacer esto los transfiere al servidor de Seq2logo y all\u00ed, sin tocar ninguna opci\u00f3n, denle Submit . Arriba les va a aparecer la opci\u00f3n de descargar cada imagen por separado (JPEG(1), JPEG(2), etc.) o en un s\u00f3lo archivo EPS (similar a PDF). Se recomienda esto \u00faltimo. 10. Viendo el logo: \u00bfPor qu\u00e9 creen que las primeras ~150 posiciones se ven bastante planas (Bits<1)? \u00bfCu\u00e1les son las posiciones con contenido de informaci\u00f3n m\u00e1s alto? \u00bfPueden identificar el dominio conservado que hab\u00edan visto en el ejercicio anterior? Para probar qu\u00e9 residuos dentro del dominio m\u00e1s conservado son los m\u00e1s relevantes para la estructura y/o funci\u00f3n de nuestra prote\u00edna, podr\u00edamos realizar un ensayo de mutag\u00e9nesis en el laboratorio. Debido a que la secuencia de nuestra prote\u00edna es larga (m\u00e1s de 400 amino\u00e1cidos), un estudio completo de mutag\u00e9nesis podr\u00eda resultar extremadamente costoso. Por esta raz\u00f3n, teniendo en cuenta lo realizado con el servidor Blast2logo, vamos a seleccionar (guiados por la conservaci\u00f3n de los residuos) 4 de los siguientes 8 residuos para llevar a cabo nuestro hipot\u00e9tico ensayo de mutag\u00e9nesis: (a): H271 (b): R287 (c): E290 (d): Y334 (e): F371 (f): R379 (g): R400 (h): Y436 11. \u00bfCu\u00e1les creen que son los 4 residuos que podr\u00edamos mutar de la lista para generar un impacto en la estructura de nuestra prote\u00edna query ?","title":"Identificando residuos conservados"},{"location":"practicos/TP05_PSI-BLAST/#ejercicio-a-informar","text":"Info Fecha l\u00edmite de entrega: Viernes, 16 de Septiembre 2022, 23:59hs.","title":"Ejercicio a informar"},{"location":"practicos/TP05_PSI-BLAST/#enunciado","text":"Una vez que usted hizo el an\u00e1lisis (informado en el TP3), se comunic\u00f3 con el laboratorio AVENAI y le indican que una vez secuenciado el aislamiento, tienen como pol\u00edtica hacer todas sus secuencias de dominio p\u00fablico, esto significa que su secuencia de estudio ya figura en las bases de datos (Usted suspira, de haberlo sabido antes...). Para poder identificarla, y sabiendo que es un Betacoronavirus , usted decide utilizar la herramienta provista por NCBI y hacer un BLASTn de su secuencia inc\u00f3gnita contra la base de datos genomic/Viruses/Betacoronavirus . 1. \u00bfCu\u00e1l es el resultado de realizar el BLASTn? \u00bfObtiene alg\u00fan hit con 100% de cobertura y E-value=0.0? Si obtiene m\u00e1s de un hit, recupere el primero. 2. \u00bfA qu\u00e9 aislamiento corresponde su secuencia? Para recolectar m\u00e1s informaci\u00f3n de su secuencia, decide acceder al GenBank yendo a la pesta\u00f1a Alignments de la salida del BLASTn y cliqueando en el accession number correspondiente. Su jefe est\u00e1 muy interesado en estudiar qu\u00e9 prote\u00ednas de esta variante de coronavirus contienen ligandos del alelo HLA-A*02:01 . Para eso a usted se le ocurre realizar predicciones utilizando la matriz peso-espec\u00edfica del alelo correspondiente que ya hab\u00eda generado en un curso de Bioinform\u00e1tica (TP5) tiempo atr\u00e1s y que sabe que funciona muy bien. Puede encontrar una descripci\u00f3n de coronavirus y sus prote\u00ednas en ViralZone de Expasy . Usted decide trabajar con las prote\u00ednas S (spike o prote\u00edna de glicoprote\u00edna de superficie), E (prote\u00edna de la envoltura), M (prote\u00edna de membrana) y N (fosfoprote\u00edna de la nucleoc\u00e1pside) de esta variante de coronavirus (ex secuencia inc\u00f3gnito) ya que cree, adem\u00e1s, que son las que podr\u00edan llegar a contener los p\u00e9ptidos m\u00e1s inmunog\u00e9nicos. Para obtener las secuencias de las prote\u00ednas en estudio decide recurrir al registro del GenBank que afortunadamente guard\u00f3 despu\u00e9s de hacer el BLASTn. Decide adem\u00e1s utilizar la herramienta EasyPred que ya us\u00f3 tiempo atr\u00e1s para generar su matriz peso-espec\u00edfica, pero esta vez la usar\u00e1 para realizar una predicci\u00f3n. Por lo tanto, deja el recuadro de entrenamiento vac\u00edo e ingresa el archivo con la secuencia de la prote\u00edna a evaluar en el recuadro de evaluaci\u00f3n. Por \u00faltimo, sube el archivo con la matriz en la secci\u00f3n Load saved prediction method . Selecciona Sort output on predicted values y aprieta el bot\u00f3n Submit query. Atenci\u00f3n Importante: En la salida no hay logos ni m\u00e9tricas porque ya no se est\u00e1 entrenando ni testeando el modelo. En este punto se est\u00e1 utilizando un modelo ya entrenado (su matriz) para hacer predicciones en datos que nunca vi\u00f3. La lista de p\u00e9ptidos son todas aquellas secuencias de 9 amino\u00e1cidos que se pueden obtener de la secuencia proteica que se le administra al servidor, junto con el valor de predicci\u00f3n. 3. Describa lo que observa en el output de EasyPred. \u00bfQu\u00e9 operaci\u00f3n realiza el servidor para obtener las predicciones para cada p\u00e9ptido? 4. \u00bfQu\u00e9 p\u00e9ptidos de cada una de las prote\u00ednas analizadas elegir\u00eda para testear en el laboratorio? Para analizar en forma conjunta los mejores ligandos que obtuvo seg\u00fan los puntajes predichos por su PSSM decide realizar un logo con todos los p\u00e9ptidos de las prote\u00ednas M , E , S y N que contengan un valor de predicci\u00f3n mayor a 1. Extra (y por ende opcional) Puede realizar un for loop junto con un awk para seleccionar los p\u00e9ptidos relevantes de cada una de las prote\u00ednas (recuerde que en un TP se realiz\u00f3 un awk para seleccionar columnas). Para realizar el logo, utiliza Seq2Logo y genera un logo con todos estos p\u00e9ptidos ajustando los par\u00e1metros seg\u00fan su criterio. 5. En base a los conocimientos adquiridos en su curso de Bioinform\u00e1tica, \u00bfle parece razonable el motivo hallado para el alelo HLA-A*02:01? \u00bfPuede ver claramente las posiciones ancla? \u00bfQu\u00e9 amino\u00e1cidos son los preferidos para estas posiciones? 6. \u00bfObserva algo raro en el logo obtenido? \u00bfC\u00f3mo har\u00eda para modificarlo?","title":"Enunciado"},{"location":"practicos/TP06_Filogenia/","text":"TP 6 . Filogenias, \u00e1rboles filogen\u00e9ticos y filogen\u00f3mica Materiales Videos de la clase grabada Introducci\u00f3n al TP Cierre TP Software a usar Alineamientos: emma y clustalw (en EMBOSS suite) Visualizaci\u00f3n de alineamientos: Jalview www.jalview.org M\u00e9todos basados en distancias: fprotdist (en EMBOSS suite) fneighbor (en EMBOSS suite) M\u00e9todos de b\u00fasqueda de \u00e1rboles: fproml (en EMBOSS suite) fprotpars (en EMBOSS suite) Visualizaci\u00f3n de \u00e1rboles: FigTree tree.bio.ed.ac.uk/software/figtree/ Remuestreo y \u00e1rbol consenso: fseqboot (en EMBOSS suite) fconsense (en EMBOSS suite) Objetivos Familiarizarse con el uso de \u00e1rboles filogen\u00e9ticos Entender como leer \u00e1rboles simples Entender las distintas representaciones de \u00e1rboles filogen\u00e9ticos Entender las diferenicias entre los distintos algoritmos para la construcci\u00f3n de \u00e1rboles filogen\u00e9ticos Filogenia La filogen\u00e9tica es la ciencia que estudia las relaciones evolutivas entre entidades biol\u00f3gicas, frecuentemente especies, individuos, genes o prote\u00ednas. Es decir, que estima el pasado evolutivo basado en la comparaci\u00f3n de caracteres morfol\u00f3gicos o moleculares como secuencias de ADN o prote\u00edna. Una filogenia, es un \u00e1rbol (filogen\u00e9tico, claro) que describe la secuencia de eventos que llev\u00f3 a la distribuci\u00f3n de caracteres que observamos en la actualidad. Pero la secuencia de eventos y los eventos del pasado son desconocidos, es decir, se infieren. Por lo tanto, un \u00e1rbol filogen\u00e9tico es una hip\u00f3tesis evolutiva Los \u00e1rboles filogen\u00e9ticos est\u00e1n compuestos por: Ramas (o ejes) y Nodos . Ambos pueden ser internos o externos . Los nodos externos (hojas del \u00e1rbol o terminales) son las secuencias o especies actuales (o eventos observados) a partir de las cuales se construy\u00f3 el \u00e1rbol. Los nodos internos son las secuencias o especies ancestrales inferidas. Corresponden al \u00faltimo ancestro com\u00fan hipot\u00e9tico de todo lo que est\u00e1 debajo de \u00e9l, es decir de los descendientes. Los nodos internos son los puntos en los cuales dos o m\u00e1s ramas divergen. Por \u00faltimo, las ramas conectan nodos ancestrales con sus descendientes. Los \u00e1rboles pueden representarse de diversas maneras. Seg\u00fan el significado de la longitud de la rama podemos distinguir entre: el cladograma , donde cada rama representa \u00fanicamente la transici\u00f3n evolutiva entre un nodo ancestral y sus descendientes independientemente de la longitud. La longitud de la rama no corresponde con informaci\u00f3n alguna m\u00e1s all\u00e1 de los agrupamientos. el filograma , donde la longitud de cada rama es proporcional al n\u00famero de cambios que existe entre un ancestro y sus descendientes, calculada a partir de la similitud entre los nodos que conectan. Por lo tanto, mientras m\u00e1s largas son las ramas mayor es la divergencia entre eventos que une. Por \u00faltimo, los \u00e1rboles pueden poseer ra\u00edz ( Rooted ) o no poseer ra\u00edz ( Unrooted ). La ra\u00edz es el punto m\u00e1s antiguo del \u00e1rbol y marca el orden de ramificaci\u00f3n del mismo, es decir, qui\u00e9n comparte un ancestro m\u00e1s reciente con qui\u00e9n. La forma m\u00e1s frecuente de ubicar la ra\u00edz del \u00e1rbol es a trav\u00e9s de un outgroup : un punto externo de referencia. Un outgroup puede ser cualquier secuencia que no sea un miembro natural del grupo de inter\u00e9s. Cuando uno no cuenta con un elemento que pueda usarse como referencia, la ra\u00edz suele ubicarse en el medio del \u00e1rbol, o aun mejor, no se coloca en ning\u00fan lado. Ejercicios: Paso por paso hacia un \u00e1rbol Paso 1. Construcci\u00f3n del dataset: Recolecci\u00f3n de datos Un \u00e1rbol filogen\u00e9tico se construye a partir de un alineamiento m\u00faltiple que a su vez debe calcularse a partir de un conjunto de secuencias representativas. La topolog\u00eda de el o los \u00e1rboles resultantes va a depender mucho de la cantidad y calidad de los datos que utilicemos. Tener en cuenta: Generalmente la mayor cantidad de tiempo y esfuerzo se invierten en este paso ya que un set de datos ruidoso puede llevarnos a resultados err\u00f3neos y por lo tanto a conclusiones inv\u00e1lidas. Recolecci\u00f3n de secuencias: En la pr\u00e1ctica, la obtenci\u00f3n de secuencias puede realizarse como ya se vi\u00f3 en este curso, utilizando herramientas como PSI-BLAST para identificar secuencias hom\u00f3logas distantes y evitar aquellas que comparten similitud de secuencia pero no estructura/funci\u00f3n. Curaci\u00f3n: Las secuencias recolectadas luego deben ser sometidas a una meticulosa curaci\u00f3n, donde se eliminan secuencias redundantes, incompletas o con errores detectables. Incluso pueden realizarse pasos de modelado de estructura para validar la pertinencia de las mol\u00e9culas al grupo de prote\u00ednas que se desea utilizar. Atenci\u00f3n: En este trabajo pr\u00e1ctico, por cuestiones de tiempo, se les entrega un conjunto de secuencias seleccionadas y curadas. Pero... tengan presente a la hora de hacer sus propias filogenias que se debe prestar m\u00e1xima atenci\u00f3n al acondicionamiento de los datos . Se utilizar\u00e1n las secuencias contenidas en el archivo Ribonucleasas.fasta cuyos datos asociados pueden encontrarlos en el Ribonucleasas_organismos.pdf . En el archivo multiFASTA contiene 64 secuencias proteicas de ribonucleasas pancre\u00e1ticas de diversos animales. Si observan el archivo Ribonucleasas_organismos.pdf pueden ver que todas pertenecen a mam\u00edferos placentarios, excepto por nuestro viejo amigo el canguro, que como despist\u00f3 a m\u00e1s de uno en el trabajo pr\u00e1ctico de Alineamientos se gan\u00f3 su lugar. Paso 2. Construcci\u00f3n y Curaci\u00f3n del Alineamiento m\u00faltiple Para este paso se utilizar\u00e1 la herramienta de EMBOSS del trabajo pr\u00e1ctico anterior: emma Por si no recuerdan, emma utiliza los siguientes argumentos: -sequence : Se indica la ENTRADA que es un archivo multiFASTA -outseq : Se guarda una de las dos SALIDAS. En este caso, el nombre del archivo donde se guardar\u00e1n las secuencias con los gaps incluidos para su debido alineamiento. -dendoutfile : Se guarda la segunda de las dos SALIDAS. En este caso, el nombre del archivo donde se guarda un dendograma que sirve de gu\u00eda para el alineamiento. emma -sequence Ribonucleasas.fasta -dendoutfile Ribonucleasas.dend -outseq Ribonucleasas.msa Recordatorio instalaci\u00f3n de ClustalW Recuerden que emma utiliza clustalw . En el TP de alineamientos ya fue instalado pero si tuvieran que instalarlo, pueden hacerlo ingresando: sudo apt-get install clustalw Inspeccionen el archivo Ribonucleasas.msa y respondan: 2.1. \u00bfQu\u00e9 diferencia principal se ve en este archivo comparado con el archivo Ribonucleasas.fasta ? 2.2. Este archivo, \u00bfPermite visualizar r\u00e1pidamente si hay regiones conservadas o con muchos gaps a simple vista? \u00bfRecord\u00e1s el comando necesario para una mejor visualizaci\u00f3n? Clicke\u00e1 para ver el comando Para una mejor visualizaci\u00f3n se puede utilizar el comando showalign que ya hemos utilizado anteriormente con la opci\u00f3n -show A para que no reemplace las bases conservadas por puntos: showalign -show A -sequence Ribonucleasas.msa -outfile Ribonucleasas.showalign less Ribonucleasas.showalign La premisa b\u00e1sica de los alineamientos m\u00faltiples es que, en cada columna del alineamiento, cada residuo de cada secuencia sea hom\u00f3logo; osea, ha evolucionado de la misma posici\u00f3n en un ancestro com\u00fan. Cuando esto se cumple, se puede obtener much\u00edsima informaci\u00f3n de un alineamiento m\u00faltiple sobre estructura, funci\u00f3n, modo de evoluci\u00f3n y, por supuesto, filogenia. Sin embargo, las conclusiones a las que lleguemos van a depender mucho de la calidad del alineamiento m\u00faltiple. Es muy importante revisar los alineamientos Un alineamiento m\u00faltiple de mala calidad en el mejor de los casos no nos va a dar informaci\u00f3n \u00fatil, pero... en el peor de los casos nos va a dar informaci\u00f3n err\u00f3nea muy convincente. Por esta raz\u00f3n es muy importante revisar los alineamientos m\u00faltiples (es decir, curarlos). Los algoritmos de alineamiento utilizan heur\u00edsticas y aproximaciones que pueden (y suelen) dar lugar a errores. Por ello muchas veces (o siempre) es necesario curar manualmente los alineamientos, eliminando o agregando gaps . Tambi\u00e9n se puede recurrir a la eliminaci\u00f3n de columnas completas si contienen una gran mayor\u00eda de gaps o hay dudas sobre su veracidad. En muchos casos, es mejor eliminar estos eventos para deshacernos del ruido. Dado que el curado de un alineamiento para filogen\u00e9tica es un proceso cr\u00edtico y muy \"visual\", existen herramientas m\u00e1s apropiadas (y vistosas) para esta tarea que showalign . El visualizador de alineamientos a utilizar se llama Jalview. Jalview requiere la instalaci\u00f3n de la versi\u00f3n 8 de java. Para instalar ejecute en su terminal: sudo apt install openjdk-8-jdk openjdk-8-jre sudo update-java-alternatives --set /usr/lib/jvm/java-1.8.0-openjdk-i386 Preferentemente desde una nueva terminal, pueden ejecutar Jalview: cd ~/Tools/Jalview bash jalview.sh Cuando abren el programa hay algunas ventanas abiertas. Cierren todo. Adem\u00e1s ignoren la \"barra de avance\" que se encuentra en la parte inferior de la ventana. Una vez abierto el programa, carguen el alineamiento generado por emma ( Ribonucleasas.msa ) haciendo click en: Archivo > Alineamiento de entrada > Desde fichero . Esto abrir\u00e1 una ventana en la que se puede buscar el archivo yendo a la carpeta de trabajo. Atenci\u00f3n Por defecto, Jalview NO ve el archivo. Aseg\u00farense de seleccionar TODOS LOS ARCHIVOS en el men\u00fa desplegable de Archivos de Tipo Para colorear el alineamiento vayan a: Color > ClustalX 2.3. Revisen su alineamiento con Jalview para ver si hay errores o posiciones dudosas y, en caso de encontrarlos, corr\u00edjanlos en Ribonucleasas.msa y guarden en Ribonucleasas.curado.msa ! Eliminar columnas En la parte superior pueden seleccionar columnas del alineamiento y luego presionan delete para eliminarlas. Paso 3. Construcci\u00f3n del \u00c1rbol Los m\u00e9todos para llevar a cabo la filogenia se pueden separar en dos categor\u00edas generales: M\u00e9todos basados en distancia , tambi\u00e9n conocidos como de clustering o algor\u00edtmicos: UPGMA, neighbour-joining, Fitch\u2013Margoliash. M\u00e9todos de b\u00fasqueda de \u00e1rboles o discretos: m\u00e1xima parsimonia, maximum likelihood (m\u00e1xima verosimilitud), m\u00e9todos bayesianos. Parte I. M\u00e9todos basados en distancias: Neighbor Joining y UPGMA El funcionamiento de estos es relativamente sencillo. Se cuenta con un solo par\u00e1metro: la distancia, que se calcula entre todos los elementos con los que vamos a construir el \u00e1rbol (OTUs por sus siglas en ingl\u00e9s: Operational Taxonomic Unit ), el cual es utilizado para ensamblar el \u00e1rbol agrupando elementos cercanos. M\u00e9todo Neighbor-Joining. Este m\u00e9todo se puede utilizar usando el comando fneighbor . Pero debemos instalarlo: sudo apt install embassy-phylip Este comando construye un \u00e1rbol a partir de una matriz de distancias, haciendo clustering de sus elementos, utilizando los valores de la matriz para calcular el largo de las ramas. El \u00e1rbol resultante es un \u00e1rbol sin ra\u00edz , lo que quiere decir es que las distancias son relativas entre los miembros y no hay informaci\u00f3n sobre qu\u00e9 evento se produjo primero (no hay un reloj evolutivo). Para poder calcular el \u00e1rbol primero es necesario obtener la matriz de distancias, mediante el comando fprotdist . Este comando utiliza uno de cinco m\u00e9todos para calcular las distancias: PAM: Utiliza una matriz PAM 001. La matriz PAM es una matriz de sustituci\u00f3n obtenida emp\u00edricamente. El n\u00famero 001 indica que las secuencias con las que se construy\u00f3 tienen una tasa de mutaci\u00f3n esperada del 1% ( -method d ). JTT: Nombrado por sus creadores, Jones, Taylor y Thornton, se basa en el mismo concepto que el m\u00e9todo PAM, solo que la matriz de sustituci\u00f3n fue creada con un set de datos mucho m\u00e1s grande ( -method j ). PBM: Las matrices de este modelo derivan de la base de datos Blocks que contiene secuencias de dominios conservados ( -method h ). Kimura Formula : Una aproximaci\u00f3n precalculada de la matriz PAM, lo que ofrece un c\u00e1lculo m\u00e1s veloz sacrificando specificidad ( -method k ). Similarity Table : Una proyecci\u00f3n de distancias en la que se asume que los amino\u00e1cidos var\u00edan seg\u00fan un caso particular de la f\u00f3rmula de Kimura ( -method s ). Los tres primeros (PAM, JTT y PBM) son los m\u00e1s ampliamente utilizados. Mirando el nombre del comando fprotdist y leyendo los m\u00e9todos que utiliza este comando conteste: \u00bfSe utiliza para construir la matriz a partir de un alineamiento de prote\u00ednas o secuencias de ADN? Despu\u00e9s de contestar la pregunta anterior \u00bfC\u00f3mo cree que se llama el comando para construir la matriz a partir de secuencias de ADN? \u00bfCree que utiliza los mismos m\u00e9todos que el comando utiliza para prote\u00ednas? Chequee su respuesta en EMBOSS !!!! 3.I.1 Construya la matriz de distancia utilizando el m\u00e9todo JTT: fprotdist -method j -sequence Ribonucleasas.curado.msa -outfile Ribonucleasas.dist 3.I.2 \u00bfQu\u00e9 son los siguientes par\u00e1metros del comando? -sequence -outfile Ahora si, con las distancias calculadas se puede comenzar a agrupar. fneighbor -datafile Ribonucleasas.dist -outfile Ribonucleasas-NJ.tree -outtreefile Ribonucleasas-NJ.treefile 3.I.3 Investiguen los archivos Ribonucleasas.tree y Ribonucleasas.treefile y respondan: a. \u00bfQu\u00e9 informaci\u00f3n tiene Ribonucleasas-NJ.tree ? b. \u00bfQu\u00e9 les parece que contiene Ribonucleasas-NJ.treefile ? \u00bfC\u00f3mo se conoce este formato? \u00bfPor qu\u00e9 cree que es conveniente la creaci\u00f3n de este archivo? Si bien uno puede ver \u00e1rboles dibujados en ascii en los archivos .tree hay formas m\u00e1s armoniosas para ver un \u00e1rbol. Por lo tanto, vamos a instalar el programa: figtree sudo apt install figtree Para utilizar el programa figtree , en la terminal, ub\u00edquese en la carpeta donde tiene el archivo .treefile e ingrese: figtree Ribonucleasas-NJ.treefile Para guardar la imagen y poder verla en detalle tienen que ir a: File > Export PDF Explore las distintas opciones de representaci\u00f3n de \u00e1rboles y grafique los \u00e1rboles como le parezca m\u00e1s correcto En FigTree se puede seleccionar a nivel de nodos, clados y taxas (nombres de las hojas del \u00e1rbol) y colorear de distintas maneras. Todo lo realizado con FigTree se puede guardar en un archivo nuevo para seguir trabajando luego o modificar una representaci\u00f3n de \u00e1rbol yendo a: File > Save as... 3.I.4 Observen la topolog\u00eda del \u00e1rbol a diferentes niveles e identifiquen diferentes \u00f3rdenes. \u00bfTiene sentido el agrupamiento que se realiz\u00f3? Regla mnemot\u00e9cnica para Taxonom\u00eda Si a\u00fan no vieron taxonom\u00eda o si no recuerdan lo que es un Orden... \"Lineo dijo que el Rey ( Reino ) era un tipo ( phylo ) con mucha Clase que puso Orden en su Familia comprando un G\u00e9nero de cada Especie \" 3.I.5 Hay algunos OTUs que no parecen estar bien ubicados. \u00bfCu\u00e1les son? \u00bfQu\u00e9 puede estar pasando? M\u00e9todo UPGMA. La manera de generar el \u00e1rbol por el m\u00e9todo UPGMA es esencialmente la misma que Neighbor-Joining , ir agrupando los pares de elementos con la menor distancia. La diferencia radica en c\u00f3mo se calculan las distancias una vez que se empiezan a generar grupos. Neighbor-Joining utiliza una metodolog\u00eda un tanto compleja que pueden encontrar explicada ac\u00e1 UPGMA usa un average linking pesado por la cantidad de secuencias que componen cada grupo. Para construir un \u00e1rbol con UPGMA corremos el comando fneighbor pero con la opci\u00f3n -treetype u : fneighbor -treetype u -datafile Ribonucleasas.dist -outfile Ribonucleasas-UPGMA.tree -outtreefile Ribonucleasas-UPGMA.treefile 3.I.6 Comparen el \u00e1rbol obtenido por Neighbor-Joining y por UPGMA . a. \u00bfHay cambios en las agrupaciones? b. Grafiquen los resultados de ambos m\u00e9todos. Se ven diferentes \u00bfno? Investigue las razones. Parte II. M\u00e9todos de b\u00fasqueda de \u00e1rboles: M\u00e1xima Verosimilitud y M\u00e1xima Parsimonia Los m\u00e9todos de b\u00fasqueda de \u00e1rboles examinan cada columna del MSA de manera individual y buscan un \u00e1rbol que mejor represente esta informaci\u00f3n. Este procedimiento los vuelve mas lentos que los m\u00e9todos basados en distancia, pero examinar cada posici\u00f3n por separado da un \u00e1rbol m\u00e1s acertado y brinda la posibilidad de relacionar los eventos a cada una de las posiciones. En este caso NO va a ser necesario calcular una matriz de distancias, podemos ejecutar el m\u00e9todo directamente sobre el alineamiento. M\u00e9todo de M\u00e1xima Verosimilitud Para utilizar M\u00e1xima Verosimilitud ( maximum likelihood ) se usa el comando fproml . Los argumentos de este comando son: -sequence : Indica el MSA de entrada -oufile : Indica donde guardar la salida -intrefile (opcional), \u00c1rbol para usar de gu\u00eda. No se utilizar\u00e1 en este caso, pero lo va a preguntar igual, en ese caso se aprieta Enter . fproml -seed 1 -sequence Ribonucleasas.curado.msa -outfile Ribonucleasas-ML.tree -outtreefile Ribonucleasas-ML.treefile \u00bfQu\u00e9 es Seed? Adem\u00e1s de los argumentos m\u00ednimos, se utiliz\u00f3 el argumento -seed . Esto es una buena pr\u00e1ctica para que el experimento sea reproducible . En computaci\u00f3n, lo que se llama random (por azar) en realidad no lo es. Para obtener n\u00fameros cuya distribuci\u00f3n se acerque a la aleatoria se aplica una serie de f\u00f3rmulas que dan un resultado dependiendo del n\u00famero del cual se parte. Este valor es la semilla (seed). Por lo general se utiliza como semilla el tiempo, el cual cambia constantemente, pero nosotros podemos fijar esa semilla , para que otras personas, o nosotros mismos en alg\u00fan futuro, podamos correr nuestros comandos y obtener exactamente los mismos resultados. 3.II.1 Observen e interpreten la salida obtenida. \u00bfHubo cambios radicales con respecto a los \u00e1rboles anteriores?. 3.II.2 \u00bfCon qu\u00e9 nueva informaci\u00f3n contamos? Mirando el nombre del comando fproml conteste: \u00bfSe utiliza con secuencias de prote\u00ednas o de ADN? La forma correcta de sacarnos nuestra duda es corriendo: tfm fproml Despu\u00e9s de contestar la pregunta anterior \u00bfC\u00f3mo cree que se llama el comando para utilizar el m\u00e9todo maximum likelihood con secuencias de ADN? \u00bfCree que utiliza los mismos m\u00e9todos que el comando utiliza para prote\u00ednas? Chequee su respuesta en EMBOSS !!!! Uso de Outgroups Hasta ahora se generaron \u00e1rboles sin raiz , donde las distancias entre los OTUs son relativas. Para colocar una ra\u00edz se utiliza un OTU que se sabe a priori que divergi\u00f3 antes que el resto, as\u00ed se obtiene una referencia a partir de la cual construir el \u00e1rbol. \u00a1Aprovechemos que tenemos a un intruso! El set de secuencias est\u00e1 compuesto casi en su totalidad por mam\u00edferos placentarios, excepto por el canguro rojo. Su aparici\u00f3n no es casualidad ya que como miembro de otra infraclase sirve de referencia para proponer una ra\u00edz al \u00e1rbol. Para ello se utiliza el argumento -outgrno , que recibe el n\u00famero del organismo a utilizar como referencia. Este n\u00famero esta dado por la posici\u00f3n de la secuencia en el alineamiento m\u00faltiple. Para averiguar que n\u00famero es hay dos opciones: Contar a mano Correr un comando Contar a mano puede llevar a errores, y dado que esto es bioinform\u00e1tica, se utilizar\u00e1 el siguiente comando: cat Ribonucleasas.curado.msa | grep \">\" | grep -n \"Macropus\" La salida se ver\u00e1 similar a esta: 45:>Macropus_rufus . La secuencia en el alineamiento en este caso est\u00e1 en la posici\u00f3n 45 pero este n\u00famero puede cambiar seg\u00fan el usuario. Una vez obtenido este valor se vuelve a correr fproml fproml -outgrno 45 -seed 1 -sequence Ribonucleasas.curado.msa -outfile Ribonucleasas-ML-OUTGR.tree -outtreefile Ribonucleasas-ML-OUTGR.treefile Ventaja del M\u00e9todo de Maximum Likelihood ML utiliza un modelo de Markov para estimar las tasas de cambio de las diferentes posiciones y as\u00ed poder hacer c\u00e1lculos m\u00e1s precisos. Esto se debe a que no todas las posiciones var\u00edan con la misma frecuencia. Posiciones importantes para la estructura/funci\u00f3n de la prote\u00edna, por ejemplo el sitio activo de una enzima, tienden a variar mucho menos que el resto y esto debe ser tenido en cuenta a la hora de construir la filogenia. M\u00e9todo de M\u00e1xima Parsimonia Genere el \u00e1rbol utilizando m\u00e1xima parsimonia con el comando fprotpars , utilice -help para ver qu\u00e9 argumentos recibe. Responda: 3.II.3 \u00bfQu\u00e9 informaci\u00f3n nos da este m\u00e9todo? 3.II.4 \u00bfCu\u00e1ntos \u00e1rboles nos devuelve? \u00bfPor qu\u00e9? Paso 4. Tests \u2013 Seleccionar \u00e1rboles en el bosque Entonces, \u00bfqu\u00e9 tan bueno es nuestro \u00e1rbol? Uno de los test m\u00e1s simples para medir la veracidad del \u00e1rbol es el bootstrap . Hoy en d\u00eda ser\u00eda muy raro encontrar un \u00e1rbol filogen\u00e9tico que no lo haya utilizado. El bootstrap esencialmente prueba si todo el set de datos est\u00e1 de acuerdo con el \u00e1rbol resultante, o si dicho \u00e1rbol es un outlier entre varias otras posibilidades. Esto se hace tomando muestras aleatorias de nuestro set de datos, armando varios \u00e1rboles y calculando la frecuencia de ocurrencia de cada fragmento del \u00e1rbol. Si un agrupamiento determinado es encontrado en todos los \u00e1rboles, entonces tienen un score de 100%; si solo ocurre en 2/3 de los \u00e1rboles generados el score ser\u00e1 de 67% y as\u00ed. Es importante aclarar que el muestreo se hace a nivel columna del MSA, y no a nivel de secuencia. Nuestro \u00e1rbol va a establecer la relaci\u00f3n entre diferentes secuencias dada la conservaci\u00f3n/mutaci\u00f3n de posiciones hom\u00f3logas y esto es lo que se intenta probar con bootstrap : que cualquier tipo de composici\u00f3n que mantenga esos patrones de conservaci\u00f3n/mutaci\u00f3n va a dar el mismo \u00e1rbol. Por ello, vamos a tener la misma cantidad de secuencias, y del mismo largo, ya que no solo vamos a reordenar las posiciones al azar sino que tambi\u00e9n vamos a quitar y repetir columnas. En la siguiente imagen pueden ver un ejemplo de los resultados de un Bootstrapping Al final de este proceso se obtiene un conjunto de alineamientos. A partir de cada alineamiento se construye un \u00e1rbol. Este test parece sencillo, y estudios en filogenias conocidas (poblaciones virales cultivadas en laboratorio) muestran que es una medida adecuada de la certeza del \u00e1rbol resultante; y que un valor de 70% o m\u00e1s suele indicar un agrupamiento adecuado. Para generar el conjunto de alineamientos se utiliza el comando fseqboot los argumentos son -sequence (datos de ENTRADA), -outfile (datos de SALIDA) y -reps : fseqboot -reps 10 -sequence Ribonucleasas.curado.msa -outfile Ribonucleasas.boot En este comando falta algo muy importante! \u00bfLo ven? Falta el seed !!! fseqboot -reps 10 -seed 1 -sequence Ribonucleasas.curado.msa -outfile Ribonucleasas.boot -reps indica el n\u00famero de remuestreos a realizar. Calcular varios \u00e1rboles puede llevar bastante tiempo por lo que solo se har\u00e1n 10 repeticiones. En un t\u00edpico ensayo se realizan muchas m\u00e1s repeticiones. Exploren el archivo Ribonucleasas.boot . Hay varios MSA correspondientes al resmuestreo, con posiciones faltantes, repetidas y en distinto orden que el MSA original. Este archivo se utilizar\u00e1 para llevar a cabo numerosos \u00e1rboles filogen\u00e9ticos: fproml -seed 1 -sequence Ribonucleasas.boot -outfile Ribonucleasas-ML-BOOT.tree -outtreefile Ribonucleasas-ML-BOOT.treefile Esto puede tardar un rato, podr\u00eda ser un buen momento para preparar un mate... El archivo de salida Ribonucleasas-ML-BOOT.tree contiene todos los \u00e1rboles resultantes de todos nuestros muestreos. Al ser tantos, uno puede ver las diferentes topolog\u00edas creadas, sin embargo es muy dif\u00edcil sacar conclusiones. Para poder utilizar toda la informaci\u00f3n de estas numerosas r\u00e9plicas vamos a unirlas con el comando fconsense . Este toma como entrada el archivo .treefile que contiene todos los \u00e1rboles en formato Phyllip y los va a condensar en uno solo, anotando a cada rama la cantidad de veces que esta fue hallada en nuestros muestreo. fconsense -intreefile Ribonucleasas-ML-BOOT.treefile -outfile Ribonucleasas-CONS.tree -outtreefile Ribonucleasas-CONS.treefile 3.II.5 Un buen ejercicio antes de copiar y pegar un comando es ENTENDER que es cada argumento del comando. \u00bfQue hace cada argumento? -intreefile -outfile -outtreefile Observando el \u00e1rbol consenso. Responda: 3.II.6 \u00bfResulta ser un buen \u00e1rbol? \u00bfEn qu\u00e9 se basan para afirmarlo? 3.II.7 \u00bfC\u00f3mo podr\u00edan lidiar con nodos de baja calidad? Paso 5. Presentaci\u00f3n de resultados Finalmente algunos conceptos en cuanto a la presentaci\u00f3n de los datos. Por lo general no hay reglas duras de c\u00f3mo debe hacerse pero s\u00ed convenciones que est\u00e1n bastante aceptadas. En \u00e1rboles de filogenia molecular, los largos de las ramas suelen dibujarse a escala; esto es, proporcional a la cantidad de evoluci\u00f3n que se estima ocurri\u00f3 entre los nodos que conecta. A pesar de que la relaci\u00f3n entre el largo de la rama y el tiempo real no es directa y muy probablemente no es confiable, los largos dan una idea general de las tasa de cambio relativas del \u00e1rbol. Los valores de Bootstrap deben ser presentados en forma de porcentajes, no de valores crudos, para que sea m\u00e1s sencillo de leer y comparar con otros \u00e1rboles. Por convenci\u00f3n, s\u00f3lo valores de Bootstrap del 50% o mayores son reportados; valores menores significan que la calidad del nodo encontrado es muy baja. Por \u00faltimo, tengan en cuenta la legibilidad del \u00e1rbol en general. Utilizar nombres para las ramas con c\u00f3digos de acceso a bases de datos o acr\u00f3nimos de pocas letras puede resultar muy confuso. Hoy en d\u00eda existen numerosos softwares para la visualizaci\u00f3n de \u00e1rboles (ej. Hypertree) que nos permiten, mediante agrupamientos, colores, fuentes, etc. llamar la atenci\u00f3n del lector sobre uno u otro aspecto importante del mismo y lograr que transmita la informaci\u00f3n que nos interesa mostrar.","title":"TP 6 - Filogenias"},{"location":"practicos/TP06_Filogenia/#tp-6-filogenias-arboles-filogeneticos-y-filogenomica","text":"Materiales","title":"TP 6. Filogenias, \u00e1rboles filogen\u00e9ticos y filogen\u00f3mica"},{"location":"practicos/TP06_Filogenia/#videos-de-la-clase-grabada","text":"Introducci\u00f3n al TP Cierre TP","title":"Videos de la clase grabada"},{"location":"practicos/TP06_Filogenia/#software-a-usar","text":"Alineamientos: emma y clustalw (en EMBOSS suite) Visualizaci\u00f3n de alineamientos: Jalview www.jalview.org M\u00e9todos basados en distancias: fprotdist (en EMBOSS suite) fneighbor (en EMBOSS suite) M\u00e9todos de b\u00fasqueda de \u00e1rboles: fproml (en EMBOSS suite) fprotpars (en EMBOSS suite) Visualizaci\u00f3n de \u00e1rboles: FigTree tree.bio.ed.ac.uk/software/figtree/ Remuestreo y \u00e1rbol consenso: fseqboot (en EMBOSS suite) fconsense (en EMBOSS suite)","title":"Software a usar"},{"location":"practicos/TP06_Filogenia/#objetivos","text":"Familiarizarse con el uso de \u00e1rboles filogen\u00e9ticos Entender como leer \u00e1rboles simples Entender las distintas representaciones de \u00e1rboles filogen\u00e9ticos Entender las diferenicias entre los distintos algoritmos para la construcci\u00f3n de \u00e1rboles filogen\u00e9ticos","title":"Objetivos"},{"location":"practicos/TP06_Filogenia/#filogenia","text":"La filogen\u00e9tica es la ciencia que estudia las relaciones evolutivas entre entidades biol\u00f3gicas, frecuentemente especies, individuos, genes o prote\u00ednas. Es decir, que estima el pasado evolutivo basado en la comparaci\u00f3n de caracteres morfol\u00f3gicos o moleculares como secuencias de ADN o prote\u00edna. Una filogenia, es un \u00e1rbol (filogen\u00e9tico, claro) que describe la secuencia de eventos que llev\u00f3 a la distribuci\u00f3n de caracteres que observamos en la actualidad. Pero la secuencia de eventos y los eventos del pasado son desconocidos, es decir, se infieren. Por lo tanto, un \u00e1rbol filogen\u00e9tico es una hip\u00f3tesis evolutiva Los \u00e1rboles filogen\u00e9ticos est\u00e1n compuestos por: Ramas (o ejes) y Nodos . Ambos pueden ser internos o externos . Los nodos externos (hojas del \u00e1rbol o terminales) son las secuencias o especies actuales (o eventos observados) a partir de las cuales se construy\u00f3 el \u00e1rbol. Los nodos internos son las secuencias o especies ancestrales inferidas. Corresponden al \u00faltimo ancestro com\u00fan hipot\u00e9tico de todo lo que est\u00e1 debajo de \u00e9l, es decir de los descendientes. Los nodos internos son los puntos en los cuales dos o m\u00e1s ramas divergen. Por \u00faltimo, las ramas conectan nodos ancestrales con sus descendientes. Los \u00e1rboles pueden representarse de diversas maneras. Seg\u00fan el significado de la longitud de la rama podemos distinguir entre: el cladograma , donde cada rama representa \u00fanicamente la transici\u00f3n evolutiva entre un nodo ancestral y sus descendientes independientemente de la longitud. La longitud de la rama no corresponde con informaci\u00f3n alguna m\u00e1s all\u00e1 de los agrupamientos. el filograma , donde la longitud de cada rama es proporcional al n\u00famero de cambios que existe entre un ancestro y sus descendientes, calculada a partir de la similitud entre los nodos que conectan. Por lo tanto, mientras m\u00e1s largas son las ramas mayor es la divergencia entre eventos que une. Por \u00faltimo, los \u00e1rboles pueden poseer ra\u00edz ( Rooted ) o no poseer ra\u00edz ( Unrooted ). La ra\u00edz es el punto m\u00e1s antiguo del \u00e1rbol y marca el orden de ramificaci\u00f3n del mismo, es decir, qui\u00e9n comparte un ancestro m\u00e1s reciente con qui\u00e9n. La forma m\u00e1s frecuente de ubicar la ra\u00edz del \u00e1rbol es a trav\u00e9s de un outgroup : un punto externo de referencia. Un outgroup puede ser cualquier secuencia que no sea un miembro natural del grupo de inter\u00e9s. Cuando uno no cuenta con un elemento que pueda usarse como referencia, la ra\u00edz suele ubicarse en el medio del \u00e1rbol, o aun mejor, no se coloca en ning\u00fan lado.","title":"Filogenia"},{"location":"practicos/TP06_Filogenia/#ejercicios-paso-por-paso-hacia-un-arbol","text":"","title":"Ejercicios"},{"location":"practicos/TP06_Filogenia/#paso-1-construccion-del-dataset-recoleccion-de-datos","text":"Un \u00e1rbol filogen\u00e9tico se construye a partir de un alineamiento m\u00faltiple que a su vez debe calcularse a partir de un conjunto de secuencias representativas. La topolog\u00eda de el o los \u00e1rboles resultantes va a depender mucho de la cantidad y calidad de los datos que utilicemos. Tener en cuenta: Generalmente la mayor cantidad de tiempo y esfuerzo se invierten en este paso ya que un set de datos ruidoso puede llevarnos a resultados err\u00f3neos y por lo tanto a conclusiones inv\u00e1lidas. Recolecci\u00f3n de secuencias: En la pr\u00e1ctica, la obtenci\u00f3n de secuencias puede realizarse como ya se vi\u00f3 en este curso, utilizando herramientas como PSI-BLAST para identificar secuencias hom\u00f3logas distantes y evitar aquellas que comparten similitud de secuencia pero no estructura/funci\u00f3n. Curaci\u00f3n: Las secuencias recolectadas luego deben ser sometidas a una meticulosa curaci\u00f3n, donde se eliminan secuencias redundantes, incompletas o con errores detectables. Incluso pueden realizarse pasos de modelado de estructura para validar la pertinencia de las mol\u00e9culas al grupo de prote\u00ednas que se desea utilizar. Atenci\u00f3n: En este trabajo pr\u00e1ctico, por cuestiones de tiempo, se les entrega un conjunto de secuencias seleccionadas y curadas. Pero... tengan presente a la hora de hacer sus propias filogenias que se debe prestar m\u00e1xima atenci\u00f3n al acondicionamiento de los datos . Se utilizar\u00e1n las secuencias contenidas en el archivo Ribonucleasas.fasta cuyos datos asociados pueden encontrarlos en el Ribonucleasas_organismos.pdf . En el archivo multiFASTA contiene 64 secuencias proteicas de ribonucleasas pancre\u00e1ticas de diversos animales. Si observan el archivo Ribonucleasas_organismos.pdf pueden ver que todas pertenecen a mam\u00edferos placentarios, excepto por nuestro viejo amigo el canguro, que como despist\u00f3 a m\u00e1s de uno en el trabajo pr\u00e1ctico de Alineamientos se gan\u00f3 su lugar.","title":"Paso 1 - Recolecci\u00f3n de datos"},{"location":"practicos/TP06_Filogenia/#paso-2-construccion-y-curacion-del-alineamiento-multiple","text":"Para este paso se utilizar\u00e1 la herramienta de EMBOSS del trabajo pr\u00e1ctico anterior: emma Por si no recuerdan, emma utiliza los siguientes argumentos: -sequence : Se indica la ENTRADA que es un archivo multiFASTA -outseq : Se guarda una de las dos SALIDAS. En este caso, el nombre del archivo donde se guardar\u00e1n las secuencias con los gaps incluidos para su debido alineamiento. -dendoutfile : Se guarda la segunda de las dos SALIDAS. En este caso, el nombre del archivo donde se guarda un dendograma que sirve de gu\u00eda para el alineamiento. emma -sequence Ribonucleasas.fasta -dendoutfile Ribonucleasas.dend -outseq Ribonucleasas.msa Recordatorio instalaci\u00f3n de ClustalW Recuerden que emma utiliza clustalw . En el TP de alineamientos ya fue instalado pero si tuvieran que instalarlo, pueden hacerlo ingresando: sudo apt-get install clustalw Inspeccionen el archivo Ribonucleasas.msa y respondan: 2.1. \u00bfQu\u00e9 diferencia principal se ve en este archivo comparado con el archivo Ribonucleasas.fasta ? 2.2. Este archivo, \u00bfPermite visualizar r\u00e1pidamente si hay regiones conservadas o con muchos gaps a simple vista? \u00bfRecord\u00e1s el comando necesario para una mejor visualizaci\u00f3n? Clicke\u00e1 para ver el comando Para una mejor visualizaci\u00f3n se puede utilizar el comando showalign que ya hemos utilizado anteriormente con la opci\u00f3n -show A para que no reemplace las bases conservadas por puntos: showalign -show A -sequence Ribonucleasas.msa -outfile Ribonucleasas.showalign less Ribonucleasas.showalign La premisa b\u00e1sica de los alineamientos m\u00faltiples es que, en cada columna del alineamiento, cada residuo de cada secuencia sea hom\u00f3logo; osea, ha evolucionado de la misma posici\u00f3n en un ancestro com\u00fan. Cuando esto se cumple, se puede obtener much\u00edsima informaci\u00f3n de un alineamiento m\u00faltiple sobre estructura, funci\u00f3n, modo de evoluci\u00f3n y, por supuesto, filogenia. Sin embargo, las conclusiones a las que lleguemos van a depender mucho de la calidad del alineamiento m\u00faltiple. Es muy importante revisar los alineamientos Un alineamiento m\u00faltiple de mala calidad en el mejor de los casos no nos va a dar informaci\u00f3n \u00fatil, pero... en el peor de los casos nos va a dar informaci\u00f3n err\u00f3nea muy convincente. Por esta raz\u00f3n es muy importante revisar los alineamientos m\u00faltiples (es decir, curarlos). Los algoritmos de alineamiento utilizan heur\u00edsticas y aproximaciones que pueden (y suelen) dar lugar a errores. Por ello muchas veces (o siempre) es necesario curar manualmente los alineamientos, eliminando o agregando gaps . Tambi\u00e9n se puede recurrir a la eliminaci\u00f3n de columnas completas si contienen una gran mayor\u00eda de gaps o hay dudas sobre su veracidad. En muchos casos, es mejor eliminar estos eventos para deshacernos del ruido. Dado que el curado de un alineamiento para filogen\u00e9tica es un proceso cr\u00edtico y muy \"visual\", existen herramientas m\u00e1s apropiadas (y vistosas) para esta tarea que showalign . El visualizador de alineamientos a utilizar se llama Jalview. Jalview requiere la instalaci\u00f3n de la versi\u00f3n 8 de java. Para instalar ejecute en su terminal: sudo apt install openjdk-8-jdk openjdk-8-jre sudo update-java-alternatives --set /usr/lib/jvm/java-1.8.0-openjdk-i386 Preferentemente desde una nueva terminal, pueden ejecutar Jalview: cd ~/Tools/Jalview bash jalview.sh Cuando abren el programa hay algunas ventanas abiertas. Cierren todo. Adem\u00e1s ignoren la \"barra de avance\" que se encuentra en la parte inferior de la ventana. Una vez abierto el programa, carguen el alineamiento generado por emma ( Ribonucleasas.msa ) haciendo click en: Archivo > Alineamiento de entrada > Desde fichero . Esto abrir\u00e1 una ventana en la que se puede buscar el archivo yendo a la carpeta de trabajo. Atenci\u00f3n Por defecto, Jalview NO ve el archivo. Aseg\u00farense de seleccionar TODOS LOS ARCHIVOS en el men\u00fa desplegable de Archivos de Tipo Para colorear el alineamiento vayan a: Color > ClustalX 2.3. Revisen su alineamiento con Jalview para ver si hay errores o posiciones dudosas y, en caso de encontrarlos, corr\u00edjanlos en Ribonucleasas.msa y guarden en Ribonucleasas.curado.msa ! Eliminar columnas En la parte superior pueden seleccionar columnas del alineamiento y luego presionan delete para eliminarlas.","title":"Paso 2 - Alineamiento"},{"location":"practicos/TP06_Filogenia/#paso-3-construccion-del-arbol","text":"Los m\u00e9todos para llevar a cabo la filogenia se pueden separar en dos categor\u00edas generales: M\u00e9todos basados en distancia , tambi\u00e9n conocidos como de clustering o algor\u00edtmicos: UPGMA, neighbour-joining, Fitch\u2013Margoliash. M\u00e9todos de b\u00fasqueda de \u00e1rboles o discretos: m\u00e1xima parsimonia, maximum likelihood (m\u00e1xima verosimilitud), m\u00e9todos bayesianos.","title":"Paso 3 - Construcci\u00f3n del \u00c1rbol"},{"location":"practicos/TP06_Filogenia/#parte-i-metodos-basados-en-distancias-neighbor-joining-y-upgma","text":"El funcionamiento de estos es relativamente sencillo. Se cuenta con un solo par\u00e1metro: la distancia, que se calcula entre todos los elementos con los que vamos a construir el \u00e1rbol (OTUs por sus siglas en ingl\u00e9s: Operational Taxonomic Unit ), el cual es utilizado para ensamblar el \u00e1rbol agrupando elementos cercanos.","title":"Parte I - M\u00e9todos basados en distancias"},{"location":"practicos/TP06_Filogenia/#metodo-neighbor-joining","text":"Este m\u00e9todo se puede utilizar usando el comando fneighbor . Pero debemos instalarlo: sudo apt install embassy-phylip Este comando construye un \u00e1rbol a partir de una matriz de distancias, haciendo clustering de sus elementos, utilizando los valores de la matriz para calcular el largo de las ramas. El \u00e1rbol resultante es un \u00e1rbol sin ra\u00edz , lo que quiere decir es que las distancias son relativas entre los miembros y no hay informaci\u00f3n sobre qu\u00e9 evento se produjo primero (no hay un reloj evolutivo). Para poder calcular el \u00e1rbol primero es necesario obtener la matriz de distancias, mediante el comando fprotdist . Este comando utiliza uno de cinco m\u00e9todos para calcular las distancias: PAM: Utiliza una matriz PAM 001. La matriz PAM es una matriz de sustituci\u00f3n obtenida emp\u00edricamente. El n\u00famero 001 indica que las secuencias con las que se construy\u00f3 tienen una tasa de mutaci\u00f3n esperada del 1% ( -method d ). JTT: Nombrado por sus creadores, Jones, Taylor y Thornton, se basa en el mismo concepto que el m\u00e9todo PAM, solo que la matriz de sustituci\u00f3n fue creada con un set de datos mucho m\u00e1s grande ( -method j ). PBM: Las matrices de este modelo derivan de la base de datos Blocks que contiene secuencias de dominios conservados ( -method h ). Kimura Formula : Una aproximaci\u00f3n precalculada de la matriz PAM, lo que ofrece un c\u00e1lculo m\u00e1s veloz sacrificando specificidad ( -method k ). Similarity Table : Una proyecci\u00f3n de distancias en la que se asume que los amino\u00e1cidos var\u00edan seg\u00fan un caso particular de la f\u00f3rmula de Kimura ( -method s ). Los tres primeros (PAM, JTT y PBM) son los m\u00e1s ampliamente utilizados. Mirando el nombre del comando fprotdist y leyendo los m\u00e9todos que utiliza este comando conteste: \u00bfSe utiliza para construir la matriz a partir de un alineamiento de prote\u00ednas o secuencias de ADN? Despu\u00e9s de contestar la pregunta anterior \u00bfC\u00f3mo cree que se llama el comando para construir la matriz a partir de secuencias de ADN? \u00bfCree que utiliza los mismos m\u00e9todos que el comando utiliza para prote\u00ednas? Chequee su respuesta en EMBOSS !!!! 3.I.1 Construya la matriz de distancia utilizando el m\u00e9todo JTT: fprotdist -method j -sequence Ribonucleasas.curado.msa -outfile Ribonucleasas.dist 3.I.2 \u00bfQu\u00e9 son los siguientes par\u00e1metros del comando? -sequence -outfile Ahora si, con las distancias calculadas se puede comenzar a agrupar. fneighbor -datafile Ribonucleasas.dist -outfile Ribonucleasas-NJ.tree -outtreefile Ribonucleasas-NJ.treefile 3.I.3 Investiguen los archivos Ribonucleasas.tree y Ribonucleasas.treefile y respondan: a. \u00bfQu\u00e9 informaci\u00f3n tiene Ribonucleasas-NJ.tree ? b. \u00bfQu\u00e9 les parece que contiene Ribonucleasas-NJ.treefile ? \u00bfC\u00f3mo se conoce este formato? \u00bfPor qu\u00e9 cree que es conveniente la creaci\u00f3n de este archivo? Si bien uno puede ver \u00e1rboles dibujados en ascii en los archivos .tree hay formas m\u00e1s armoniosas para ver un \u00e1rbol. Por lo tanto, vamos a instalar el programa: figtree sudo apt install figtree Para utilizar el programa figtree , en la terminal, ub\u00edquese en la carpeta donde tiene el archivo .treefile e ingrese: figtree Ribonucleasas-NJ.treefile Para guardar la imagen y poder verla en detalle tienen que ir a: File > Export PDF Explore las distintas opciones de representaci\u00f3n de \u00e1rboles y grafique los \u00e1rboles como le parezca m\u00e1s correcto En FigTree se puede seleccionar a nivel de nodos, clados y taxas (nombres de las hojas del \u00e1rbol) y colorear de distintas maneras. Todo lo realizado con FigTree se puede guardar en un archivo nuevo para seguir trabajando luego o modificar una representaci\u00f3n de \u00e1rbol yendo a: File > Save as... 3.I.4 Observen la topolog\u00eda del \u00e1rbol a diferentes niveles e identifiquen diferentes \u00f3rdenes. \u00bfTiene sentido el agrupamiento que se realiz\u00f3? Regla mnemot\u00e9cnica para Taxonom\u00eda Si a\u00fan no vieron taxonom\u00eda o si no recuerdan lo que es un Orden... \"Lineo dijo que el Rey ( Reino ) era un tipo ( phylo ) con mucha Clase que puso Orden en su Familia comprando un G\u00e9nero de cada Especie \" 3.I.5 Hay algunos OTUs que no parecen estar bien ubicados. \u00bfCu\u00e1les son? \u00bfQu\u00e9 puede estar pasando?","title":"M\u00e9todo Neighbor-Joining."},{"location":"practicos/TP06_Filogenia/#metodo-upgma","text":"La manera de generar el \u00e1rbol por el m\u00e9todo UPGMA es esencialmente la misma que Neighbor-Joining , ir agrupando los pares de elementos con la menor distancia. La diferencia radica en c\u00f3mo se calculan las distancias una vez que se empiezan a generar grupos. Neighbor-Joining utiliza una metodolog\u00eda un tanto compleja que pueden encontrar explicada ac\u00e1 UPGMA usa un average linking pesado por la cantidad de secuencias que componen cada grupo. Para construir un \u00e1rbol con UPGMA corremos el comando fneighbor pero con la opci\u00f3n -treetype u : fneighbor -treetype u -datafile Ribonucleasas.dist -outfile Ribonucleasas-UPGMA.tree -outtreefile Ribonucleasas-UPGMA.treefile 3.I.6 Comparen el \u00e1rbol obtenido por Neighbor-Joining y por UPGMA . a. \u00bfHay cambios en las agrupaciones? b. Grafiquen los resultados de ambos m\u00e9todos. Se ven diferentes \u00bfno? Investigue las razones.","title":"M\u00e9todo UPGMA."},{"location":"practicos/TP06_Filogenia/#parte-ii-metodos-de-busqueda-de-arboles-maxima-verosimilitud-y-maxima-parsimonia","text":"Los m\u00e9todos de b\u00fasqueda de \u00e1rboles examinan cada columna del MSA de manera individual y buscan un \u00e1rbol que mejor represente esta informaci\u00f3n. Este procedimiento los vuelve mas lentos que los m\u00e9todos basados en distancia, pero examinar cada posici\u00f3n por separado da un \u00e1rbol m\u00e1s acertado y brinda la posibilidad de relacionar los eventos a cada una de las posiciones. En este caso NO va a ser necesario calcular una matriz de distancias, podemos ejecutar el m\u00e9todo directamente sobre el alineamiento.","title":"Parte II - M\u00e9todos de b\u00fasqueda de \u00e1rboles"},{"location":"practicos/TP06_Filogenia/#metodo-de-maxima-verosimilitud","text":"Para utilizar M\u00e1xima Verosimilitud ( maximum likelihood ) se usa el comando fproml . Los argumentos de este comando son: -sequence : Indica el MSA de entrada -oufile : Indica donde guardar la salida -intrefile (opcional), \u00c1rbol para usar de gu\u00eda. No se utilizar\u00e1 en este caso, pero lo va a preguntar igual, en ese caso se aprieta Enter . fproml -seed 1 -sequence Ribonucleasas.curado.msa -outfile Ribonucleasas-ML.tree -outtreefile Ribonucleasas-ML.treefile \u00bfQu\u00e9 es Seed? Adem\u00e1s de los argumentos m\u00ednimos, se utiliz\u00f3 el argumento -seed . Esto es una buena pr\u00e1ctica para que el experimento sea reproducible . En computaci\u00f3n, lo que se llama random (por azar) en realidad no lo es. Para obtener n\u00fameros cuya distribuci\u00f3n se acerque a la aleatoria se aplica una serie de f\u00f3rmulas que dan un resultado dependiendo del n\u00famero del cual se parte. Este valor es la semilla (seed). Por lo general se utiliza como semilla el tiempo, el cual cambia constantemente, pero nosotros podemos fijar esa semilla , para que otras personas, o nosotros mismos en alg\u00fan futuro, podamos correr nuestros comandos y obtener exactamente los mismos resultados. 3.II.1 Observen e interpreten la salida obtenida. \u00bfHubo cambios radicales con respecto a los \u00e1rboles anteriores?. 3.II.2 \u00bfCon qu\u00e9 nueva informaci\u00f3n contamos? Mirando el nombre del comando fproml conteste: \u00bfSe utiliza con secuencias de prote\u00ednas o de ADN? La forma correcta de sacarnos nuestra duda es corriendo: tfm fproml Despu\u00e9s de contestar la pregunta anterior \u00bfC\u00f3mo cree que se llama el comando para utilizar el m\u00e9todo maximum likelihood con secuencias de ADN? \u00bfCree que utiliza los mismos m\u00e9todos que el comando utiliza para prote\u00ednas? Chequee su respuesta en EMBOSS !!!!","title":"M\u00e9todo de M\u00e1xima Verosimilitud"},{"location":"practicos/TP06_Filogenia/#uso-de-outgroups","text":"Hasta ahora se generaron \u00e1rboles sin raiz , donde las distancias entre los OTUs son relativas. Para colocar una ra\u00edz se utiliza un OTU que se sabe a priori que divergi\u00f3 antes que el resto, as\u00ed se obtiene una referencia a partir de la cual construir el \u00e1rbol. \u00a1Aprovechemos que tenemos a un intruso! El set de secuencias est\u00e1 compuesto casi en su totalidad por mam\u00edferos placentarios, excepto por el canguro rojo. Su aparici\u00f3n no es casualidad ya que como miembro de otra infraclase sirve de referencia para proponer una ra\u00edz al \u00e1rbol. Para ello se utiliza el argumento -outgrno , que recibe el n\u00famero del organismo a utilizar como referencia. Este n\u00famero esta dado por la posici\u00f3n de la secuencia en el alineamiento m\u00faltiple. Para averiguar que n\u00famero es hay dos opciones: Contar a mano Correr un comando Contar a mano puede llevar a errores, y dado que esto es bioinform\u00e1tica, se utilizar\u00e1 el siguiente comando: cat Ribonucleasas.curado.msa | grep \">\" | grep -n \"Macropus\" La salida se ver\u00e1 similar a esta: 45:>Macropus_rufus . La secuencia en el alineamiento en este caso est\u00e1 en la posici\u00f3n 45 pero este n\u00famero puede cambiar seg\u00fan el usuario. Una vez obtenido este valor se vuelve a correr fproml fproml -outgrno 45 -seed 1 -sequence Ribonucleasas.curado.msa -outfile Ribonucleasas-ML-OUTGR.tree -outtreefile Ribonucleasas-ML-OUTGR.treefile Ventaja del M\u00e9todo de Maximum Likelihood ML utiliza un modelo de Markov para estimar las tasas de cambio de las diferentes posiciones y as\u00ed poder hacer c\u00e1lculos m\u00e1s precisos. Esto se debe a que no todas las posiciones var\u00edan con la misma frecuencia. Posiciones importantes para la estructura/funci\u00f3n de la prote\u00edna, por ejemplo el sitio activo de una enzima, tienden a variar mucho menos que el resto y esto debe ser tenido en cuenta a la hora de construir la filogenia.","title":"Uso de Outgroups"},{"location":"practicos/TP06_Filogenia/#metodo-de-maxima-parsimonia","text":"Genere el \u00e1rbol utilizando m\u00e1xima parsimonia con el comando fprotpars , utilice -help para ver qu\u00e9 argumentos recibe. Responda: 3.II.3 \u00bfQu\u00e9 informaci\u00f3n nos da este m\u00e9todo? 3.II.4 \u00bfCu\u00e1ntos \u00e1rboles nos devuelve? \u00bfPor qu\u00e9?","title":"M\u00e9todo de M\u00e1xima Parsimonia"},{"location":"practicos/TP06_Filogenia/#paso-4-tests-seleccionar-arboles-en-el-bosque","text":"Entonces, \u00bfqu\u00e9 tan bueno es nuestro \u00e1rbol? Uno de los test m\u00e1s simples para medir la veracidad del \u00e1rbol es el bootstrap . Hoy en d\u00eda ser\u00eda muy raro encontrar un \u00e1rbol filogen\u00e9tico que no lo haya utilizado. El bootstrap esencialmente prueba si todo el set de datos est\u00e1 de acuerdo con el \u00e1rbol resultante, o si dicho \u00e1rbol es un outlier entre varias otras posibilidades. Esto se hace tomando muestras aleatorias de nuestro set de datos, armando varios \u00e1rboles y calculando la frecuencia de ocurrencia de cada fragmento del \u00e1rbol. Si un agrupamiento determinado es encontrado en todos los \u00e1rboles, entonces tienen un score de 100%; si solo ocurre en 2/3 de los \u00e1rboles generados el score ser\u00e1 de 67% y as\u00ed. Es importante aclarar que el muestreo se hace a nivel columna del MSA, y no a nivel de secuencia. Nuestro \u00e1rbol va a establecer la relaci\u00f3n entre diferentes secuencias dada la conservaci\u00f3n/mutaci\u00f3n de posiciones hom\u00f3logas y esto es lo que se intenta probar con bootstrap : que cualquier tipo de composici\u00f3n que mantenga esos patrones de conservaci\u00f3n/mutaci\u00f3n va a dar el mismo \u00e1rbol. Por ello, vamos a tener la misma cantidad de secuencias, y del mismo largo, ya que no solo vamos a reordenar las posiciones al azar sino que tambi\u00e9n vamos a quitar y repetir columnas. En la siguiente imagen pueden ver un ejemplo de los resultados de un Bootstrapping Al final de este proceso se obtiene un conjunto de alineamientos. A partir de cada alineamiento se construye un \u00e1rbol. Este test parece sencillo, y estudios en filogenias conocidas (poblaciones virales cultivadas en laboratorio) muestran que es una medida adecuada de la certeza del \u00e1rbol resultante; y que un valor de 70% o m\u00e1s suele indicar un agrupamiento adecuado. Para generar el conjunto de alineamientos se utiliza el comando fseqboot los argumentos son -sequence (datos de ENTRADA), -outfile (datos de SALIDA) y -reps : fseqboot -reps 10 -sequence Ribonucleasas.curado.msa -outfile Ribonucleasas.boot En este comando falta algo muy importante! \u00bfLo ven? Falta el seed !!! fseqboot -reps 10 -seed 1 -sequence Ribonucleasas.curado.msa -outfile Ribonucleasas.boot -reps indica el n\u00famero de remuestreos a realizar. Calcular varios \u00e1rboles puede llevar bastante tiempo por lo que solo se har\u00e1n 10 repeticiones. En un t\u00edpico ensayo se realizan muchas m\u00e1s repeticiones. Exploren el archivo Ribonucleasas.boot . Hay varios MSA correspondientes al resmuestreo, con posiciones faltantes, repetidas y en distinto orden que el MSA original. Este archivo se utilizar\u00e1 para llevar a cabo numerosos \u00e1rboles filogen\u00e9ticos: fproml -seed 1 -sequence Ribonucleasas.boot -outfile Ribonucleasas-ML-BOOT.tree -outtreefile Ribonucleasas-ML-BOOT.treefile Esto puede tardar un rato, podr\u00eda ser un buen momento para preparar un mate... El archivo de salida Ribonucleasas-ML-BOOT.tree contiene todos los \u00e1rboles resultantes de todos nuestros muestreos. Al ser tantos, uno puede ver las diferentes topolog\u00edas creadas, sin embargo es muy dif\u00edcil sacar conclusiones. Para poder utilizar toda la informaci\u00f3n de estas numerosas r\u00e9plicas vamos a unirlas con el comando fconsense . Este toma como entrada el archivo .treefile que contiene todos los \u00e1rboles en formato Phyllip y los va a condensar en uno solo, anotando a cada rama la cantidad de veces que esta fue hallada en nuestros muestreo. fconsense -intreefile Ribonucleasas-ML-BOOT.treefile -outfile Ribonucleasas-CONS.tree -outtreefile Ribonucleasas-CONS.treefile 3.II.5 Un buen ejercicio antes de copiar y pegar un comando es ENTENDER que es cada argumento del comando. \u00bfQue hace cada argumento? -intreefile -outfile -outtreefile Observando el \u00e1rbol consenso. Responda: 3.II.6 \u00bfResulta ser un buen \u00e1rbol? \u00bfEn qu\u00e9 se basan para afirmarlo? 3.II.7 \u00bfC\u00f3mo podr\u00edan lidiar con nodos de baja calidad?","title":"Paso 4 - Elecci\u00f3n del \u00e1rbol"},{"location":"practicos/TP06_Filogenia/#paso-5-presentacion-de-resultados","text":"Finalmente algunos conceptos en cuanto a la presentaci\u00f3n de los datos. Por lo general no hay reglas duras de c\u00f3mo debe hacerse pero s\u00ed convenciones que est\u00e1n bastante aceptadas. En \u00e1rboles de filogenia molecular, los largos de las ramas suelen dibujarse a escala; esto es, proporcional a la cantidad de evoluci\u00f3n que se estima ocurri\u00f3 entre los nodos que conecta. A pesar de que la relaci\u00f3n entre el largo de la rama y el tiempo real no es directa y muy probablemente no es confiable, los largos dan una idea general de las tasa de cambio relativas del \u00e1rbol. Los valores de Bootstrap deben ser presentados en forma de porcentajes, no de valores crudos, para que sea m\u00e1s sencillo de leer y comparar con otros \u00e1rboles. Por convenci\u00f3n, s\u00f3lo valores de Bootstrap del 50% o mayores son reportados; valores menores significan que la calidad del nodo encontrado es muy baja. Por \u00faltimo, tengan en cuenta la legibilidad del \u00e1rbol en general. Utilizar nombres para las ramas con c\u00f3digos de acceso a bases de datos o acr\u00f3nimos de pocas letras puede resultar muy confuso. Hoy en d\u00eda existen numerosos softwares para la visualizaci\u00f3n de \u00e1rboles (ej. Hypertree) que nos permiten, mediante agrupamientos, colores, fuentes, etc. llamar la atenci\u00f3n del lector sobre uno u otro aspecto importante del mismo y lograr que transmita la informaci\u00f3n que nos interesa mostrar.","title":"Paso 5 - Presentaci\u00f3n de resultados"},{"location":"practicos/TP07_HMM_ANN/","text":"TP 7 . Artificial Neural Networks (ANNs) y Hidden Markov Models (HMMs) Materiales Atenci\u00f3n: Este TP tiene informe. Slides mostrados en la clase Explicaci\u00f3n ANNs Explicaci\u00f3n HMMs Videos de la clase grabada Introducci\u00f3n ANNs Puesta en com\u00fan ANNs Ejercicio guiado HMMer Objetivos Comprender c\u00f3mo se entrena y eval\u00faa un modelo basado en redes neuronales. Familiarizarse con el esquema de validaci\u00f3n cruzada para el entrenamiento de dichos modelos. Construir un perfil basado en HMMs y utilizar el mismo para realizar b\u00fasquedas en bases de datos de secuencias. Crear una base de datos de perfiles de secuencias y utilizar la misma para identificar dominios conservados en secuencias query . Parte I. Artificial neural networks En esta secci\u00f3n vamos a utilizar redes neuronales para hacer predicciones como hab\u00edamos hecho anteriormente con las PSSM. La idea es similar a la del TP5 donde entrenamos un modelo con p\u00e9ptidos que se unen a MHC. Variaremos los par\u00e1metros de modelo para mejorarlo, sensando en cada corrida los indicadores de desempe\u00f1o del mismo ( Aroc y Pearson correlation coefficient ). Atenci\u00f3n Si no recuerdan qu\u00e9 significan las m\u00e9tricas Aroc y Pearson correlation coefficient (PCC) dir\u00edjanse al TP5 para refrescar estos conceptos. Para esto vamos a volver a utilizar EasyPred y los archivos de Entrenamiento.set y Evaluacion.set en la carpeta del TP (que descargaron al inicio). Entrenamiento.set contiene 1200 p\u00e9ptidos de longitud 9, con un valor asociado de afinidad de uni\u00f3n a HLA-A*02:01 transformado entre 0 y 1. Recuerde que mientras m\u00e1s cercano a 1 el p\u00e9ptido tiene mayor afinidad de uni\u00f3n y que a partir de 0.426 se considera que el p\u00e9ptido es un ligando. Evaluacion.set contiene 66 p\u00e9ptidos, tambi\u00e9n con sus valores correspondientes de afinidad de uni\u00f3n. Para el entrenamiento del modelo se particionar\u00e1 el archivo Entrenamiento.set , de tal manera que una parte se usar\u00e1 para entrenar y la restante se emplear\u00e1 para ir monitoreando el proceso de entrenamiento y as\u00ed evitar el sobreajuste de los pesos de nuestra red. Luego el archivo Evaluacion.set contiene datos independientes, que se utilizar\u00e1n para evaluar la capacidad de generalizaci\u00f3n de nuestro modelo. Tip Es recomendable abrir los archivos y ver qu\u00e9 es lo que contienen. Esto SIEMPRE es una buena pr\u00e1ctica. Nota A lo largo del TP vamos a mantener el valor de Cutoff for counting an example as a positive example en 0.5. Atenci\u00f3n Vayan corriendo las diferentes pruebas en diferentes pesta\u00f1as o guarden el reporte de salida para poder compararlo cuando sea necesario. Primera prueba: Comprendiendo los resultados que indican el desempe\u00f1o de la red Para nuestro primer modelo vamos a ir a EasyPred y cargamos los archivos en los cuadros correspondientes: Luego bajamos hasta la opci\u00f3n Select method d\u00f3nde vamos a cambiar de Matrix method a Neural Network . All\u00ed vamos a poder ver que nos habilita a ingresar otros parametros que est\u00e1n relacionados a la arquitectura y el entrenamiento de la red. Los par\u00e1metros que queremos utilizar en este paso son: Number of hidden units : 2 Number iterations (epochs) to run neural network : 300 Fraction of data to train on (the rest is used to avoid overtraining) : 0.8 Learning rate : 0.05 Use top sequences for training Es decir dejamos los valores por defecto y le damos Submit . Una vez entrenado el modelo, recuerde que puede chequear el desempe\u00f1o del mismo iteraci\u00f3n a iteraci\u00f3n haciendo click en Output from the neural network program (HOW) \u00bfCu\u00e1l es el m\u00e1ximo valor de PCC alcanzado sobre el set de prueba? ( Maximal test set pearson correlation coefficient sum ) \u00bfEn qu\u00e9 iteraci\u00f3n se alcanza ese m\u00e1ximo? \u00bfQu\u00e9 informaci\u00f3n le est\u00e1 dando esto sobre el proceso de entrenamiento del modelo? \u00bfCu\u00e1les son los valores de desempe\u00f1o del modelo sobre el set de evaluaci\u00f3n? (PCC y Aroc) \u00bfEl PCC obtenido en el punto 3. es mayor o menor al obtenido en el punto 1.? \u00bfQu\u00e9 implica este resultado? Segunda prueba: Cambiando el set de entrenamiento Mantenga los mismos par\u00e1metros que en el paso anterior pero esta vez seleccione Use bottom sequences for training . \u00bfCu\u00e1l es el m\u00e1ximo valor de PCC alcanzado sobre el set de prueba y en qu\u00e9 iteraci\u00f3n ocurre esta vez? \u00bfQu\u00e9 valores de desempe\u00f1o alcanza el modelo aplicado al set de evaluaci\u00f3n? \u00bfA qu\u00e9 se debe que no coincidan con lo obtenido en la primera prueba? Tercera prueba: Cambiando la arquitectura de la ANN Repita los par\u00e1metros de la primera prueba excepto por el n\u00famero de neuronas en la capa intermedia o hidden layer : Number of hidden units : 1 Observe el impacto en los par\u00e1metros de desempe\u00f1o del modelo. Guarde los resultados. Repita el ensayo esta vez con: Number of hidden units : 5 Responda a las siguientes preguntas para ambos casos estudiados: \u00bfC\u00f3mo var\u00eda la performance en el set de prueba? \u00bfQu\u00e9 impacto tienen estos cambios en la performance del set de evaluaci\u00f3n? \u00bfPuede elegir un n\u00famero \u00f3ptimo de neuronas para la capa oculta? \u00bfPor qu\u00e9 cree que el n\u00famero de neuronas en la capa oculta tiene tan poco impacto en esta prueba? Piense en el n\u00famero de datos de entrada y el n\u00famero de pesos de la red. Cuarta prueba: Empleando un esquema de validaci\u00f3n cruzada Como deber\u00edan haber notado en las dos primeras pruebas, la partici\u00f3n de los datos que se utilizan en el entrenamiento/prueba influyen significativamente en el desempe\u00f1o del modelo. Como a priori uno no puede establecer cu\u00e1l es la mejor forma de partir los datos en entrenamiento y test se recurre a una estrategia denominada cross-validation . La t\u00e9cnica de validaci\u00f3n cruzada consiste en hacer N particiones (por lo general 5) y rotarlas, utilizando N-1 para entrenar y la N-\u00e9sima (es decir la que queda afuera) como set de prueba. Esto resulta en N modelos diferentes, cada uno entrenado y probado en datos diferentes. Para realizar predicciones en nuevos sets, como el de evaluaci\u00f3n, se realizan predicciones con los N m\u00e9todos y se promedian sus predicciones. Para realizar esta prueba vuelvan a los par\u00e1metros de la Primera prueba pero modifiquen lo siguiente: Number of partitions for cross-validated training : 5 Este paso puede llevar varios minutos. Paciencia. \u00bfEncuentran diferencias entre los desempe\u00f1os de los 5 modelos? \u00bfEs esperable? \u00bfPor qu\u00e9? Comparen los resultados obtenidos para el set de evaluaci\u00f3n con respecto a la primera prueba. En este caso se usa el ensamble de los 5 modelos para realizar las predicciones sobre el set de evaluaci\u00f3n. \u00bfC\u00f3mo piensa que se obtienen los valores predichos? Utilizando el modelo entrenado Como vimos en el TP de PSSM, una vez que uno entrena un m\u00e9todo, puede guardar los valores ajustados (ya sea de la matriz en el caso de la PSSM o los pesos de la red en el caso de ANN) y utilizarlos para hacer predicciones en un set nuevo de datos. Guardar el modelo entrenado Para ello vamos a guardar el modelo entrenado en la Cuarta prueba haciendo click derecho en Parameters for prediction method del reporte de resultados y seleccionando \"Guardar enlace como...\" (el archivo se guarda como para.dat ). Este modelo ser\u00e1 utilizado en el ejercicio a entregar de este TP. Parte II. HMMer Atenci\u00f3n Antes de comenzar ejecuten en la terminal de su VM sudo apt install hmmer2 , para instalar el programa hmmer2 . Introducci\u00f3n HMMer es un paquete de programas que nuclea varias funciones para realizar b\u00fasquedas en bases de datos mediante la utilizaci\u00f3n de perfiles de secuencias. Est\u00e1 basado en profile Hidden Markov Models , presentados por Anders Krogh (Krogh et al. , 1994). Estos perfiles son una aproximaci\u00f3n estad\u00edstica del consenso de un alineamiento m\u00faltiple y utilizan un sistema de puntaje posici\u00f3n-espec\u00edfico, en contraste con m\u00e9todos ya vistos como BLAST o FASTA en donde la matriz de puntajes utilizada es la misma en cada posici\u00f3n. Construcci\u00f3n de un perfil Supongamos que trabajamos con globinas y queremos buscar hom\u00f3logos lejanos. Para ello contamos con 50 secuencias de globinas las cuales alineamos y guardamos en el archivo globins50.msf . Como primer paso para realizar la b\u00fasqueda debemos generar un profile o perfil que las represente. Para crear el profile utilizamos la funci\u00f3n hmm2build de la siguiente manera: hmm2build globin.hmm globins50.msf hmm2build recibe como argumentos el archivo en el cual va a guardar el perfil ( globin.hmm ) y el archivo con el cual crearlo ( globins50.msf ). Si bien el contenido del archivo donde se guard\u00f3 el perfil es legible, su contenido no deber\u00eda tener sentido para ustedes (m\u00e1s all\u00e1 del encabezado con informaci\u00f3n sobre las opciones que se utilizaron para crearlo) porque \u00fanicamente almacena los pesos de las transiciones de estado del HMM. Calibraci\u00f3n del perfil Este paso no es imprescindible pero s\u00ed aconsejable. La calibraci\u00f3n del perfil le otorga mayor sensibilidad en la b\u00fasqueda ya que modifica la estimaci\u00f3n del E-value de los hits encontrados. Si recuerdan, la b\u00fasqueda contra bases de datos nos devuelve junto con cada alineamiento un score y un E-value, este \u00faltimo nos da una idea sobre la cantidad de hits que esperamos encontrar con ese score en una base de datos construida con secuencias aleatorias y se calcula seg\u00fan la longitud de la secuencia query y subject , el tama\u00f1o de la base de datos y la matriz de scoring . En el caso de HMMer, la estimaci\u00f3n del E-value es anal\u00edtica y resulta muy conservativa, por lo que se dejan de lado posibles hits (como hom\u00f3logos lejanos). Utilizando hmm2calibrate podemos calibrar el c\u00e1lculo de E-values de manera emp\u00edrica incrementando de manera significativa la sensibilidad de la b\u00fasqueda. hmm2calibrate globin.hmm hmm2calibrate lee un archivo con un modelo HMM como globin.hmm y punt\u00faa un n\u00famero grande de secuencias sintetizadas al azar (por default 5000 secuencias) con este modelo. Luego ajusta una EVD (Extreme Value Distribution) al histograma de los puntajes obtenidos y guarda nuevamente el modelo HMM con estos nuevos par\u00e1metros. Como para realizar este c\u00e1lculo se sintetizan secuencias al azar, estableceremos una semilla (o seed ) para poder reproducir nuestros resultados. Entonces el comando se modifica de la siguiente forma, hmm2calibrate --seed 1 globin.hmm B\u00fasqueda en bases de datos El comando para utilizar nuestro flamante profile en una b\u00fasqueda es hmm2search . En este caso lo vamos a utilizar contra el archivo Artemia.fa que contiene una \u00fanica secuencia de globina en b\u00fasqueda de dominios pertenecientes a nuestra familia de inter\u00e9s. hmm2search globin.hmm Artemia.fa La salida de este comando es m\u00e1s larga que las anteriores, consta de un encabezado con la informaci\u00f3n sobre el programa y los par\u00e1metros que utilizamos en la b\u00fasqueda: hmmsearch - search a sequence database with a profile HMM HMMER 2.3.2 (Oct 2003) Copyright (C) 1992-2003 HHMI/Washington University School of Medicine Freely distributed under the GNU General Public License (GPL) - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - HMM file: globin.hmm [globins50] Sequence database: Artemia.fa per-sequence score cutoff: [none] per-domain score cutoff: [none] per-sequence Eval cutoff: <= 10 per-domain Eval cutoff: [none] - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Query HMM: globins50 Accession: [none] Description: [none] [HMM has been calibrated; E-values are empirical estimates] Una lista parecida a la que da BLAST con los hits m\u00e1s importantes ordenados por su E-value: Scores for complete sequences (score includes all domains): Sequence Description Score E-value N -------- ----------- ----- ------- --- S13421 S13421 GLOBIN - BRINE SHRIMP 120.3 6.2e-37 4 Noten que despu\u00e9s del E-value hay un campo que no se encontraba en los otros algoritmos de b\u00fasqueda denominado \"N\". Este valor representa la cantidad de dominios de nuestro profile que fueron encontrados en el hit. Luego encontramos informaci\u00f3n sobre los dominios de nuestro profile individualmente. Parsed for domains: Sequence Domain seq-f seq-t hmm-f hmm-t score E-value -------- ------- ----- ----- ----- ----- ----- ------- S13421 3/4 771 1075 .. 1 333 [] 34.0 3e-13 S13421 1/4 1 288 [. 1 333 [] 31.9 3.8e-13 S13421 4/4 1085 1390 .. 1 333 [] 29.4 5e-13 S13421 2/4 303 607 .. 1 333 [] 25.0 8.1e-13 Los campos son: el nombre del hit el dominio que se aline\u00f3 (por ej. 2/4 significa que es el dominio Nro 2 de 4 que hay en total en nuestro perfil) seq-f y seq-t son las posiciones del hit donde comienza y termina el alineamiento con ese dominio y el campo siguiente a estos valores (sin nombre) es una codificaci\u00f3n de qu\u00e9 parte de la secuencia fue alineada. los corchetes significan extremos y los puntos posiciones en el medio, por lo que: \"..\" significa que el alineamiento comenz\u00f3 y termin\u00f3 en una posici\u00f3n que no es terminal de la secuencia hit \"[.\" significa que el alineamiento empieza al comienzo de la secuencia y termina en alguna posici\u00f3n en medio al rev\u00e9s, \".]\" empieza en una posici\u00f3n intermedia y termina en el fin de la secuencia por \u00faltimo \"[]\" es que el dominio abarca toda la secuencia. Los tres siguientes campos son an\u00e1logos pero refiri\u00e9ndose a la secuencia del dominio en nuestro perfil HMM. Luego se reportan el score y el E-value. La secci\u00f3n siguiente contiene los alineamientos de los dominios que fueron hit en la lista anterior en un formato similar al de BLAST, teniendo como primera secuencia el consenso del profile (noten que hay amino\u00e1cidos en may\u00fasculas, estos se encuentran altamente conservados en el profile). Al igual que BLAST en medio de ambas secuencias se escriben los amino\u00e1cidos que coinciden o \"matchean\" y signos m\u00e1s (+) en donde hay mismatches con puntaje positivo en la matriz de sustituci\u00f3n. Alignments of top-scoring domains: S13421: domain 3 of 4, from 771 to 1075: score 34.0, E = 3e-13 *->viqealvnssShLsaeeKalvkslWygKV..ggnaeeyGaeaLgRlF L+a eK+ ++++W + ++ g +++ +++++ RlF S13421 771 T-----------LTALEKQSIQDIW-SNLrsTG-LQDLAVKIFTRLF 804 vvYPwTqryFp.hFgdLssldAvkGspkvKAHGkKVltalgdavkhLDdt ++P+ + F + Fg++ + ++ +KAH +Vl+a++ ++ LDd S13421 805 SAHPEYKLLFTgRFGNVDN---INENAPFKAHLHRVLSAFDIVISTLDDS 851 gnlkgalakLSelHAdKLrVDPeNFklLghclivVLAahfgkdFtPevqA + l l++L+ H + L+ ++ +F +++ +++ V + + t S13421 852 EHLIRQLKDLGLFH-TRLGMTRSHFDNFATAFLSVAQDIAPNQLTVLGRE 900 AwdKflagvanaLahKYrelgFQggftviqealvnssShLsaeeKalvks ++ K +++ ++ ++ l t+ Lsa e a vk+ S13421 901 SLNKGFKLMHGVIEEGLLQLERINPITG-----------LSAREVAVVKQ 939 lWygKVggnaeeyGaeaLgRlFvvYPwTqryFphFgdLssldAvkGspkv +W V++++ ++G ++ lF ++P q+ Fp+F+d+ +ld + + p v S13421 940 TW-NLVKPDLMGVGMRIFKSLFEAFPAYQAVFPKFSDV-PLDKLEDTPAV 987 KAHGkKVltalgdavkhLDdtgnlkgalakLSelHAdKLrVDPeNFklLg +H V t l++ + LD nl+ +L+e H LrV Fk +g S13421 988 GKHSISVTTKLDELIQTLDEPANLALLARQLGEDH-IVLRVNKPMFKSFG 1036 hclivVLAahfgkdFtPevqAAwdKflagvanaLahKYr<-* ++l+ L +g F+ + +w K++++++ + ++ S13421 1037 KVLVRLLENDLGQRFSSFASRSWHKAYDVIVEYIEEGLQ 1075 Llegando al final encontramos un histograma, similar al que nos mostraba FASTA. En este caso como nuestra \"base de datos\" tiene una sola secuencia no es informativo en absoluto. Histogram of all scores: score obs exp (one = represents 1 sequences) ----- --- --- 120 1 0|= Y por \u00faltimo algunos detalles estad\u00edsticos que corresponden al ajuste de la EVD, en los cuales no vamos a focalizar. % Statistical details of theoretical EVD fit: mu = -226.7154 lambda = 0.1106 chi-sq statistic = 0.0000 P(chi-square) = 0 Total sequences searched: 1 Whole sequence top hits: tophits_s report: Total hits: 1 Satisfying E cutoff: 1 Total memory: 20K Domain top hits: tophits_s report: Total hits: 4 Satisfying E cutoff: 4 Total memory: 25K B\u00fasqueda en bases de datos reales HMMer puede leer los formatos de la mayor\u00eda de las bases de datos conocidas. A diferencia de BLAST no es necesario indexar la base de datos. Si recuerdan de la pr\u00e1ctica de BLAST/FASTA, uno pod\u00eda crear su propia base de datos donde realizar los alineamientos a partir de un archivo multifasta utilizando el comando formatdb , el cual crea todo el sistema de \u00edndices de ktuplas y dem\u00e1s archivos para facilitar la b\u00fasqueda. En este caso HMMer puede realizar la b\u00fasqueda directamente sobre el multifasta sin necesidad de m\u00e1s procesamiento. En nuestro servidor podemos realizar la b\u00fasqueda utilizando: hmm2search globin.hmm ~/Swissprot_db/Swissprot.fasta > globin.swissprot.search less globin.swissprot.search Atenci\u00f3n Este comando no les va a funcionar si no tienen a la carpeta Swissprot_db en su home directory. A tener en cuenta: Notar\u00e1n que la b\u00fasqueda directa aumenta considerablemente el tiempo de c\u00f3mputo necesario para obtener un resultado. Modos de alineamiento HMMer no utiliza los m\u00e9todos cl\u00e1sicos de alineamiento ( Smith-Waterman o Needleman-Wunsch ) como el resto de los algoritmos de alineamiento sino que el modo de alinear (local o global) est\u00e1 dado por el modelo que construimos. Por defecto hmm2build lleva a cabo alineamientos que son globales con respecto al HMM y locales con respecto a la secuencia objetivo, permitiendo alinear varios dominios en esa misma secuencia. \u00bfQu\u00e9 significa esto? Que cada dominio se intenta alinear completamente en alguna porci\u00f3n de la secuencia objetivo. Si queremos recuperar secuencias que contengan alineamientos parciales de dominios podemos agregar a hmm2build la opcion -f . Bases de datos de HMM As\u00ed como nos es posible realizar b\u00fasquedas de profiles contra bases de datos de secuencias, podemos crear una base de datos de profiles y utilizar como query a una secuencia. Este es el caso de la base de datos PFAM (Sonnhammer et al. , 1997; Sonnhammer et al. , 1998) que nuclea profiles de una gran variedad de dominios y es una herramienta sumamente utilizada para analizar secuencias de prote\u00ednas de las cuales no tenemos informaci\u00f3n previa. Como ejemplo, tomemos el producto del gen Sevenless de Drosophila melanogaster que codifica un receptor de tyrosine kinase esencial para el desarrollo de las c\u00e9lulas R7 del ojo de la mosca. La secuencia proteica de este receptor se encuentra en el archivo 7LES_DROME . Realice una b\u00fasqueda de esta secuencia en PFAM . Para esto haga click en la pesta\u00f1a Sequence en el men\u00fa de la izquierda y pegue la secuencia en el recuadro correspondiente. \u00bfQu\u00e9 dominios fueron identificados en esta prote\u00edna? Recuerde estos resultados para contrastarlo con lo que har\u00e1 m\u00e1s adelante. Las bases de datos de profiles no son m\u00e1s que m\u00faltiples HMMs concatenados, por lo que el comando para construirlas es tambi\u00e9n hmm2build , pero vamos a utilizar la opci\u00f3n -A (append) para agregar nuevos profiles a nuestro archivo de HMMs original. Por ejemplo, si queremos construir una base de datos \"myhmms\" que contiene perfiles de dominios rrm de reconocimiento de ARN, fn3 de fibronectina tipo III y pkinase del dominio catal\u00edtico de las kinasas podemos realizarlo f\u00e1cilmente con: hmm2build -A myhmms rrm.sto hmm2build -A myhmms fn3.sto hmm2build -A myhmms pkinase.sto Para realizar b\u00fasquedas en nuestra nueva base de datos utilizamos el comando hmm2pfam . En este caso empleamos nuevamente, como ejemplo, a la prote\u00edna codificada por el gen Sevenless de Drosophila melanogaster (archivo 7LES_DROME ): hmm2pfam myhmms 7LES_DROME La salida es muy parecida a la de hmm2search pero los hits reportados no ser\u00e1n secuencias sino dominios contenidos en la base de datos. En nuestro caso particular podr\u00e1n notar que tenemos un hit contra un dominio RRM a\u00fan cuando nuestra prote\u00edna query no contiene ning\u00fan dominio de este tipo. Relacionado con esto mismo, \u00bfrecuerdan si la base de datos PFAM identific\u00f3 este dominio en la prote\u00edna de estudio? Nos podemos dar cuenta que este hit es al menos sospechoso debido a su score negativo y su E-value cercano a 1. Por defecto el l\u00edmite de E-value, al igual que BLAST es 10, este umbral es extremadamente permisivo y proclive a devolver ruido. Si queremos ser m\u00e1s quisquillosos podemos utilizar la opci\u00f3n -E seguida del umbral deseado. Por ejemplo: hmm2pfam -E 0 .1 myhmms 7LES_DROME Adicional: Alineamientos m\u00faltiples con HMM Otro uso que se les da a los profiles es el de asistir a la hora de llevar a cabo alineamientos m\u00faltiples de grandes cantidades de secuencias. En general este proceso suele ser lento y los alineamientos resultantes contienen errores que requieren curarse a mano. Utilizando HMMs construidos a partir de un alineamiento de unas pocas secuencias representativas, se pueden alinear grandes cantidades de secuencias relacionadas f\u00e1cilmente. Siguiendo con nuestras globinas, tenemos un archivo ( globins630.fa ), que como habr\u00e1n deducido, contiene 630 secuencias de globinas que vamos a alinear utilizando el comando hmm2align : hmm2align -o globins630.ali globin.hmm globins630.fa mediante la opci\u00f3n -o indicamos el archivo en el que deseamos guardar el alineamiento ( globins630.ali ), y como argumentos debemos indicar el profile que vamos a utilizar como \"semilla\" y el archivo con las secuencias a alinear ( globin.hmm y globins630.fa respectivamente). Noten que tambi\u00e9n se puede utilizar la opci\u00f3n --outformat para cambiar el formato del alineamiento producido. Por defecto se utiliza el formato Stockholm , pero tambi\u00e9n puede producir alineamientos en formato MSF , Clustal , Phylip y SELEX . Ejercicio a informar Info Fecha l\u00edmite de entrega: Viernes, 30 de Septiembre 2022, 23:59hs. Enunciado Su jefe analiz\u00f3 los resultados de la identificaci\u00f3n de ligandos de HLA-A02*01 utilizando una PSSM. Lamentablemente no est\u00e1 muy conforme con los resultados porque considera que hay m\u00e9todos mejores para realizar esta predicci\u00f3n. Por lo tanto, usted decide volver a realizar las predicciones, utilizando la red que entren\u00f3 en la cuarta prueba del TP7, para las mismas prote\u00ednas de la variante de coronavirus que est\u00e1 estudiando actualmente. Recordemos que eran las siguientes: prote\u00edna S (spike o prote\u00edna de glicoprote\u00edna de superficie), E (prote\u00edna de la envoltura), M (prote\u00edna de membrana) y N (fosfoprote\u00edna de la nucleoc\u00e1pside). Para lograr su objetivo utilizar\u00e1 la herramienta EasyPred . Como va a realizar una predicci\u00f3n, siga los mismos pasos que realiz\u00f3 para hacer la predicci\u00f3n con la PSSM con la diferencia de que en Load saved prediction method debe subir el archivo con los pesos de la red. Seleccione Sort output on predicted values y apriete el bot\u00f3n Submit query . Interprete la salida que obtiene al correr Easypred . \u00bfCu\u00e1ntas redes se utilizan para realizar las predicciones? \u00bfCu\u00e1ntos p\u00e9ptidos se podr\u00edan considerar ligandos en cada caso? Recuerde los umbrales para la clasificaci\u00f3n de ligandos que enunciamos en los TP5 y TP7. \u00bfCu\u00e1les son los p\u00e9ptidos que elegir\u00eda para testear en el laboratorio de cada una de las prote\u00ednas analizadas? Tenga en cuenta que puede elegir como m\u00e1ximo 5 p\u00e9ptidos en total. Teniendo en cuenta su respuesta al punto 2., \u00bftiene sentido este resultado considerando la alta especificidad del MHC analizado? Ingrese a Seq2Logo y genere un logo con todos los p\u00e9ptidos que etiquet\u00f3 como ligandos. Ajuste los par\u00e1metros seg\u00fan su criterio. En base a los conocimientos adquiridos, \u00bfle parece razonable el motivo hallado para el alelo HLA-A*02:01? \u00bfPuede ver claramente las posiciones ancla? \u00bfQu\u00e9 amino\u00e1cidos son los preferidos para estas posiciones? Compare el logo obtenido con el que construy\u00f3 para el ejercicio final del TP5 (p\u00e9ptidos con un puntaje predicho mayor a 1). \u00bfQu\u00e9 diferencias y similitudes observa? \u00bfQu\u00e9 diferencia observa en el information content (eje y), y a qu\u00e9 se lo atribuye? \u00bfPor qu\u00e9 cree que el motivo generado por redes neuronales es m\u00e1s parecido a lo ya conocido en la literatura que el motivo constru\u00eddo a partir de la PSSM? Ahora compare todas las predicciones realizadas con la PSSM con las obtenidas utilizando la red neuronal. Calcule el coeficiente de correlaci\u00f3n de Pearson y Spearman entre ambos conjuntos de predicciones. Investigue cu\u00e1l de estas dos m\u00e9tricas ser\u00eda la m\u00e1s adecuada para realizar esta comparaci\u00f3n (Pista: \u00bfNot\u00f3 que las predicciones est\u00e1n en diferentes escalas?). Para completar esta tarea puede usar Excel (ver Extras) o cualquier otro programa de su preferencia. A su jefe le gustan las figuras, as\u00ed que decide realizar un plot o gr\u00e1fico de dispersi\u00f3n de los datos, adem\u00e1s de calcular las m\u00e9tricas enunciadas anteriormente. Extras (y por ende opcionales): Puede realizar un for loop junto con un awk para seleccionar los p\u00e9ptidos relevantes de cada una de las prote\u00ednas (recuerde que en un TP se realiz\u00f3 un awk para seleccionar columnas). Para completar el punto 8., puede usar R para calcular las m\u00e9tricas y ggplot2 para realizar el gr\u00e1fico de dispersi\u00f3n. Algunos links que les pueden resultar \u00fatiles para resolver el punto 8. y los extras: C\u00e1lculo de coeficientes de correlaci\u00f3n en R Scatterplot en ggplot2","title":"TP 7 - HMMs & ANNs"},{"location":"practicos/TP07_HMM_ANN/#tp-7-artificial-neural-networks-anns-y-hidden-markov-models-hmms","text":"Materiales Atenci\u00f3n: Este TP tiene informe.","title":"data-toc-label"},{"location":"practicos/TP07_HMM_ANN/#slides-mostrados-en-la-clase","text":"Explicaci\u00f3n ANNs Explicaci\u00f3n HMMs","title":"Slides mostrados en la clase"},{"location":"practicos/TP07_HMM_ANN/#videos-de-la-clase-grabada","text":"Introducci\u00f3n ANNs Puesta en com\u00fan ANNs Ejercicio guiado HMMer","title":"Videos de la clase grabada"},{"location":"practicos/TP07_HMM_ANN/#objetivos","text":"Comprender c\u00f3mo se entrena y eval\u00faa un modelo basado en redes neuronales. Familiarizarse con el esquema de validaci\u00f3n cruzada para el entrenamiento de dichos modelos. Construir un perfil basado en HMMs y utilizar el mismo para realizar b\u00fasquedas en bases de datos de secuencias. Crear una base de datos de perfiles de secuencias y utilizar la misma para identificar dominios conservados en secuencias query .","title":"Objetivos"},{"location":"practicos/TP07_HMM_ANN/#parte-i-artificial-neural-networks","text":"En esta secci\u00f3n vamos a utilizar redes neuronales para hacer predicciones como hab\u00edamos hecho anteriormente con las PSSM. La idea es similar a la del TP5 donde entrenamos un modelo con p\u00e9ptidos que se unen a MHC. Variaremos los par\u00e1metros de modelo para mejorarlo, sensando en cada corrida los indicadores de desempe\u00f1o del mismo ( Aroc y Pearson correlation coefficient ). Atenci\u00f3n Si no recuerdan qu\u00e9 significan las m\u00e9tricas Aroc y Pearson correlation coefficient (PCC) dir\u00edjanse al TP5 para refrescar estos conceptos. Para esto vamos a volver a utilizar EasyPred y los archivos de Entrenamiento.set y Evaluacion.set en la carpeta del TP (que descargaron al inicio). Entrenamiento.set contiene 1200 p\u00e9ptidos de longitud 9, con un valor asociado de afinidad de uni\u00f3n a HLA-A*02:01 transformado entre 0 y 1. Recuerde que mientras m\u00e1s cercano a 1 el p\u00e9ptido tiene mayor afinidad de uni\u00f3n y que a partir de 0.426 se considera que el p\u00e9ptido es un ligando. Evaluacion.set contiene 66 p\u00e9ptidos, tambi\u00e9n con sus valores correspondientes de afinidad de uni\u00f3n. Para el entrenamiento del modelo se particionar\u00e1 el archivo Entrenamiento.set , de tal manera que una parte se usar\u00e1 para entrenar y la restante se emplear\u00e1 para ir monitoreando el proceso de entrenamiento y as\u00ed evitar el sobreajuste de los pesos de nuestra red. Luego el archivo Evaluacion.set contiene datos independientes, que se utilizar\u00e1n para evaluar la capacidad de generalizaci\u00f3n de nuestro modelo. Tip Es recomendable abrir los archivos y ver qu\u00e9 es lo que contienen. Esto SIEMPRE es una buena pr\u00e1ctica. Nota A lo largo del TP vamos a mantener el valor de Cutoff for counting an example as a positive example en 0.5. Atenci\u00f3n Vayan corriendo las diferentes pruebas en diferentes pesta\u00f1as o guarden el reporte de salida para poder compararlo cuando sea necesario.","title":"Parte I. Artificial neural networks"},{"location":"practicos/TP07_HMM_ANN/#primera-prueba-comprendiendo-los-resultados-que-indican-el-desempeno-de-la-red","text":"Para nuestro primer modelo vamos a ir a EasyPred y cargamos los archivos en los cuadros correspondientes: Luego bajamos hasta la opci\u00f3n Select method d\u00f3nde vamos a cambiar de Matrix method a Neural Network . All\u00ed vamos a poder ver que nos habilita a ingresar otros parametros que est\u00e1n relacionados a la arquitectura y el entrenamiento de la red. Los par\u00e1metros que queremos utilizar en este paso son: Number of hidden units : 2 Number iterations (epochs) to run neural network : 300 Fraction of data to train on (the rest is used to avoid overtraining) : 0.8 Learning rate : 0.05 Use top sequences for training Es decir dejamos los valores por defecto y le damos Submit . Una vez entrenado el modelo, recuerde que puede chequear el desempe\u00f1o del mismo iteraci\u00f3n a iteraci\u00f3n haciendo click en Output from the neural network program (HOW) \u00bfCu\u00e1l es el m\u00e1ximo valor de PCC alcanzado sobre el set de prueba? ( Maximal test set pearson correlation coefficient sum ) \u00bfEn qu\u00e9 iteraci\u00f3n se alcanza ese m\u00e1ximo? \u00bfQu\u00e9 informaci\u00f3n le est\u00e1 dando esto sobre el proceso de entrenamiento del modelo? \u00bfCu\u00e1les son los valores de desempe\u00f1o del modelo sobre el set de evaluaci\u00f3n? (PCC y Aroc) \u00bfEl PCC obtenido en el punto 3. es mayor o menor al obtenido en el punto 1.? \u00bfQu\u00e9 implica este resultado?","title":"Primera prueba: Comprendiendo los resultados que indican el desempe\u00f1o de la red"},{"location":"practicos/TP07_HMM_ANN/#segunda-prueba-cambiando-el-set-de-entrenamiento","text":"Mantenga los mismos par\u00e1metros que en el paso anterior pero esta vez seleccione Use bottom sequences for training . \u00bfCu\u00e1l es el m\u00e1ximo valor de PCC alcanzado sobre el set de prueba y en qu\u00e9 iteraci\u00f3n ocurre esta vez? \u00bfQu\u00e9 valores de desempe\u00f1o alcanza el modelo aplicado al set de evaluaci\u00f3n? \u00bfA qu\u00e9 se debe que no coincidan con lo obtenido en la primera prueba?","title":"Segunda prueba: Cambiando el set de entrenamiento"},{"location":"practicos/TP07_HMM_ANN/#tercera-prueba-cambiando-la-arquitectura-de-la-ann","text":"Repita los par\u00e1metros de la primera prueba excepto por el n\u00famero de neuronas en la capa intermedia o hidden layer : Number of hidden units : 1 Observe el impacto en los par\u00e1metros de desempe\u00f1o del modelo. Guarde los resultados. Repita el ensayo esta vez con: Number of hidden units : 5 Responda a las siguientes preguntas para ambos casos estudiados: \u00bfC\u00f3mo var\u00eda la performance en el set de prueba? \u00bfQu\u00e9 impacto tienen estos cambios en la performance del set de evaluaci\u00f3n? \u00bfPuede elegir un n\u00famero \u00f3ptimo de neuronas para la capa oculta? \u00bfPor qu\u00e9 cree que el n\u00famero de neuronas en la capa oculta tiene tan poco impacto en esta prueba? Piense en el n\u00famero de datos de entrada y el n\u00famero de pesos de la red.","title":"Tercera prueba: Cambiando la arquitectura de la ANN"},{"location":"practicos/TP07_HMM_ANN/#cuarta-prueba-empleando-un-esquema-de-validacion-cruzada","text":"Como deber\u00edan haber notado en las dos primeras pruebas, la partici\u00f3n de los datos que se utilizan en el entrenamiento/prueba influyen significativamente en el desempe\u00f1o del modelo. Como a priori uno no puede establecer cu\u00e1l es la mejor forma de partir los datos en entrenamiento y test se recurre a una estrategia denominada cross-validation . La t\u00e9cnica de validaci\u00f3n cruzada consiste en hacer N particiones (por lo general 5) y rotarlas, utilizando N-1 para entrenar y la N-\u00e9sima (es decir la que queda afuera) como set de prueba. Esto resulta en N modelos diferentes, cada uno entrenado y probado en datos diferentes. Para realizar predicciones en nuevos sets, como el de evaluaci\u00f3n, se realizan predicciones con los N m\u00e9todos y se promedian sus predicciones. Para realizar esta prueba vuelvan a los par\u00e1metros de la Primera prueba pero modifiquen lo siguiente: Number of partitions for cross-validated training : 5 Este paso puede llevar varios minutos. Paciencia. \u00bfEncuentran diferencias entre los desempe\u00f1os de los 5 modelos? \u00bfEs esperable? \u00bfPor qu\u00e9? Comparen los resultados obtenidos para el set de evaluaci\u00f3n con respecto a la primera prueba. En este caso se usa el ensamble de los 5 modelos para realizar las predicciones sobre el set de evaluaci\u00f3n. \u00bfC\u00f3mo piensa que se obtienen los valores predichos?","title":"Cuarta prueba: Empleando un esquema de validaci\u00f3n cruzada"},{"location":"practicos/TP07_HMM_ANN/#utilizando-el-modelo-entrenado","text":"Como vimos en el TP de PSSM, una vez que uno entrena un m\u00e9todo, puede guardar los valores ajustados (ya sea de la matriz en el caso de la PSSM o los pesos de la red en el caso de ANN) y utilizarlos para hacer predicciones en un set nuevo de datos. Guardar el modelo entrenado Para ello vamos a guardar el modelo entrenado en la Cuarta prueba haciendo click derecho en Parameters for prediction method del reporte de resultados y seleccionando \"Guardar enlace como...\" (el archivo se guarda como para.dat ). Este modelo ser\u00e1 utilizado en el ejercicio a entregar de este TP.","title":"Utilizando el modelo entrenado"},{"location":"practicos/TP07_HMM_ANN/#parte-ii-hmmer","text":"Atenci\u00f3n Antes de comenzar ejecuten en la terminal de su VM sudo apt install hmmer2 , para instalar el programa hmmer2 .","title":"Parte II. HMMer"},{"location":"practicos/TP07_HMM_ANN/#introduccion","text":"HMMer es un paquete de programas que nuclea varias funciones para realizar b\u00fasquedas en bases de datos mediante la utilizaci\u00f3n de perfiles de secuencias. Est\u00e1 basado en profile Hidden Markov Models , presentados por Anders Krogh (Krogh et al. , 1994). Estos perfiles son una aproximaci\u00f3n estad\u00edstica del consenso de un alineamiento m\u00faltiple y utilizan un sistema de puntaje posici\u00f3n-espec\u00edfico, en contraste con m\u00e9todos ya vistos como BLAST o FASTA en donde la matriz de puntajes utilizada es la misma en cada posici\u00f3n.","title":"Introducci\u00f3n"},{"location":"practicos/TP07_HMM_ANN/#construccion-de-un-perfil","text":"Supongamos que trabajamos con globinas y queremos buscar hom\u00f3logos lejanos. Para ello contamos con 50 secuencias de globinas las cuales alineamos y guardamos en el archivo globins50.msf . Como primer paso para realizar la b\u00fasqueda debemos generar un profile o perfil que las represente. Para crear el profile utilizamos la funci\u00f3n hmm2build de la siguiente manera: hmm2build globin.hmm globins50.msf hmm2build recibe como argumentos el archivo en el cual va a guardar el perfil ( globin.hmm ) y el archivo con el cual crearlo ( globins50.msf ). Si bien el contenido del archivo donde se guard\u00f3 el perfil es legible, su contenido no deber\u00eda tener sentido para ustedes (m\u00e1s all\u00e1 del encabezado con informaci\u00f3n sobre las opciones que se utilizaron para crearlo) porque \u00fanicamente almacena los pesos de las transiciones de estado del HMM.","title":"Construcci\u00f3n de un perfil"},{"location":"practicos/TP07_HMM_ANN/#calibracion-del-perfil","text":"Este paso no es imprescindible pero s\u00ed aconsejable. La calibraci\u00f3n del perfil le otorga mayor sensibilidad en la b\u00fasqueda ya que modifica la estimaci\u00f3n del E-value de los hits encontrados. Si recuerdan, la b\u00fasqueda contra bases de datos nos devuelve junto con cada alineamiento un score y un E-value, este \u00faltimo nos da una idea sobre la cantidad de hits que esperamos encontrar con ese score en una base de datos construida con secuencias aleatorias y se calcula seg\u00fan la longitud de la secuencia query y subject , el tama\u00f1o de la base de datos y la matriz de scoring . En el caso de HMMer, la estimaci\u00f3n del E-value es anal\u00edtica y resulta muy conservativa, por lo que se dejan de lado posibles hits (como hom\u00f3logos lejanos). Utilizando hmm2calibrate podemos calibrar el c\u00e1lculo de E-values de manera emp\u00edrica incrementando de manera significativa la sensibilidad de la b\u00fasqueda. hmm2calibrate globin.hmm hmm2calibrate lee un archivo con un modelo HMM como globin.hmm y punt\u00faa un n\u00famero grande de secuencias sintetizadas al azar (por default 5000 secuencias) con este modelo. Luego ajusta una EVD (Extreme Value Distribution) al histograma de los puntajes obtenidos y guarda nuevamente el modelo HMM con estos nuevos par\u00e1metros. Como para realizar este c\u00e1lculo se sintetizan secuencias al azar, estableceremos una semilla (o seed ) para poder reproducir nuestros resultados. Entonces el comando se modifica de la siguiente forma, hmm2calibrate --seed 1 globin.hmm","title":"Calibraci\u00f3n del perfil"},{"location":"practicos/TP07_HMM_ANN/#busqueda-en-bases-de-datos","text":"El comando para utilizar nuestro flamante profile en una b\u00fasqueda es hmm2search . En este caso lo vamos a utilizar contra el archivo Artemia.fa que contiene una \u00fanica secuencia de globina en b\u00fasqueda de dominios pertenecientes a nuestra familia de inter\u00e9s. hmm2search globin.hmm Artemia.fa La salida de este comando es m\u00e1s larga que las anteriores, consta de un encabezado con la informaci\u00f3n sobre el programa y los par\u00e1metros que utilizamos en la b\u00fasqueda: hmmsearch - search a sequence database with a profile HMM HMMER 2.3.2 (Oct 2003) Copyright (C) 1992-2003 HHMI/Washington University School of Medicine Freely distributed under the GNU General Public License (GPL) - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - HMM file: globin.hmm [globins50] Sequence database: Artemia.fa per-sequence score cutoff: [none] per-domain score cutoff: [none] per-sequence Eval cutoff: <= 10 per-domain Eval cutoff: [none] - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Query HMM: globins50 Accession: [none] Description: [none] [HMM has been calibrated; E-values are empirical estimates] Una lista parecida a la que da BLAST con los hits m\u00e1s importantes ordenados por su E-value: Scores for complete sequences (score includes all domains): Sequence Description Score E-value N -------- ----------- ----- ------- --- S13421 S13421 GLOBIN - BRINE SHRIMP 120.3 6.2e-37 4 Noten que despu\u00e9s del E-value hay un campo que no se encontraba en los otros algoritmos de b\u00fasqueda denominado \"N\". Este valor representa la cantidad de dominios de nuestro profile que fueron encontrados en el hit. Luego encontramos informaci\u00f3n sobre los dominios de nuestro profile individualmente. Parsed for domains: Sequence Domain seq-f seq-t hmm-f hmm-t score E-value -------- ------- ----- ----- ----- ----- ----- ------- S13421 3/4 771 1075 .. 1 333 [] 34.0 3e-13 S13421 1/4 1 288 [. 1 333 [] 31.9 3.8e-13 S13421 4/4 1085 1390 .. 1 333 [] 29.4 5e-13 S13421 2/4 303 607 .. 1 333 [] 25.0 8.1e-13 Los campos son: el nombre del hit el dominio que se aline\u00f3 (por ej. 2/4 significa que es el dominio Nro 2 de 4 que hay en total en nuestro perfil) seq-f y seq-t son las posiciones del hit donde comienza y termina el alineamiento con ese dominio y el campo siguiente a estos valores (sin nombre) es una codificaci\u00f3n de qu\u00e9 parte de la secuencia fue alineada. los corchetes significan extremos y los puntos posiciones en el medio, por lo que: \"..\" significa que el alineamiento comenz\u00f3 y termin\u00f3 en una posici\u00f3n que no es terminal de la secuencia hit \"[.\" significa que el alineamiento empieza al comienzo de la secuencia y termina en alguna posici\u00f3n en medio al rev\u00e9s, \".]\" empieza en una posici\u00f3n intermedia y termina en el fin de la secuencia por \u00faltimo \"[]\" es que el dominio abarca toda la secuencia. Los tres siguientes campos son an\u00e1logos pero refiri\u00e9ndose a la secuencia del dominio en nuestro perfil HMM. Luego se reportan el score y el E-value. La secci\u00f3n siguiente contiene los alineamientos de los dominios que fueron hit en la lista anterior en un formato similar al de BLAST, teniendo como primera secuencia el consenso del profile (noten que hay amino\u00e1cidos en may\u00fasculas, estos se encuentran altamente conservados en el profile). Al igual que BLAST en medio de ambas secuencias se escriben los amino\u00e1cidos que coinciden o \"matchean\" y signos m\u00e1s (+) en donde hay mismatches con puntaje positivo en la matriz de sustituci\u00f3n. Alignments of top-scoring domains: S13421: domain 3 of 4, from 771 to 1075: score 34.0, E = 3e-13 *->viqealvnssShLsaeeKalvkslWygKV..ggnaeeyGaeaLgRlF L+a eK+ ++++W + ++ g +++ +++++ RlF S13421 771 T-----------LTALEKQSIQDIW-SNLrsTG-LQDLAVKIFTRLF 804 vvYPwTqryFp.hFgdLssldAvkGspkvKAHGkKVltalgdavkhLDdt ++P+ + F + Fg++ + ++ +KAH +Vl+a++ ++ LDd S13421 805 SAHPEYKLLFTgRFGNVDN---INENAPFKAHLHRVLSAFDIVISTLDDS 851 gnlkgalakLSelHAdKLrVDPeNFklLghclivVLAahfgkdFtPevqA + l l++L+ H + L+ ++ +F +++ +++ V + + t S13421 852 EHLIRQLKDLGLFH-TRLGMTRSHFDNFATAFLSVAQDIAPNQLTVLGRE 900 AwdKflagvanaLahKYrelgFQggftviqealvnssShLsaeeKalvks ++ K +++ ++ ++ l t+ Lsa e a vk+ S13421 901 SLNKGFKLMHGVIEEGLLQLERINPITG-----------LSAREVAVVKQ 939 lWygKVggnaeeyGaeaLgRlFvvYPwTqryFphFgdLssldAvkGspkv +W V++++ ++G ++ lF ++P q+ Fp+F+d+ +ld + + p v S13421 940 TW-NLVKPDLMGVGMRIFKSLFEAFPAYQAVFPKFSDV-PLDKLEDTPAV 987 KAHGkKVltalgdavkhLDdtgnlkgalakLSelHAdKLrVDPeNFklLg +H V t l++ + LD nl+ +L+e H LrV Fk +g S13421 988 GKHSISVTTKLDELIQTLDEPANLALLARQLGEDH-IVLRVNKPMFKSFG 1036 hclivVLAahfgkdFtPevqAAwdKflagvanaLahKYr<-* ++l+ L +g F+ + +w K++++++ + ++ S13421 1037 KVLVRLLENDLGQRFSSFASRSWHKAYDVIVEYIEEGLQ 1075 Llegando al final encontramos un histograma, similar al que nos mostraba FASTA. En este caso como nuestra \"base de datos\" tiene una sola secuencia no es informativo en absoluto. Histogram of all scores: score obs exp (one = represents 1 sequences) ----- --- --- 120 1 0|= Y por \u00faltimo algunos detalles estad\u00edsticos que corresponden al ajuste de la EVD, en los cuales no vamos a focalizar. % Statistical details of theoretical EVD fit: mu = -226.7154 lambda = 0.1106 chi-sq statistic = 0.0000 P(chi-square) = 0 Total sequences searched: 1 Whole sequence top hits: tophits_s report: Total hits: 1 Satisfying E cutoff: 1 Total memory: 20K Domain top hits: tophits_s report: Total hits: 4 Satisfying E cutoff: 4 Total memory: 25K","title":"B\u00fasqueda en bases de datos"},{"location":"practicos/TP07_HMM_ANN/#busqueda-en-bases-de-datos-reales","text":"HMMer puede leer los formatos de la mayor\u00eda de las bases de datos conocidas. A diferencia de BLAST no es necesario indexar la base de datos. Si recuerdan de la pr\u00e1ctica de BLAST/FASTA, uno pod\u00eda crear su propia base de datos donde realizar los alineamientos a partir de un archivo multifasta utilizando el comando formatdb , el cual crea todo el sistema de \u00edndices de ktuplas y dem\u00e1s archivos para facilitar la b\u00fasqueda. En este caso HMMer puede realizar la b\u00fasqueda directamente sobre el multifasta sin necesidad de m\u00e1s procesamiento. En nuestro servidor podemos realizar la b\u00fasqueda utilizando: hmm2search globin.hmm ~/Swissprot_db/Swissprot.fasta > globin.swissprot.search less globin.swissprot.search Atenci\u00f3n Este comando no les va a funcionar si no tienen a la carpeta Swissprot_db en su home directory. A tener en cuenta: Notar\u00e1n que la b\u00fasqueda directa aumenta considerablemente el tiempo de c\u00f3mputo necesario para obtener un resultado.","title":"B\u00fasqueda en bases de datos reales"},{"location":"practicos/TP07_HMM_ANN/#modos-de-alineamiento","text":"HMMer no utiliza los m\u00e9todos cl\u00e1sicos de alineamiento ( Smith-Waterman o Needleman-Wunsch ) como el resto de los algoritmos de alineamiento sino que el modo de alinear (local o global) est\u00e1 dado por el modelo que construimos. Por defecto hmm2build lleva a cabo alineamientos que son globales con respecto al HMM y locales con respecto a la secuencia objetivo, permitiendo alinear varios dominios en esa misma secuencia. \u00bfQu\u00e9 significa esto? Que cada dominio se intenta alinear completamente en alguna porci\u00f3n de la secuencia objetivo. Si queremos recuperar secuencias que contengan alineamientos parciales de dominios podemos agregar a hmm2build la opcion -f .","title":"Modos de alineamiento"},{"location":"practicos/TP07_HMM_ANN/#bases-de-datos-de-hmm","text":"As\u00ed como nos es posible realizar b\u00fasquedas de profiles contra bases de datos de secuencias, podemos crear una base de datos de profiles y utilizar como query a una secuencia. Este es el caso de la base de datos PFAM (Sonnhammer et al. , 1997; Sonnhammer et al. , 1998) que nuclea profiles de una gran variedad de dominios y es una herramienta sumamente utilizada para analizar secuencias de prote\u00ednas de las cuales no tenemos informaci\u00f3n previa. Como ejemplo, tomemos el producto del gen Sevenless de Drosophila melanogaster que codifica un receptor de tyrosine kinase esencial para el desarrollo de las c\u00e9lulas R7 del ojo de la mosca. La secuencia proteica de este receptor se encuentra en el archivo 7LES_DROME . Realice una b\u00fasqueda de esta secuencia en PFAM . Para esto haga click en la pesta\u00f1a Sequence en el men\u00fa de la izquierda y pegue la secuencia en el recuadro correspondiente. \u00bfQu\u00e9 dominios fueron identificados en esta prote\u00edna? Recuerde estos resultados para contrastarlo con lo que har\u00e1 m\u00e1s adelante. Las bases de datos de profiles no son m\u00e1s que m\u00faltiples HMMs concatenados, por lo que el comando para construirlas es tambi\u00e9n hmm2build , pero vamos a utilizar la opci\u00f3n -A (append) para agregar nuevos profiles a nuestro archivo de HMMs original. Por ejemplo, si queremos construir una base de datos \"myhmms\" que contiene perfiles de dominios rrm de reconocimiento de ARN, fn3 de fibronectina tipo III y pkinase del dominio catal\u00edtico de las kinasas podemos realizarlo f\u00e1cilmente con: hmm2build -A myhmms rrm.sto hmm2build -A myhmms fn3.sto hmm2build -A myhmms pkinase.sto Para realizar b\u00fasquedas en nuestra nueva base de datos utilizamos el comando hmm2pfam . En este caso empleamos nuevamente, como ejemplo, a la prote\u00edna codificada por el gen Sevenless de Drosophila melanogaster (archivo 7LES_DROME ): hmm2pfam myhmms 7LES_DROME La salida es muy parecida a la de hmm2search pero los hits reportados no ser\u00e1n secuencias sino dominios contenidos en la base de datos. En nuestro caso particular podr\u00e1n notar que tenemos un hit contra un dominio RRM a\u00fan cuando nuestra prote\u00edna query no contiene ning\u00fan dominio de este tipo. Relacionado con esto mismo, \u00bfrecuerdan si la base de datos PFAM identific\u00f3 este dominio en la prote\u00edna de estudio? Nos podemos dar cuenta que este hit es al menos sospechoso debido a su score negativo y su E-value cercano a 1. Por defecto el l\u00edmite de E-value, al igual que BLAST es 10, este umbral es extremadamente permisivo y proclive a devolver ruido. Si queremos ser m\u00e1s quisquillosos podemos utilizar la opci\u00f3n -E seguida del umbral deseado. Por ejemplo: hmm2pfam -E 0 .1 myhmms 7LES_DROME","title":"Bases de datos de HMM"},{"location":"practicos/TP07_HMM_ANN/#adicional-alineamientos-multiples-con-hmm","text":"Otro uso que se les da a los profiles es el de asistir a la hora de llevar a cabo alineamientos m\u00faltiples de grandes cantidades de secuencias. En general este proceso suele ser lento y los alineamientos resultantes contienen errores que requieren curarse a mano. Utilizando HMMs construidos a partir de un alineamiento de unas pocas secuencias representativas, se pueden alinear grandes cantidades de secuencias relacionadas f\u00e1cilmente. Siguiendo con nuestras globinas, tenemos un archivo ( globins630.fa ), que como habr\u00e1n deducido, contiene 630 secuencias de globinas que vamos a alinear utilizando el comando hmm2align : hmm2align -o globins630.ali globin.hmm globins630.fa mediante la opci\u00f3n -o indicamos el archivo en el que deseamos guardar el alineamiento ( globins630.ali ), y como argumentos debemos indicar el profile que vamos a utilizar como \"semilla\" y el archivo con las secuencias a alinear ( globin.hmm y globins630.fa respectivamente). Noten que tambi\u00e9n se puede utilizar la opci\u00f3n --outformat para cambiar el formato del alineamiento producido. Por defecto se utiliza el formato Stockholm , pero tambi\u00e9n puede producir alineamientos en formato MSF , Clustal , Phylip y SELEX .","title":"Adicional: Alineamientos m\u00faltiples con HMM"},{"location":"practicos/TP07_HMM_ANN/#ejercicio-a-informar","text":"Info Fecha l\u00edmite de entrega: Viernes, 30 de Septiembre 2022, 23:59hs.","title":"Ejercicio a informar"},{"location":"practicos/TP07_HMM_ANN/#enunciado","text":"Su jefe analiz\u00f3 los resultados de la identificaci\u00f3n de ligandos de HLA-A02*01 utilizando una PSSM. Lamentablemente no est\u00e1 muy conforme con los resultados porque considera que hay m\u00e9todos mejores para realizar esta predicci\u00f3n. Por lo tanto, usted decide volver a realizar las predicciones, utilizando la red que entren\u00f3 en la cuarta prueba del TP7, para las mismas prote\u00ednas de la variante de coronavirus que est\u00e1 estudiando actualmente. Recordemos que eran las siguientes: prote\u00edna S (spike o prote\u00edna de glicoprote\u00edna de superficie), E (prote\u00edna de la envoltura), M (prote\u00edna de membrana) y N (fosfoprote\u00edna de la nucleoc\u00e1pside). Para lograr su objetivo utilizar\u00e1 la herramienta EasyPred . Como va a realizar una predicci\u00f3n, siga los mismos pasos que realiz\u00f3 para hacer la predicci\u00f3n con la PSSM con la diferencia de que en Load saved prediction method debe subir el archivo con los pesos de la red. Seleccione Sort output on predicted values y apriete el bot\u00f3n Submit query . Interprete la salida que obtiene al correr Easypred . \u00bfCu\u00e1ntas redes se utilizan para realizar las predicciones? \u00bfCu\u00e1ntos p\u00e9ptidos se podr\u00edan considerar ligandos en cada caso? Recuerde los umbrales para la clasificaci\u00f3n de ligandos que enunciamos en los TP5 y TP7. \u00bfCu\u00e1les son los p\u00e9ptidos que elegir\u00eda para testear en el laboratorio de cada una de las prote\u00ednas analizadas? Tenga en cuenta que puede elegir como m\u00e1ximo 5 p\u00e9ptidos en total. Teniendo en cuenta su respuesta al punto 2., \u00bftiene sentido este resultado considerando la alta especificidad del MHC analizado? Ingrese a Seq2Logo y genere un logo con todos los p\u00e9ptidos que etiquet\u00f3 como ligandos. Ajuste los par\u00e1metros seg\u00fan su criterio. En base a los conocimientos adquiridos, \u00bfle parece razonable el motivo hallado para el alelo HLA-A*02:01? \u00bfPuede ver claramente las posiciones ancla? \u00bfQu\u00e9 amino\u00e1cidos son los preferidos para estas posiciones? Compare el logo obtenido con el que construy\u00f3 para el ejercicio final del TP5 (p\u00e9ptidos con un puntaje predicho mayor a 1). \u00bfQu\u00e9 diferencias y similitudes observa? \u00bfQu\u00e9 diferencia observa en el information content (eje y), y a qu\u00e9 se lo atribuye? \u00bfPor qu\u00e9 cree que el motivo generado por redes neuronales es m\u00e1s parecido a lo ya conocido en la literatura que el motivo constru\u00eddo a partir de la PSSM? Ahora compare todas las predicciones realizadas con la PSSM con las obtenidas utilizando la red neuronal. Calcule el coeficiente de correlaci\u00f3n de Pearson y Spearman entre ambos conjuntos de predicciones. Investigue cu\u00e1l de estas dos m\u00e9tricas ser\u00eda la m\u00e1s adecuada para realizar esta comparaci\u00f3n (Pista: \u00bfNot\u00f3 que las predicciones est\u00e1n en diferentes escalas?). Para completar esta tarea puede usar Excel (ver Extras) o cualquier otro programa de su preferencia. A su jefe le gustan las figuras, as\u00ed que decide realizar un plot o gr\u00e1fico de dispersi\u00f3n de los datos, adem\u00e1s de calcular las m\u00e9tricas enunciadas anteriormente. Extras (y por ende opcionales): Puede realizar un for loop junto con un awk para seleccionar los p\u00e9ptidos relevantes de cada una de las prote\u00ednas (recuerde que en un TP se realiz\u00f3 un awk para seleccionar columnas). Para completar el punto 8., puede usar R para calcular las m\u00e9tricas y ggplot2 para realizar el gr\u00e1fico de dispersi\u00f3n. Algunos links que les pueden resultar \u00fatiles para resolver el punto 8. y los extras: C\u00e1lculo de coeficientes de correlaci\u00f3n en R Scatterplot en ggplot2","title":"Enunciado"},{"location":"practicos/TP08a_R/","text":"TP 8a . R - Programando en biolog\u00eda - Parte 1 Videos de la clase grabada Introducci\u00f3n a la programaci\u00f3n en R Puesta en com\u00fan del TP e introducci\u00f3n a funciones Software a usar R (ya instalado en la VM). RStudio (ya instalado en la VM) Recursos Online Curso online de R de Coursera (se puede hacer gratis) (en ese caso no da certificado) Tips de comandos b\u00e1sicos de R Data Tables: Introducci\u00f3n oficial y otra p\u00e1gina con m\u00e1s info ggplot2: Vistazo r\u00e1pido , otra p\u00e1gina con cada plot detallando sus par\u00e1metros y cheatsheet Objetivos Familiarizarse en el lenguaje de programaci\u00f3n R . Ver como los mismos conceptos de programaci\u00f3n se transladan de un lenguaje a otro. Utilizar herramientas de programaci\u00f3n para resolver problemas biol\u00f3gicos. Introducci\u00f3n al Tema En los \u00faltimos a\u00f1os se produjo un crecimiento exponencial tanto en nuestra capacidad de producir informaci\u00f3n biol\u00f3gica como en nuestra capacidad de analizarla. Ensayos de alto rendimiento, o high-throughput , nos permiten analizar miles a millones de interacciones biol\u00f3gicas a la vez, mientras que computadoras de nueva generaci\u00f3n o clusters de ellas nos permiten procesar en d\u00edas u horas lo que en otra \u00e9poca hubiera tomado a\u00f1os. Al momento de analizar datos a esta escala muchos programas conocidos se quedan atr\u00e1s. Si bien Excell o Google Sheets van a poder abrir y procesar una tabla con unos pocos miles de filas, probablemente se cuelguen de tratar de hacer lo mismo para una tabla que contenga millones de ellas. No solo eso, sino que hojas de c\u00e1lculo de ese estilo son bastante limitadas en lo que permiten hacer, donde es muy dificil realizar un an\u00e1lisis o plot que no est\u00e9 entre los predeterminados por ellos. En este trabajo pr\u00e1ctico vamos a aprender a usar el lenguaje de programaci\u00f3n R , el cual es uno de los lenguajes m\u00e1s utilizados hoy en d\u00eda al momento de analizar datos biol\u00f3gicos (junto a Python ) debido a su practicidad al momento de leer, modificar o hacer estad\u00edstica con tablas de gran tama\u00f1o, asi como la gran variedad de figuras (o plots ) que permite crear. Historia de R En 1976 se crea S , un lenguaje de programaci\u00f3n dise\u00f1ado para an\u00e1lisis estad\u00edsticos. S fue creado en Bell Labs, que es el mismo lugar mismo lugar donde se creo Unix (pero por otras personas). En 1991, Ross Ihaka (estad\u00edstico) y Robert Gentleman (estad\u00edstico y bioinform\u00e1tico) empiezan a trabajar en una versi\u00f3n gratis y de c\u00f3digo abierto de S . Debido a sus nombres le ponen R a dicho lenguaje. La primera versi\u00f3n oficial de R fue publicada en 1995 bajo una licencia de c\u00f3digo abierto GNU General Public License . Esta licencia fue creada originalmente para el desarrollo de GNU y Linux , pero hoy en d\u00eda es muy com\u00fan al momento de distribuir programas gratis o de c\u00f3digo abierto. En 1997 se crea CRAN ( Comprehensive R Archive Network ), un repositorio oficial para R as\u00ed como los paquetes creados por usuarios agregaban nuevas funcionalidades a R . Originalmente hab\u00eda solo 12 paquetes, pero a principios del 2022 ya exist\u00edan m\u00e1s de 18.500 diferentes paquetes de R en CRAN . RStudio Cuando nosotros programamos en Bash lo hicimos usando Leafpad , un editor de texto gen\u00e9rico de Lubuntu. Luego al momento de ejecutar nuestro script ibamos a la terminal de Lubuntu y lo ejecutabamos con el comando bash . Si bien esto funciona bien para c\u00f3digos simples, al momento de crear programas complejos puede resultar un poco lento y engorroso. En programaci\u00f3n existen programas denominados entornos de desarrollo o IDE s ( Integrated Development Environment ) que nos permiten programar, encontrar errores ( debuguear ) y correr el script todo desde el mismo lugar. No solo esto, sino que varios IDE s tambi\u00e9n ayudan en el proceso de programar, insertando estructuras vacias ( ifs , fors ) o autocompletando los comandos o par\u00e1metros mientras uno los escribe. Antiguamente los IDEs funcionaban casi exclusivamente para un solo lenguaje de programaci\u00f3n, pero los IDEs m\u00e1s recientes suelen funcionar para varios lenguajes (tras un poco de configuraci\u00f3n). RStudio es el IDE m\u00e1s conocido del lenguaje de programaci\u00f3n R y nos va a ayudar a programar en dicho lenguaje. 1) Abran RStudio en sus computadoras (acceso directo en el escritorio, o desde Inicio Programaci\u00f3n RStudio ). Importante Si les pregunta de actualizar pongan \"Ignore Update\" . Si no estan usando la Maquina Virtual de Introducci\u00f3n a la Bioinform\u00e1tica lean esto: R y RStudio estan ya instalados en la m\u00e1quina virtual que les pasamos. Si no estas usando la m\u00e1quina virtual tenes que instalar ambos siguiendo la gu\u00eda de la p\u00e1gina de RStudio . Tambi\u00e9n hay algunos paquetes de R ya instalados en la m\u00e1quina virtual que van a necesitar instalar cuando aparezcan en las gu\u00edas. Los paquetes se pueden instalar desde R corriendo por ejemplo: install.packages ( \"data.table\" , repos = \"https://cloud.r-project.org\" ) Diferentes versiones de R pueden llegar a usar diferentes versiones de paquetes (y algunos paquetes pueden no ser triviales de instalar en algunas versiones). RStudio se divide en 4 paneles, pero probablemente solo vean 3 ya que todav\u00eda no hemos abierto ning\u00fan archivo. 2) Creen un nuevo script haciendo click en File New File R Script Ahora s\u00ed, deber\u00edan ver lo siguiente: Panel superior izquierdo: Editor de Scripts En este panel est\u00e1 el script que acabamos de crear. Igual que en Bash , un script no es m\u00e1s que un archivo de texto con instrucciones para un lenguaje de programaci\u00f3n espec\u00edfico, que en este caso es R . Este panel puede contener varias pesta\u00f1as al mismo tiempo, cada una con un script diferente. Tambi\u00e9n puede contener pesta\u00f1as con visualizaciones de tablas. Panel inferior izquierdo: Consola La consola (pesta\u00f1a Console ) es similar a la terminal de Lubuntu, pero para el lenguaje de programaci\u00f3n R . En ella podemos escribir comandos en R directamente y ser\u00e1n corridos. Tamb\u00eden es donde vamos a ver la salida de nuestro script de correrlo dentro de RStudio. Hablando de la terminal de Lubuntu, la pesta\u00f1a Terminal es literalmente eso. No vamos a utilizar esta pesta\u00f1a en esta materia. Panel superior derecho: Variables La pesta\u00f1a Environment tiene una lista de todas las variables cargadas en el \"entorno\" que est\u00e1n trabajando, o sea, todas las variables que crearon desde que abrieron RStudio (esto va a quedar m\u00e1s claro cuando corramos c\u00f3digo). De ser posible va a mostrar el valor de la variable y de no serlo va a mostrar alguna informaci\u00f3n al respecto (como el largo de una lista). Para el caso de tablas, pueden hacer click sobre ellas y se abrir\u00e1n en una nueva pesta\u00f1a del panel superior izquierdo. Tener esta lista de variables es muy \u00fatil para aprender a programar en R as\u00ed como para encontrar errores (o debugear ). La pesta\u00f1a History tiene una lista de los \u00faltimos comandos usados y la pesta\u00f1a Connections se usa para unir bases de datos. No vamos a utilizar ninguna de estas pesta\u00f1as en esta materia. Panel inferior derecho: Archivos, Plots y Ayuda La pesta\u00f1a Files es simplemente un explorador de archivos donde pueden navegar entre las carpetas disponibles y visualizar los archivos que encuentren. Es especialmente \u00fatil cuando estan trabajando en proyectos grandes con varios scripts . La pesta\u00f1a Plots es donde apareceran todos los gr\u00e1ficos que vayan generando (o plots ). M\u00e1s adelante veremos m\u00e1s informaci\u00f3n sobre los diferentes botones de esta pesta\u00f1a. Desde la pesta\u00f1a Help podr\u00e1n acceder a toda la ayuda disponible de R y de todos los paquetes y funciones que quieran usar (similar a man en Bash ). Pueden buscar informaci\u00f3n sobre una funci\u00f3n desde la caja de texto junto a la lupa o seleccionando dicho comando en el editor de scripts y apretando F1 . La pesta\u00f1a Packages tiene informaci\u00f3n sobre los paquetes de R instalados y la pesta\u00f1a Viewer es usada para visualizar contenido web local. No vamos a utilizar ninguna de estas pesta\u00f1as en esta materia. Archivos .RHistory En la pesta\u00f1a Files pueden ver un archivo llamado .RHistory . Este es un archivo creado por RStudio que guarda los \u00faltimos comandos corridos (que pueden recorrer en la consola con Up y Down ). Estos archivos pesan poco, pero se van a crear en varios directorios donde trabajemos con R . Si les molesta y no les importa guardar los \u00faltimos comandos usados pueden borrarlos sin problema. Programando en RStudio Ahora que tenemos una idea de la interfaz de RStudio vamos a ver como se crean los programas. 3) En la consola (pesta\u00f1a Console ) escriban lo siguiente y aprieten Enter : print ( \"Hello World!\" ) print es equivalente al echo de bash y cuando lo usamos decimos que imprimimos a la variable. Puede ser que usemos las frases \"imprimir por terminal\" , \"imprimir por consola\" , o \"imprimir por por pantalla\" de forma intercambiable. Como muestra el c\u00f3digo anterior, en R los argumentos van pegados a la funci\u00f3n y entre par\u00e9ntesis; de haber mas de un argumento se separan con comas (dentro de los par\u00e9ntesis). Al correr el c\u00f3digo deber\u00edan ver algo como: [1] \"Hello World!\" El [1] lo est\u00e1 agregando RStudio y se debe a que en R todo es un vector, pero por ahora pueden ignorarlo. Lo que hicimos hasta ahora fue similar a correr un comando en la terminal. Vamos ahora a crear un script de R . 4) En la editor de scripts (que deber\u00eda tener una p\u00e1gina vac\u00eda) escriban: print ( \"Hola Mundo!\" ) Hay varias formas de ejecutar c\u00f3digo desde el editor de scripts, algunas de ellas son: Ejecutar una linea: poner el cursor sobre la linea a correr Ctrl + Enter Ejecutar varias l\u00edneas: seleccionar o pintar las lineas a correr Ctrl + Enter Ejecutar todas las l\u00edneas hasta el cursor: poner el cursor en la \u00faltima l\u00ednea que quiero correr Ctrl + Alt + B Ejecutar todas las l\u00edneas en el script: Ctrl + Alt + R 5) Elijan uno de los m\u00e9todos y corran la l\u00ednea que acabamos de escribir en el editor de scripts . Esto tambi\u00e9n lo pueden hacer a mano desde el men\u00fa Code , pero es recomendado usar los atajos de teclado ya que es algo que van a hacer bastante seguido mientras programan. 6) Por \u00faltimo vamos a guardar nuestro script . Vayan a File Save (o aprieten Ctrl + S ) Creen donde prefieran una carpeta para el TP P\u00f3nganle un nombre al script y gu\u00e1rdenlo Van a ver que Rstudio le agrega autom\u00e1ticamente la extensi\u00f3n .R , que es la extensi\u00f3n usada por los scripts de R y asocia autom\u00e1ticamente dichos scripts con RStudio . Tip - Ejecutando scripts de R desde la terminal de Lubuntu Ahora que creamos un archivo en disco, es posible tambien ejecutar nuestro script de R desde la terminal de Lubuntu. De querer hacerlo, tendr\u00edan que correr: Rscript ARCHIVO_SCRIPT.R Como siempre, reemplazando ARCHIVO_SCRIPT.R por el nombre de su archivo. R: Variables Como dijimos cuando vimos Bash , diferentes lenguajes tienen elementos similares, pero se usan ligeramente diferente. Vamos a entonces a aprender como se usan las variables en R . 1) Escriban en el editor de scripts la siguiente l\u00ednea y corranl\u00e1: saludo <- \"Hola Mundo!\" En R las variables se asignan con el s\u00edmbolo <- (o \"flecha a la izquierda\" ) y se usan mencionando el nombre de la variable. En RStudio se puede insertar el s\u00edmbolo <- rapidamente usando el atajo de teclado Alt + - (signo \"menos\" ). \u00bfSe acuerdan de la pesta\u00f1a Environment de la que hablamos antes? Si la ven ahora va a tener la variable saludo y su valor. 2) Agreguen entonces la siguiente linea al editor de scripts y corran solo esta l\u00ednea: print ( saludo ) No se si se dan cuenta lo que acaba de pasar, pero estan imprimiendo en la consola el valor de una variable que declararon previamente. Esto es un gran beneficio de RStudio , que nos permite guardar valores de variables y usarlos en el futuro, sin tener que correr todo el script de arriba a abajo cada vez que queremos modificar algo. Sin embargo, un gran poder conlleva una gran responsabilidad, ya que este sistema tambi\u00e9n hace posible estar usando un valor \"viejo\" o \"equivocado\" en una variable. La forma correcta de trabajar es ir dejando en nuestro script un registro de las \u00f3rdenes correctas para llegar al output deseado. Tambi\u00e9n es buena pr\u00e1ctica comentar las instrucciones m\u00e1s importantes para que se pueda entender por quien tenga que reutilizar el c\u00f3digo. Es algo as\u00ed como el cuaderno de laboratorio bioinform\u00e1tico . De poner solo el nombre de una variable es equivalente a hacer un print , o sea los siguiente dos comandos son equivalentes: print ( saludo ) saludo Sin embargo, en el c\u00f3digo es recomendable usar print para dejar clara nuestra intenci\u00f3n y evitar ciertos escenarios donde la variable sola no funcionar\u00eda como queremos. Dicho esto, este m\u00e9todo es muy \u00fatil para ver r\u00e1pidamente lo que contiene una variable (hagan doble click en una variable, lo que la selecciona o pinta , y luego aprieten Ctrl + Enter ). Asignar variables con = R tambi\u00e9n permite asignar variables usando el s\u00edmbolo = , por ejemplo, a = \"Hola Mundo!\" funcionar\u00eda perfecto en el c\u00f3digo anterior. Sin embargo, el s\u00edmbolo = tambi\u00e9n es el usado para pasar argumentos y es similar al usado en los condicionales, por lo que se recomienda usar el <- al momento de asignar valores a variables en R . Comentarios Los comentarios en R se hacen de la misma forma que para Bash , ignorando todo lo que est\u00e1 despues de un # . saludo <- \"Hola Mundo!\" # saludo <- \"Esto no va a hacer nada\" print ( saludo ) # print(\"Esto tampoco\") Tip - Comentar en masa Es posible comentar o descomentar grandes secciones de texto. Para esto hay que seleccionar o pintar las lineas y apretar Ctrl + Shift + C . N\u00fameros En R hay 2 tipos principales de variables num\u00e9ricas, numeros enteros (o integer ) y numeros reales (o numeric ). Por temas de simplicidad, es bastante com\u00fan trabajar con variables del tipo numeric por m\u00e1s que esten usando n\u00fameros enteros (y de hecho es lo que hace R por defecto). 3) Prueben correr el pr\u00f3ximo c\u00f3digo l\u00ednea a l\u00ednea y vean como se va modificando el valor de n en el Environment : n <- 2 # *n* es una variable *numeric* # pueden hacer diferentes operaciones matem\u00e1ticas con las variables num\u00e9ricas n <- (( n + 2 ) * 2 ) ^ 2 n <- (( n - 2 ) / 2 ) ^ ( 1 / 2 ) print ( n ) Tip - Averiguar el tipo de una variable Si uno no sabe el tipo de una variable puede usar la funci\u00f3n class() la cual devuelve por consola el tipo de dicha variable. Por ejemplo, en este caso class(n) devolver\u00eda \"numeric\" . Tipos de variables Si bien al momento de trabajar con R vamos a aceptar usar numeric incluso cuando trabajamos con integer , en otros lenguajes de programaci\u00f3n esta diferencia puede ser m\u00e1s estricta por lo que habr\u00eda que usar integer al trabajar con n\u00fameros enteros. Otro factor a considerar es que los integer ocupan menos tama\u00f1o en memoria, lo que puede ser relevante en ciertos casos. Cadenas de caracteres o Strings En R las cadenas de caracteres, comunmente llamadas strings , tienen el tipo de variable character . 4) Prueben correr el pr\u00f3ximo c\u00f3digo l\u00ednea a l\u00ednea, lean los comentarios y vean como se va modificando el valor de la variable frase en el Environment : C\u00f3digo C\u00f3digo con comentarios frase <- \"Hab\u00eda\" frase <- paste ( frase , \"una\" ) frase <- paste ( frase , \"vez\" , sep = \" \" ) frase <- paste ( frase , \"...\" , sep = \"\" ) print ( frase ) frase <- \"Hab\u00eda\" # *frase* es una variable *character* # paste es una funcion de R que concatena strings frase <- paste ( frase , \"una\" ) # Las funciones de R tienen argumentos # *sep* es el argumento que indica que caracter va a ponerse entre las palabras que paste esta pegando # Varios argumentos en R tienen valores por defecto, que son el valor que van a tener si no los aclaro # En el caso de *sep*, el valor por defecto es \" \", por lo que en la siguiente linea podr\u00eda haberlo omitido frase <- paste ( frase , \"vez\" , sep = \" \" ) # Quiero agregar tres puntos, pero no quiero un espacio entre \"vez\" y los puntos # Uso la funcion paste y cambio el argumento *sep* al valor \"\" (que es el string vacio, lo que significa # no agregarle ningun separador) frase <- paste ( frase , \"...\" , sep = \"\" ) print ( frase ) Tip - paste0 Tambi\u00e9n existe en R una funci\u00f3n llamada paste0 , que es igual a paste , pero en la cual el valor por defecto de sep es \"\" (string vacio). Se pueden hacer muchas m\u00e1s cosas con strings en R , como por ejemplo extraer un substrings ( substr o substring ) o buscar si un substring existe dentro del string ( grep , grepl , gsub ), pero las vamos a ir viendo cuando las necesitemos. Ejercicio 1 - Variables simples En este ejercicio vamos a practicar el uso de variables num\u00e9ricas y strings en R : Creen un nuevo script que declare 2 variables, asigne un n\u00famero a cada una, calcule la suma de ambos n\u00fameros y la imprima por la consola. Editen el script anterior agregando 2 otras operaciones matem\u00e1ticas e impriman sus resultados. En el mismo script , creen una nueva variable y asignenle el valor 0. Fijense que pasa si quieren dividir alguno de los otros n\u00fameros por esta nueva variable. Creen un nuevo script que declare 2 variables, asigne un string a cada una, imprima la longitud de cada variable, concatene ambas variables (sin espacio entre ellas) e imprima la concatenaci\u00f3n. Para este \u00faltimo punto van a necesitar la funci\u00f3n nchar() . Pueden ver que hace desde la pesta\u00f1a Help . Tip - Carpetas para los ejercicios Como ya mencionamos varias veces en la materia es recomendado utilizar diferentes carpetas para los diferentes TPs y Ejercicios. Esto es especialmente cierto al momento de trabajar con scripts de R ya que no es raro que un programa real tenga archivos de entrada ( /input ), archivos finales o de salida ( /output ) y archivos temporales ( /temp ). Por ahora probablemente no necesiten crear subcarpetas de este estilo, pero t\u00e9nganlo en cuenta. R: Vectores y Plots Vectores R tiene la variable de tipo vector , que son vectores o arreglos, es decir, listas ordenadas de elementos de un mismo tipo. Vendr\u00edan a ser el equivalente de las listas que vimos de costado en Bash . Es importante ir aclarando que R tambi\u00e9n tiene variables del tipo list que vamos a ver en un rato, y que si bien son similares no son lo mismo. # Los vectores se declaran con c() y sus elementos se separan con \",\" # Este es un vector con 3 elementos de tipo *character* vector_frase <- c ( \"Hab\u00eda\" , \"una\" , \"vez...\" ) # Este es un vector con 10 elementos de tipo *numeric* vector_numeros <- c ( 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ) # Este vector es igual al anterior # R permite usar rangos al momento de definir vectores usando el simbolo \":\" vector_numeros_rango <- c ( 1 : 10 ) # Este vector es igual al anterior # Escribir solo el rango tambi\u00e9n devuelve un vector vector_numeros_rango2 <- 1 : 10 # Es posible combinar \",\" y \":\" # Este vector tiene los valores c(1,2,3,7,8,9,10) vector_numeros_hueco <- c ( 1 : 3 , 7 : 10 ) Los vectores son una parte escencial de R ; de hecho, la mayor\u00eda de las variables son vectores de l\u00f3ngitud 1 (raz\u00f3n por la que aparece el [1] al imprimirlas con print ). Como consecuencia, la mayor\u00eda de las funciones u operaciones de R aceptan reemplazar n\u00fameros o strings por vectores de ellos. 1) Ejecuten el c\u00f3digo anterior para crear los vectores y corran las siguientes l\u00edneas una a la vez. Vean que pasa en cada caso. print ( vector_frase ) print ( vector_numeros ) print ( vector_frase [ 2 ]) # *paste* se puede usar tambien con vectores # En este caso no se usa *sep*, sino *collapse*, pero cumplen la misma funci\u00f3n print ( paste ( vector_frase , collapse = \" \" )) print ( vector_numeros + 2 ) print ( vector_numeros_rango * vector_numeros_rango ) Como pueden ver, en R se puede trabajar con vectores de una forma muy similar a que si trabajaramos con un solo n\u00famero o string , lo que abre la puerta a grandes posibilidades. Otra cosa a destacar de lo anterior es que es posible acceder a una variable individual del vector usando corchetes, donde por ejemplo vector_frase[2] es el segundo valor del vector vector_frase . \u00cdndices de los vectores En R el \u00edndice del primer elemento de los vectores, listas y tablas es el 1. En muchos lenguajes de programaci\u00f3n (incluyendo Python ) el \u00edndice del primer item de un vector es el 0. Esto es algo que es importante acordarse de checkear cuando estas usando vectores en un nuevo lenguaje de programaci\u00f3n. Lo \u00faltimo que queremos volver a remarcar sobre los vectores es que son listas de elementos del mismo tipo . Sin embargo R probablemente no les tire un error si mezclan tipos de variables, sino que va a transformar autom\u00e1ticamente todas las variables a un mismo tipo. 2) Vean que pasa al correr: vector_mixto <- c ( 1 , 2 , \"asd\" ) print ( vector_mixto ) # Aca los n\u00fameros tienen comillas en el *print*, indicando que ya no son m\u00e1s n\u00fameros print ( vector_mixto [ 1 ] + 2 ) # Esto les va a tirar error ya que no puede sumar el n\u00famero 2 al *string* \"1\" Plots simples R tiene muchas formas de hacer plots, especialmente usando paquetes externos. Sin embargo, para empezar vamos a ver las formas que vienen por defecto con R , que si bien crean plots m\u00e1s simples, tambi\u00e9n son m\u00e1s f\u00e1ciles de usar y sirven para hacer una inspecci\u00f3n r\u00e1pida de sus datos. 3) Creen un nuevo script, escriban el siguiente c\u00f3digo y corranl\u00f3: x <- c ( 1 : 100 ) y <- x ^ 2 plot ( x , y ) Si todo funcion\u00f3 bien les deber\u00eda haber aparecido el siguiente plot en la pesta\u00f1a Plots del panel de abajo a la derecha (puede estar mas o menos achatado). La funci\u00f3n plot por defecto hace lo que se denomina \"dot plot\" o \"scatter plot\" , donde dibuja un punto para cada valor (x, y) . 4) En unos minutos vamos a hablar de los botones de la ventana Plots , pero antes corran el siguiente c\u00f3digo: # rnorm es una funci\u00f3n que crea numeros random (o aleatorios) que siguen una distribuci\u00f3n normal # En este caso esta devolviendo 1000 n\u00fameros sacados de una distribuci\u00f3n normal con # media de 15 y un desv\u00edo est\u00e1ndar de 2.5 vector_numeros <- rnorm ( mean = 15 , sd = 2.5 , n = 1000 ) hist ( vector_numeros ) Si todo funcion\u00f3 bien el plot de la pesta\u00f1a Plots deber\u00eda haber cambiado al siguiente plot (como rnorm devuelve valores aleatorios puede no ser id\u00e9ntico). La funci\u00f3n hist hace un histograma de frecuencias a partir de un vector de valores. En la pesta\u00f1a Plots hay varios botones que van a ser muy \u00fatiles al momento de trabajar con plots: Flechas hacia la izquierda y derecha: nos permiten navegar entre los \u00faltimos plots que creamos. Zoom: nos permite abrir una nueva ventana para ver una versi\u00f3n mas grande del plot. Export: nos permite salvar el plot a varios formatos de imagen ( PNG , SVG , etc.) o a PDF . De trabajar con varios plots es com\u00fan salvar las im\u00e1genes desde el c\u00f3digo mismo, pero cuando se trabaja con pocas im\u00e1genes este m\u00e9todo es bastante \u00fatil. Remove the current plot: elimina el plot actual de la lista de plots guardados. Clear all Plots: vac\u00eda la lista de plots guardados. 5) Prueben entonces salvar el plot actual como una imagen PNG usando el bot\u00f3n Export . En la ventana que les va a aparecer pueden cambiar el formato de la imagen y tambi\u00e9n su tama\u00f1o, ya sea ingresando el ancho ( Width ) y el alto ( Height ) o a mano usando el \"triangulo\" de abajo a la derecha (ver figura). Ejercicio 2 - Vectores y plots Para valores enteros de x entre 1 y 200, calculen el y correspondiente a una recta con pendiente 3 y ordenada al origen 5 y hagan el plot de dicha recta usando el comando plot . Una vez creado el plot, salvenl\u00f3 en un archivo con extensi\u00f3n SVG . Tip - Plotear una l\u00ednea Al momento de usar plot pueden agregar el par\u00e1metro type = \"l\" al final para que plotee l\u00edneas en vez de puntos. R: Estructuras l\u00f3gicas Condicionales y Booleanos De igual forma que en Bash , en R tambi\u00e9n existen los condicionales ifs , pero se escriben ligeramente diferente: C\u00f3digo C\u00f3digo con comentarios numero <- 42 print ( paste ( numero , \"es un numero\" )) if ( numero > 10 ) { print ( paste ( numero , \"es mayor a 10\" )) } else { print ( paste ( numero , \"es menor o igual a 10\" )) } numero <- 42 print ( paste ( numero , \"es un numero\" )) # *if* es la estructura m\u00e1s usada para condicionales. # Adentro de los par\u00e9ntesis va la condici\u00f3n. # > es el comparador, o sea, estamos preguntando si la variable *numero* es mayor que 10 if ( numero > 10 ) { # El codigo entre *{* y el primer *}* solo si ejecuta si la condici\u00f3n es verdad, de otra forma se saltea # Este codigo esta m\u00e1s a la derecha, o *indentado*. Esto se hace con tab y en la mayor\u00eda de los lenguajes # es solo para entender m\u00e1s f\u00e1cil el c\u00f3digo (RStudio lo va a hacer autom\u00e1ticamente de pegar c\u00f3digo) print ( paste ( numero , \"es mayor a 10\" )) } else { # El c\u00f3digo entre *else {* y *}* se ejecuta solo cuando la condici\u00f3n no es verdad print ( paste ( numero , \"es menor o igual a 10\" )) } # Este *}* indica donde termina el condicional Es bastante similar a lo que conoc\u00edan, pero aca no esta then ni fi y los diferentes bloques l\u00f3gicos se marcan con llaves (en R esto tambi\u00e9n va a pasar en fors y en muchas otras estructuras). Las condiciones del if existen m\u00e1s alla de los condicionales y de hecho la comparaci\u00f3n numero > 10 es una variable en s\u00ed misma. A estas variables las vamos a llamar booleanos y pueden tener 1 de 2 valores: o TRUE (verdadero) o FALSE (falso). Hay 3 formas principales de generar variables booleanas: # D\u00e1ndoles el valor TRUE o FALSE a mano booleano1 <- TRUE # Usando un comparador, en este caso el *>* numero1 <- 5 booleano2 <- numero1 > 10 # Combinando booleanos con operadores l\u00f3gicos, en este caso con *and* booleano3 <- booleano1 & booleano2 Como mostramos en la tercer forma de generar variables booleanas, se pueden hacer operaciones entre los booleanos usando la llamada algebra booleana . Esto es un mundo en s\u00ed mismo, pero por suerte al momento de programar solo nos van a importar las tres operaciones b\u00e1sicas de la algebra booleana: el AND , el OR y el NOT . El AND y el OR son operaciones entre dos booleanos, mientras que NOT es una operaci\u00f3n que se le aplica a un solo booleano. El AND es el \"Y\" , devolviendo TRUE solo cuando ambos booleanos eran TRUE . Se escribe en R con & El OR es el \"O\" , devolviendo TRUE cuando por lo menos uno de ambos booleanos era TRUE . Se escribe en R con | ( pipe ) El NOT es el \"NO\" , invirtiendo el valor del booleano (o sea, devuelve TRUE solo si el booleano era FALSE ). Se escribe en R con ! Detalles de AND , OR y NOT Booleano 1 Booleano 2 AND (&) OR (|) TRUE TRUE TRUE TRUE TRUE FALSE FALSE TRUE FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE Booleano 1 NOT (!) TRUE FALSE FALSE TRUE Las variables booleanas se pueden usar en los directamente en las condiciones de los ifs . Si bien se pueden comparar contra TRUE y FALSE , de poner solo la variable en la condici\u00f3n del if , es equivalente a preguntar si esa variable es TRUE . Vean las siguientes tres pesta\u00f1as para entenderlo mejor: C\u00f3digo C\u00f3digo con comentarios C\u00f3digo - Versi\u00f3n m\u00ednima llueve <- TRUE tengo_paraguas <- TRUE if (( llueve == TRUE ) & ( tengo_paraguas == FALSE )) { print ( \"Me mojo\" ) } else { print ( \"No me mojo\" ) } llueve <- TRUE tengo_paraguas <- TRUE if (( llueve == TRUE ) & ( tengo_paraguas == FALSE )) { # Aca solo voy a entrar si llueve y no tengo paraguas # Si una o ambas de esas afirmaciones son falsas, entonces se imprime el c\u00f3digo en el *else* print ( \"Me mojo\" ) } else { print ( \"No me mojo\" ) } # T es equivalente a escribir TRUE # F es equivalente a escribir FALSE llueve <- T tengo_paraguas <- T # *llueve* es equivalente a *llueve == TRUE* # *!tengo_paraguas* es equivalente a *(!tengo_paraguas) == TRUE*, o sea, *tengo_paraguas == FALSE* if (( llueve ) & ( ! tengo_paraguas )) { print ( \"Me mojo\" ) } else { print ( \"No me mojo\" ) } Par\u00e9ntesis en las condiciones En la versi\u00f3n m\u00ednima los par\u00e9ntesis internos no son estrictamente necesarios, es decir, que podr\u00edan haber puesto: if ( llueve & ! tengo_paraguas ) { De hecho, la versi\u00f3n del c\u00f3digo que tiene los == tambi\u00e9n andar\u00eda bien de sacarle los par\u00e9ntesis internos, pero esto es mucho m\u00e1s peligroso. Al momento de encadenar condiciones con AND ( & ) u OR ( | ) les recomendamos poner cada condici\u00f3n entre par\u00e9ntesis para evitar errores, especialmente si las condiciones tienen < , > , == , etc. Ciclos Ciclo For En R todos los ciclos for tienen una estructura similar a lo que nosotros llamamos anteriormente ciclos for each . Se escribe de la siguiente forma: C\u00f3digo C\u00f3digo con comentarios for ( i in 1 : 1000 ) { print ( i ) } # *for* es una de las estructuras m\u00e1s usadas para hacer ciclos # *i* es el nombre de la variable que va a cambiar de valor en cada ciclo. Se le podria poner cualquier nombre a # \u00e9sta variable, por ejemplo *numero* en nuestro caso, pero es costumbre ponele *i* # En este caso, *i* va a recorrer cada valor del rango 1:1000 (es decir, del n\u00famero 1 al n\u00famero 1000) for ( i in 1 : 1000 ) { # El c\u00f3digo entre las llaves se va a ejecutar una vez para cada posible *i* en el rango print ( i ) } En este caso el for va a recorrer todos los elementos de un vector de n\u00fameros que v\u00e1 entre 1 y 1000. Tambi\u00e9n podemos recorrer en el for los elementos de un vector previamente declarado, por ejemplo: C\u00f3digo C\u00f3digo con comentarios vector_colores <- c ( \"rojo\" , \"amarillo\" , \"verde\" ) for ( color in vector_colores ) { print ( color ) } vector_colores <- c ( \"rojo\" , \"amarillo\" , \"verde\" ) for ( color in vector_colores ) { # *color* es la variable que va cambiando en cada iteraci\u00f3n del *for* (como antes era *i*) # En este caso va a ir tomando los valores de los diferentes elementos de *vector_colores* print ( color ) } Ciclo While El for es muy \u00fatil, pero tiene el problema de que uno necesita saber cuantas iteraciones va a realizar antes de empezar el ciclo, lo que no es siempre posible. Para casos donde desconocemos el n\u00famero de iteraciones, existen herramientas como el ciclo while que se puede pensar como una combinaci\u00f3n entre el for y el if . El c\u00f3digo dentro de este ciclo se va a repetir mientras se cumpla una condici\u00f3n. Por ejemplo: C\u00f3digo C\u00f3digo con comentarios contador <- 1 while ( contador <= 1000 ) { print ( contador ) contador <- contador + 1 } # Estamos declarando una variable *contador* que vale 1 contador <- 1 # Todo lo que esta adentro del ciclo *while* se va a repetir mientras la condici\u00f3n *contador <= 1000* sea TRUE while ( contador <= 1000 ) { # Imprimo la variable *contador* en la terminal print ( contador ) # Le sumo uno a la variable *contador* # Esto es equivalente al *contador++* de Bash contador <- contador + 1 } Tal vez no se dan cuenta, pero este programa va a hacer lo mismo que el for (i in 1:1000) que usamos arriba: La variable contador va a empezar en 1 y al final de cada ciclo va a aumentarse en 1 gracias al comando contador <- contador + 1 . Cuando contador llegue a 1001, la condici\u00f3n contador <= 1000 va a ser FALSE y el while va a terminar (es decir, el n\u00famero 1001 nunca se imprime en la terminal). Ahora bien, para el caso anterior no tiene mucho sentido usar un ciclo while ya que se podr\u00eda haber hecho perfectamente con un for . Supongamos entonces que queremos escribir las potencias de 2 que son menores a 1.000.000, en ese caso podemos hacer: C\u00f3digo C\u00f3digo con comentarios numero <- 1 while ( numero < 1000000 ) { print ( numero ) numero <- numero * 2 } # Declaro una variable *numero* con el valor 1 (que es 2^0) numero <- 1 # El loop este va a seguir mientras *numero* sea menor a 1 millon while ( numero < 1000000 ) { # Imprimo *numero* en la terminal print ( numero ) # Multiplico a *numero* por 2, lo que me va a dar la pr\u00f3xima potencia de 2 # 2^1 = 2 # 2^2 = 2 * 2 = 4 # 2^3 = 2 * 2 * 2 = 8 # 2^4 = 2 * 2 * 2 * 2 = 16 # etc numero <- numero * 2 } Si bien hay formas de hacer este \u00faltimo loop con un for , esto es m\u00e1s que nada un ejemplo para que entiendan el concepto de que el while nos permite repetir algo una cantidad indeterminada de veces. Loops Infinitos Al usar el ciclo while hay que prestar mucha atenci\u00f3n de no escribir un c\u00f3digo que genere un loop infinito , es decir, un loop donde la condici\u00f3n del while siempre va a ser TRUE . Si pasa esto probablemente se cuelgue R y tendr\u00e1n que reiniciarlo o interrumpirlo para volver a programar. En el ejemplo anterior esto habr\u00eda ocurrido si no hubiesemos puesto la l\u00ednea que aumenta el valor de numero . Ejercicio 3 - Estructuras l\u00f3gicas El objetivo de este ejercicio es hacer un script de R que: Cree una variable llamada resultado y le asigne el valor 0 Cree un for que defina una variable i que recorra los n\u00fameros de 1 a 50 En cada iteraci\u00f3n vamos a sumarle o restarle algo a resultado (guardando el nuevo valor en resultado ): Para todo i menor a 5 o mayor a 47 Restarle i a resultado Para todo i mayor a 20 y menor a 30 Sumarle i a resultado Imprima el valor final de resultado por la consola Tip Aca van a necesitar usar diferentes estructuras ifs adentro del for teniendo en cuenta que hay varias condiciones. R: Tablas Data Frames El Data Frame es el tipo de variable que viene por defecto con R para usar tablas. Hay varias formas de crearlas, pero la m\u00e1s simple es con la funci\u00f3n data.frame() . Por ejemplo: genes <- c ( \"ERT2\" , \"TTR4\" , \"REC1\" ) esencialidad <- c ( F , F , T ) expresiones <- c ( 100 , 1000 , 10000 ) df <- data.frame ( gen = genes , esencial = esencialidad , expresion = expresiones ) Aca estamos creando una variable llamada df que contiene 3 columnas, gen , esencial y expresion , cada una conteniendo los valores de los vectores que declaramos previamente. Noten que los tres vectores tienen la misma cantidad de elementos. El primer elemento de cada vector corresponde a los valores de las columnas para la primera fila de la tabla, y as\u00ed. Tip Una cosa que les puede llamar la atenci\u00f3n es que pusimos los diferentes par\u00e1metros de la funci\u00f3n data.frame en tres l\u00edneas diferentes. Para R es equivalente poner todo en la misma l\u00ednea o como lo hicimos en el ejemplo anterior, lo que ayuda a leer m\u00e1s f\u00e1cil cada uno de los par\u00e1metros. Sin embargo, es importante notar que los saltos de l\u00ednea tienen que ir inmediatamente despu\u00e9s de una coma. Podemos ver los contenidos de la tabla usando el comando: print ( df ) gen esencial expresion 1 ERT2 FALSE 100 2 TTR4 FALSE 1000 3 REC1 TRUE 10000 Data Tables Si bien los Data Frames tienen bastantes funcionalidades, existe un tipo de variable llamada Data Table que b\u00e1sicamente es un Data Frame con muchas mejoras, por lo que va a ser la variable que vamos a usar nosotros al momento de trabajar con tablas. El problema es que las variables Data Tables no vienen por defecto con R , sino que necesitamos usar un paquete externo llamado data.table . Este paquete de R ya est\u00e1 preinstalado en sus m\u00e1quinas virtuales, pero pueden ver como se instala de 0 en la secci\u00f3n RStudio al principio de esta guia. Por m\u00e1s que est\u00e9 instalado el paquete, es necesario cargarlo cada vez que abramos R . Es com\u00fan cargar al principio de cada script todos los paquetes que uno va a usar (no hay problemas al intentar cargar un paquete ya cargado): library ( data.table ) # Esto carga el paquete data.table para poder usar el tipo de variable Data Tables genes <- c ( \"ERT2\" , \"TTR4\" , \"REC1\" ) esencialidad <- c ( F , F , T ) expresiones <- c ( 100 , 1000 , 10000 ) dt <- data.table ( gen = genes , esencial = esencialidad , expresion = expresiones ) print ( dt ) gen esencial expresion 1 ERT2 FALSE 100 2 TTR4 FALSE 1000 3 REC1 TRUE 10000 En los Data Tables vamos a usar el s\u00edmbolo $ para acceder a las diferentes columnas (en cuyo caso va a devolver un vector con los contenidos de dicha columna): print ( dt $ gen ) [ 1 ] \"ERT2\" \"TTR4\" \"REC1\" Por otro lado, podemos usar los corchetes [] de forma similar a como los usabamos en los vectores para devolver una fila espec\u00edfica. print ( dt [ 1 ]) gen esencial expresion 1 : ERT2 FALSE 100 Otra funci\u00f3n que les puede ser util es el comando summary , quien devuelve informaci\u00f3n de las diferentes columnas de la tabla: summary ( dt ) gen esencial expresion Length : 3 Mode : logical Min. : 100 Class : character FALSE : 2 1 st Qu. : 550 Mode : character TRUE : 1 Median : 1000 Mean : 3700 3 rd Qu. : 5500 Max. : 10000 Fijense que summary va a devolver informaci\u00f3n en base a que contiene la columna ( gen tiene strings , por lo que devuelve info general; esencial tiene booleanos , por lo que devuelve la cantidad de cada uno; expresion tiene n\u00fameros, por lo que devuelve varios estad\u00edsticos). Lo \u00faltimo que vamos a aprender hoy sobre Data Tables es a filtar filas, por ejemplo si quisieramos quedarnos solo con aquellas no esenciales ser\u00eda: dt [ esencial == FALSE ] gen esencial expresion 1 : ERT2 FALSE 100 2 : TTR4 FALSE 1000 Algunas ventajas de Data Tables vs Data Frames Lee tablas m\u00e1s r\u00e1pido L\u00edmita autom\u00e1ticamente la s\u00e1lida por terminal al usar print() con tablas muy grandes Permite filtrar sin repetir el nombre de la tabla varias veces Tiene variables internas que facilitan calcular el n\u00famero de filas o el \u00edndice de cada fila Tiene funciones internas que permiten calcular promedio por grupos, por ejemplo \u00a1Y muchas m\u00e1s! Working Directory Esto es algo que lo ven\u00edamos posponiendo desde el principio de este TP, pero ahora vamos a querer leer y escribir archivos de disco, por lo que es necesario. El Working Directory es el path en donde estoy trabajando y compar\u00e1ndolo con lo que hicimos en Bash se puede pensar como en que carpeta est\u00e1 ahora la terminal. En R el comando para saber en que path estoy \"parado\" es la funci\u00f3n getwd() . Si quiero cambiar este path , tengo que usar la funci\u00f3n setwd(\"PATH_ABSOLUTO\") . 1) Creen una carpeta donde van a trabajar, por ejemplo ~/Documentos/TP_08 2) Usen la funci\u00f3n getwd() para ver el Working Directory actual 3) Usen la funci\u00f3n setwd() para asignar la carpeta creada en 1) como Working Directory (recuerden que tienen que pasarle como par\u00e1metro el path absoluto de dicha carpeta) Escribir Tablas Hay varias funciones para escribir tablas, pero la que vamos a usar nosotros es write.table , por ejemplo: write.table ( dt , file = \"ARCHIVO_DT\" , col.names = T , row.names = F , sep = \"\\t\" , quote = T ) Los par\u00e1metros de write.table que estamos usando son: dt es el Data Table que estamos guardando file es donde se escribe el nombre del archivo. Si es un path absoluto se guarda en dicho path , y si es un path relativo es relativo al Working Directory \"ARCHIVO_DT\" suele tener extensi\u00f3n .tsv de separar las columnas con tabs, o extensi\u00f3n .csv de separarlas con comas col.names pregunta si queremos o n\u00f3 guardar el nombre de nuestras columnas en el archivo de salida (puede ser T o F ) row.names pregunta si queremos o n\u00f3 guardar el nombre de nuestras filas en el archivo de salida, el cual generalmente es el n\u00famero de fila (puede ser T o F ) sep indica cual es el separador de columnas. En este caso es \"\\t\" , es decir, Tab quote indica si queremos colocar comillas bordeando a los strings que tengamos en la tabla. Puede ser T o F , o tamb\u00eden puede ser un vector num\u00e9rico que indica a las columnas a las que hay que ponerle comillas (con la primera siendo la n\u00famero 1) 4) Existen algunas tablas en R que estan siempre cargadas en memoria y sirven para probar cosas. Una de estas tablas es iris . Usen print para ver esta tabla y luego usen help(iris) para ver la ayuda relacionada a esta tabla (que explica un poco las columnas). 5) Guarden la tabla iris en un archivo llamado iris.tsv dentro de la carpeta creada en el punto 1) . Usen los par\u00e1metros usados en el ejemplo de arriba. Confirmen que se creo el archivo. Comillas en los archivos .tsv Si abren con Leafpad el archivo iris.tsv reci\u00e9n creado van a ver que los nombres de las columnas y todos los valores de la columna Species estan rodeados por comillas. Estas comillas no son parte de los nombres o valores de las columnas, sino que es la forma que usamos para indicar que lo que est\u00e1 dentro de ellas es un string . Estas comillas aparecen por haber usado el par\u00e1metro quote = T y son \u00fatiles para varios casos, por ejemplo de trabajar con strings con espacios. Data Tables y nombres de las filas Es medio t\u00e9cnico, pero a diferencia de los Data Frames , los Data Tables no pueden tener nombres en las filas (raz\u00f3n por la que estoy usando row.names = F en el c\u00f3digo anterior). Esta es una decisi\u00f3n consciente de los creadores de los Data Tables ya que cualquier informaci\u00f3n que uno quiera almacenar en los nombres de las filas tambi\u00e9n se puede almacenar en una nueva columna, lo que hace mucho m\u00e1s f\u00e1cil trabajar con esa informaci\u00f3n (filtrar, ordenar, etc). Leer Tablas Hay varias funciones para leer tablas, pero la que vamos a usar nosotros es fread , por ejemplo: nuevo_dt <- fread ( \"ARCHIVO_DT\" , header = T , sep = \"\\t\" ) Esta funci\u00f3n es una de las funciones del paquete data.table . Los par\u00e1metros de fread que estamos usando son: nuevo_dt es el nombre de la variable donde se va a cargar la tabla \"ARCHIVO_DT\" es el nombre del archivo a leer. Si es un path absoluto se lee dicho path , y si es un path relativo es relativo al Working Directory header pregunta si nuestro archivo tiene el nombre de nuestras columnas (puede ser T o F ) sep indica cual es el separador de columnas. En este caso es \"\\t\" , es decir, Tab 6) Creen una variable llamada nuevo_dt_iris y carguen la tabla creada en el punto 5) . Usen print para confirmar visualmente que se la tabla se ley\u00f3 bien. Info No se si lo notaron, pero de imprimir iris y nuevo_dt_iris por consola van a ver que se imprimen de forma ligeramente diferente. Esto se debe a que iris es un Data Frame (ya que viene por defecto con R ), mientras que nuevo_dt_iris es un Data Table (por haber sido le\u00eddo con fread ). Ejercicio 4 - Tablas Creen un vector de 5 strings (cualquiera, pero no muy largos) y otro vector de 5 numeros (entre 1 a 10) Creen un Data Table con 2 columnas llamadas col1 y col2 col1 va a contener el vector de strings col2 va a contener el vector de numeros Impriman por pantalla los valores de la columna col1 Impriman por pantalla los valores de la tercera fila de la tabla Impriman por pantalla el valor de col2 de la cuarta fila de la tabla Impriman por pantalla todas las filas donde col2 sea menor o igual a 7 R: Funciones Como ya mencionamos cuando hablamos de los ciclos , es com\u00fan en programaci\u00f3n querer realizar una tarea varias veces en condiciones ligeramente diferentes. Otra herramienta que tenemos a nuestra disposici\u00f3n son las funciones, que ademas de ser parte de R y de los paquetes, pueden ser creadas por nosotros desde 0. Supongamos que por alguna raz\u00f3n es com\u00fan para nosotros querer calcular \\(y = 2x + x^2\\) , podemos entonces hacer: myFunction <- function ( x ) { output <- 2 * x + x ^ 2 return ( output ) } x1 <- 5 x2 <- 7 vector_x3 <- c ( 1 : 100 ) y1 <- myFunction ( x = x1 ) y2 <- myFunction ( x = x2 ) vector_y3 <- myFunction ( x = vector_x3 ) # Ya que estamos hacemos un plot de los vectores (a x1, x2, y1 e y2 no los estoy usando para nada por ahora) plot ( x = vector_x3 , y = vector_y3 ) Si bien en este caso puede no ser super necesario, van viendo como me ahorro bastante c\u00f3digo al usar funciones. Imaginenese ahora si lo que est\u00e1 adentro de la funci\u00f3n es algo mas complejo que ocupa 20 l\u00edneas de c\u00f3digo. Tambi\u00e9n es posible darle m\u00e1s de un par\u00e1metro a una funci\u00f3n, por ejemplo: myFunction <- function ( x , exp = 2 ) { output <- 2 * x + x ^ exp return ( output ) } x1 <- 5 x2 <- 7 vector_x3 <- c ( 1 : 100 ) # El parametro *exp* tiene por defecto el valor 2 # Estas dos lineas de c\u00f3digo devuelven lo mismo y1 <- myFunction ( x = x1 ) y1 <- myFunction ( x = x1 , exp = 2 ) y4 <- myFunction ( x = x2 , exp = 4 ) vector_y5 <- myFunction ( x = vector_x3 , exp = 10 ) plot ( x = vector_x3 , y = vector_y5 ) R: Plots m\u00e1s complejos Si bien la funciones plot e hist se pueden usar para hacer muchos tipos de plots, la mayor\u00eda de los plots hechos por R que uno puede llegar a ver en papers o similar estan hechos con paquetes de R que se especializan en plots. El paquete ggplot2 es uno de los m\u00e1s usados, debido a su gran variedad de plots y a que le permite al usuario modificar practicamente cualquier detalle del plot (con m\u00e1s o menos dificultad). 1) La funci\u00f3n principal del paquete ggplot2 se llama ggplot y comunmente es usada con Data Frames o Data Tables . Entonces, corran el siguiente c\u00f3digo que usa la tabla iris para hacer un ejemplo de un plot simple con ggplot : library ( ggplot2 ) ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length )) + geom_point () data es el par\u00e1metro que indica la tabla de la que se va a sacar la informaci\u00f3n aes es una subfunci\u00f3n a la que le pasamos cual columna es el x y cual el y geom_point() est\u00e1 indicando uno de los varios plots posibles con ese x e y , en este caso es un \"dot plot\" o \"scatter plot\" Si bien es medio extra\u00f1o, las diferentes opciones que le pasamos a ggplot se van a unir con el signo + 2) Existen varias otras funciones de plots y cada una de ellas tiene sus propios par\u00e1metros. Vean como cambia el plot el siguiente c\u00f3digo: ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length )) + geom_point ( shape = 3 , color = \"red\" ) + geom_line ( linetype = \"dashed\" , color = \"blue\" , alpha = 0.25 ) Como dijimos antes hay muchas funciones de ploteo, cada una con muchos par\u00e1metos posibles. Lo m\u00e1s normal al usar ggplot es googlear el uso espec\u00edfico que uno quiere hacer en ese momento y ver como se hace. 3) El siguiente c\u00f3digo es un ejemplo m\u00e1s \"completo\" de un plot hecho con ggplot . Corran el siguiente c\u00f3digo y vean el plot. Fijense si pueden inferir en base a su nombre que hacen algunos de los par\u00e1metros que le pasamos a ggplot (pueden ver el cheatsheet ): ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species )) + geom_point ( size = 1.5 ) + xlim ( c ( 1 , 8 )) + ylim ( c ( 1 , 8 )) + theme_bw () + xlab ( \"Sepal Length\" ) + ylab ( \"Petal Length\" ) + ggtitle ( \"Sepal vs Petal Length per Species\" ) + theme ( plot.title = element_text ( size = 16 , hjust = 0.5 ), axis.title = element_text ( size = 14 ), axis.text = element_text ( size = 12 )) + scale_color_discrete ( labels = c ( \"Setosa\" , \"Versicolor\" , \"Virginica\" )) R: Variables m\u00e1s complejas Listas El concepto de las listas es similar al de los vectores, solo que las listas pueden contener elementos de diferentes tipos (incluyendo vectores, plots, tablas u otras listas). Sin embargo, las listas son estructuras un poco m\u00e1s complejas, por lo que de querer multiplicar cada elemento de una lista por dos no alcanza con hacer lista * 2 . Las listas se crean de la siguiente forma: lista_numeros <- list ( 3 , 4 , 7 , 13 , 45.3 ) lista_strings <- list ( \"hola\" , \"chau\" , \"perro\" ) lista_mixta <- list ( 3 , 4 , 7 , \"perro\" ) Si bien los nombres indicar\u00edan que creamos tres \"tipos\" de lista, en realidad a las listas les da lo mismo si todos sus elementos son del mismo tipo o no. 1) Impriman por pantalla a la lista_mixta . Deber\u00edan ver lo siguiente: [[1]] [1] 3 [[2]] [1] 4 [[3]] [1] 7 [[4]] [1] \"perro\" Hay 2 cosas de inter\u00e9s. Primero que cada elemento esta en su propia fila con un encabezado con su \u00edndice [[i]] , y segundo que los n\u00fameros aca no tienen comillas (como pasaba en los vectores al mezclar tipos de datos) por lo que siguen siendo n\u00fameros. Como sospecharan por los \u00edndices que aparecen, al momento de querer un elemento espec\u00edfico de una lista hay que usar doble corchete, por ejemplo: C\u00f3digo C\u00f3digo con comentarios lista_super_mixta <- list ( 3 , 4 , 7 , \"perro\" , c ( 20 : 30 )) print ( lista_super_mixta [[ 1 ]]) print ( lista_super_mixta [[ 2 ]] + lista_super_mixta [[ 3 ]]) print ( lista_super_mixta [[ 5 ]][ 7 ]) lista_super_mixta <- list ( 3 , 4 , 7 , \"perro\" , c ( 20 : 30 )) # Imprimo el primer elemento de la lista print ( lista_super_mixta [[ 1 ]]) # Esto funciona por ser una lista. Si fuera un vector mixto los n\u00fameros se habr\u00edan transformado en *strings* # y tirar\u00eda un error al tratar de sumarlos print ( lista_super_mixta [[ 2 ]] + lista_super_mixta [[ 3 ]]) # El quinto elemento de la lista es un vector conteniendo los n\u00fameros de 20 a 30 # Estoy imprimiendo el s\u00e9ptimo elemento de dicho vector print ( lista_super_mixta [[ 5 ]][ 7 ]) Si bien las listas tienen sus usos, en esta materia nos vamos a enfocar m\u00e1s en usar vectores. Dicho esto, existen funciones de R que van a devolver listas por defecto. Para transformar estas listas en vectores pueden usar la funci\u00f3n unlist . 2) Prueben usar unlist con la variable lista_super_mixta y vean que pasa. Factores Los factores son un tipo de variable que es usada para cuando tenemos variables categ\u00f3ricas, por ejemplo la columna Species en la tabla iris que vimos anteriormente era una variable de tipo factor . Para entenderlo mejor supongamos que tenemos 5 individuos que fueron tratados con diferentes niveles de una droga y mostraron diferentes resultados. Queremos entonces plotear boxplots mostrando los resultados por cada nivel de tratamiento: 3) Prueben correr el pr\u00f3ximo c\u00f3digo y vean si funciona (spoiler: no va a funcionar). niveles_tratamiento <- c ( \"bajo\" , \"medio\" , \"alto\" , \"alto\" , \"bajo\" ) resultados_tratamiento <- c ( 2 , 5 , 8 , 9 , 4 ) plot ( x = niveles_tratamiento , y = resultados_tratamiento ) El problema con el c\u00f3digo anterior es que plot no sabe que hacer cuando uno le pasa un vector de strings , es decir, no entiende que son categor\u00edas. Necesitamos entonces transformar nuestros datos en factores. 4) Vean que pasa de correr el siguiente c\u00f3digo: niveles_tratamiento <- c ( \"bajo\" , \"medio\" , \"alto\" , \"alto\" , \"bajo\" ) resultados_tratamiento <- c ( 2 , 5 , 8 , 9 , 4 ) factor_niveles_tratamiento <- factor ( niveles_tratamiento ) plot ( x = factor_niveles_tratamiento , y = resultados_tratamiento ) En este momento aunque sea vemos un plot, pero si se fijan en el eje X tenemos un problema: los niveles de tratamiento no est\u00e1n en un \u00f3rden l\u00f3gico. Cuando uno crea factores puede asignar este orden a mano. 5) Cambien entonces el c\u00f3digo anterior al c\u00f3digo siguiente y corranl\u00f3: niveles_tratamiento <- c ( \"bajo\" , \"medio\" , \"alto\" , \"alto\" , \"bajo\" ) resultados_tratamiento <- c ( 2 , 5 , 8 , 9 , 4 ) factor_niveles_tratamiento <- factor ( niveles_tratamiento , levels = c ( \"bajo\" , \"medio\" , \"alto\" )) plot ( x = factor_niveles_tratamiento , y = resultados_tratamiento ) Como ven el par\u00e1metro levels nos permite indicar a mano el orden de los factores. 6) Impriman por consola a niveles_tratamiento y a factor_niveles_tratamiento y vean las diferencias. Factores y ggplot2 La funci\u00f3n ggplot transforma lista de strings a factores automaticamente al momento de plotear, por lo que no va a dar error de haber usado niveles_tratamiento (en una columna de un Data Table ). Sin embargo, los factores siguen siendo \u00fatiles en estos casos para controlar el \u00f3rden en los que se plotean las variables categ\u00f3ricas. Estructura interna de los factores Esto es un poco t\u00e9cnico, pero otro beneficio de los factores es que ahorran memoria. Esto se debe a que en realidad no se guardan como una lista de strings , sino que R le asigna un n\u00famero a cada level y eso es lo que realmente guarda para todos los datos. Esto se puede ver con la funci\u00f3n as.numeric() : as.numeric ( factor_niveles_tratamiento ) [ 1 ] 1 2 3 3 1 Averiguar el tipo de las variables Muchas veces queremos operar con variables y obtenemos errores puesto que son de un tipo distinto al que esper\u00e1bamos. \u00bfC\u00f3mo podemos averiguar entonces de que tipo son las variables? Sabemos que si tienen comillas es texto, pero esto no alcanza. La forma correcta de saber que tipo de variable es una variable es usando las funciones class() o typeof() . No vamos a detallar mucho estas funciones, pero class() suele devolver el nombre de la variable a la que estamos acostumbrados ( numeric , factor , etc), mientras que typeof() devuelve como se almacena esa variable internamente. 7) Vean que devuelve class() y typeof() para las siguientes variables (en algunos casos typeof() va a ser un poco raro): library ( data.table ) numero <- 2 cadena <- \"uno dos tres\" booleano <- TRUE vector_numeros <- c ( 1 , 2 , 3 ) vector_strings <- c ( \"uno\" , \"dos\" , \"tres\" ) df <- data.frame ( numeros = vector_numeros , strings = vector_strings ) dt <- data.table ( numeros = vector_numeros , strings = vector_strings ) factor_vector_strings <- factor ( vector_strings , levels = c ( \"dos\" , \"tres\" , \"uno\" )) class ( numero ) typeof ( numero ) Ejercicio Adicional 1 En este Ejercicio vamos a ver si los n\u00fameros aleatorios de R se portan como deber\u00edan. Para esto vamos a hacer un script que: Tire una moneda Anote si sali\u00f3 cara o seca Repita los pasos anteriores hasta tener 100 caras o 100 secas (o dicho de otra forma, repita los pasos mientras no tenga 100 caras ni 100 secas) Imprima por pantalla cuantas secas y cuantas caras obtuvo (usar paste para que que en la salida se entienda bien que n\u00famero corresponde a quien) Una cosa que van a necesitar para hacer esto es la siguiente funci\u00f3n: moneda <- sample ( x = c ( \"Cara\" , \"Seca\" ), size = 1 ) Donde sample devuelve un sampleo al azar de size elementos (en este caso 1 ) del vector x (en este caso c(\"Cara\", \"Seca\") ). En definitiva esto quiere decir que cada vez que ejecuten esa l\u00ednea moneda va a recibir el valor \"Cara\" o el valor \"Seca\" al azar. Ejecuten el c\u00f3digo anterior varias veces y vean si los n\u00fameros aleatorios funcionan bien en R o si est\u00e1 todo arreglado. Bibliograf\u00eda Consola de R Comando help()","title":"TP 8a - R - Introducci\u00f3n"},{"location":"practicos/TP08a_R/#tp-8a-r-programando-en-biologia-parte-1","text":"","title":"data-toc-label"},{"location":"practicos/TP08a_R/#videos-de-la-clase-grabada","text":"Introducci\u00f3n a la programaci\u00f3n en R Puesta en com\u00fan del TP e introducci\u00f3n a funciones","title":"Videos de la clase grabada"},{"location":"practicos/TP08a_R/#software-a-usar","text":"R (ya instalado en la VM). RStudio (ya instalado en la VM)","title":"Software a usar"},{"location":"practicos/TP08a_R/#recursos-online","text":"Curso online de R de Coursera (se puede hacer gratis) (en ese caso no da certificado) Tips de comandos b\u00e1sicos de R Data Tables: Introducci\u00f3n oficial y otra p\u00e1gina con m\u00e1s info ggplot2: Vistazo r\u00e1pido , otra p\u00e1gina con cada plot detallando sus par\u00e1metros y cheatsheet","title":"Recursos Online"},{"location":"practicos/TP08a_R/#objetivos","text":"Familiarizarse en el lenguaje de programaci\u00f3n R . Ver como los mismos conceptos de programaci\u00f3n se transladan de un lenguaje a otro. Utilizar herramientas de programaci\u00f3n para resolver problemas biol\u00f3gicos.","title":"Objetivos"},{"location":"practicos/TP08a_R/#introduccion-al-tema","text":"En los \u00faltimos a\u00f1os se produjo un crecimiento exponencial tanto en nuestra capacidad de producir informaci\u00f3n biol\u00f3gica como en nuestra capacidad de analizarla. Ensayos de alto rendimiento, o high-throughput , nos permiten analizar miles a millones de interacciones biol\u00f3gicas a la vez, mientras que computadoras de nueva generaci\u00f3n o clusters de ellas nos permiten procesar en d\u00edas u horas lo que en otra \u00e9poca hubiera tomado a\u00f1os. Al momento de analizar datos a esta escala muchos programas conocidos se quedan atr\u00e1s. Si bien Excell o Google Sheets van a poder abrir y procesar una tabla con unos pocos miles de filas, probablemente se cuelguen de tratar de hacer lo mismo para una tabla que contenga millones de ellas. No solo eso, sino que hojas de c\u00e1lculo de ese estilo son bastante limitadas en lo que permiten hacer, donde es muy dificil realizar un an\u00e1lisis o plot que no est\u00e9 entre los predeterminados por ellos. En este trabajo pr\u00e1ctico vamos a aprender a usar el lenguaje de programaci\u00f3n R , el cual es uno de los lenguajes m\u00e1s utilizados hoy en d\u00eda al momento de analizar datos biol\u00f3gicos (junto a Python ) debido a su practicidad al momento de leer, modificar o hacer estad\u00edstica con tablas de gran tama\u00f1o, asi como la gran variedad de figuras (o plots ) que permite crear.","title":"Introducci\u00f3n al Tema"},{"location":"practicos/TP08a_R/#historia-de-r","text":"En 1976 se crea S , un lenguaje de programaci\u00f3n dise\u00f1ado para an\u00e1lisis estad\u00edsticos. S fue creado en Bell Labs, que es el mismo lugar mismo lugar donde se creo Unix (pero por otras personas). En 1991, Ross Ihaka (estad\u00edstico) y Robert Gentleman (estad\u00edstico y bioinform\u00e1tico) empiezan a trabajar en una versi\u00f3n gratis y de c\u00f3digo abierto de S . Debido a sus nombres le ponen R a dicho lenguaje. La primera versi\u00f3n oficial de R fue publicada en 1995 bajo una licencia de c\u00f3digo abierto GNU General Public License . Esta licencia fue creada originalmente para el desarrollo de GNU y Linux , pero hoy en d\u00eda es muy com\u00fan al momento de distribuir programas gratis o de c\u00f3digo abierto. En 1997 se crea CRAN ( Comprehensive R Archive Network ), un repositorio oficial para R as\u00ed como los paquetes creados por usuarios agregaban nuevas funcionalidades a R . Originalmente hab\u00eda solo 12 paquetes, pero a principios del 2022 ya exist\u00edan m\u00e1s de 18.500 diferentes paquetes de R en CRAN .","title":"Historia de R"},{"location":"practicos/TP08a_R/#rstudio","text":"Cuando nosotros programamos en Bash lo hicimos usando Leafpad , un editor de texto gen\u00e9rico de Lubuntu. Luego al momento de ejecutar nuestro script ibamos a la terminal de Lubuntu y lo ejecutabamos con el comando bash . Si bien esto funciona bien para c\u00f3digos simples, al momento de crear programas complejos puede resultar un poco lento y engorroso. En programaci\u00f3n existen programas denominados entornos de desarrollo o IDE s ( Integrated Development Environment ) que nos permiten programar, encontrar errores ( debuguear ) y correr el script todo desde el mismo lugar. No solo esto, sino que varios IDE s tambi\u00e9n ayudan en el proceso de programar, insertando estructuras vacias ( ifs , fors ) o autocompletando los comandos o par\u00e1metros mientras uno los escribe. Antiguamente los IDEs funcionaban casi exclusivamente para un solo lenguaje de programaci\u00f3n, pero los IDEs m\u00e1s recientes suelen funcionar para varios lenguajes (tras un poco de configuraci\u00f3n). RStudio es el IDE m\u00e1s conocido del lenguaje de programaci\u00f3n R y nos va a ayudar a programar en dicho lenguaje. 1) Abran RStudio en sus computadoras (acceso directo en el escritorio, o desde Inicio Programaci\u00f3n RStudio ). Importante Si les pregunta de actualizar pongan \"Ignore Update\" . Si no estan usando la Maquina Virtual de Introducci\u00f3n a la Bioinform\u00e1tica lean esto: R y RStudio estan ya instalados en la m\u00e1quina virtual que les pasamos. Si no estas usando la m\u00e1quina virtual tenes que instalar ambos siguiendo la gu\u00eda de la p\u00e1gina de RStudio . Tambi\u00e9n hay algunos paquetes de R ya instalados en la m\u00e1quina virtual que van a necesitar instalar cuando aparezcan en las gu\u00edas. Los paquetes se pueden instalar desde R corriendo por ejemplo: install.packages ( \"data.table\" , repos = \"https://cloud.r-project.org\" ) Diferentes versiones de R pueden llegar a usar diferentes versiones de paquetes (y algunos paquetes pueden no ser triviales de instalar en algunas versiones). RStudio se divide en 4 paneles, pero probablemente solo vean 3 ya que todav\u00eda no hemos abierto ning\u00fan archivo. 2) Creen un nuevo script haciendo click en File New File R Script Ahora s\u00ed, deber\u00edan ver lo siguiente: Panel superior izquierdo: Editor de Scripts En este panel est\u00e1 el script que acabamos de crear. Igual que en Bash , un script no es m\u00e1s que un archivo de texto con instrucciones para un lenguaje de programaci\u00f3n espec\u00edfico, que en este caso es R . Este panel puede contener varias pesta\u00f1as al mismo tiempo, cada una con un script diferente. Tambi\u00e9n puede contener pesta\u00f1as con visualizaciones de tablas. Panel inferior izquierdo: Consola La consola (pesta\u00f1a Console ) es similar a la terminal de Lubuntu, pero para el lenguaje de programaci\u00f3n R . En ella podemos escribir comandos en R directamente y ser\u00e1n corridos. Tamb\u00eden es donde vamos a ver la salida de nuestro script de correrlo dentro de RStudio. Hablando de la terminal de Lubuntu, la pesta\u00f1a Terminal es literalmente eso. No vamos a utilizar esta pesta\u00f1a en esta materia. Panel superior derecho: Variables La pesta\u00f1a Environment tiene una lista de todas las variables cargadas en el \"entorno\" que est\u00e1n trabajando, o sea, todas las variables que crearon desde que abrieron RStudio (esto va a quedar m\u00e1s claro cuando corramos c\u00f3digo). De ser posible va a mostrar el valor de la variable y de no serlo va a mostrar alguna informaci\u00f3n al respecto (como el largo de una lista). Para el caso de tablas, pueden hacer click sobre ellas y se abrir\u00e1n en una nueva pesta\u00f1a del panel superior izquierdo. Tener esta lista de variables es muy \u00fatil para aprender a programar en R as\u00ed como para encontrar errores (o debugear ). La pesta\u00f1a History tiene una lista de los \u00faltimos comandos usados y la pesta\u00f1a Connections se usa para unir bases de datos. No vamos a utilizar ninguna de estas pesta\u00f1as en esta materia. Panel inferior derecho: Archivos, Plots y Ayuda La pesta\u00f1a Files es simplemente un explorador de archivos donde pueden navegar entre las carpetas disponibles y visualizar los archivos que encuentren. Es especialmente \u00fatil cuando estan trabajando en proyectos grandes con varios scripts . La pesta\u00f1a Plots es donde apareceran todos los gr\u00e1ficos que vayan generando (o plots ). M\u00e1s adelante veremos m\u00e1s informaci\u00f3n sobre los diferentes botones de esta pesta\u00f1a. Desde la pesta\u00f1a Help podr\u00e1n acceder a toda la ayuda disponible de R y de todos los paquetes y funciones que quieran usar (similar a man en Bash ). Pueden buscar informaci\u00f3n sobre una funci\u00f3n desde la caja de texto junto a la lupa o seleccionando dicho comando en el editor de scripts y apretando F1 . La pesta\u00f1a Packages tiene informaci\u00f3n sobre los paquetes de R instalados y la pesta\u00f1a Viewer es usada para visualizar contenido web local. No vamos a utilizar ninguna de estas pesta\u00f1as en esta materia. Archivos .RHistory En la pesta\u00f1a Files pueden ver un archivo llamado .RHistory . Este es un archivo creado por RStudio que guarda los \u00faltimos comandos corridos (que pueden recorrer en la consola con Up y Down ). Estos archivos pesan poco, pero se van a crear en varios directorios donde trabajemos con R . Si les molesta y no les importa guardar los \u00faltimos comandos usados pueden borrarlos sin problema.","title":"RStudio"},{"location":"practicos/TP08a_R/#programando-en-rstudio","text":"Ahora que tenemos una idea de la interfaz de RStudio vamos a ver como se crean los programas. 3) En la consola (pesta\u00f1a Console ) escriban lo siguiente y aprieten Enter : print ( \"Hello World!\" ) print es equivalente al echo de bash y cuando lo usamos decimos que imprimimos a la variable. Puede ser que usemos las frases \"imprimir por terminal\" , \"imprimir por consola\" , o \"imprimir por por pantalla\" de forma intercambiable. Como muestra el c\u00f3digo anterior, en R los argumentos van pegados a la funci\u00f3n y entre par\u00e9ntesis; de haber mas de un argumento se separan con comas (dentro de los par\u00e9ntesis). Al correr el c\u00f3digo deber\u00edan ver algo como: [1] \"Hello World!\" El [1] lo est\u00e1 agregando RStudio y se debe a que en R todo es un vector, pero por ahora pueden ignorarlo. Lo que hicimos hasta ahora fue similar a correr un comando en la terminal. Vamos ahora a crear un script de R . 4) En la editor de scripts (que deber\u00eda tener una p\u00e1gina vac\u00eda) escriban: print ( \"Hola Mundo!\" ) Hay varias formas de ejecutar c\u00f3digo desde el editor de scripts, algunas de ellas son: Ejecutar una linea: poner el cursor sobre la linea a correr Ctrl + Enter Ejecutar varias l\u00edneas: seleccionar o pintar las lineas a correr Ctrl + Enter Ejecutar todas las l\u00edneas hasta el cursor: poner el cursor en la \u00faltima l\u00ednea que quiero correr Ctrl + Alt + B Ejecutar todas las l\u00edneas en el script: Ctrl + Alt + R 5) Elijan uno de los m\u00e9todos y corran la l\u00ednea que acabamos de escribir en el editor de scripts . Esto tambi\u00e9n lo pueden hacer a mano desde el men\u00fa Code , pero es recomendado usar los atajos de teclado ya que es algo que van a hacer bastante seguido mientras programan. 6) Por \u00faltimo vamos a guardar nuestro script . Vayan a File Save (o aprieten Ctrl + S ) Creen donde prefieran una carpeta para el TP P\u00f3nganle un nombre al script y gu\u00e1rdenlo Van a ver que Rstudio le agrega autom\u00e1ticamente la extensi\u00f3n .R , que es la extensi\u00f3n usada por los scripts de R y asocia autom\u00e1ticamente dichos scripts con RStudio . Tip - Ejecutando scripts de R desde la terminal de Lubuntu Ahora que creamos un archivo en disco, es posible tambien ejecutar nuestro script de R desde la terminal de Lubuntu. De querer hacerlo, tendr\u00edan que correr: Rscript ARCHIVO_SCRIPT.R Como siempre, reemplazando ARCHIVO_SCRIPT.R por el nombre de su archivo.","title":"Programando en RStudio"},{"location":"practicos/TP08a_R/#r-variables","text":"Como dijimos cuando vimos Bash , diferentes lenguajes tienen elementos similares, pero se usan ligeramente diferente. Vamos a entonces a aprender como se usan las variables en R . 1) Escriban en el editor de scripts la siguiente l\u00ednea y corranl\u00e1: saludo <- \"Hola Mundo!\" En R las variables se asignan con el s\u00edmbolo <- (o \"flecha a la izquierda\" ) y se usan mencionando el nombre de la variable. En RStudio se puede insertar el s\u00edmbolo <- rapidamente usando el atajo de teclado Alt + - (signo \"menos\" ). \u00bfSe acuerdan de la pesta\u00f1a Environment de la que hablamos antes? Si la ven ahora va a tener la variable saludo y su valor. 2) Agreguen entonces la siguiente linea al editor de scripts y corran solo esta l\u00ednea: print ( saludo ) No se si se dan cuenta lo que acaba de pasar, pero estan imprimiendo en la consola el valor de una variable que declararon previamente. Esto es un gran beneficio de RStudio , que nos permite guardar valores de variables y usarlos en el futuro, sin tener que correr todo el script de arriba a abajo cada vez que queremos modificar algo. Sin embargo, un gran poder conlleva una gran responsabilidad, ya que este sistema tambi\u00e9n hace posible estar usando un valor \"viejo\" o \"equivocado\" en una variable. La forma correcta de trabajar es ir dejando en nuestro script un registro de las \u00f3rdenes correctas para llegar al output deseado. Tambi\u00e9n es buena pr\u00e1ctica comentar las instrucciones m\u00e1s importantes para que se pueda entender por quien tenga que reutilizar el c\u00f3digo. Es algo as\u00ed como el cuaderno de laboratorio bioinform\u00e1tico . De poner solo el nombre de una variable es equivalente a hacer un print , o sea los siguiente dos comandos son equivalentes: print ( saludo ) saludo Sin embargo, en el c\u00f3digo es recomendable usar print para dejar clara nuestra intenci\u00f3n y evitar ciertos escenarios donde la variable sola no funcionar\u00eda como queremos. Dicho esto, este m\u00e9todo es muy \u00fatil para ver r\u00e1pidamente lo que contiene una variable (hagan doble click en una variable, lo que la selecciona o pinta , y luego aprieten Ctrl + Enter ). Asignar variables con = R tambi\u00e9n permite asignar variables usando el s\u00edmbolo = , por ejemplo, a = \"Hola Mundo!\" funcionar\u00eda perfecto en el c\u00f3digo anterior. Sin embargo, el s\u00edmbolo = tambi\u00e9n es el usado para pasar argumentos y es similar al usado en los condicionales, por lo que se recomienda usar el <- al momento de asignar valores a variables en R .","title":"R: Variables"},{"location":"practicos/TP08a_R/#comentarios","text":"Los comentarios en R se hacen de la misma forma que para Bash , ignorando todo lo que est\u00e1 despues de un # . saludo <- \"Hola Mundo!\" # saludo <- \"Esto no va a hacer nada\" print ( saludo ) # print(\"Esto tampoco\") Tip - Comentar en masa Es posible comentar o descomentar grandes secciones de texto. Para esto hay que seleccionar o pintar las lineas y apretar Ctrl + Shift + C .","title":"Comentarios"},{"location":"practicos/TP08a_R/#numeros","text":"En R hay 2 tipos principales de variables num\u00e9ricas, numeros enteros (o integer ) y numeros reales (o numeric ). Por temas de simplicidad, es bastante com\u00fan trabajar con variables del tipo numeric por m\u00e1s que esten usando n\u00fameros enteros (y de hecho es lo que hace R por defecto). 3) Prueben correr el pr\u00f3ximo c\u00f3digo l\u00ednea a l\u00ednea y vean como se va modificando el valor de n en el Environment : n <- 2 # *n* es una variable *numeric* # pueden hacer diferentes operaciones matem\u00e1ticas con las variables num\u00e9ricas n <- (( n + 2 ) * 2 ) ^ 2 n <- (( n - 2 ) / 2 ) ^ ( 1 / 2 ) print ( n ) Tip - Averiguar el tipo de una variable Si uno no sabe el tipo de una variable puede usar la funci\u00f3n class() la cual devuelve por consola el tipo de dicha variable. Por ejemplo, en este caso class(n) devolver\u00eda \"numeric\" . Tipos de variables Si bien al momento de trabajar con R vamos a aceptar usar numeric incluso cuando trabajamos con integer , en otros lenguajes de programaci\u00f3n esta diferencia puede ser m\u00e1s estricta por lo que habr\u00eda que usar integer al trabajar con n\u00fameros enteros. Otro factor a considerar es que los integer ocupan menos tama\u00f1o en memoria, lo que puede ser relevante en ciertos casos.","title":"N\u00fameros"},{"location":"practicos/TP08a_R/#cadenas-de-caracteres-o-strings","text":"En R las cadenas de caracteres, comunmente llamadas strings , tienen el tipo de variable character . 4) Prueben correr el pr\u00f3ximo c\u00f3digo l\u00ednea a l\u00ednea, lean los comentarios y vean como se va modificando el valor de la variable frase en el Environment : C\u00f3digo C\u00f3digo con comentarios frase <- \"Hab\u00eda\" frase <- paste ( frase , \"una\" ) frase <- paste ( frase , \"vez\" , sep = \" \" ) frase <- paste ( frase , \"...\" , sep = \"\" ) print ( frase ) frase <- \"Hab\u00eda\" # *frase* es una variable *character* # paste es una funcion de R que concatena strings frase <- paste ( frase , \"una\" ) # Las funciones de R tienen argumentos # *sep* es el argumento que indica que caracter va a ponerse entre las palabras que paste esta pegando # Varios argumentos en R tienen valores por defecto, que son el valor que van a tener si no los aclaro # En el caso de *sep*, el valor por defecto es \" \", por lo que en la siguiente linea podr\u00eda haberlo omitido frase <- paste ( frase , \"vez\" , sep = \" \" ) # Quiero agregar tres puntos, pero no quiero un espacio entre \"vez\" y los puntos # Uso la funcion paste y cambio el argumento *sep* al valor \"\" (que es el string vacio, lo que significa # no agregarle ningun separador) frase <- paste ( frase , \"...\" , sep = \"\" ) print ( frase ) Tip - paste0 Tambi\u00e9n existe en R una funci\u00f3n llamada paste0 , que es igual a paste , pero en la cual el valor por defecto de sep es \"\" (string vacio). Se pueden hacer muchas m\u00e1s cosas con strings en R , como por ejemplo extraer un substrings ( substr o substring ) o buscar si un substring existe dentro del string ( grep , grepl , gsub ), pero las vamos a ir viendo cuando las necesitemos.","title":"Cadenas de caracteres"},{"location":"practicos/TP08a_R/#ejercicio-1-variables-simples","text":"En este ejercicio vamos a practicar el uso de variables num\u00e9ricas y strings en R : Creen un nuevo script que declare 2 variables, asigne un n\u00famero a cada una, calcule la suma de ambos n\u00fameros y la imprima por la consola. Editen el script anterior agregando 2 otras operaciones matem\u00e1ticas e impriman sus resultados. En el mismo script , creen una nueva variable y asignenle el valor 0. Fijense que pasa si quieren dividir alguno de los otros n\u00fameros por esta nueva variable. Creen un nuevo script que declare 2 variables, asigne un string a cada una, imprima la longitud de cada variable, concatene ambas variables (sin espacio entre ellas) e imprima la concatenaci\u00f3n. Para este \u00faltimo punto van a necesitar la funci\u00f3n nchar() . Pueden ver que hace desde la pesta\u00f1a Help . Tip - Carpetas para los ejercicios Como ya mencionamos varias veces en la materia es recomendado utilizar diferentes carpetas para los diferentes TPs y Ejercicios. Esto es especialmente cierto al momento de trabajar con scripts de R ya que no es raro que un programa real tenga archivos de entrada ( /input ), archivos finales o de salida ( /output ) y archivos temporales ( /temp ). Por ahora probablemente no necesiten crear subcarpetas de este estilo, pero t\u00e9nganlo en cuenta.","title":"Ejercicio 1 - Variables"},{"location":"practicos/TP08a_R/#r-vectores-y-plots","text":"","title":"R: Vectores y Plots"},{"location":"practicos/TP08a_R/#vectores","text":"R tiene la variable de tipo vector , que son vectores o arreglos, es decir, listas ordenadas de elementos de un mismo tipo. Vendr\u00edan a ser el equivalente de las listas que vimos de costado en Bash . Es importante ir aclarando que R tambi\u00e9n tiene variables del tipo list que vamos a ver en un rato, y que si bien son similares no son lo mismo. # Los vectores se declaran con c() y sus elementos se separan con \",\" # Este es un vector con 3 elementos de tipo *character* vector_frase <- c ( \"Hab\u00eda\" , \"una\" , \"vez...\" ) # Este es un vector con 10 elementos de tipo *numeric* vector_numeros <- c ( 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ) # Este vector es igual al anterior # R permite usar rangos al momento de definir vectores usando el simbolo \":\" vector_numeros_rango <- c ( 1 : 10 ) # Este vector es igual al anterior # Escribir solo el rango tambi\u00e9n devuelve un vector vector_numeros_rango2 <- 1 : 10 # Es posible combinar \",\" y \":\" # Este vector tiene los valores c(1,2,3,7,8,9,10) vector_numeros_hueco <- c ( 1 : 3 , 7 : 10 ) Los vectores son una parte escencial de R ; de hecho, la mayor\u00eda de las variables son vectores de l\u00f3ngitud 1 (raz\u00f3n por la que aparece el [1] al imprimirlas con print ). Como consecuencia, la mayor\u00eda de las funciones u operaciones de R aceptan reemplazar n\u00fameros o strings por vectores de ellos. 1) Ejecuten el c\u00f3digo anterior para crear los vectores y corran las siguientes l\u00edneas una a la vez. Vean que pasa en cada caso. print ( vector_frase ) print ( vector_numeros ) print ( vector_frase [ 2 ]) # *paste* se puede usar tambien con vectores # En este caso no se usa *sep*, sino *collapse*, pero cumplen la misma funci\u00f3n print ( paste ( vector_frase , collapse = \" \" )) print ( vector_numeros + 2 ) print ( vector_numeros_rango * vector_numeros_rango ) Como pueden ver, en R se puede trabajar con vectores de una forma muy similar a que si trabajaramos con un solo n\u00famero o string , lo que abre la puerta a grandes posibilidades. Otra cosa a destacar de lo anterior es que es posible acceder a una variable individual del vector usando corchetes, donde por ejemplo vector_frase[2] es el segundo valor del vector vector_frase . \u00cdndices de los vectores En R el \u00edndice del primer elemento de los vectores, listas y tablas es el 1. En muchos lenguajes de programaci\u00f3n (incluyendo Python ) el \u00edndice del primer item de un vector es el 0. Esto es algo que es importante acordarse de checkear cuando estas usando vectores en un nuevo lenguaje de programaci\u00f3n. Lo \u00faltimo que queremos volver a remarcar sobre los vectores es que son listas de elementos del mismo tipo . Sin embargo R probablemente no les tire un error si mezclan tipos de variables, sino que va a transformar autom\u00e1ticamente todas las variables a un mismo tipo. 2) Vean que pasa al correr: vector_mixto <- c ( 1 , 2 , \"asd\" ) print ( vector_mixto ) # Aca los n\u00fameros tienen comillas en el *print*, indicando que ya no son m\u00e1s n\u00fameros print ( vector_mixto [ 1 ] + 2 ) # Esto les va a tirar error ya que no puede sumar el n\u00famero 2 al *string* \"1\"","title":"Vectores"},{"location":"practicos/TP08a_R/#plots-simples","text":"R tiene muchas formas de hacer plots, especialmente usando paquetes externos. Sin embargo, para empezar vamos a ver las formas que vienen por defecto con R , que si bien crean plots m\u00e1s simples, tambi\u00e9n son m\u00e1s f\u00e1ciles de usar y sirven para hacer una inspecci\u00f3n r\u00e1pida de sus datos. 3) Creen un nuevo script, escriban el siguiente c\u00f3digo y corranl\u00f3: x <- c ( 1 : 100 ) y <- x ^ 2 plot ( x , y ) Si todo funcion\u00f3 bien les deber\u00eda haber aparecido el siguiente plot en la pesta\u00f1a Plots del panel de abajo a la derecha (puede estar mas o menos achatado). La funci\u00f3n plot por defecto hace lo que se denomina \"dot plot\" o \"scatter plot\" , donde dibuja un punto para cada valor (x, y) . 4) En unos minutos vamos a hablar de los botones de la ventana Plots , pero antes corran el siguiente c\u00f3digo: # rnorm es una funci\u00f3n que crea numeros random (o aleatorios) que siguen una distribuci\u00f3n normal # En este caso esta devolviendo 1000 n\u00fameros sacados de una distribuci\u00f3n normal con # media de 15 y un desv\u00edo est\u00e1ndar de 2.5 vector_numeros <- rnorm ( mean = 15 , sd = 2.5 , n = 1000 ) hist ( vector_numeros ) Si todo funcion\u00f3 bien el plot de la pesta\u00f1a Plots deber\u00eda haber cambiado al siguiente plot (como rnorm devuelve valores aleatorios puede no ser id\u00e9ntico). La funci\u00f3n hist hace un histograma de frecuencias a partir de un vector de valores. En la pesta\u00f1a Plots hay varios botones que van a ser muy \u00fatiles al momento de trabajar con plots: Flechas hacia la izquierda y derecha: nos permiten navegar entre los \u00faltimos plots que creamos. Zoom: nos permite abrir una nueva ventana para ver una versi\u00f3n mas grande del plot. Export: nos permite salvar el plot a varios formatos de imagen ( PNG , SVG , etc.) o a PDF . De trabajar con varios plots es com\u00fan salvar las im\u00e1genes desde el c\u00f3digo mismo, pero cuando se trabaja con pocas im\u00e1genes este m\u00e9todo es bastante \u00fatil. Remove the current plot: elimina el plot actual de la lista de plots guardados. Clear all Plots: vac\u00eda la lista de plots guardados. 5) Prueben entonces salvar el plot actual como una imagen PNG usando el bot\u00f3n Export . En la ventana que les va a aparecer pueden cambiar el formato de la imagen y tambi\u00e9n su tama\u00f1o, ya sea ingresando el ancho ( Width ) y el alto ( Height ) o a mano usando el \"triangulo\" de abajo a la derecha (ver figura).","title":"Plots simples"},{"location":"practicos/TP08a_R/#ejercicio-2-vectores-y-plots","text":"Para valores enteros de x entre 1 y 200, calculen el y correspondiente a una recta con pendiente 3 y ordenada al origen 5 y hagan el plot de dicha recta usando el comando plot . Una vez creado el plot, salvenl\u00f3 en un archivo con extensi\u00f3n SVG . Tip - Plotear una l\u00ednea Al momento de usar plot pueden agregar el par\u00e1metro type = \"l\" al final para que plotee l\u00edneas en vez de puntos.","title":"Ejercicio 2 - Plots"},{"location":"practicos/TP08a_R/#r-estructuras-logicas","text":"","title":"R: Estructuras l\u00f3gicas"},{"location":"practicos/TP08a_R/#condicionales-y-booleanos","text":"De igual forma que en Bash , en R tambi\u00e9n existen los condicionales ifs , pero se escriben ligeramente diferente: C\u00f3digo C\u00f3digo con comentarios numero <- 42 print ( paste ( numero , \"es un numero\" )) if ( numero > 10 ) { print ( paste ( numero , \"es mayor a 10\" )) } else { print ( paste ( numero , \"es menor o igual a 10\" )) } numero <- 42 print ( paste ( numero , \"es un numero\" )) # *if* es la estructura m\u00e1s usada para condicionales. # Adentro de los par\u00e9ntesis va la condici\u00f3n. # > es el comparador, o sea, estamos preguntando si la variable *numero* es mayor que 10 if ( numero > 10 ) { # El codigo entre *{* y el primer *}* solo si ejecuta si la condici\u00f3n es verdad, de otra forma se saltea # Este codigo esta m\u00e1s a la derecha, o *indentado*. Esto se hace con tab y en la mayor\u00eda de los lenguajes # es solo para entender m\u00e1s f\u00e1cil el c\u00f3digo (RStudio lo va a hacer autom\u00e1ticamente de pegar c\u00f3digo) print ( paste ( numero , \"es mayor a 10\" )) } else { # El c\u00f3digo entre *else {* y *}* se ejecuta solo cuando la condici\u00f3n no es verdad print ( paste ( numero , \"es menor o igual a 10\" )) } # Este *}* indica donde termina el condicional Es bastante similar a lo que conoc\u00edan, pero aca no esta then ni fi y los diferentes bloques l\u00f3gicos se marcan con llaves (en R esto tambi\u00e9n va a pasar en fors y en muchas otras estructuras). Las condiciones del if existen m\u00e1s alla de los condicionales y de hecho la comparaci\u00f3n numero > 10 es una variable en s\u00ed misma. A estas variables las vamos a llamar booleanos y pueden tener 1 de 2 valores: o TRUE (verdadero) o FALSE (falso). Hay 3 formas principales de generar variables booleanas: # D\u00e1ndoles el valor TRUE o FALSE a mano booleano1 <- TRUE # Usando un comparador, en este caso el *>* numero1 <- 5 booleano2 <- numero1 > 10 # Combinando booleanos con operadores l\u00f3gicos, en este caso con *and* booleano3 <- booleano1 & booleano2 Como mostramos en la tercer forma de generar variables booleanas, se pueden hacer operaciones entre los booleanos usando la llamada algebra booleana . Esto es un mundo en s\u00ed mismo, pero por suerte al momento de programar solo nos van a importar las tres operaciones b\u00e1sicas de la algebra booleana: el AND , el OR y el NOT . El AND y el OR son operaciones entre dos booleanos, mientras que NOT es una operaci\u00f3n que se le aplica a un solo booleano. El AND es el \"Y\" , devolviendo TRUE solo cuando ambos booleanos eran TRUE . Se escribe en R con & El OR es el \"O\" , devolviendo TRUE cuando por lo menos uno de ambos booleanos era TRUE . Se escribe en R con | ( pipe ) El NOT es el \"NO\" , invirtiendo el valor del booleano (o sea, devuelve TRUE solo si el booleano era FALSE ). Se escribe en R con ! Detalles de AND , OR y NOT Booleano 1 Booleano 2 AND (&) OR (|) TRUE TRUE TRUE TRUE TRUE FALSE FALSE TRUE FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE Booleano 1 NOT (!) TRUE FALSE FALSE TRUE Las variables booleanas se pueden usar en los directamente en las condiciones de los ifs . Si bien se pueden comparar contra TRUE y FALSE , de poner solo la variable en la condici\u00f3n del if , es equivalente a preguntar si esa variable es TRUE . Vean las siguientes tres pesta\u00f1as para entenderlo mejor: C\u00f3digo C\u00f3digo con comentarios C\u00f3digo - Versi\u00f3n m\u00ednima llueve <- TRUE tengo_paraguas <- TRUE if (( llueve == TRUE ) & ( tengo_paraguas == FALSE )) { print ( \"Me mojo\" ) } else { print ( \"No me mojo\" ) } llueve <- TRUE tengo_paraguas <- TRUE if (( llueve == TRUE ) & ( tengo_paraguas == FALSE )) { # Aca solo voy a entrar si llueve y no tengo paraguas # Si una o ambas de esas afirmaciones son falsas, entonces se imprime el c\u00f3digo en el *else* print ( \"Me mojo\" ) } else { print ( \"No me mojo\" ) } # T es equivalente a escribir TRUE # F es equivalente a escribir FALSE llueve <- T tengo_paraguas <- T # *llueve* es equivalente a *llueve == TRUE* # *!tengo_paraguas* es equivalente a *(!tengo_paraguas) == TRUE*, o sea, *tengo_paraguas == FALSE* if (( llueve ) & ( ! tengo_paraguas )) { print ( \"Me mojo\" ) } else { print ( \"No me mojo\" ) } Par\u00e9ntesis en las condiciones En la versi\u00f3n m\u00ednima los par\u00e9ntesis internos no son estrictamente necesarios, es decir, que podr\u00edan haber puesto: if ( llueve & ! tengo_paraguas ) { De hecho, la versi\u00f3n del c\u00f3digo que tiene los == tambi\u00e9n andar\u00eda bien de sacarle los par\u00e9ntesis internos, pero esto es mucho m\u00e1s peligroso. Al momento de encadenar condiciones con AND ( & ) u OR ( | ) les recomendamos poner cada condici\u00f3n entre par\u00e9ntesis para evitar errores, especialmente si las condiciones tienen < , > , == , etc.","title":"Condicionales y Booleanos"},{"location":"practicos/TP08a_R/#ciclos","text":"","title":"Ciclos"},{"location":"practicos/TP08a_R/#ciclo-for","text":"En R todos los ciclos for tienen una estructura similar a lo que nosotros llamamos anteriormente ciclos for each . Se escribe de la siguiente forma: C\u00f3digo C\u00f3digo con comentarios for ( i in 1 : 1000 ) { print ( i ) } # *for* es una de las estructuras m\u00e1s usadas para hacer ciclos # *i* es el nombre de la variable que va a cambiar de valor en cada ciclo. Se le podria poner cualquier nombre a # \u00e9sta variable, por ejemplo *numero* en nuestro caso, pero es costumbre ponele *i* # En este caso, *i* va a recorrer cada valor del rango 1:1000 (es decir, del n\u00famero 1 al n\u00famero 1000) for ( i in 1 : 1000 ) { # El c\u00f3digo entre las llaves se va a ejecutar una vez para cada posible *i* en el rango print ( i ) } En este caso el for va a recorrer todos los elementos de un vector de n\u00fameros que v\u00e1 entre 1 y 1000. Tambi\u00e9n podemos recorrer en el for los elementos de un vector previamente declarado, por ejemplo: C\u00f3digo C\u00f3digo con comentarios vector_colores <- c ( \"rojo\" , \"amarillo\" , \"verde\" ) for ( color in vector_colores ) { print ( color ) } vector_colores <- c ( \"rojo\" , \"amarillo\" , \"verde\" ) for ( color in vector_colores ) { # *color* es la variable que va cambiando en cada iteraci\u00f3n del *for* (como antes era *i*) # En este caso va a ir tomando los valores de los diferentes elementos de *vector_colores* print ( color ) }","title":"Ciclo For"},{"location":"practicos/TP08a_R/#ciclo-while","text":"El for es muy \u00fatil, pero tiene el problema de que uno necesita saber cuantas iteraciones va a realizar antes de empezar el ciclo, lo que no es siempre posible. Para casos donde desconocemos el n\u00famero de iteraciones, existen herramientas como el ciclo while que se puede pensar como una combinaci\u00f3n entre el for y el if . El c\u00f3digo dentro de este ciclo se va a repetir mientras se cumpla una condici\u00f3n. Por ejemplo: C\u00f3digo C\u00f3digo con comentarios contador <- 1 while ( contador <= 1000 ) { print ( contador ) contador <- contador + 1 } # Estamos declarando una variable *contador* que vale 1 contador <- 1 # Todo lo que esta adentro del ciclo *while* se va a repetir mientras la condici\u00f3n *contador <= 1000* sea TRUE while ( contador <= 1000 ) { # Imprimo la variable *contador* en la terminal print ( contador ) # Le sumo uno a la variable *contador* # Esto es equivalente al *contador++* de Bash contador <- contador + 1 } Tal vez no se dan cuenta, pero este programa va a hacer lo mismo que el for (i in 1:1000) que usamos arriba: La variable contador va a empezar en 1 y al final de cada ciclo va a aumentarse en 1 gracias al comando contador <- contador + 1 . Cuando contador llegue a 1001, la condici\u00f3n contador <= 1000 va a ser FALSE y el while va a terminar (es decir, el n\u00famero 1001 nunca se imprime en la terminal). Ahora bien, para el caso anterior no tiene mucho sentido usar un ciclo while ya que se podr\u00eda haber hecho perfectamente con un for . Supongamos entonces que queremos escribir las potencias de 2 que son menores a 1.000.000, en ese caso podemos hacer: C\u00f3digo C\u00f3digo con comentarios numero <- 1 while ( numero < 1000000 ) { print ( numero ) numero <- numero * 2 } # Declaro una variable *numero* con el valor 1 (que es 2^0) numero <- 1 # El loop este va a seguir mientras *numero* sea menor a 1 millon while ( numero < 1000000 ) { # Imprimo *numero* en la terminal print ( numero ) # Multiplico a *numero* por 2, lo que me va a dar la pr\u00f3xima potencia de 2 # 2^1 = 2 # 2^2 = 2 * 2 = 4 # 2^3 = 2 * 2 * 2 = 8 # 2^4 = 2 * 2 * 2 * 2 = 16 # etc numero <- numero * 2 } Si bien hay formas de hacer este \u00faltimo loop con un for , esto es m\u00e1s que nada un ejemplo para que entiendan el concepto de que el while nos permite repetir algo una cantidad indeterminada de veces. Loops Infinitos Al usar el ciclo while hay que prestar mucha atenci\u00f3n de no escribir un c\u00f3digo que genere un loop infinito , es decir, un loop donde la condici\u00f3n del while siempre va a ser TRUE . Si pasa esto probablemente se cuelgue R y tendr\u00e1n que reiniciarlo o interrumpirlo para volver a programar. En el ejemplo anterior esto habr\u00eda ocurrido si no hubiesemos puesto la l\u00ednea que aumenta el valor de numero .","title":"Ciclo While"},{"location":"practicos/TP08a_R/#ejercicio-3-estructuras-logicas","text":"El objetivo de este ejercicio es hacer un script de R que: Cree una variable llamada resultado y le asigne el valor 0 Cree un for que defina una variable i que recorra los n\u00fameros de 1 a 50 En cada iteraci\u00f3n vamos a sumarle o restarle algo a resultado (guardando el nuevo valor en resultado ): Para todo i menor a 5 o mayor a 47 Restarle i a resultado Para todo i mayor a 20 y menor a 30 Sumarle i a resultado Imprima el valor final de resultado por la consola Tip Aca van a necesitar usar diferentes estructuras ifs adentro del for teniendo en cuenta que hay varias condiciones.","title":"Ejercicio 3 - Estructuras l\u00f3gicas"},{"location":"practicos/TP08a_R/#r-tablas","text":"","title":"R: Tablas"},{"location":"practicos/TP08a_R/#data-frames","text":"El Data Frame es el tipo de variable que viene por defecto con R para usar tablas. Hay varias formas de crearlas, pero la m\u00e1s simple es con la funci\u00f3n data.frame() . Por ejemplo: genes <- c ( \"ERT2\" , \"TTR4\" , \"REC1\" ) esencialidad <- c ( F , F , T ) expresiones <- c ( 100 , 1000 , 10000 ) df <- data.frame ( gen = genes , esencial = esencialidad , expresion = expresiones ) Aca estamos creando una variable llamada df que contiene 3 columnas, gen , esencial y expresion , cada una conteniendo los valores de los vectores que declaramos previamente. Noten que los tres vectores tienen la misma cantidad de elementos. El primer elemento de cada vector corresponde a los valores de las columnas para la primera fila de la tabla, y as\u00ed. Tip Una cosa que les puede llamar la atenci\u00f3n es que pusimos los diferentes par\u00e1metros de la funci\u00f3n data.frame en tres l\u00edneas diferentes. Para R es equivalente poner todo en la misma l\u00ednea o como lo hicimos en el ejemplo anterior, lo que ayuda a leer m\u00e1s f\u00e1cil cada uno de los par\u00e1metros. Sin embargo, es importante notar que los saltos de l\u00ednea tienen que ir inmediatamente despu\u00e9s de una coma. Podemos ver los contenidos de la tabla usando el comando: print ( df ) gen esencial expresion 1 ERT2 FALSE 100 2 TTR4 FALSE 1000 3 REC1 TRUE 10000","title":"Data Frames"},{"location":"practicos/TP08a_R/#data-tables","text":"Si bien los Data Frames tienen bastantes funcionalidades, existe un tipo de variable llamada Data Table que b\u00e1sicamente es un Data Frame con muchas mejoras, por lo que va a ser la variable que vamos a usar nosotros al momento de trabajar con tablas. El problema es que las variables Data Tables no vienen por defecto con R , sino que necesitamos usar un paquete externo llamado data.table . Este paquete de R ya est\u00e1 preinstalado en sus m\u00e1quinas virtuales, pero pueden ver como se instala de 0 en la secci\u00f3n RStudio al principio de esta guia. Por m\u00e1s que est\u00e9 instalado el paquete, es necesario cargarlo cada vez que abramos R . Es com\u00fan cargar al principio de cada script todos los paquetes que uno va a usar (no hay problemas al intentar cargar un paquete ya cargado): library ( data.table ) # Esto carga el paquete data.table para poder usar el tipo de variable Data Tables genes <- c ( \"ERT2\" , \"TTR4\" , \"REC1\" ) esencialidad <- c ( F , F , T ) expresiones <- c ( 100 , 1000 , 10000 ) dt <- data.table ( gen = genes , esencial = esencialidad , expresion = expresiones ) print ( dt ) gen esencial expresion 1 ERT2 FALSE 100 2 TTR4 FALSE 1000 3 REC1 TRUE 10000 En los Data Tables vamos a usar el s\u00edmbolo $ para acceder a las diferentes columnas (en cuyo caso va a devolver un vector con los contenidos de dicha columna): print ( dt $ gen ) [ 1 ] \"ERT2\" \"TTR4\" \"REC1\" Por otro lado, podemos usar los corchetes [] de forma similar a como los usabamos en los vectores para devolver una fila espec\u00edfica. print ( dt [ 1 ]) gen esencial expresion 1 : ERT2 FALSE 100 Otra funci\u00f3n que les puede ser util es el comando summary , quien devuelve informaci\u00f3n de las diferentes columnas de la tabla: summary ( dt ) gen esencial expresion Length : 3 Mode : logical Min. : 100 Class : character FALSE : 2 1 st Qu. : 550 Mode : character TRUE : 1 Median : 1000 Mean : 3700 3 rd Qu. : 5500 Max. : 10000 Fijense que summary va a devolver informaci\u00f3n en base a que contiene la columna ( gen tiene strings , por lo que devuelve info general; esencial tiene booleanos , por lo que devuelve la cantidad de cada uno; expresion tiene n\u00fameros, por lo que devuelve varios estad\u00edsticos). Lo \u00faltimo que vamos a aprender hoy sobre Data Tables es a filtar filas, por ejemplo si quisieramos quedarnos solo con aquellas no esenciales ser\u00eda: dt [ esencial == FALSE ] gen esencial expresion 1 : ERT2 FALSE 100 2 : TTR4 FALSE 1000 Algunas ventajas de Data Tables vs Data Frames Lee tablas m\u00e1s r\u00e1pido L\u00edmita autom\u00e1ticamente la s\u00e1lida por terminal al usar print() con tablas muy grandes Permite filtrar sin repetir el nombre de la tabla varias veces Tiene variables internas que facilitan calcular el n\u00famero de filas o el \u00edndice de cada fila Tiene funciones internas que permiten calcular promedio por grupos, por ejemplo \u00a1Y muchas m\u00e1s!","title":"Data Tables"},{"location":"practicos/TP08a_R/#working-directory","text":"Esto es algo que lo ven\u00edamos posponiendo desde el principio de este TP, pero ahora vamos a querer leer y escribir archivos de disco, por lo que es necesario. El Working Directory es el path en donde estoy trabajando y compar\u00e1ndolo con lo que hicimos en Bash se puede pensar como en que carpeta est\u00e1 ahora la terminal. En R el comando para saber en que path estoy \"parado\" es la funci\u00f3n getwd() . Si quiero cambiar este path , tengo que usar la funci\u00f3n setwd(\"PATH_ABSOLUTO\") . 1) Creen una carpeta donde van a trabajar, por ejemplo ~/Documentos/TP_08 2) Usen la funci\u00f3n getwd() para ver el Working Directory actual 3) Usen la funci\u00f3n setwd() para asignar la carpeta creada en 1) como Working Directory (recuerden que tienen que pasarle como par\u00e1metro el path absoluto de dicha carpeta)","title":"Working Directory"},{"location":"practicos/TP08a_R/#escribir-tablas","text":"Hay varias funciones para escribir tablas, pero la que vamos a usar nosotros es write.table , por ejemplo: write.table ( dt , file = \"ARCHIVO_DT\" , col.names = T , row.names = F , sep = \"\\t\" , quote = T ) Los par\u00e1metros de write.table que estamos usando son: dt es el Data Table que estamos guardando file es donde se escribe el nombre del archivo. Si es un path absoluto se guarda en dicho path , y si es un path relativo es relativo al Working Directory \"ARCHIVO_DT\" suele tener extensi\u00f3n .tsv de separar las columnas con tabs, o extensi\u00f3n .csv de separarlas con comas col.names pregunta si queremos o n\u00f3 guardar el nombre de nuestras columnas en el archivo de salida (puede ser T o F ) row.names pregunta si queremos o n\u00f3 guardar el nombre de nuestras filas en el archivo de salida, el cual generalmente es el n\u00famero de fila (puede ser T o F ) sep indica cual es el separador de columnas. En este caso es \"\\t\" , es decir, Tab quote indica si queremos colocar comillas bordeando a los strings que tengamos en la tabla. Puede ser T o F , o tamb\u00eden puede ser un vector num\u00e9rico que indica a las columnas a las que hay que ponerle comillas (con la primera siendo la n\u00famero 1) 4) Existen algunas tablas en R que estan siempre cargadas en memoria y sirven para probar cosas. Una de estas tablas es iris . Usen print para ver esta tabla y luego usen help(iris) para ver la ayuda relacionada a esta tabla (que explica un poco las columnas). 5) Guarden la tabla iris en un archivo llamado iris.tsv dentro de la carpeta creada en el punto 1) . Usen los par\u00e1metros usados en el ejemplo de arriba. Confirmen que se creo el archivo. Comillas en los archivos .tsv Si abren con Leafpad el archivo iris.tsv reci\u00e9n creado van a ver que los nombres de las columnas y todos los valores de la columna Species estan rodeados por comillas. Estas comillas no son parte de los nombres o valores de las columnas, sino que es la forma que usamos para indicar que lo que est\u00e1 dentro de ellas es un string . Estas comillas aparecen por haber usado el par\u00e1metro quote = T y son \u00fatiles para varios casos, por ejemplo de trabajar con strings con espacios. Data Tables y nombres de las filas Es medio t\u00e9cnico, pero a diferencia de los Data Frames , los Data Tables no pueden tener nombres en las filas (raz\u00f3n por la que estoy usando row.names = F en el c\u00f3digo anterior). Esta es una decisi\u00f3n consciente de los creadores de los Data Tables ya que cualquier informaci\u00f3n que uno quiera almacenar en los nombres de las filas tambi\u00e9n se puede almacenar en una nueva columna, lo que hace mucho m\u00e1s f\u00e1cil trabajar con esa informaci\u00f3n (filtrar, ordenar, etc).","title":"Escribir Tablas"},{"location":"practicos/TP08a_R/#leer-tablas","text":"Hay varias funciones para leer tablas, pero la que vamos a usar nosotros es fread , por ejemplo: nuevo_dt <- fread ( \"ARCHIVO_DT\" , header = T , sep = \"\\t\" ) Esta funci\u00f3n es una de las funciones del paquete data.table . Los par\u00e1metros de fread que estamos usando son: nuevo_dt es el nombre de la variable donde se va a cargar la tabla \"ARCHIVO_DT\" es el nombre del archivo a leer. Si es un path absoluto se lee dicho path , y si es un path relativo es relativo al Working Directory header pregunta si nuestro archivo tiene el nombre de nuestras columnas (puede ser T o F ) sep indica cual es el separador de columnas. En este caso es \"\\t\" , es decir, Tab 6) Creen una variable llamada nuevo_dt_iris y carguen la tabla creada en el punto 5) . Usen print para confirmar visualmente que se la tabla se ley\u00f3 bien. Info No se si lo notaron, pero de imprimir iris y nuevo_dt_iris por consola van a ver que se imprimen de forma ligeramente diferente. Esto se debe a que iris es un Data Frame (ya que viene por defecto con R ), mientras que nuevo_dt_iris es un Data Table (por haber sido le\u00eddo con fread ).","title":"Leer Tablas"},{"location":"practicos/TP08a_R/#ejercicio-4-tablas","text":"Creen un vector de 5 strings (cualquiera, pero no muy largos) y otro vector de 5 numeros (entre 1 a 10) Creen un Data Table con 2 columnas llamadas col1 y col2 col1 va a contener el vector de strings col2 va a contener el vector de numeros Impriman por pantalla los valores de la columna col1 Impriman por pantalla los valores de la tercera fila de la tabla Impriman por pantalla el valor de col2 de la cuarta fila de la tabla Impriman por pantalla todas las filas donde col2 sea menor o igual a 7","title":"Ejercicio 4 - Tablas"},{"location":"practicos/TP08a_R/#r-funciones","text":"Como ya mencionamos cuando hablamos de los ciclos , es com\u00fan en programaci\u00f3n querer realizar una tarea varias veces en condiciones ligeramente diferentes. Otra herramienta que tenemos a nuestra disposici\u00f3n son las funciones, que ademas de ser parte de R y de los paquetes, pueden ser creadas por nosotros desde 0. Supongamos que por alguna raz\u00f3n es com\u00fan para nosotros querer calcular \\(y = 2x + x^2\\) , podemos entonces hacer: myFunction <- function ( x ) { output <- 2 * x + x ^ 2 return ( output ) } x1 <- 5 x2 <- 7 vector_x3 <- c ( 1 : 100 ) y1 <- myFunction ( x = x1 ) y2 <- myFunction ( x = x2 ) vector_y3 <- myFunction ( x = vector_x3 ) # Ya que estamos hacemos un plot de los vectores (a x1, x2, y1 e y2 no los estoy usando para nada por ahora) plot ( x = vector_x3 , y = vector_y3 ) Si bien en este caso puede no ser super necesario, van viendo como me ahorro bastante c\u00f3digo al usar funciones. Imaginenese ahora si lo que est\u00e1 adentro de la funci\u00f3n es algo mas complejo que ocupa 20 l\u00edneas de c\u00f3digo. Tambi\u00e9n es posible darle m\u00e1s de un par\u00e1metro a una funci\u00f3n, por ejemplo: myFunction <- function ( x , exp = 2 ) { output <- 2 * x + x ^ exp return ( output ) } x1 <- 5 x2 <- 7 vector_x3 <- c ( 1 : 100 ) # El parametro *exp* tiene por defecto el valor 2 # Estas dos lineas de c\u00f3digo devuelven lo mismo y1 <- myFunction ( x = x1 ) y1 <- myFunction ( x = x1 , exp = 2 ) y4 <- myFunction ( x = x2 , exp = 4 ) vector_y5 <- myFunction ( x = vector_x3 , exp = 10 ) plot ( x = vector_x3 , y = vector_y5 )","title":"R: Funciones"},{"location":"practicos/TP08a_R/#r-plots-mas-complejos","text":"Si bien la funciones plot e hist se pueden usar para hacer muchos tipos de plots, la mayor\u00eda de los plots hechos por R que uno puede llegar a ver en papers o similar estan hechos con paquetes de R que se especializan en plots. El paquete ggplot2 es uno de los m\u00e1s usados, debido a su gran variedad de plots y a que le permite al usuario modificar practicamente cualquier detalle del plot (con m\u00e1s o menos dificultad). 1) La funci\u00f3n principal del paquete ggplot2 se llama ggplot y comunmente es usada con Data Frames o Data Tables . Entonces, corran el siguiente c\u00f3digo que usa la tabla iris para hacer un ejemplo de un plot simple con ggplot : library ( ggplot2 ) ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length )) + geom_point () data es el par\u00e1metro que indica la tabla de la que se va a sacar la informaci\u00f3n aes es una subfunci\u00f3n a la que le pasamos cual columna es el x y cual el y geom_point() est\u00e1 indicando uno de los varios plots posibles con ese x e y , en este caso es un \"dot plot\" o \"scatter plot\" Si bien es medio extra\u00f1o, las diferentes opciones que le pasamos a ggplot se van a unir con el signo + 2) Existen varias otras funciones de plots y cada una de ellas tiene sus propios par\u00e1metros. Vean como cambia el plot el siguiente c\u00f3digo: ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length )) + geom_point ( shape = 3 , color = \"red\" ) + geom_line ( linetype = \"dashed\" , color = \"blue\" , alpha = 0.25 ) Como dijimos antes hay muchas funciones de ploteo, cada una con muchos par\u00e1metos posibles. Lo m\u00e1s normal al usar ggplot es googlear el uso espec\u00edfico que uno quiere hacer en ese momento y ver como se hace. 3) El siguiente c\u00f3digo es un ejemplo m\u00e1s \"completo\" de un plot hecho con ggplot . Corran el siguiente c\u00f3digo y vean el plot. Fijense si pueden inferir en base a su nombre que hacen algunos de los par\u00e1metros que le pasamos a ggplot (pueden ver el cheatsheet ): ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species )) + geom_point ( size = 1.5 ) + xlim ( c ( 1 , 8 )) + ylim ( c ( 1 , 8 )) + theme_bw () + xlab ( \"Sepal Length\" ) + ylab ( \"Petal Length\" ) + ggtitle ( \"Sepal vs Petal Length per Species\" ) + theme ( plot.title = element_text ( size = 16 , hjust = 0.5 ), axis.title = element_text ( size = 14 ), axis.text = element_text ( size = 12 )) + scale_color_discrete ( labels = c ( \"Setosa\" , \"Versicolor\" , \"Virginica\" ))","title":"R: Plots m\u00e1s complejos"},{"location":"practicos/TP08a_R/#r-variables-mas-complejas","text":"","title":"R: Variables m\u00e1s complejas"},{"location":"practicos/TP08a_R/#listas","text":"El concepto de las listas es similar al de los vectores, solo que las listas pueden contener elementos de diferentes tipos (incluyendo vectores, plots, tablas u otras listas). Sin embargo, las listas son estructuras un poco m\u00e1s complejas, por lo que de querer multiplicar cada elemento de una lista por dos no alcanza con hacer lista * 2 . Las listas se crean de la siguiente forma: lista_numeros <- list ( 3 , 4 , 7 , 13 , 45.3 ) lista_strings <- list ( \"hola\" , \"chau\" , \"perro\" ) lista_mixta <- list ( 3 , 4 , 7 , \"perro\" ) Si bien los nombres indicar\u00edan que creamos tres \"tipos\" de lista, en realidad a las listas les da lo mismo si todos sus elementos son del mismo tipo o no. 1) Impriman por pantalla a la lista_mixta . Deber\u00edan ver lo siguiente: [[1]] [1] 3 [[2]] [1] 4 [[3]] [1] 7 [[4]] [1] \"perro\" Hay 2 cosas de inter\u00e9s. Primero que cada elemento esta en su propia fila con un encabezado con su \u00edndice [[i]] , y segundo que los n\u00fameros aca no tienen comillas (como pasaba en los vectores al mezclar tipos de datos) por lo que siguen siendo n\u00fameros. Como sospecharan por los \u00edndices que aparecen, al momento de querer un elemento espec\u00edfico de una lista hay que usar doble corchete, por ejemplo: C\u00f3digo C\u00f3digo con comentarios lista_super_mixta <- list ( 3 , 4 , 7 , \"perro\" , c ( 20 : 30 )) print ( lista_super_mixta [[ 1 ]]) print ( lista_super_mixta [[ 2 ]] + lista_super_mixta [[ 3 ]]) print ( lista_super_mixta [[ 5 ]][ 7 ]) lista_super_mixta <- list ( 3 , 4 , 7 , \"perro\" , c ( 20 : 30 )) # Imprimo el primer elemento de la lista print ( lista_super_mixta [[ 1 ]]) # Esto funciona por ser una lista. Si fuera un vector mixto los n\u00fameros se habr\u00edan transformado en *strings* # y tirar\u00eda un error al tratar de sumarlos print ( lista_super_mixta [[ 2 ]] + lista_super_mixta [[ 3 ]]) # El quinto elemento de la lista es un vector conteniendo los n\u00fameros de 20 a 30 # Estoy imprimiendo el s\u00e9ptimo elemento de dicho vector print ( lista_super_mixta [[ 5 ]][ 7 ]) Si bien las listas tienen sus usos, en esta materia nos vamos a enfocar m\u00e1s en usar vectores. Dicho esto, existen funciones de R que van a devolver listas por defecto. Para transformar estas listas en vectores pueden usar la funci\u00f3n unlist . 2) Prueben usar unlist con la variable lista_super_mixta y vean que pasa.","title":"Listas"},{"location":"practicos/TP08a_R/#factores","text":"Los factores son un tipo de variable que es usada para cuando tenemos variables categ\u00f3ricas, por ejemplo la columna Species en la tabla iris que vimos anteriormente era una variable de tipo factor . Para entenderlo mejor supongamos que tenemos 5 individuos que fueron tratados con diferentes niveles de una droga y mostraron diferentes resultados. Queremos entonces plotear boxplots mostrando los resultados por cada nivel de tratamiento: 3) Prueben correr el pr\u00f3ximo c\u00f3digo y vean si funciona (spoiler: no va a funcionar). niveles_tratamiento <- c ( \"bajo\" , \"medio\" , \"alto\" , \"alto\" , \"bajo\" ) resultados_tratamiento <- c ( 2 , 5 , 8 , 9 , 4 ) plot ( x = niveles_tratamiento , y = resultados_tratamiento ) El problema con el c\u00f3digo anterior es que plot no sabe que hacer cuando uno le pasa un vector de strings , es decir, no entiende que son categor\u00edas. Necesitamos entonces transformar nuestros datos en factores. 4) Vean que pasa de correr el siguiente c\u00f3digo: niveles_tratamiento <- c ( \"bajo\" , \"medio\" , \"alto\" , \"alto\" , \"bajo\" ) resultados_tratamiento <- c ( 2 , 5 , 8 , 9 , 4 ) factor_niveles_tratamiento <- factor ( niveles_tratamiento ) plot ( x = factor_niveles_tratamiento , y = resultados_tratamiento ) En este momento aunque sea vemos un plot, pero si se fijan en el eje X tenemos un problema: los niveles de tratamiento no est\u00e1n en un \u00f3rden l\u00f3gico. Cuando uno crea factores puede asignar este orden a mano. 5) Cambien entonces el c\u00f3digo anterior al c\u00f3digo siguiente y corranl\u00f3: niveles_tratamiento <- c ( \"bajo\" , \"medio\" , \"alto\" , \"alto\" , \"bajo\" ) resultados_tratamiento <- c ( 2 , 5 , 8 , 9 , 4 ) factor_niveles_tratamiento <- factor ( niveles_tratamiento , levels = c ( \"bajo\" , \"medio\" , \"alto\" )) plot ( x = factor_niveles_tratamiento , y = resultados_tratamiento ) Como ven el par\u00e1metro levels nos permite indicar a mano el orden de los factores. 6) Impriman por consola a niveles_tratamiento y a factor_niveles_tratamiento y vean las diferencias. Factores y ggplot2 La funci\u00f3n ggplot transforma lista de strings a factores automaticamente al momento de plotear, por lo que no va a dar error de haber usado niveles_tratamiento (en una columna de un Data Table ). Sin embargo, los factores siguen siendo \u00fatiles en estos casos para controlar el \u00f3rden en los que se plotean las variables categ\u00f3ricas. Estructura interna de los factores Esto es un poco t\u00e9cnico, pero otro beneficio de los factores es que ahorran memoria. Esto se debe a que en realidad no se guardan como una lista de strings , sino que R le asigna un n\u00famero a cada level y eso es lo que realmente guarda para todos los datos. Esto se puede ver con la funci\u00f3n as.numeric() : as.numeric ( factor_niveles_tratamiento ) [ 1 ] 1 2 3 3 1","title":"Factores"},{"location":"practicos/TP08a_R/#averiguar-el-tipo-de-las-variables","text":"Muchas veces queremos operar con variables y obtenemos errores puesto que son de un tipo distinto al que esper\u00e1bamos. \u00bfC\u00f3mo podemos averiguar entonces de que tipo son las variables? Sabemos que si tienen comillas es texto, pero esto no alcanza. La forma correcta de saber que tipo de variable es una variable es usando las funciones class() o typeof() . No vamos a detallar mucho estas funciones, pero class() suele devolver el nombre de la variable a la que estamos acostumbrados ( numeric , factor , etc), mientras que typeof() devuelve como se almacena esa variable internamente. 7) Vean que devuelve class() y typeof() para las siguientes variables (en algunos casos typeof() va a ser un poco raro): library ( data.table ) numero <- 2 cadena <- \"uno dos tres\" booleano <- TRUE vector_numeros <- c ( 1 , 2 , 3 ) vector_strings <- c ( \"uno\" , \"dos\" , \"tres\" ) df <- data.frame ( numeros = vector_numeros , strings = vector_strings ) dt <- data.table ( numeros = vector_numeros , strings = vector_strings ) factor_vector_strings <- factor ( vector_strings , levels = c ( \"dos\" , \"tres\" , \"uno\" )) class ( numero ) typeof ( numero )","title":"Tipos de las variables"},{"location":"practicos/TP08a_R/#ejercicio-adicional-1","text":"En este Ejercicio vamos a ver si los n\u00fameros aleatorios de R se portan como deber\u00edan. Para esto vamos a hacer un script que: Tire una moneda Anote si sali\u00f3 cara o seca Repita los pasos anteriores hasta tener 100 caras o 100 secas (o dicho de otra forma, repita los pasos mientras no tenga 100 caras ni 100 secas) Imprima por pantalla cuantas secas y cuantas caras obtuvo (usar paste para que que en la salida se entienda bien que n\u00famero corresponde a quien) Una cosa que van a necesitar para hacer esto es la siguiente funci\u00f3n: moneda <- sample ( x = c ( \"Cara\" , \"Seca\" ), size = 1 ) Donde sample devuelve un sampleo al azar de size elementos (en este caso 1 ) del vector x (en este caso c(\"Cara\", \"Seca\") ). En definitiva esto quiere decir que cada vez que ejecuten esa l\u00ednea moneda va a recibir el valor \"Cara\" o el valor \"Seca\" al azar. Ejecuten el c\u00f3digo anterior varias veces y vean si los n\u00fameros aleatorios funcionan bien en R o si est\u00e1 todo arreglado.","title":"Ejercicio Adicional 1"},{"location":"practicos/TP08a_R/#bibliografia","text":"","title":"Bibliograf\u00eda"},{"location":"practicos/TP08a_R/#consola-de-r","text":"Comando help()","title":" Consola de R"},{"location":"practicos/TP08b_R/","text":"TP 8b . R - Programando en biolog\u00eda - Parte 2 Materiales Videos de la clase grabada Introducci\u00f3n al TP Puesta en com\u00fan del TP C\u00f3digos resueltos C\u00f3digos completos (tienen que setear el Working Directory ) (si corren el 3, 4 y 5 llegan al PDF ) Software a usar R (ya instalado en la VM). RStudio (ya instalado en la VM) Recursos Online Curso online de R de Coursera (se puede hacer gratis) (en ese caso no da certificado) Tips de comandos b\u00e1sicos de R Data Tables: Introducci\u00f3n oficial y otra p\u00e1gina con m\u00e1s info ggplot2: Vistazo r\u00e1pido , otra p\u00e1gina con cada plot detallando sus par\u00e1metros y cheatsheet Objetivos Familiarizarse en el lenguaje de programaci\u00f3n R . Ver como los mismos conceptos de programaci\u00f3n se trasladan de un lenguaje a otro. Utilizar herramientas de programaci\u00f3n para resolver problemas biol\u00f3gicos. Introducci\u00f3n al Tema Es muy normal que en trabajos de biolog\u00eda sea necesario trabajar con datos provenientes de servicios o equipos que no generan outputs de formato est\u00e1ndar (separados por tabs, comas, etc). Esto hace que cuando queramos cargar estos outputs en cualquier programa de an\u00e1lisis de datos vamos a tener que darles formato manualmente, algo que puede no ser muy complicado cuando se trata de unos pocos archivos o un solo ensayo, pero se vuelve un problema en grandes cantidades. En la materia ya vimos varios archivos de salida con patrones propios, por ejemplo los archivos FASTA, donde el marcador > es usado para indicar el comienzo del header una secuencia. Diferentes programas van a tener diferentes patrones de salida, pero suelen haber ciertos caracteres bastante usados como # , ! , * , | , etc. En este trabajo pr\u00e1ctico vamos a usar el lenguaje de programaci\u00f3n R para leer datos generados por un lector de placas de wells. Vamos a parsear dichos datos para que est\u00e9n en un formato con el que podamos trabajar, y vamos a procesarlos como necesitemos para calcular estad\u00edsticos y plots que contengan informaci\u00f3n sobre el experimento realizado. Experimento Objetivo En el TP de hoy vamos a querer encontrar un compuesto que funcione de inhibidor para una enzima de inter\u00e9s, a la que vamos a denominar enzima Z . No solo nos va a interesar que compuestos funcionan como inhibidores para ella, sino que tambi\u00e9n queremos calcular el IC 50 de cada uno de dichos compuestos (que en nuestro caso ser\u00eda la concentraci\u00f3n a la cual el inhibidor produce una reacci\u00f3n un 50% m\u00e1s lenta que sin inhibidor). Por suerte nuestra enzima de inter\u00e9s tiene como producto un compuesto fluorescente. Sabiendo esto podemos estimar la velocidad de la reacci\u00f3n calculando una regresi\u00f3n lineal de la abundancia de dicho producto a lo largo del tiempo (esto lo vamos a explicar un poco m\u00e1s detalladamente cuando lo hagamos). Si un compuesto funciona como inhibidor en algunas de las concentraciones evaluadas, la velocidad de la reacci\u00f3n deber\u00eda caer. FilterMax Una forma de analizar varios compuestos y concentraciones a la vez es usar el equipo FilterMax F5 , el cual permite hacer mediciones puntuales de absorbancia y fluorescencia (entre otros) en placas de wells de 96, 384 y 1536. Incluso permite hacer mediciones a distintos tiempos (por ejemplo, se le puede programar para hacer mediciones cada ciertos intervalos temporales). En nuestro ejemplo (datos reales, nombres ficticios), vamos a utilizar el FilterMax F5 para evaluar varias placas de 384 wells y vamos a hacer 4 evaluaciones por placa, una cada 5 minutos. Cada columna de la placa corresponde compuesto distinto (22 compuestos, 1 por columna) y cada fila tiene concentraciones diferentes de cada compuesto (16 concentraciones, diluciones seriadas). Un esquema de este experimento se puede ver en esta planilla . Paso 1 - Familiarizarnos con el Archivo El primer paso cuando uno empieza a trabajar con un archivo nuevo es siempre mirarlo y deducir su formato. Los resultados reales de este experimento pueden verlos en el archivo 00_datos_filtermax.txt que se encuentra en sus materiales de trabajo. Abran el archivo 00_datos_filtermax.txt con Leafpad, vean su estructura y respondan las siguientes preguntas: 1) \u00bfSe parece un poco a alg\u00fan .csv (columnas separadas por comas) o .tsv (columnas separadas por tabs) que hayan visto antes? \u00bfQue diferencias tiene? Teniendo en cuenta esas diferencias y considerando que vamos a querer leerlo como una tabla en R \u00bfLes parece que hay filas que est\u00e1n de m\u00e1s? 2) Mirando el archivo y la planilla del experimento: \u00bfQu\u00e9 hay en la celda A1? \u00bfQu\u00e9 posiciones contienen las diferentes diluciones del compuesto \"Umbrella2\"? \u00bfCu\u00e1ntos datos hay para cada diluci\u00f3n del compuesto \"Umbrella2\"? \u00bfPor qu\u00e9? 3) Ahora abra el archivo con Gnumeric (Click derecho sobre el archivo Abrir con Oficina Gnumeric). Al final de cada placa hay varias celdas sin datos. \u00bfHay algo en la planilla del experimento que explique por qu\u00e9 pasa esto? Paso 2 - Limpiar y Parsear el Archivo En este paso queremos hacer 2 cosas: Primero, queremos sacar cualquier fila extra de 00_datos_filtermax.txt que nos impida leer el archivo usando fread . Si bien en este caso esto se podr\u00eda hacer a mano, como programadores queremos soluciones que escalen bien con el n\u00famero de datos, asi que lo vamos a hacer en un script . Segundo, queremos reorganizar los datos para poder trabajar con ellos m\u00e1s f\u00e1cil, y para eso queremos una tabla con la siguiente estructura: time temperature fila columna signal \"00:00:00\" 30 \"A\" 1 417246 \"00:04:59\" 30 \"A\" 1 595504 \"00:10:00\" 30 \"A\" 1 789920 \"00:15:00\" 30 \"A\" 1 985947 \"00:00:00\" 30 \"A\" 2 389328 ... ... ... ... ... Si bien este paso es importante, tambi\u00e9n es bastante espec\u00edfico a la salida del FilterMax F5 . Por esta raz\u00f3n les vamos a dar el archivo ya parseado para que pasemos directamente al an\u00e1lisis de datos m\u00e1s general. Este es el archivo 02_datos_filtermax_parseados.tsv que se encuentra en sus materiales de trabajo. Dicho esto, si completan el resto del TP a tiempo y quieren aprender c\u00f3mo llegar del archivo original a \u00e9ste archivo pueden hacer el Ejercicio Adicional 1 abajo de todo. 1) Abran el archivo 02_datos_filtermax_parseados.tsv con Leafpad y vean la columna signal . \u00bfQu\u00e9 piensan que significan los NA en esa columna? Paso 3 - Agregar la informaci\u00f3n que necesito En este momento tenemos una tabla donde cada fila es una se\u00f1al independiente, pero tenemos algunos problemas: No tengo informaci\u00f3n de los compuestos en la tabla, solo de los n\u00fameros de las columnas No tengo informaci\u00f3n de las diluciones en la tabla, solo de las letras de las filas M\u00e1s adelante vamos a querer calcular la velocidad de reacci\u00f3n , es decir, c\u00f3mo var\u00eda la signal seg\u00fan el time . Sin embargo, ac\u00e1 time es un string , por lo que necesito transformarlo a n\u00famero Estas son las cosas que queremos arreglar. Por suerte tenemos tambi\u00e9n otras dos tablas, una indicando que compuesto hay en cada columna ( 00_datos_compuestos.tsv ) y otra indicando que diluci\u00f3n hay en cada fila ( 00_datos_concentraciones.tsv ). Esto se podr\u00eda hacer a mano, pero llevar\u00eda mucho tiempo y podr\u00eda haber errores de tipeo. Por esta raz\u00f3n vamos a crear un programa que haga todo esto por nosotos. Sin embargo, antes de crear este programa necesitamos aprender algunas cosas nuevas: Herramientas necesarias Filtrar filas en Data Table Algo de esto vimos en el TP anterior, pero es posible filtrar filas de un Data Table seg\u00fan el valor de las diferentes columnas en dicha fila. Vamos a volver a usar el data set iris que est\u00e1 siempre cargado en memoria; sin embargo, iris es un Data Frame , por lo que lo vamos a tener que convertir en Data Table . library ( data.table ) #tenemos que cargar el paquete data.table en memoria cada vez que cerramos RStudio dt_iris <- as.data.table ( iris ) Ahora supongamos que queremos solo las filas donde la columna Species es versicolor \u00f3 virginica . Hay varias formas de hacer esto y todas les van a ser \u00fatiles para lo que tenemos que hacer hoy. 1) Corran por lo menos dos de las l\u00edneas de c\u00f3digo siguientes y vean lo que devuelven: # Cualquiera de estas 5 l\u00edneas de c\u00f3digo devuelve el mismo *Data Table* dt_iris [( Species == \"versicolor\" ) | ( Species == \"virginica\" )] dt_iris [ Species %in% c ( \"versicolor\" , \"virginica\" )] dt_iris [ Species != \"setosa\" ] dt_iris [ ! ( Species == \"setosa\" )] dt_iris [ ! ( Species %in% c ( \"setosa\" ))] Mergear Data Tables Por mergear nos referimos a juntar dos Data Tables horizontalmente, es decir, agregar de alguna forma las columnas de uno al otro. 2) Corran el siguiente ejemplo y vean lo que devuelve. genes <- c ( \"ERT2\" , \"TTR4\" , \"REC1\" ) esencialidad <- c ( F , F , T ) expresiones <- c ( 100 , 1000 , 10000 ) dt_info_de_esencialidad <- data.table ( gen = genes , esencial = esencialidad ) dt_info_de_expresion <- data.table ( gen = genes , expresion = expresiones ) dt_toda_la_info <- merge ( dt_info_de_esencialidad , dt_info_de_expresion , by = \"gen\" ) print ( dt_toda_la_info ) Como ven, la funci\u00f3n merge toma 2 Data Tables y los une por la columna definida en el par\u00e1metro by . Una cosa interesante es que no es necesario que ambos Data Frames tengan el mismo tama\u00f1o. 3) Corran el siguiente ejemplo y vean lo que devuelve. especies <- c ( \"setosa\" , \"virginica\" , \"versicolor\" ) empieza_con_S <- c ( T , F , F ) dt_info_S <- data.table ( Species = especies , empieza_con_S = empieza_con_S ) nueva_dt_iris <- merge ( dt_iris , dt_info_S , by = \"Species\" ) print ( nueva_dt_iris ) Para cada fila de dt_iris el merge agrego el valor de empieza_con_S seg\u00fan la columna Species . Van a ver que se desordenaron las filas y las columnas. Esto sucede ya que merge va a mover a la columna usada en el by al principio. Uno despu\u00e9s tiene que reordenarlas como prefiera. Agregar filas a Data Tables Ahora que aprendimos a agregar columnas en masa tambi\u00e9n queremos hacer lo mismo con una o m\u00e1s filas. 4) Corran el siguiente ejemplo y vean lo que devuelve. genes <- c ( \"ERT2\" , \"TTR4\" , \"REC1\" ) esencialidad <- c ( F , F , T ) expresiones <- c ( 100 , 1000 , 10000 ) dt_toda_la_info <- data.table ( gen = genes , esencial = esencialidad , expresion = expresiones ) dt_nueva_fila <- data.table ( gen = \"AFK5\" , esencial = T , expresion = 50 ) dt_toda_la_info <- rbindlist ( list ( dt_toda_la_info , dt_nueva_fila )) print ( dt_toda_la_info ) El comando rbindlist concatena dos Data Tables , donde el segundo puede ser una sola fila o algo m\u00e1s grande. Es importante que ambos Data Tables tengan la misma estructura para que el comando no devuelva errores. Crear Data Table vac\u00edo Ahora que sabemos agregar filas a un Data Table , puede ser entonces \u00fatil tener un Data Table vac\u00edo al que le voy a agregando filas que voy calculando (por ejemplo en un ciclo). 5) Corran el siguiente ejemplo y vean lo que devuelve. dt_toda_la_info_vacio <- data.table ( gen = character (), esencial = logical (), expresion = numeric ()) print ( dt_toda_la_info_vacio ) dt_nueva_fila <- data.table ( gen = \"AFK5\" , esencial = T , expresion = 50 ) dt_toda_la_info <- rbindlist ( list ( dt_toda_la_info_vacio , dt_nueva_fila )) print ( dt_toda_la_info ) Como ven, al crear un Data Table vac\u00edo tengo que asignar a cada columna el tipo de datos que va a contener. Aca estoy usando character() ( strings ), logical() ( booleano ) y numeric() (n\u00fameros reales). El \u00fanico otro tipo que puede ser que usen en esta materia es el integer() que son n\u00fameros enteros, pero como dijimos en el TP anterior es com\u00fan usar numeric() para estos tambi\u00e9n. Reordenar columnas en Data Tables Como mencionamos antes, el merge nos va a desordenar las columnas de la tabla. Adem\u00e1s, es posible querer quedarnos con solo algunas de las columnas de una tabla porque ya no tenemos m\u00e1s usos para otras. Una forma de hacer esto es: dt_iris <- as.data.table ( iris ) #Los tres siguientes bloques hacen lo mismo, qued\u00e1ndonos solo con las #columnas Species, Sepal.Length y Sepal.Width dt_iris [, . ( Species , Sepal.Length , Sepal.Width )] dt_iris [, c ( \"Species\" , \"Sepal.Length\" , \"Sepal.Width\" )] columnas_a_quedarnos <- c ( \"Species\" , \"Sepal.Length\" , \"Sepal.Width\" ) dt_iris [, columnas_a_quedarnos , with = F ] Esto es \u00fatil cuando queremos quedarnos con pocas columnas, pero \u00bfqu\u00e9 pasa cuando tenemos muchas y solo queremos sacar algunas? Ah\u00ed podemos hacer: dt_iris <- as.data.table ( iris ) #Los dos siguientes bloques hacen lo mismo, sacando las columnas Species, Sepal.Length y Sepal.Width dt_iris [, - c ( \"Species\" , \"Sepal.Length\" , \"Sepal.Width\" )] columnas_a_borrar <- c ( \"Species\" , \"Sepal.Length\" , \"Sepal.Width\" ) dt_iris [, - columnas_a_borrar , with = F ] Splitear strings Hay varias funciones en R que nos permiten parsear texto y una de las m\u00e1s f\u00e1ciles de entender es strsplit . Como su nombre lo indica esta funci\u00f3n splitea (o corta) un string (o cadena de caracteres). Veamos un ejemplo: frase <- \"Habia-una-vez\" frase_spliteada <- strsplit ( frase , split = \"-\" ) print ( frase_spliteada ) [[ 1 ]] [ 1 ] \"Habia\" \"una\" \"vez\" Como ven la funci\u00f3n strsplit toma un string y lo divide en diferentes fragmentos seg\u00fan el par\u00e1metro split . No se si lo recuerdan, pero en el TP anterior hablamos de las variables llamadas listas, que se pueden pensar como vectores que pueden contener variables de distinto tipo dentro de ellas (mientras que todos los elementos de un vector son de un mismo tipo). Ese [[1]] en el output anterior nos est\u00e1 indicando que strsplit nos est\u00e1 devolviendo una variable de tipo list donde el primer elemento es el vector con la frase spliteada . 6) Si bien el par\u00e1metro split suele ser un caracter, en realidad puede ser un string cualquiera. Prueben el c\u00f3digo anterior usando split = \"-una-\" y vean que pasa. 7) Vean que pasa cuando usan split = \"\" . 8) P\u00e1senle ahora a strsplit el siguiente vector de strings: frases <- c(\"Aqu\u00ed me pongo a cantar\", \"al comp\u00e1s de la vig\u00fcela\") . Sabiendo que queremos splitear las diferentes palabras, \u00bfcu\u00e1l ser\u00eda el valor de split en este caso? \u00bfCu\u00e1ntos elementos tiene la lista que devuelve strsplit ? \u00bfPor qu\u00e9? \u00bfCu\u00e1l es la tercera palabra de la segunda frase? (impr\u00edmanla por pantalla usando print ) Eliminar elementos repetidos en vectores En los Data Tables es com\u00fan tener columnas con categor\u00edas, por ejemplo la columna Species en la tabla iris . Es normal al momento de programar no saber previamente cu\u00e1les van a ser esas categor\u00edas (especies en este caso), por lo que muchas veces se extraen de la columna misma. Una forma de hacer esto es usar la funci\u00f3n unique() , la cual toma un vector y saca los elementos repetidos, dejando uno de cada uno. 9) Corran el siguiente ejemplo y vean lo que devuelve. vector_especies <- iris $ Species vector_especies_unicas <- unique ( vector_especies ) print ( vector_especies ) print ( vector_especies_unicas ) La columna iris$Species es t\u00e9cnicamente un factor , pero estos son simplemente vectores con propiedades extras. La funci\u00f3n unique() va a funcionar igual de pasarle un vector de caracteres; de hecho, esta funci\u00f3n tambi\u00e9n puede remover filas repetidas de un Data Table . Usar fread con datos faltantes Es com\u00fan que un set de datos tenga datos faltantes, lo que en nuestro caso vendr\u00eda a ser wells sin se\u00f1al. Diferentes tablas los van a indicar de diferentes maneras, pero es com\u00fan verlos como nada (o sea veo los separadores de columnas, pero no hay informaci\u00f3n en el medio), NaN ( Not a Number ), ND ( No Data ) o como NA ( Not Available ). En esta caso vamos a usar NA . Es importante al momento de leer un archivo saber si mi archivo tiene o no estos datos faltantes, ya que de no tenerlo en cuenta puedo terminar leyendo a NA como el string \"NA\", lo cual puede insertar datos falsos y hasta forzar a R a leer una columna num\u00e9rica como si fueran todos strings . Podemos indicarle a fread si hay celdas sin valores y como est\u00e1n escritas con el par\u00e1metro na.strings : dt <- fread ( \"ARCHIVO_DT\" , header = T , sep = \"\\t\" , na.strings = \"NA\" ) En este caso le estamos indicando que hay celdas sin valores y que est\u00e1n escritas en la tabla como \"NA\" (pueden estar con o sin comillas en el archivo). De querer indicarle a fread que los datos faltantes est\u00e1n como nada se usa na.strings = \"\" , aunque en este caso cualquier columna con un string vac\u00edo tambi\u00e9n va a ser considerada dato faltante. Tip - Carga m\u00e1s r\u00e1pida de los datos Si estamos seguros que no hay celdas sin valores en nuestros datos, le podemos pasar na.strings = NULL para indicarle que no busque celdas vac\u00edas, lo que acelera la carga de la tabla. Usar fread con decimales espa\u00f1oles Otro problema com\u00fan al momento de trabajar con datos es que por alguna diab\u00f3lica raz\u00f3n el separador de decimales y el separador de miles no son iguales para algunos pa\u00edses que para otros, de hecho, son exactamente al rev\u00e9s. Es posible entonces que tengan una tabla que hizo alguien en Argentina donde uso comas como separador de decimales, pero que al cargarla en R , el cual fue creado en Estados Unidos, piense que dichas comas son separador de miles, lo que rompe completamente los n\u00fameros pasados. Por suerte algo de consideraci\u00f3n tienen y existe un par\u00e1metro de fread que nos permite especificar cual es el separador de decimales (que por defecto es el punto): dt <- fread ( \"ARCHIVO_DT\" , header = T , sep = \"\\t\" , dec = \",\" ) Paso 3 - Ejercicio 10) Creen un nuevo script de R , copien el siguiente c\u00f3digo y guardenlo en su carpeta de trabajo. Vayan avanzando por el script y cambien las secciones que dicen @@EDITAR@@ por lo que corresponda (esto puede ser un valor, una variable, una operaci\u00f3n matem\u00e1tica, una comparaci\u00f3n o una funci\u00f3n de R ). Warning - Working Directory Cada vez que lean o escriban un archivo recuerden que el path que le pasen debe ser un path absoluto o un path relativo al Working Directory . Para cambiar el Working Directory pueden usar la funci\u00f3n setwd() que aprendimos en el TP anterior. Tip - \u00d1 y acentos Van a ver que en los c\u00f3digos tratamos de no usar la letra \u00d1 o acentos. Esto es as\u00ed ya que cuando uno comparte c\u00f3digo entre varias personas suele pasar que algunas de esos caracteres se \"rompen\" y se ven feo (por ejemplo un texto que era dise\u00f1o_compuestos se ve\u00eda como dise\u00c3\u00b1o_compuestos en otra PC). Si bien es posible poner est\u00e1ndares de codificaci\u00f3n de texto en grupos, la realidad es que solemos programar en ingl\u00e9s por lo que el problema se evita solo. Este tip es especialmente importante para los nombres de las variables. Ah\u00ed si que recomendamos nunca usar acentos o \u00d1 (o espacios). #Aca hay que poner el Path Absoluto que apunta a su carpeta de trabajo #Por ej: \"/home/ibioinfo/Documentos/data_TP8b\" setwd ( @@ EDITAR @@ ) library ( data.table ) #Uso fread para cargar los datos parseados teniendo en cuenta que tienen NAs dt_parsed_data <- fread ( @@ EDITAR @@ ) #Primero que nada se que las columnas de los wells 23 y 24 estan vacias, asi que saco las filas #donde *columna* sea 23 o 24 (o sea, me quedo con las filas donde *columna* es 1 a 22) dt_parsed_data <- dt_parsed_data [ @@ EDITAR @@ ] #Ahora, la fila y la columna no me esta dando mucha informacion de lo que esta pasando, #por lo que quiero agregar informacion de los compuestos y de concentraciones #Agrego informacion compuestos dt_datos_compuestos <- fread ( \"00_datos_compuestos.tsv\" , header = T , sep = \"\\t\" , na.strings = NULL ) dt_parsed_data <- merge ( dt_parsed_data , dt_datos_compuestos , by = \"columna\" ) #Agrego informacion concentraciones (ojo que en *00_datos_concentraciones.tsv* el separador decimal es la coma) dt_datos_concentraciones <- fread ( @@ EDITAR @@ ) dt_parsed_data <- merge ( @@ EDITAR @@ ) #Para cada combinacion de compuesto y concentracion quiero saber la velocidad de la reaccion, es decir, #la pendiente de la recta que sale de hacer una regresion lineal por los 4 tiempos ensayados #El primer problema que tengo es que la variable time es un *string*, por lo que no puedo usarla #como X en una ecuacion. Por esta razon vamos a convertir a time en cantidad de segundos #Si bien hay 1408 filas, en si solo hay 4 tiempos que se repiten: #\"00:00:00\", \"00:04:59\", \"00:10:00\" y \"00:15:00\" #Voy entonces a hacer una tabla llamada dt_times_in_seconds que va a empezar vac\u00eda y una vez corrido el #siguiente *for* va a tener 4 filas, una por cada uno de los 4 tiempos #Esta tabla va a tener dos columnas, la columna *time* indicando el tiempo en string que estamos analizando #y la columna *segundos_totales* que contiene ese tiempo transformado en numero y en segundos #Extraigo entonces los diferentes tiempos y creo una tabla vacia donde voy a guardar la cantidad de segundos #para cada *time* unique_times <- unique ( dt_parsed_data $ time ) dt_times_in_seconds <- data.table ( time = character (), segundos_totales = numeric ()) for ( time_for in unique_times ) { # Esta siguiente linea comentada la uso para debuggear, es decir, para cuando estoy creando el programa # Si la ejecutan a mano (sin el #) pueden entonces ir paso a paso en el *for* viendo que funcione todo # Recuerden que pueden usar CTRL + ENTER para ejecutar el codigo seleccionado o ver el valor de una variable # time_for <- unique_times[2] #Divido las horas, minutos y segundos y las transformo a numeros time_spliteado <- strsplit ( time_for , \":\" ) #*strsplit* devuelve una lista, que es como un vector, pero mas complicado #Voy a sobreescribir la variable quedandome solo con el primer elemento de la lista, que es un vector time_spliteado <- time_spliteado [[ 1 ]] #Guardo cada uno de los tres numeros en otra variable. Como ahora son *strings* uso as.numeric() para #convertirlos en numeros horas <- as.numeric ( @@ EDITAR @@ ) minutos <- as.numeric ( @@ EDITAR @@ ) segundos <- as.numeric ( @@ EDITAR @@ ) #Calculo los segundos totales, es decir, del paso anterior transformo las horas y los minutos en segundos #y sumo las tres variables segundos_totales <- @@ EDITAR @@ #Guardo esta info en la tabla que acabo de crear dt_new_row_times_in_seconds <- data.table ( time = @@ EDITAR @@ , segundos_totales = @@ EDITAR @@ ) dt_times_in_seconds <- rbindlist ( list ( dt_times_in_seconds , dt_new_row_times_in_seconds )) } #Agrego la informacion de los segundos totales (guardada en dt_times_in_seconds) a mi tabla original dt_parsed_data <- merge ( @@ EDITAR @@ ) #Ahora van a ver que las columnas de la tabla parecen estar mezcladas, lo que se debe a los merge #Por otro lado hay columnas que ya no vamos a usar #Resolvemos las dos cosas a la vez rearmando las columnas de la tabla dt_parsed_data <- dt_parsed_data [, . ( compuesto , concentracion , segundos_totales , signal )] #Escribo los datos en una nueva tabla write.table ( dt_parsed_data , file = \"03_datos_filtermax_parseados_y_formateados.tsv\" , col.names = T , row.names = F , sep = \"\\t\" , quote = T ) Si todo sali\u00f3 bien, el archivo 03_datos_filtermax_parseados_y_formateados.tsv deber\u00eda ser una tabla del estilo: compuesto concentracion segundos_totales signal \"Umbrella1\" 200 0 417246 \"Umbrella2\" 200 0 389328 \"Umbrella3\" 200 0 225039 \"Umbrella4\" 200 0 248039 ... ... ... ... Warning - Gnumeric transforma visualmente los separadores decimales Si abren el archivo 03_datos_filtermax_parseados_y_formateados.tsv con Gnumeric van a ver que parece que el separador decimal de los n\u00fameros sigue siendo la coma. Sin embargo, si abren el archivo usando Leafpad van a ver que en realidad el separador decimal es ahora el punto, por lo que para los pr\u00f3ximos ejercicios podemos usar fread sin poner el par\u00e1metr\u00f3 dec . Gnumeric cambia los puntos visualmente a comas por estar en espa\u00f1ol. Paso 4 - Calcular velocidades de reacci\u00f3n En f\u00edsica la velocidad es la variaci\u00f3n de posici\u00f3n por unidad de tiempo. La velocidad de reacci\u00f3n es similar, donde queremos averiguar la variaci\u00f3n de se\u00f1al por unidad de tiempo (en nuestro caso es un segundo). Para cada diluci\u00f3n de cada compuesto, nosotros tenemos la se\u00f1al a cuatro puntos en el tiempo (una vez cada 5 minutos, o 300 segundos). Vamos a asumir que la se\u00f1al var\u00eda linealmente con el tiempo, por lo que la forma m\u00e1s directa de conseguir la velocidad de reacci\u00f3n es calcular la pendiente de la recta que pasa por los cuatro puntos que conseguimos experimentalmente. Es de esperar que los cuatro puntos no se alineen perfectamente, pero hay formas en R de calcular y plotear la l\u00ednea que m\u00e1s se ajusta a ellos (hacer una regresi\u00f3n lineal). A continuaci\u00f3n mostramos el ejemplo de \"Umbrella1\" a concentraci\u00f3n 0, es decir, la velocidad de reacci\u00f3n base cuando no hay ning\u00fan compuesto. En este plot vemos que la pendiente de la recta es aproximadamente 1718, lo que quiere decir que cada segundo la se\u00f1al aumenta en 1718. Nuestro objetivo en este paso del TP es calcular este n\u00famero para todas las concentraciones de todos los compuestos. C\u00f3digo usado para hacer el plot anterior (para los curiosos) library ( data.table ) library ( ggplot2 ) dt_parsed_formatted_data <- fread ( \"03_datos_filtermax_parseados_y_formateados.tsv\" , header = T , sep = \"\\t\" , na.strings = NULL ) linear_regression_aux <- lm ( data = dt_parsed_formatted_data [ compuesto == \"Umbrella1\" & concentracion == 0 ], signal ~ segundos_totales ) # La funcion *sprintf* se usa similar a *paste* ya que permite reemplazar los *%s* en el primer string por las variables que le paso # a continuacion formula_aux <- sprintf ( \"Y = %s * X + %s\" , round ( linear_regression_aux $ coefficients [ 2 ], 2 ), round ( linear_regression_aux $ coefficients [ 1 ], 2 )) ggplot ( data = dt_parsed_formatted_data [ compuesto == \"Umbrella1\" & concentracion == 0 ], aes ( x = segundos_totales , y = signal )) + geom_point ( size = 2 ) + geom_smooth ( method = 'lm' ) + theme_bw () + xlab ( \"Tiempo (s)\" ) + ylab ( \"Signal\" ) + ggtitle ( \"Velocidad base (sin compuesto)\" ) + theme ( axis.title = element_text ( size = 14 , hjust = 0.5 ), axis.text = element_text ( size = 14 , hjust = 0.5 ), plot.title = element_text ( size = 16 , hjust = 0.5 )) + annotate ( \"text\" , x = 10 , y = 2000000 , label = formula_aux , hjust = 0 , size = 5 ) Herramientas necesarias En este ejercicio tambi\u00e9n vamos a necesitar varias herramientas, pero la buena noticia es que la mayor\u00eda ya las vieron en el TP anterior o en el paso anterior. Fors anidados Es bastante com\u00fan cuando se trabaja con tablas querer recorrer todas las combinaciones de dos variables categ\u00f3ricas. Una forma de hacer esto es usar fors anidados , es decir, un for adentro de otro for . En este caso el for interno se va a ejecutar completo una vez por cada elemento del for externo. Dentro del for interno es donde vamos a poner el c\u00f3digo que queramos hacer con cada combinaci\u00f3n de nuestras variables. 1) Corran el siguiente ejemplo y vean lo que devuelve. \u00bfCu\u00e1ntas veces se ejecut\u00f3 el print ? \u00bfEn qu\u00e9 orden se recorrieron los diferentes prefijos y sufijos? vector_prefijos <- c ( \"veinti\" , \"cuarenti\" , \"ciento\" ) vector_sufijos <- c ( \"cuatro\" , \"dos\" , \"ocho\" ) for ( prefijo_for in vector_prefijos ) { for ( sufijo_for in vector_sufijos ) { numero_for <- paste ( prefijo_for , sufijo_for , sep = \"-\" ) print ( numero_for ) } } Regresi\u00f3n lineal El ajuste de mis datos a una f\u00f3rmula matem\u00e1tica es un tema s\u00faper complejo; sin embargo, en este TP necesitamos la versi\u00f3n m\u00e1s simple de esto, que son las regresiones lineales. Existe una funci\u00f3n que viene con R llamada lm que nos va a permitir calcular una regresi\u00f3n lineal a partir de dos vectores num\u00e9ricos. regresion_lineal <- lm ( data = iris , formula = Sepal.Length ~ Petal.Length ) print ( regresion_lineal ) Call : lm ( formula = Sepal.Length ~ Petal.Length , data = iris ) Coefficients : ( Intercept ) Petal.Length 4.3066 0.4089 El par\u00e1metro data nos permite poner un Data Frame o Data Table para luego poder mencionar las columnas directamente (de otra forma habr\u00eda que hacer iris$Sepal.Length ) El par\u00e1metro formula es donde le decimos a lm a que f\u00f3rmula debe ajustar los datos. Para regresi\u00f3n lineal es Y ~ X De imprimir regresion_lineal por pantalla vemos los coeficientes de la f\u00f3rmula (Intercept) es la ordenada al origen y la otra columna (en este caso llamada Petal.Length ) es la pendiente Podemos extraer cada uno de estos dos n\u00fameros haciendo: ordenada_al_origen <- regresion_lineal $ coefficients [ 1 ] pendiente <- regresion_lineal $ coefficients [ 2 ] \u00bfSe ajustan mis datos a una recta? Si bien no lo vamos a usar en este TP, es normal al momento de hacer una regresi\u00f3n querer saber que tan bien se ajustan mis datos a la f\u00f3rmula que us\u00e9. Existen varios estad\u00edsticos para analizar esto, pero uno muy usado para regresiones lineales es el R cuadrado , que no tiene nada que ver con el lenguaje de programaci\u00f3n y es un estad\u00edstico que va entre 0 y 1 y cuanto m\u00e1s cerca de 1 es mejor es el ajuste lineal (simplificando infinitamente el tema). En el ejemplo anterior podemos conseguir el R cuadrado haciendo: r_cuadrado <- summary ( regresion_lineal ) $ r.squared Paso 4 - Ejercicio 2) Creen un nuevo script de R , copien el siguiente c\u00f3digo y guardenlo en su carpeta de trabajo. Vayan avanzando por el script y cambien las secciones que dicen @@EDITAR@@ por lo que corresponda (esto puede ser un valor, una variable, una operaci\u00f3n matem\u00e1tica, una comparaci\u00f3n o una funci\u00f3n de R ). #Aca hay que poner el Path Absoluto que apunta a su carpeta de trabajo #Por ej: \"/home/ibioinfo/Documentos/data_TP8b\" setwd ( @@ EDITAR @@ ) library ( data.table ) #Leo los datos ya parseados y formateados dt_parsed_formatted_data <- fread ( @@ EDITAR @@ ) #Para cada combinacion de compuesto y concentracion quiero saber la velocidad de la reaccion, es decir, #la pendiente de la recta que sale de hacer una regresion lineal por los 4 tiempos ensayados #Creo la tabla vacia donde voy a guardar estos datos dt_velocidades_de_reaccion <- data.table ( compuesto = character (), concentracion = numeric (), velocidad = numeric ()) #Voy a tener que recorrer todas las combinaciones de compuestos y concentraciones #Consigo vectores con cada compuesto diferente y con cada concentracion diferente unique_compuestos <- unique ( dt_parsed_formatted_data $ compuesto ) unique_concentraciones <- @@ EDITAR @@ for ( compuesto_for in unique_compuestos ) { # compuesto_for <- unique_compuestos[1] for ( concentracion_for in unique_concentraciones ) { # concentracion_for <- unique_concentraciones[1] #Por cada combinacion de compuesto + concentracion quiero calcular la velocidad de reaccion #Para eso lo primero que necesito hacer es filtrar los datos de *dt_parsed_formatted_data*, para quedarme solo #con aquellas signals que correspondan al compuesto y concentracion de la iteracion actual del *for* sub_dt_parsed_formatted_data <- dt_parsed_formatted_data [( compuesto == @@ EDITAR @@ ) & ( @@ EDITAR @@ )] #Calculo la regresion lineal usando los datos de *sub_dt_parsed_formatted_data* y considerando a #*segundos_totales* como el X y a *signal* como el Y regresion_lineal <- lm ( data = sub_dt_parsed_formatted_data , formula = signal ~ segundos_totales ) #Extraigo la pendiente, que es el segundo elemento del elemento *coefficients* velocidad_de_reaccion <- regresion_lineal $ coefficients [ 2 ] #Creo una nueva fila para agregar a mi tabla de velocidades de reaccion #Esta fila corresponde al compuesto y a la concentracion de esta iteracion de los *fors*, asi como #la velocidad que acabo de calcular new_row_dt_velocidades_de_reaccion <- data.table ( compuesto = @@ EDITAR @@ , concentracion = @@ EDITAR @@ , velocidad = @@ EDITAR @@ ) #Agrego la nueva fila recien creada a mi tabla en donde guardo todas las velocidades dt_velocidades_de_reaccion <- @@ EDITAR @@ } } #Escribo los datos en una nueva tabla write.table ( dt_velocidades_de_reaccion , file = \"04_velocidades_de_reaccion.tsv\" , col.names = T , row.names = F , sep = \"\\t\" , quote = T ) Si todo sali\u00f3 bien, el archivo 04_velocidades_de_reaccion.tsv deber\u00eda ser una tabla del estilo: compuesto concentracion velocidad \"Umbrella1\" 200 633.30896128865 \"Umbrella1\" 133.3333333 672.561474192526 \"Umbrella1\" 88.88888889 710.350673411048 \"Umbrella1\" 59.25925926 630.08948130777 \"Umbrella1\" 39.50617284 720.288720371885 ... ... ... (s\u00ed, los decimales son horribles, en un ratito los arreglamos) Paso 5 - Calcular y plotear IC 50 Primero que nada tenemos que definir un par de conceptos: Vamos a llamar velocidad de reacci\u00f3n base a la velocidad de reacci\u00f3n de la enzima cuando no tiene ning\u00fan inhibidor, o lo que es lo mismo, cuando la concentraci\u00f3n del inhibidor es 0. En nuestro caso tenemos 22 wells donde la concentraci\u00f3n del inhibidor es 0, por lo que vamos a calcular a la velocidad de reacci\u00f3n base como el promedio de las velocidades en esos 22 wells. Vamos a llamar actividad a la relaci\u00f3n entre la velocidad de reacci\u00f3n observada al usar una concentraci\u00f3n dada de un compuesto, y la velocidad de reacci\u00f3n base . Es decir: \\[ actividad = \\frac{velocidadReaccion}{velocidadReaccionBase} \\] Si no hay inhibidor o si la concentraci\u00f3n del inhibidor es muy baja para que haga efecto Actividad ~ 1 Si no hay enzima o si estoy usando un inhibidor perfecto Actividad ~ 0 Ahora s\u00ed, queremos calcular una curva de dosis-respuesta para ver como es afectada nuestra enzima Z por diferentes concentraciones de cada uno de los 22 compuestos. En general es esperable que: A muy bajas concentraciones del compuesto no hay efecto sobre la enzima, por lo que estoy viendo la una actividad cercana a 1. Esto quiere decir que esperamos ver varias concentraciones bajas de un compuesto que muestren la misma actividad . A muy altas concentraciones del compuesto ya est\u00e1 saturado el efecto que \u00e9l pueda hacer sobre la enzima (por ejemplo todos los sitios de uni\u00f3n ya est\u00e1n ocupados), por lo que estoy viendo el m\u00e1ximo efecto que puede hacer dicho compuesto a la actividad de la enzima. Esto quiere decir que esperamos ver varias concentraciones altas que muestren la misma actividad . Las concentraciones intermedias son aquellas en donde una variaci\u00f3n en la concentraci\u00f3n del compuesto produce un cambio en la actividad de la enzima. Est\u00e1s tres propiedades hacen que la curva dosis-respuesta tenga una forma sigmoidea, es decir: Donde en nuestro caso la respuesta va a ser la actividad y la dosis va a ser la concentraci\u00f3n de nuestro compuesto. Dependiendo de las concentraciones elegidas, es normal ver que el eje X de este plot est\u00e9 en escala logar\u00edtmica. En el plot est\u00e1 marcado el IC 50 , el cual es la concentraci\u00f3n del compuesto a la cual la actividad de la enzima cae al 50% (es decir, cuando la velocidad de reacci\u00f3n es la mitad que la velocidad de reacci\u00f3n base ). El IC 50 da informaci\u00f3n de donde est\u00e1 el rango de concentraciones de dicho compuesto que hacen variar la actividad enzim\u00e1tica, entre otras cosas. Herramientas Instalar paquetes de R Para calcular el IC 50 vamos a ajustar nuestros datos a una curva sigmoidea, para lo cual vamos a instalar un paquete de R llamado nplr que hace estos c\u00e1lculos por nosotros. 1) Para instalar un paquete corran en R la l\u00ednea: install.packages ( \"nplr\" ) Y recuerden que cuando lo quieran usar tienen que cargarlo usando library(nplr) o library(\"nplr\") . Como es bastante avanzado no vamos a hablar de nplr por ahora y les vamos a dar esa parte del c\u00f3digo ya hecha. Crear y modificar columnas Una cosa m\u00e1s que tenemos que aprender con los Data Tables es como agregar una columna nueva, o como modificar una columna ya existente. Esto se hace simplemente asign\u00e1ndole el nuevo valor a la columna como si fuera una variable o vector, solo que es importante que el nuevo valor sea o un solo elemento o un vector con longitud igual al n\u00famero de filas de la tabla. 2) Corran el siguiente ejemplo y vean lo que devuelve. library ( data.table ) dt_iris <- as.data.table ( iris ) #Creo nuevas columnas #Si le paso un valor solo toda esa columna va a tener ese valor dt_iris $ nueva_columna <- 1 #De otra forma tengo que pasarle un vector con longitud igual al numero de filas #Este vector puede ser combinacion de otras de las columnas de la tabla dt_iris $ otra_nueva_columna <- dt_iris $ Sepal.Length + dt_iris $ Petal.Length - 1 #Me arrepenti del valor que cree en la columna al principio dt_iris $ nueva_columna <- 5 print ( dt_iris ) Crear plots en PDFs Nosotros sabemos crear plots en RStudio, pero hay veces donde uno tiene que hacer decenas (o miles) de plots y quiere guardarlos todos en un solo proceso. R tiene varias funciones que nos permiten guardar los plots como .jpg , .png , .svg , etc. Ac\u00e1 nos vamos a enfocar en la funci\u00f3n que nos permite guardarlos como .pdf . 3) Corran el siguiente ejemplo y vean lo que devuelve (va a crear un archivo en su Working Directory ). pdf ( \"test.pdf\" , width = 7 , height = 7 ) plot ( x = iris $ Sepal.Length , y = iris $ Petal.Length ) plot ( x = iris $ Sepal.Width , y = iris $ Petal.Width ) plot ( x = iris $ Species , y = iris $ Petal.Length ) dev.off () Los par\u00e1metros width y height indican el tama\u00f1o en pulgadas de cada p\u00e1gina en el pdf. Noten que a partir que abren el pdf los plots ya no van a aparecer en la pesta\u00f1a Plots de RStudio hasta que cierren el pdf (se podr\u00eda pensar que redirige la salida del plot al archivo pdf). Tip - Resetear los gr\u00e1ficos A veces pasa que un pdf queda abierto m\u00e1s de lo que deber\u00eda y no se cierra bien, o que no se crea como deber\u00eda. En estos casos pueden usar la funci\u00f3n graphics.off() antes y despu\u00e9s del c\u00f3digo anterior (especialmente antes) para limpiar cualquier cosa abierta. Solo tengan en cuenta que esto va a vaciarles los plots que tengan guardados en el panel Plots de RStudio. La verdad de la funci\u00f3n plot Nosotros acabamos de ver unos plots hechos con la funci\u00f3n plot() , que es la forma de plotear por defecto en R . Sin embargo plot no solo plotea cosas pas\u00e1ndole un X y un Y, sino que tambi\u00e9n es una funci\u00f3n que de pasarle ciertos tipos de variables (como puede ser una regresi\u00f3n log\u00edstica) usa un plot interno de dichas variables. El paquete nplr trae sus propios plots que se van a hacer mediante plot(regresion_logistica) . Esto no es \u00fanico de este paquete y existen otras librer\u00edas, por ejemplo de filogenia, que tienen este mismo funcionamiento, donde plot hace \u00e1rboles filogen\u00e9ticos. Google Es muy importante al momento de programar saber buscar funcionalidades que uno quiere usar en sus programas. 4) Busquen en internet: C\u00f3mo se calcula el m\u00e1ximo de los elementos de un vector de n\u00fameros en R C\u00f3mo se calcula el m\u00ednimo de los elementos de un vector de n\u00fameros en R C\u00f3mo se calcula el promedio de los elementos de un vector de n\u00fameros en R C\u00f3mo se redondea los decimales de un n\u00famero en R Paso 5 - Ejercicio 5) Creen un nuevo script de R , copien el siguiente c\u00f3digo y gu\u00e1rdenlo en su carpeta de trabajo. Vayan avanzando por el script y cambien las secciones que dicen @@EDITAR@@ por lo que corresponda (esto puede ser un valor, una variable, una operaci\u00f3n matem\u00e1tica, una comparaci\u00f3n o una funci\u00f3n de R ). Warnings en el c\u00f3digo Al ejecutar el siguiente c\u00f3digo les va a aparecer por consola varios Warnings de nplr sobre el fiteo del modelo y la predicci\u00f3n del IC 50. Los Warnings son advertencias, las cuales informan eventos que pueden o no causar problemas. Si bien es importante prestarle atenci\u00f3n a estos Warnings cuando aparecen, en este caso ya est\u00e1n contemplados y pueden ignorarlos. #Aca hay que poner el Path Absoluto que apunta a su carpeta de trabajo #Por ej: \"/home/ibioinfo/Documentos/data_TP8b\" setwd ( @@ EDITAR @@ ) library ( data.table ) library ( nplr ) #Leo los datos de las velocidades de reaccion dt_velocidades_de_reaccion <- @@ EDITAR @@ #Quiero calcular la velocidad de reaccion base, es decir, la velocidad de reaccion sin compuestos #Esto es cuando la concentracion del compuesto es 0 #Nosotros tenemos uno de esos casos para cada compuesto, o sea, tenemos 22 versiones del experimento sin compuesto #Vamos a calcular la velocidad de reaccion base como el promedio de esas 22 velocidades velocidades_reaccion_sin_compuesto <- dt_velocidades_de_reaccion [ @@ EDITAR @@ ] $ velocidad velocidad_reaccion_base <- mean ( velocidades_reaccion_sin_compuesto ) #Ahora que ya las use, voy a sacar las filas que no tengan concentracion de compuesto #ya que no tiene sentido analizarlas para el IC 50 dt_velocidades_de_reaccion <- dt_velocidades_de_reaccion [ concentracion > 0 ] #Quiero calcular la actividad para cada combinacion de compuesto y concentracion #La actividad es la relacion entre la velocidad de reaccion y la velocidad de reaccion base (es decir, la division) dt_velocidades_de_reaccion $ actividad <- @@ EDITAR @@ #El *for* de mas adelante va a tener 2 salidas, un pdf con los plots y un tsv con los datos #Tengo que inicializar ambos #Abro el pdf (toda imagen que se plotee hasta que se cierre el pdf va a ir a el) pdf ( \"05_IC50_plots.pdf\" , width = 7 , height = 7 ) #Creo la tabla vacia dt_IC50 <- data.table ( compuesto = character (), actividad_minima = numeric (), actividad_maxima = numeric (), IC50 = numeric ()) #Recorro todos los compuestos 1 a la vez y calculo el IC 50 para cada uno unique_compuestos <- @@ EDITAR @@ for ( compuesto_for in unique_compuestos ) { # compuesto_for <- unique_compuestos[1] #Por cada compuesto quiero calcular el IC 50 y plotearlo #Para eso lo primero que necesito hacer es filtrar los datos de *dt_velocidades_de_reaccion*, para quedarme solo #con aquellas concentraciones y actividades que correspondan al compuesto de la iteracion actual del *for* sub_dt_velocidades_de_reaccion <- @@ EDITAR @@ #Calculo la regresion sigmoidea usando los datos de *sub_dt_parsed_formatted_data* y considerando a #*concentracion* como el X y a *actividad* como el Y regresion_sigmoidea <- nplr ( x = sub_dt_velocidades_de_reaccion $ concentracion , y = sub_dt_velocidades_de_reaccion $ actividad ) #Esto es una funcion de nplr que calcula el X correspondiente a Y = 0.5, es decir, el IC 50 estimacion_IC50 <- getEstimates ( regresion_sigmoidea , targets = 0.5 ) #Hay casos donde no puede calcularlo, pero en vez de devolver NA calcula el X para el Y mas cercano a 0.5 #Yo no quiero eso, quiero solo los X cuando Y es 0.5, y sino devolver NA if ( estimacion_IC50 $ y == 0.5 ) { IC50 <- estimacion_IC50 $ x } else { #Aca estoy asignando a mano el valor NA (sin comillas), o sea, el valor \"vacio\" IC50 <- NA } #Calculo la actividad minima y maxima para guardarla en el output actividad_minima <- min ( sub_dt_velocidades_de_reaccion $ actividad ) actividad_maxima <- @@ EDITAR @@ #Creo una nueva fila para agregar a mi tabla de IC 50 #Esta fila corresponde al compuesto de esta iteracion de los *fors*, asi como #el IC 50 que acabo de calcular new_row_dt_IC50 <- data.table ( @@ EDITAR @@ ) #Agrego la nueva fila recien creada a mi tabla en donde guardo todas las velocidades dt_IC50 <- @@ EDITAR @@ #Ploteo la regresion (les recomiendo poner el numero de compuesto y el IC 50 en el titulo) titulo_plot <- @@ EDITAR @@ plot ( regresion_sigmoidea , main = titulo_plot , xlab = \"Log10 Concentracion (micromolar)\" , ylab = \"Actividad\" , ylim = c ( 0 , 1.5 ), showGOF = F , xaxt = \"n\" ) #Reescribo el eje X para que se entienda que es logaritmico axis ( side = 1 , at = c ( 0 , 0.5 , 1 , 1.5 , 2 ), labels = c ( expression ( 10 ^ 0 ), expression ( 10 ^ 0.5 ), expression ( 10 ^ 1 ), expression ( 10 ^ 1.5 ), expression ( 10 ^ 2 ))) } #Cierro el pdf dev.off () #Redondeo los decimales extras de los numeros dt_IC50 $ IC50 <- round ( dt_IC50 $ IC50 , 4 ) dt_IC50 $ actividad_minima <- @@ EDITAR @@ dt_IC50 $ actividad_maxima <- @@ EDITAR @@ #Escribo los datos en una nueva tabla write.table ( dt_IC50 , file = \"05_IC50_data.tsv\" , col.names = T , row.names = F , sep = \"\\t\" , quote = T ) Si todo sali\u00f3 bien, el archivo 05_IC50_data.tsv deber\u00eda ser una tabla del estilo: compuesto actividad_minima actividad_maxima IC50 \"Umbrella1\" 0.1708 0.8627 5.2665 \"Umbrella2\" 0.3451 0.7292 2.3456 \"Umbrella3\" 0.125 0.1688 NA \"Umbrella4\" 0.1595 0.7243 2.8252 ... ... ... ... Detr\u00e1s de escenas del armado de este TP Al momento de hacer este TP tuvimos que analizar nosotros los mismos datos que ahora est\u00e1n utilizando ustedes y no ten\u00edamos mucha experiencia con nplr . En las primeras versiones de este TP no estaba la condici\u00f3n if (estimacion_IC50$y == 0.5) , pero mirando los datos de la tabla vs los datos del plot nos dimos cuenta que algo no cerraba. Por ejemplo, el IC 50 en el \"Umbrella22\" daba 0.6851, pero miren el plot, no ten\u00eda sentido eso. Fuimos al for y reemplazamos la primera l\u00ednea comentada por # compuesto_for <- unique_compuestos[22] , seleccionamos solo la \u00faltima parte (sin el # ) y la corrimos con Ctrl + Enter , lo que en este caso hizo que compuesto_for sea \"Umbrella22\". Ah\u00ed fuimos paso a paso por el for viendo que devolv\u00eda cada funci\u00f3n. Al ejecutar estimacion_IC50 <- getEstimates(regresion_sigmoidea, targets = 0.5) el programa nos tir\u00f3 el siguiente Warning: Warning : One ( or more ) of the values were greater or equal to the estimated top asymptote. These values have been replaced by the maximal possible value the model can estimate. Miramos entonces adentro de la variable estimacion_IC50 y vimos que estimacion_IC50$y era 0.004, lo que significaba que en esta iteraci\u00f3n no est\u00e1bamos calculando el IC 50 , sino el IC 0.4 , que no es lo que quer\u00edamos. A partir de esto pusimos el if y le asignamos NA a IC 50 cuando el y no era 0.5. Lo comentamos m\u00e1s que nada para mostrar que el an\u00e1lisis de datos es bastante prueba y error y que es importante pensar si lo que est\u00e1n viendo tiene sentido. Bienvenidos a la Bioinform\u00e1tica Paso 6 - Conclusiones Ahora que tenemos todos los datos que necesitamos es momento de analizarlos. Viendo el .pdf y la tabla generados en el paso anterior respondan: 1) \u00bfPor qu\u00e9 hay casos donde el IC 50 di\u00f3 NA ? 2) En base a los plots obtenidos, \u00bfLes parecen suficientes nuestros datos para estar seguros de los IC 50 calculados? \u00bfCu\u00e1l es un compuesto donde est\u00e1n bastantes seguros de su IC 50 ? \u00bfCu\u00e1l es un compuesto donde desconf\u00edan del IC 50 calculado? 3) \u00bfQu\u00e9 experimentos har\u00edan para tener la curva completa en \"Umbrella1\"? \u00bfY en \"Umbrella8\"? 4) En base a lo observado, nombren dos o tres compuestos que recomendar\u00edan para inhibir a la enzima Z . \u00bfPor qu\u00e9 los eligieron? Ejercicio Adicional 1 - Paso 2 - Limpiar y Parsear el Archivo Leer el Paso 2 para entender el objetivo de este ejercicio. Herramientas Leer y escribir texto plano Por \"texto plano\" nos referimos a leer un archivo de texto que no tiene un formato definido (o sea no es un .csv o .tsv , por ejemplo). Esto puede ser algo como un libro, notas, o una tabla que por alguna raz\u00f3n no la queremos leer como tabla. La forma m\u00e1s directa de leer texto plano en R es la funci\u00f3n readLines() , a la cual hay que pasarle el path del archivo a leer. Esta funci\u00f3n va a devolver un vector en el cual cada elemento es una l\u00ednea del archivo le\u00eddo. Se usa: nuevo_vector <- readLines ( con = \"ARCHIVO\" ) Por otro lado tambi\u00e9n existe la funci\u00f3n inversa, que nos permite escribir un vector en un archivo de texto, donde cada elemento del vector va a ser una l\u00ednea de texto en el archivo. Esta funci\u00f3n es writeLines() y se usa: writeLines ( vector_con_texto , con = \"ARCHIVO_SALIDA\" ) La funci\u00f3n writeLines() tambi\u00e9n se puede usar de una forma similar a print si no se le pasa el par\u00e1metro con . Extraer nombres columnas Hay varias razones por lo cual es \u00fatil extraer un vector con el nombre de las columnas de una tabla, pero hoy lo vamos a hacer para extraer informaci\u00f3n de dichos nombres. La funci\u00f3n colnames() nos devuelve un vector con el nombre de las columnas de una tabla en el orden en el que aparecen en dicha tabla. Por ej: columnas_iris <- colnames ( iris ) print ( columnas_iris ) Extraer substrings Muchas veces es \u00fatil extraer pedazos de strings y ya vimos una forma de hacer esto con split . Sin embargo, hay veces cuando no sabemos el caracter que delimita el texto que queremos extraer, pero s\u00ed sabemos su posici\u00f3n en la cadena completa. En estos casos podemos usar la funci\u00f3n substring : variable_string <- c ( \"123456789\" ) segundo_caracter <- substring ( variable_string , 2 , 2 ) tercer_a_quinto_caracteres <- substring ( variable_string , 3 , 5 ) septimo_caracter_en_adelante <- substring ( variable_string , 7 ) Usar una variable para acceder a una columna de un Data Table A veces pasa que quiero acceder a una variable de una tabla, pero no se previamente a cual. Aca nos va a ser \u00fatil otra forma de acceder a las columnas de las tablas, por ejemplo: # Los 3 bloques siguientes devuelven lo mismo iris $ Species iris [[ \"Species\" ]] columna <- \"Species\" iris [[ columna ]] Ejercicio library ( @@ EDITAR @@ ) #### Paso 2a - LIMPIAR DATOS #### #Uso readLines para cargar el archivo de texto plano plain_text_data <- readLines ( con = \"00_datos_filtermax.txt\" ) #La fila 2 es el header #Las filas 3 a 6 son los datos #Las demas no me interesan plain_text_data <- plain_text_data [ c ( 2 : 6 )] #Escribo los datos en un nuevo archivo writeLines ( plain_text_data , con = \"01_datos_filtermax_limpios.tsv\" ) #### Paso 2b - PARSEAR DATOS #### #Uso fread para cargar la tabla con los datos como salen de FilterMax (pero sin lineas extras) #Aca es importante recordar que ten\u00edamos NAs en nuestros datos y que estaban escritos como *nada*, es decir, \"\" clean_data <- @@ EDITAR @@ #Viendo clean_data pueden ver una columna extra al final llamada V387 (debido a la cantidad de tabs al final del archivo) #Ese es el nombre que le da data.tables por defecto a las columnas sin nombre (esta es la columna 387) #Para que no moleste la sacamos clean_data <- clean_data [, @@ EDITAR @@ ] #Los numeros (columnas de la placa well) son los compuestos #Las letras (filas de la placa well) son las diferentes concentraciones #Queremos poner los mismos datos en una tabla donde nos sea mas facil filtrar un dato espec\u00edfico #Creo la tabla vacia donde voy a guardar estos datos dt_parsed_data <- data.table ( time = @@ EDITAR @@ , temperature = numeric () fila = @@ EDITAR @@ , columna = numeric (), signal = @@ EDITAR @@ ) #Hay varias formas de hacer esto con paquetes extras o con codigos dificiles, pero por ahora vamos a #usar una forma un poco menos eficiente pero que se entiende un poco mas #Quiero crear una lista con todos los nombres de los wells wells_names <- colnames ( clean_data ) #Ahora tengo lo que necesito, pero las primeras dos posiciones son Time y Temperature #Las saco del vector de los nombres wells_names <- wells_names [ - c ( 1 : 2 )] #Voy a recorrer cada nombre de columna y extraer a que fila y a que columna del well corresponde #Luego voy a guardar las cuatro signals de esa columna de la tabla con la informacion que acabo de conseguir for ( well_name_for in wells_names ) { # well_name_for <- wells_names[1] #Uso substring para extraer la letra de la fila en el well fila_for <- substring ( @@ EDITAR @@ ) #Uso substring para extraer el numero de la columna en el well #Uso un patr\u00f3n que funcione para cualquiera de los wells por m\u00e1s que el n\u00famero tenga 1 o 2 decimales columna_for <- substring ( @@ EDITAR @@ ) #Quiero guardar la columna como numero, asi que transformo la variable character en un numeric #Es decir, paso de \"1\" a 1 (por ej) columna_for <- as.numeric ( columna_for ) #Creo nuevas fila para agregar a mi tabla de datos parseados #Aca fila y columna van a ser un valor \u00fanico #Por otro lado, time, temperature y signal van a ser vectores de 4 valores (son las columnas de clean_data) #La columna Temperature puede ser que se escriba un poco rara por problemas de caracteres dt_new_rows_in_parsed_data <- data.table ( time = clean_data $ Time , temperature = clean_data $ `Temperature(C)` , fila = fila_for , columna = columna_for , signal = @@ EDITAR @@ ) #Agrego las nuevas filas recien creadas a mi tabla en donde guardo los datos parseados dt_parsed_data <- @@ EDITAR @@ } #Escribo los datos en una nueva tabla llamada \"02_datos_filtermax_parseados_NUEVO.tsv\" write.table ( @@ EDITAR @@ ) Pueden comparar 02_datos_filtermax_parseados.tsv con 02_datos_filtermax_parseados_NUEVO.tsv y si todo sali\u00f3 bien deber\u00edan ser id\u00e9nticos. Bibliograf\u00eda Consola de R Comando help()","title":"TP 8b - R - Aplicaci\u00f3n"},{"location":"practicos/TP08b_R/#tp-8b-r-programando-en-biologia-parte-2","text":"Materiales","title":"data-toc-label"},{"location":"practicos/TP08b_R/#videos-de-la-clase-grabada","text":"Introducci\u00f3n al TP Puesta en com\u00fan del TP","title":"Videos de la clase grabada"},{"location":"practicos/TP08b_R/#codigos-resueltos","text":"C\u00f3digos completos (tienen que setear el Working Directory ) (si corren el 3, 4 y 5 llegan al PDF )","title":"C\u00f3digos resueltos"},{"location":"practicos/TP08b_R/#software-a-usar","text":"R (ya instalado en la VM). RStudio (ya instalado en la VM)","title":"Software a usar"},{"location":"practicos/TP08b_R/#recursos-online","text":"Curso online de R de Coursera (se puede hacer gratis) (en ese caso no da certificado) Tips de comandos b\u00e1sicos de R Data Tables: Introducci\u00f3n oficial y otra p\u00e1gina con m\u00e1s info ggplot2: Vistazo r\u00e1pido , otra p\u00e1gina con cada plot detallando sus par\u00e1metros y cheatsheet","title":"Recursos Online"},{"location":"practicos/TP08b_R/#objetivos","text":"Familiarizarse en el lenguaje de programaci\u00f3n R . Ver como los mismos conceptos de programaci\u00f3n se trasladan de un lenguaje a otro. Utilizar herramientas de programaci\u00f3n para resolver problemas biol\u00f3gicos.","title":"Objetivos"},{"location":"practicos/TP08b_R/#introduccion-al-tema","text":"Es muy normal que en trabajos de biolog\u00eda sea necesario trabajar con datos provenientes de servicios o equipos que no generan outputs de formato est\u00e1ndar (separados por tabs, comas, etc). Esto hace que cuando queramos cargar estos outputs en cualquier programa de an\u00e1lisis de datos vamos a tener que darles formato manualmente, algo que puede no ser muy complicado cuando se trata de unos pocos archivos o un solo ensayo, pero se vuelve un problema en grandes cantidades. En la materia ya vimos varios archivos de salida con patrones propios, por ejemplo los archivos FASTA, donde el marcador > es usado para indicar el comienzo del header una secuencia. Diferentes programas van a tener diferentes patrones de salida, pero suelen haber ciertos caracteres bastante usados como # , ! , * , | , etc. En este trabajo pr\u00e1ctico vamos a usar el lenguaje de programaci\u00f3n R para leer datos generados por un lector de placas de wells. Vamos a parsear dichos datos para que est\u00e9n en un formato con el que podamos trabajar, y vamos a procesarlos como necesitemos para calcular estad\u00edsticos y plots que contengan informaci\u00f3n sobre el experimento realizado.","title":"Introducci\u00f3n al Tema"},{"location":"practicos/TP08b_R/#experimento","text":"","title":"Experimento"},{"location":"practicos/TP08b_R/#objetivo","text":"En el TP de hoy vamos a querer encontrar un compuesto que funcione de inhibidor para una enzima de inter\u00e9s, a la que vamos a denominar enzima Z . No solo nos va a interesar que compuestos funcionan como inhibidores para ella, sino que tambi\u00e9n queremos calcular el IC 50 de cada uno de dichos compuestos (que en nuestro caso ser\u00eda la concentraci\u00f3n a la cual el inhibidor produce una reacci\u00f3n un 50% m\u00e1s lenta que sin inhibidor). Por suerte nuestra enzima de inter\u00e9s tiene como producto un compuesto fluorescente. Sabiendo esto podemos estimar la velocidad de la reacci\u00f3n calculando una regresi\u00f3n lineal de la abundancia de dicho producto a lo largo del tiempo (esto lo vamos a explicar un poco m\u00e1s detalladamente cuando lo hagamos). Si un compuesto funciona como inhibidor en algunas de las concentraciones evaluadas, la velocidad de la reacci\u00f3n deber\u00eda caer.","title":"Objetivo"},{"location":"practicos/TP08b_R/#filtermax","text":"Una forma de analizar varios compuestos y concentraciones a la vez es usar el equipo FilterMax F5 , el cual permite hacer mediciones puntuales de absorbancia y fluorescencia (entre otros) en placas de wells de 96, 384 y 1536. Incluso permite hacer mediciones a distintos tiempos (por ejemplo, se le puede programar para hacer mediciones cada ciertos intervalos temporales). En nuestro ejemplo (datos reales, nombres ficticios), vamos a utilizar el FilterMax F5 para evaluar varias placas de 384 wells y vamos a hacer 4 evaluaciones por placa, una cada 5 minutos. Cada columna de la placa corresponde compuesto distinto (22 compuestos, 1 por columna) y cada fila tiene concentraciones diferentes de cada compuesto (16 concentraciones, diluciones seriadas). Un esquema de este experimento se puede ver en esta planilla .","title":"FilterMax"},{"location":"practicos/TP08b_R/#paso-1-familiarizarnos-con-el-archivo","text":"El primer paso cuando uno empieza a trabajar con un archivo nuevo es siempre mirarlo y deducir su formato. Los resultados reales de este experimento pueden verlos en el archivo 00_datos_filtermax.txt que se encuentra en sus materiales de trabajo. Abran el archivo 00_datos_filtermax.txt con Leafpad, vean su estructura y respondan las siguientes preguntas: 1) \u00bfSe parece un poco a alg\u00fan .csv (columnas separadas por comas) o .tsv (columnas separadas por tabs) que hayan visto antes? \u00bfQue diferencias tiene? Teniendo en cuenta esas diferencias y considerando que vamos a querer leerlo como una tabla en R \u00bfLes parece que hay filas que est\u00e1n de m\u00e1s? 2) Mirando el archivo y la planilla del experimento: \u00bfQu\u00e9 hay en la celda A1? \u00bfQu\u00e9 posiciones contienen las diferentes diluciones del compuesto \"Umbrella2\"? \u00bfCu\u00e1ntos datos hay para cada diluci\u00f3n del compuesto \"Umbrella2\"? \u00bfPor qu\u00e9? 3) Ahora abra el archivo con Gnumeric (Click derecho sobre el archivo Abrir con Oficina Gnumeric). Al final de cada placa hay varias celdas sin datos. \u00bfHay algo en la planilla del experimento que explique por qu\u00e9 pasa esto?","title":"Paso 1 - Familiarizarnos"},{"location":"practicos/TP08b_R/#paso-2-limpiar-y-parsear-el-archivo","text":"En este paso queremos hacer 2 cosas: Primero, queremos sacar cualquier fila extra de 00_datos_filtermax.txt que nos impida leer el archivo usando fread . Si bien en este caso esto se podr\u00eda hacer a mano, como programadores queremos soluciones que escalen bien con el n\u00famero de datos, asi que lo vamos a hacer en un script . Segundo, queremos reorganizar los datos para poder trabajar con ellos m\u00e1s f\u00e1cil, y para eso queremos una tabla con la siguiente estructura: time temperature fila columna signal \"00:00:00\" 30 \"A\" 1 417246 \"00:04:59\" 30 \"A\" 1 595504 \"00:10:00\" 30 \"A\" 1 789920 \"00:15:00\" 30 \"A\" 1 985947 \"00:00:00\" 30 \"A\" 2 389328 ... ... ... ... ... Si bien este paso es importante, tambi\u00e9n es bastante espec\u00edfico a la salida del FilterMax F5 . Por esta raz\u00f3n les vamos a dar el archivo ya parseado para que pasemos directamente al an\u00e1lisis de datos m\u00e1s general. Este es el archivo 02_datos_filtermax_parseados.tsv que se encuentra en sus materiales de trabajo. Dicho esto, si completan el resto del TP a tiempo y quieren aprender c\u00f3mo llegar del archivo original a \u00e9ste archivo pueden hacer el Ejercicio Adicional 1 abajo de todo. 1) Abran el archivo 02_datos_filtermax_parseados.tsv con Leafpad y vean la columna signal . \u00bfQu\u00e9 piensan que significan los NA en esa columna?","title":"Paso 2 - Limpiar y Parsear"},{"location":"practicos/TP08b_R/#paso-3-agregar-la-informacion-que-necesito","text":"En este momento tenemos una tabla donde cada fila es una se\u00f1al independiente, pero tenemos algunos problemas: No tengo informaci\u00f3n de los compuestos en la tabla, solo de los n\u00fameros de las columnas No tengo informaci\u00f3n de las diluciones en la tabla, solo de las letras de las filas M\u00e1s adelante vamos a querer calcular la velocidad de reacci\u00f3n , es decir, c\u00f3mo var\u00eda la signal seg\u00fan el time . Sin embargo, ac\u00e1 time es un string , por lo que necesito transformarlo a n\u00famero Estas son las cosas que queremos arreglar. Por suerte tenemos tambi\u00e9n otras dos tablas, una indicando que compuesto hay en cada columna ( 00_datos_compuestos.tsv ) y otra indicando que diluci\u00f3n hay en cada fila ( 00_datos_concentraciones.tsv ). Esto se podr\u00eda hacer a mano, pero llevar\u00eda mucho tiempo y podr\u00eda haber errores de tipeo. Por esta raz\u00f3n vamos a crear un programa que haga todo esto por nosotos. Sin embargo, antes de crear este programa necesitamos aprender algunas cosas nuevas:","title":"Paso 3 - Agregar Informaci\u00f3n"},{"location":"practicos/TP08b_R/#herramientas-necesarias","text":"","title":"Herramientas necesarias"},{"location":"practicos/TP08b_R/#filtrar-filas-en-data-table","text":"Algo de esto vimos en el TP anterior, pero es posible filtrar filas de un Data Table seg\u00fan el valor de las diferentes columnas en dicha fila. Vamos a volver a usar el data set iris que est\u00e1 siempre cargado en memoria; sin embargo, iris es un Data Frame , por lo que lo vamos a tener que convertir en Data Table . library ( data.table ) #tenemos que cargar el paquete data.table en memoria cada vez que cerramos RStudio dt_iris <- as.data.table ( iris ) Ahora supongamos que queremos solo las filas donde la columna Species es versicolor \u00f3 virginica . Hay varias formas de hacer esto y todas les van a ser \u00fatiles para lo que tenemos que hacer hoy. 1) Corran por lo menos dos de las l\u00edneas de c\u00f3digo siguientes y vean lo que devuelven: # Cualquiera de estas 5 l\u00edneas de c\u00f3digo devuelve el mismo *Data Table* dt_iris [( Species == \"versicolor\" ) | ( Species == \"virginica\" )] dt_iris [ Species %in% c ( \"versicolor\" , \"virginica\" )] dt_iris [ Species != \"setosa\" ] dt_iris [ ! ( Species == \"setosa\" )] dt_iris [ ! ( Species %in% c ( \"setosa\" ))]","title":"Filtrar filas en Data Table"},{"location":"practicos/TP08b_R/#mergear-data-tables","text":"Por mergear nos referimos a juntar dos Data Tables horizontalmente, es decir, agregar de alguna forma las columnas de uno al otro. 2) Corran el siguiente ejemplo y vean lo que devuelve. genes <- c ( \"ERT2\" , \"TTR4\" , \"REC1\" ) esencialidad <- c ( F , F , T ) expresiones <- c ( 100 , 1000 , 10000 ) dt_info_de_esencialidad <- data.table ( gen = genes , esencial = esencialidad ) dt_info_de_expresion <- data.table ( gen = genes , expresion = expresiones ) dt_toda_la_info <- merge ( dt_info_de_esencialidad , dt_info_de_expresion , by = \"gen\" ) print ( dt_toda_la_info ) Como ven, la funci\u00f3n merge toma 2 Data Tables y los une por la columna definida en el par\u00e1metro by . Una cosa interesante es que no es necesario que ambos Data Frames tengan el mismo tama\u00f1o. 3) Corran el siguiente ejemplo y vean lo que devuelve. especies <- c ( \"setosa\" , \"virginica\" , \"versicolor\" ) empieza_con_S <- c ( T , F , F ) dt_info_S <- data.table ( Species = especies , empieza_con_S = empieza_con_S ) nueva_dt_iris <- merge ( dt_iris , dt_info_S , by = \"Species\" ) print ( nueva_dt_iris ) Para cada fila de dt_iris el merge agrego el valor de empieza_con_S seg\u00fan la columna Species . Van a ver que se desordenaron las filas y las columnas. Esto sucede ya que merge va a mover a la columna usada en el by al principio. Uno despu\u00e9s tiene que reordenarlas como prefiera.","title":"Mergear Data Tables"},{"location":"practicos/TP08b_R/#agregar-filas-a-data-tables","text":"Ahora que aprendimos a agregar columnas en masa tambi\u00e9n queremos hacer lo mismo con una o m\u00e1s filas. 4) Corran el siguiente ejemplo y vean lo que devuelve. genes <- c ( \"ERT2\" , \"TTR4\" , \"REC1\" ) esencialidad <- c ( F , F , T ) expresiones <- c ( 100 , 1000 , 10000 ) dt_toda_la_info <- data.table ( gen = genes , esencial = esencialidad , expresion = expresiones ) dt_nueva_fila <- data.table ( gen = \"AFK5\" , esencial = T , expresion = 50 ) dt_toda_la_info <- rbindlist ( list ( dt_toda_la_info , dt_nueva_fila )) print ( dt_toda_la_info ) El comando rbindlist concatena dos Data Tables , donde el segundo puede ser una sola fila o algo m\u00e1s grande. Es importante que ambos Data Tables tengan la misma estructura para que el comando no devuelva errores.","title":"Agregar filas a Data Tables"},{"location":"practicos/TP08b_R/#crear-data-table-vacio","text":"Ahora que sabemos agregar filas a un Data Table , puede ser entonces \u00fatil tener un Data Table vac\u00edo al que le voy a agregando filas que voy calculando (por ejemplo en un ciclo). 5) Corran el siguiente ejemplo y vean lo que devuelve. dt_toda_la_info_vacio <- data.table ( gen = character (), esencial = logical (), expresion = numeric ()) print ( dt_toda_la_info_vacio ) dt_nueva_fila <- data.table ( gen = \"AFK5\" , esencial = T , expresion = 50 ) dt_toda_la_info <- rbindlist ( list ( dt_toda_la_info_vacio , dt_nueva_fila )) print ( dt_toda_la_info ) Como ven, al crear un Data Table vac\u00edo tengo que asignar a cada columna el tipo de datos que va a contener. Aca estoy usando character() ( strings ), logical() ( booleano ) y numeric() (n\u00fameros reales). El \u00fanico otro tipo que puede ser que usen en esta materia es el integer() que son n\u00fameros enteros, pero como dijimos en el TP anterior es com\u00fan usar numeric() para estos tambi\u00e9n.","title":"Crear Data Table vac\u00edo"},{"location":"practicos/TP08b_R/#reordenar-columnas-en-data-tables","text":"Como mencionamos antes, el merge nos va a desordenar las columnas de la tabla. Adem\u00e1s, es posible querer quedarnos con solo algunas de las columnas de una tabla porque ya no tenemos m\u00e1s usos para otras. Una forma de hacer esto es: dt_iris <- as.data.table ( iris ) #Los tres siguientes bloques hacen lo mismo, qued\u00e1ndonos solo con las #columnas Species, Sepal.Length y Sepal.Width dt_iris [, . ( Species , Sepal.Length , Sepal.Width )] dt_iris [, c ( \"Species\" , \"Sepal.Length\" , \"Sepal.Width\" )] columnas_a_quedarnos <- c ( \"Species\" , \"Sepal.Length\" , \"Sepal.Width\" ) dt_iris [, columnas_a_quedarnos , with = F ] Esto es \u00fatil cuando queremos quedarnos con pocas columnas, pero \u00bfqu\u00e9 pasa cuando tenemos muchas y solo queremos sacar algunas? Ah\u00ed podemos hacer: dt_iris <- as.data.table ( iris ) #Los dos siguientes bloques hacen lo mismo, sacando las columnas Species, Sepal.Length y Sepal.Width dt_iris [, - c ( \"Species\" , \"Sepal.Length\" , \"Sepal.Width\" )] columnas_a_borrar <- c ( \"Species\" , \"Sepal.Length\" , \"Sepal.Width\" ) dt_iris [, - columnas_a_borrar , with = F ]","title":"Reordenar columnas"},{"location":"practicos/TP08b_R/#splitear-strings","text":"Hay varias funciones en R que nos permiten parsear texto y una de las m\u00e1s f\u00e1ciles de entender es strsplit . Como su nombre lo indica esta funci\u00f3n splitea (o corta) un string (o cadena de caracteres). Veamos un ejemplo: frase <- \"Habia-una-vez\" frase_spliteada <- strsplit ( frase , split = \"-\" ) print ( frase_spliteada ) [[ 1 ]] [ 1 ] \"Habia\" \"una\" \"vez\" Como ven la funci\u00f3n strsplit toma un string y lo divide en diferentes fragmentos seg\u00fan el par\u00e1metro split . No se si lo recuerdan, pero en el TP anterior hablamos de las variables llamadas listas, que se pueden pensar como vectores que pueden contener variables de distinto tipo dentro de ellas (mientras que todos los elementos de un vector son de un mismo tipo). Ese [[1]] en el output anterior nos est\u00e1 indicando que strsplit nos est\u00e1 devolviendo una variable de tipo list donde el primer elemento es el vector con la frase spliteada . 6) Si bien el par\u00e1metro split suele ser un caracter, en realidad puede ser un string cualquiera. Prueben el c\u00f3digo anterior usando split = \"-una-\" y vean que pasa. 7) Vean que pasa cuando usan split = \"\" . 8) P\u00e1senle ahora a strsplit el siguiente vector de strings: frases <- c(\"Aqu\u00ed me pongo a cantar\", \"al comp\u00e1s de la vig\u00fcela\") . Sabiendo que queremos splitear las diferentes palabras, \u00bfcu\u00e1l ser\u00eda el valor de split en este caso? \u00bfCu\u00e1ntos elementos tiene la lista que devuelve strsplit ? \u00bfPor qu\u00e9? \u00bfCu\u00e1l es la tercera palabra de la segunda frase? (impr\u00edmanla por pantalla usando print )","title":"Splitear strings"},{"location":"practicos/TP08b_R/#eliminar-elementos-repetidos-en-vectores","text":"En los Data Tables es com\u00fan tener columnas con categor\u00edas, por ejemplo la columna Species en la tabla iris . Es normal al momento de programar no saber previamente cu\u00e1les van a ser esas categor\u00edas (especies en este caso), por lo que muchas veces se extraen de la columna misma. Una forma de hacer esto es usar la funci\u00f3n unique() , la cual toma un vector y saca los elementos repetidos, dejando uno de cada uno. 9) Corran el siguiente ejemplo y vean lo que devuelve. vector_especies <- iris $ Species vector_especies_unicas <- unique ( vector_especies ) print ( vector_especies ) print ( vector_especies_unicas ) La columna iris$Species es t\u00e9cnicamente un factor , pero estos son simplemente vectores con propiedades extras. La funci\u00f3n unique() va a funcionar igual de pasarle un vector de caracteres; de hecho, esta funci\u00f3n tambi\u00e9n puede remover filas repetidas de un Data Table .","title":"Elementos repetidos"},{"location":"practicos/TP08b_R/#usar-fread-con-datos-faltantes","text":"Es com\u00fan que un set de datos tenga datos faltantes, lo que en nuestro caso vendr\u00eda a ser wells sin se\u00f1al. Diferentes tablas los van a indicar de diferentes maneras, pero es com\u00fan verlos como nada (o sea veo los separadores de columnas, pero no hay informaci\u00f3n en el medio), NaN ( Not a Number ), ND ( No Data ) o como NA ( Not Available ). En esta caso vamos a usar NA . Es importante al momento de leer un archivo saber si mi archivo tiene o no estos datos faltantes, ya que de no tenerlo en cuenta puedo terminar leyendo a NA como el string \"NA\", lo cual puede insertar datos falsos y hasta forzar a R a leer una columna num\u00e9rica como si fueran todos strings . Podemos indicarle a fread si hay celdas sin valores y como est\u00e1n escritas con el par\u00e1metro na.strings : dt <- fread ( \"ARCHIVO_DT\" , header = T , sep = \"\\t\" , na.strings = \"NA\" ) En este caso le estamos indicando que hay celdas sin valores y que est\u00e1n escritas en la tabla como \"NA\" (pueden estar con o sin comillas en el archivo). De querer indicarle a fread que los datos faltantes est\u00e1n como nada se usa na.strings = \"\" , aunque en este caso cualquier columna con un string vac\u00edo tambi\u00e9n va a ser considerada dato faltante. Tip - Carga m\u00e1s r\u00e1pida de los datos Si estamos seguros que no hay celdas sin valores en nuestros datos, le podemos pasar na.strings = NULL para indicarle que no busque celdas vac\u00edas, lo que acelera la carga de la tabla.","title":"fread y NAs"},{"location":"practicos/TP08b_R/#usar-fread-con-decimales-espanoles","text":"Otro problema com\u00fan al momento de trabajar con datos es que por alguna diab\u00f3lica raz\u00f3n el separador de decimales y el separador de miles no son iguales para algunos pa\u00edses que para otros, de hecho, son exactamente al rev\u00e9s. Es posible entonces que tengan una tabla que hizo alguien en Argentina donde uso comas como separador de decimales, pero que al cargarla en R , el cual fue creado en Estados Unidos, piense que dichas comas son separador de miles, lo que rompe completamente los n\u00fameros pasados. Por suerte algo de consideraci\u00f3n tienen y existe un par\u00e1metro de fread que nos permite especificar cual es el separador de decimales (que por defecto es el punto): dt <- fread ( \"ARCHIVO_DT\" , header = T , sep = \"\\t\" , dec = \",\" )","title":"fread y decimales"},{"location":"practicos/TP08b_R/#paso-3-ejercicio","text":"10) Creen un nuevo script de R , copien el siguiente c\u00f3digo y guardenlo en su carpeta de trabajo. Vayan avanzando por el script y cambien las secciones que dicen @@EDITAR@@ por lo que corresponda (esto puede ser un valor, una variable, una operaci\u00f3n matem\u00e1tica, una comparaci\u00f3n o una funci\u00f3n de R ). Warning - Working Directory Cada vez que lean o escriban un archivo recuerden que el path que le pasen debe ser un path absoluto o un path relativo al Working Directory . Para cambiar el Working Directory pueden usar la funci\u00f3n setwd() que aprendimos en el TP anterior. Tip - \u00d1 y acentos Van a ver que en los c\u00f3digos tratamos de no usar la letra \u00d1 o acentos. Esto es as\u00ed ya que cuando uno comparte c\u00f3digo entre varias personas suele pasar que algunas de esos caracteres se \"rompen\" y se ven feo (por ejemplo un texto que era dise\u00f1o_compuestos se ve\u00eda como dise\u00c3\u00b1o_compuestos en otra PC). Si bien es posible poner est\u00e1ndares de codificaci\u00f3n de texto en grupos, la realidad es que solemos programar en ingl\u00e9s por lo que el problema se evita solo. Este tip es especialmente importante para los nombres de las variables. Ah\u00ed si que recomendamos nunca usar acentos o \u00d1 (o espacios). #Aca hay que poner el Path Absoluto que apunta a su carpeta de trabajo #Por ej: \"/home/ibioinfo/Documentos/data_TP8b\" setwd ( @@ EDITAR @@ ) library ( data.table ) #Uso fread para cargar los datos parseados teniendo en cuenta que tienen NAs dt_parsed_data <- fread ( @@ EDITAR @@ ) #Primero que nada se que las columnas de los wells 23 y 24 estan vacias, asi que saco las filas #donde *columna* sea 23 o 24 (o sea, me quedo con las filas donde *columna* es 1 a 22) dt_parsed_data <- dt_parsed_data [ @@ EDITAR @@ ] #Ahora, la fila y la columna no me esta dando mucha informacion de lo que esta pasando, #por lo que quiero agregar informacion de los compuestos y de concentraciones #Agrego informacion compuestos dt_datos_compuestos <- fread ( \"00_datos_compuestos.tsv\" , header = T , sep = \"\\t\" , na.strings = NULL ) dt_parsed_data <- merge ( dt_parsed_data , dt_datos_compuestos , by = \"columna\" ) #Agrego informacion concentraciones (ojo que en *00_datos_concentraciones.tsv* el separador decimal es la coma) dt_datos_concentraciones <- fread ( @@ EDITAR @@ ) dt_parsed_data <- merge ( @@ EDITAR @@ ) #Para cada combinacion de compuesto y concentracion quiero saber la velocidad de la reaccion, es decir, #la pendiente de la recta que sale de hacer una regresion lineal por los 4 tiempos ensayados #El primer problema que tengo es que la variable time es un *string*, por lo que no puedo usarla #como X en una ecuacion. Por esta razon vamos a convertir a time en cantidad de segundos #Si bien hay 1408 filas, en si solo hay 4 tiempos que se repiten: #\"00:00:00\", \"00:04:59\", \"00:10:00\" y \"00:15:00\" #Voy entonces a hacer una tabla llamada dt_times_in_seconds que va a empezar vac\u00eda y una vez corrido el #siguiente *for* va a tener 4 filas, una por cada uno de los 4 tiempos #Esta tabla va a tener dos columnas, la columna *time* indicando el tiempo en string que estamos analizando #y la columna *segundos_totales* que contiene ese tiempo transformado en numero y en segundos #Extraigo entonces los diferentes tiempos y creo una tabla vacia donde voy a guardar la cantidad de segundos #para cada *time* unique_times <- unique ( dt_parsed_data $ time ) dt_times_in_seconds <- data.table ( time = character (), segundos_totales = numeric ()) for ( time_for in unique_times ) { # Esta siguiente linea comentada la uso para debuggear, es decir, para cuando estoy creando el programa # Si la ejecutan a mano (sin el #) pueden entonces ir paso a paso en el *for* viendo que funcione todo # Recuerden que pueden usar CTRL + ENTER para ejecutar el codigo seleccionado o ver el valor de una variable # time_for <- unique_times[2] #Divido las horas, minutos y segundos y las transformo a numeros time_spliteado <- strsplit ( time_for , \":\" ) #*strsplit* devuelve una lista, que es como un vector, pero mas complicado #Voy a sobreescribir la variable quedandome solo con el primer elemento de la lista, que es un vector time_spliteado <- time_spliteado [[ 1 ]] #Guardo cada uno de los tres numeros en otra variable. Como ahora son *strings* uso as.numeric() para #convertirlos en numeros horas <- as.numeric ( @@ EDITAR @@ ) minutos <- as.numeric ( @@ EDITAR @@ ) segundos <- as.numeric ( @@ EDITAR @@ ) #Calculo los segundos totales, es decir, del paso anterior transformo las horas y los minutos en segundos #y sumo las tres variables segundos_totales <- @@ EDITAR @@ #Guardo esta info en la tabla que acabo de crear dt_new_row_times_in_seconds <- data.table ( time = @@ EDITAR @@ , segundos_totales = @@ EDITAR @@ ) dt_times_in_seconds <- rbindlist ( list ( dt_times_in_seconds , dt_new_row_times_in_seconds )) } #Agrego la informacion de los segundos totales (guardada en dt_times_in_seconds) a mi tabla original dt_parsed_data <- merge ( @@ EDITAR @@ ) #Ahora van a ver que las columnas de la tabla parecen estar mezcladas, lo que se debe a los merge #Por otro lado hay columnas que ya no vamos a usar #Resolvemos las dos cosas a la vez rearmando las columnas de la tabla dt_parsed_data <- dt_parsed_data [, . ( compuesto , concentracion , segundos_totales , signal )] #Escribo los datos en una nueva tabla write.table ( dt_parsed_data , file = \"03_datos_filtermax_parseados_y_formateados.tsv\" , col.names = T , row.names = F , sep = \"\\t\" , quote = T ) Si todo sali\u00f3 bien, el archivo 03_datos_filtermax_parseados_y_formateados.tsv deber\u00eda ser una tabla del estilo: compuesto concentracion segundos_totales signal \"Umbrella1\" 200 0 417246 \"Umbrella2\" 200 0 389328 \"Umbrella3\" 200 0 225039 \"Umbrella4\" 200 0 248039 ... ... ... ... Warning - Gnumeric transforma visualmente los separadores decimales Si abren el archivo 03_datos_filtermax_parseados_y_formateados.tsv con Gnumeric van a ver que parece que el separador decimal de los n\u00fameros sigue siendo la coma. Sin embargo, si abren el archivo usando Leafpad van a ver que en realidad el separador decimal es ahora el punto, por lo que para los pr\u00f3ximos ejercicios podemos usar fread sin poner el par\u00e1metr\u00f3 dec . Gnumeric cambia los puntos visualmente a comas por estar en espa\u00f1ol.","title":"Paso 3 - Ejercicio"},{"location":"practicos/TP08b_R/#paso-4-calcular-velocidades-de-reaccion","text":"En f\u00edsica la velocidad es la variaci\u00f3n de posici\u00f3n por unidad de tiempo. La velocidad de reacci\u00f3n es similar, donde queremos averiguar la variaci\u00f3n de se\u00f1al por unidad de tiempo (en nuestro caso es un segundo). Para cada diluci\u00f3n de cada compuesto, nosotros tenemos la se\u00f1al a cuatro puntos en el tiempo (una vez cada 5 minutos, o 300 segundos). Vamos a asumir que la se\u00f1al var\u00eda linealmente con el tiempo, por lo que la forma m\u00e1s directa de conseguir la velocidad de reacci\u00f3n es calcular la pendiente de la recta que pasa por los cuatro puntos que conseguimos experimentalmente. Es de esperar que los cuatro puntos no se alineen perfectamente, pero hay formas en R de calcular y plotear la l\u00ednea que m\u00e1s se ajusta a ellos (hacer una regresi\u00f3n lineal). A continuaci\u00f3n mostramos el ejemplo de \"Umbrella1\" a concentraci\u00f3n 0, es decir, la velocidad de reacci\u00f3n base cuando no hay ning\u00fan compuesto. En este plot vemos que la pendiente de la recta es aproximadamente 1718, lo que quiere decir que cada segundo la se\u00f1al aumenta en 1718. Nuestro objetivo en este paso del TP es calcular este n\u00famero para todas las concentraciones de todos los compuestos. C\u00f3digo usado para hacer el plot anterior (para los curiosos) library ( data.table ) library ( ggplot2 ) dt_parsed_formatted_data <- fread ( \"03_datos_filtermax_parseados_y_formateados.tsv\" , header = T , sep = \"\\t\" , na.strings = NULL ) linear_regression_aux <- lm ( data = dt_parsed_formatted_data [ compuesto == \"Umbrella1\" & concentracion == 0 ], signal ~ segundos_totales ) # La funcion *sprintf* se usa similar a *paste* ya que permite reemplazar los *%s* en el primer string por las variables que le paso # a continuacion formula_aux <- sprintf ( \"Y = %s * X + %s\" , round ( linear_regression_aux $ coefficients [ 2 ], 2 ), round ( linear_regression_aux $ coefficients [ 1 ], 2 )) ggplot ( data = dt_parsed_formatted_data [ compuesto == \"Umbrella1\" & concentracion == 0 ], aes ( x = segundos_totales , y = signal )) + geom_point ( size = 2 ) + geom_smooth ( method = 'lm' ) + theme_bw () + xlab ( \"Tiempo (s)\" ) + ylab ( \"Signal\" ) + ggtitle ( \"Velocidad base (sin compuesto)\" ) + theme ( axis.title = element_text ( size = 14 , hjust = 0.5 ), axis.text = element_text ( size = 14 , hjust = 0.5 ), plot.title = element_text ( size = 16 , hjust = 0.5 )) + annotate ( \"text\" , x = 10 , y = 2000000 , label = formula_aux , hjust = 0 , size = 5 )","title":"Paso 4 - Calcular velocidad"},{"location":"practicos/TP08b_R/#herramientas-necesarias_1","text":"En este ejercicio tambi\u00e9n vamos a necesitar varias herramientas, pero la buena noticia es que la mayor\u00eda ya las vieron en el TP anterior o en el paso anterior.","title":"Herramientas necesarias"},{"location":"practicos/TP08b_R/#fors-anidados","text":"Es bastante com\u00fan cuando se trabaja con tablas querer recorrer todas las combinaciones de dos variables categ\u00f3ricas. Una forma de hacer esto es usar fors anidados , es decir, un for adentro de otro for . En este caso el for interno se va a ejecutar completo una vez por cada elemento del for externo. Dentro del for interno es donde vamos a poner el c\u00f3digo que queramos hacer con cada combinaci\u00f3n de nuestras variables. 1) Corran el siguiente ejemplo y vean lo que devuelve. \u00bfCu\u00e1ntas veces se ejecut\u00f3 el print ? \u00bfEn qu\u00e9 orden se recorrieron los diferentes prefijos y sufijos? vector_prefijos <- c ( \"veinti\" , \"cuarenti\" , \"ciento\" ) vector_sufijos <- c ( \"cuatro\" , \"dos\" , \"ocho\" ) for ( prefijo_for in vector_prefijos ) { for ( sufijo_for in vector_sufijos ) { numero_for <- paste ( prefijo_for , sufijo_for , sep = \"-\" ) print ( numero_for ) } }","title":"Fors anidados"},{"location":"practicos/TP08b_R/#regresion-lineal","text":"El ajuste de mis datos a una f\u00f3rmula matem\u00e1tica es un tema s\u00faper complejo; sin embargo, en este TP necesitamos la versi\u00f3n m\u00e1s simple de esto, que son las regresiones lineales. Existe una funci\u00f3n que viene con R llamada lm que nos va a permitir calcular una regresi\u00f3n lineal a partir de dos vectores num\u00e9ricos. regresion_lineal <- lm ( data = iris , formula = Sepal.Length ~ Petal.Length ) print ( regresion_lineal ) Call : lm ( formula = Sepal.Length ~ Petal.Length , data = iris ) Coefficients : ( Intercept ) Petal.Length 4.3066 0.4089 El par\u00e1metro data nos permite poner un Data Frame o Data Table para luego poder mencionar las columnas directamente (de otra forma habr\u00eda que hacer iris$Sepal.Length ) El par\u00e1metro formula es donde le decimos a lm a que f\u00f3rmula debe ajustar los datos. Para regresi\u00f3n lineal es Y ~ X De imprimir regresion_lineal por pantalla vemos los coeficientes de la f\u00f3rmula (Intercept) es la ordenada al origen y la otra columna (en este caso llamada Petal.Length ) es la pendiente Podemos extraer cada uno de estos dos n\u00fameros haciendo: ordenada_al_origen <- regresion_lineal $ coefficients [ 1 ] pendiente <- regresion_lineal $ coefficients [ 2 ] \u00bfSe ajustan mis datos a una recta? Si bien no lo vamos a usar en este TP, es normal al momento de hacer una regresi\u00f3n querer saber que tan bien se ajustan mis datos a la f\u00f3rmula que us\u00e9. Existen varios estad\u00edsticos para analizar esto, pero uno muy usado para regresiones lineales es el R cuadrado , que no tiene nada que ver con el lenguaje de programaci\u00f3n y es un estad\u00edstico que va entre 0 y 1 y cuanto m\u00e1s cerca de 1 es mejor es el ajuste lineal (simplificando infinitamente el tema). En el ejemplo anterior podemos conseguir el R cuadrado haciendo: r_cuadrado <- summary ( regresion_lineal ) $ r.squared","title":"Regresi\u00f3n lineal"},{"location":"practicos/TP08b_R/#paso-4-ejercicio","text":"2) Creen un nuevo script de R , copien el siguiente c\u00f3digo y guardenlo en su carpeta de trabajo. Vayan avanzando por el script y cambien las secciones que dicen @@EDITAR@@ por lo que corresponda (esto puede ser un valor, una variable, una operaci\u00f3n matem\u00e1tica, una comparaci\u00f3n o una funci\u00f3n de R ). #Aca hay que poner el Path Absoluto que apunta a su carpeta de trabajo #Por ej: \"/home/ibioinfo/Documentos/data_TP8b\" setwd ( @@ EDITAR @@ ) library ( data.table ) #Leo los datos ya parseados y formateados dt_parsed_formatted_data <- fread ( @@ EDITAR @@ ) #Para cada combinacion de compuesto y concentracion quiero saber la velocidad de la reaccion, es decir, #la pendiente de la recta que sale de hacer una regresion lineal por los 4 tiempos ensayados #Creo la tabla vacia donde voy a guardar estos datos dt_velocidades_de_reaccion <- data.table ( compuesto = character (), concentracion = numeric (), velocidad = numeric ()) #Voy a tener que recorrer todas las combinaciones de compuestos y concentraciones #Consigo vectores con cada compuesto diferente y con cada concentracion diferente unique_compuestos <- unique ( dt_parsed_formatted_data $ compuesto ) unique_concentraciones <- @@ EDITAR @@ for ( compuesto_for in unique_compuestos ) { # compuesto_for <- unique_compuestos[1] for ( concentracion_for in unique_concentraciones ) { # concentracion_for <- unique_concentraciones[1] #Por cada combinacion de compuesto + concentracion quiero calcular la velocidad de reaccion #Para eso lo primero que necesito hacer es filtrar los datos de *dt_parsed_formatted_data*, para quedarme solo #con aquellas signals que correspondan al compuesto y concentracion de la iteracion actual del *for* sub_dt_parsed_formatted_data <- dt_parsed_formatted_data [( compuesto == @@ EDITAR @@ ) & ( @@ EDITAR @@ )] #Calculo la regresion lineal usando los datos de *sub_dt_parsed_formatted_data* y considerando a #*segundos_totales* como el X y a *signal* como el Y regresion_lineal <- lm ( data = sub_dt_parsed_formatted_data , formula = signal ~ segundos_totales ) #Extraigo la pendiente, que es el segundo elemento del elemento *coefficients* velocidad_de_reaccion <- regresion_lineal $ coefficients [ 2 ] #Creo una nueva fila para agregar a mi tabla de velocidades de reaccion #Esta fila corresponde al compuesto y a la concentracion de esta iteracion de los *fors*, asi como #la velocidad que acabo de calcular new_row_dt_velocidades_de_reaccion <- data.table ( compuesto = @@ EDITAR @@ , concentracion = @@ EDITAR @@ , velocidad = @@ EDITAR @@ ) #Agrego la nueva fila recien creada a mi tabla en donde guardo todas las velocidades dt_velocidades_de_reaccion <- @@ EDITAR @@ } } #Escribo los datos en una nueva tabla write.table ( dt_velocidades_de_reaccion , file = \"04_velocidades_de_reaccion.tsv\" , col.names = T , row.names = F , sep = \"\\t\" , quote = T ) Si todo sali\u00f3 bien, el archivo 04_velocidades_de_reaccion.tsv deber\u00eda ser una tabla del estilo: compuesto concentracion velocidad \"Umbrella1\" 200 633.30896128865 \"Umbrella1\" 133.3333333 672.561474192526 \"Umbrella1\" 88.88888889 710.350673411048 \"Umbrella1\" 59.25925926 630.08948130777 \"Umbrella1\" 39.50617284 720.288720371885 ... ... ... (s\u00ed, los decimales son horribles, en un ratito los arreglamos)","title":"Paso 4 - Ejercicio"},{"location":"practicos/TP08b_R/#paso-5-calcular-y-plotear-ic-50","text":"Primero que nada tenemos que definir un par de conceptos: Vamos a llamar velocidad de reacci\u00f3n base a la velocidad de reacci\u00f3n de la enzima cuando no tiene ning\u00fan inhibidor, o lo que es lo mismo, cuando la concentraci\u00f3n del inhibidor es 0. En nuestro caso tenemos 22 wells donde la concentraci\u00f3n del inhibidor es 0, por lo que vamos a calcular a la velocidad de reacci\u00f3n base como el promedio de las velocidades en esos 22 wells. Vamos a llamar actividad a la relaci\u00f3n entre la velocidad de reacci\u00f3n observada al usar una concentraci\u00f3n dada de un compuesto, y la velocidad de reacci\u00f3n base . Es decir: \\[ actividad = \\frac{velocidadReaccion}{velocidadReaccionBase} \\] Si no hay inhibidor o si la concentraci\u00f3n del inhibidor es muy baja para que haga efecto Actividad ~ 1 Si no hay enzima o si estoy usando un inhibidor perfecto Actividad ~ 0 Ahora s\u00ed, queremos calcular una curva de dosis-respuesta para ver como es afectada nuestra enzima Z por diferentes concentraciones de cada uno de los 22 compuestos. En general es esperable que: A muy bajas concentraciones del compuesto no hay efecto sobre la enzima, por lo que estoy viendo la una actividad cercana a 1. Esto quiere decir que esperamos ver varias concentraciones bajas de un compuesto que muestren la misma actividad . A muy altas concentraciones del compuesto ya est\u00e1 saturado el efecto que \u00e9l pueda hacer sobre la enzima (por ejemplo todos los sitios de uni\u00f3n ya est\u00e1n ocupados), por lo que estoy viendo el m\u00e1ximo efecto que puede hacer dicho compuesto a la actividad de la enzima. Esto quiere decir que esperamos ver varias concentraciones altas que muestren la misma actividad . Las concentraciones intermedias son aquellas en donde una variaci\u00f3n en la concentraci\u00f3n del compuesto produce un cambio en la actividad de la enzima. Est\u00e1s tres propiedades hacen que la curva dosis-respuesta tenga una forma sigmoidea, es decir: Donde en nuestro caso la respuesta va a ser la actividad y la dosis va a ser la concentraci\u00f3n de nuestro compuesto. Dependiendo de las concentraciones elegidas, es normal ver que el eje X de este plot est\u00e9 en escala logar\u00edtmica. En el plot est\u00e1 marcado el IC 50 , el cual es la concentraci\u00f3n del compuesto a la cual la actividad de la enzima cae al 50% (es decir, cuando la velocidad de reacci\u00f3n es la mitad que la velocidad de reacci\u00f3n base ). El IC 50 da informaci\u00f3n de donde est\u00e1 el rango de concentraciones de dicho compuesto que hacen variar la actividad enzim\u00e1tica, entre otras cosas.","title":"Paso 5 - Calcular IC 50"},{"location":"practicos/TP08b_R/#herramientas","text":"","title":"Herramientas"},{"location":"practicos/TP08b_R/#instalar-paquetes-de-r","text":"Para calcular el IC 50 vamos a ajustar nuestros datos a una curva sigmoidea, para lo cual vamos a instalar un paquete de R llamado nplr que hace estos c\u00e1lculos por nosotros. 1) Para instalar un paquete corran en R la l\u00ednea: install.packages ( \"nplr\" ) Y recuerden que cuando lo quieran usar tienen que cargarlo usando library(nplr) o library(\"nplr\") . Como es bastante avanzado no vamos a hablar de nplr por ahora y les vamos a dar esa parte del c\u00f3digo ya hecha.","title":"Instalar paquetes de R"},{"location":"practicos/TP08b_R/#crear-y-modificar-columnas","text":"Una cosa m\u00e1s que tenemos que aprender con los Data Tables es como agregar una columna nueva, o como modificar una columna ya existente. Esto se hace simplemente asign\u00e1ndole el nuevo valor a la columna como si fuera una variable o vector, solo que es importante que el nuevo valor sea o un solo elemento o un vector con longitud igual al n\u00famero de filas de la tabla. 2) Corran el siguiente ejemplo y vean lo que devuelve. library ( data.table ) dt_iris <- as.data.table ( iris ) #Creo nuevas columnas #Si le paso un valor solo toda esa columna va a tener ese valor dt_iris $ nueva_columna <- 1 #De otra forma tengo que pasarle un vector con longitud igual al numero de filas #Este vector puede ser combinacion de otras de las columnas de la tabla dt_iris $ otra_nueva_columna <- dt_iris $ Sepal.Length + dt_iris $ Petal.Length - 1 #Me arrepenti del valor que cree en la columna al principio dt_iris $ nueva_columna <- 5 print ( dt_iris )","title":"Crear y modificar columnas"},{"location":"practicos/TP08b_R/#crear-plots-en-pdfs","text":"Nosotros sabemos crear plots en RStudio, pero hay veces donde uno tiene que hacer decenas (o miles) de plots y quiere guardarlos todos en un solo proceso. R tiene varias funciones que nos permiten guardar los plots como .jpg , .png , .svg , etc. Ac\u00e1 nos vamos a enfocar en la funci\u00f3n que nos permite guardarlos como .pdf . 3) Corran el siguiente ejemplo y vean lo que devuelve (va a crear un archivo en su Working Directory ). pdf ( \"test.pdf\" , width = 7 , height = 7 ) plot ( x = iris $ Sepal.Length , y = iris $ Petal.Length ) plot ( x = iris $ Sepal.Width , y = iris $ Petal.Width ) plot ( x = iris $ Species , y = iris $ Petal.Length ) dev.off () Los par\u00e1metros width y height indican el tama\u00f1o en pulgadas de cada p\u00e1gina en el pdf. Noten que a partir que abren el pdf los plots ya no van a aparecer en la pesta\u00f1a Plots de RStudio hasta que cierren el pdf (se podr\u00eda pensar que redirige la salida del plot al archivo pdf). Tip - Resetear los gr\u00e1ficos A veces pasa que un pdf queda abierto m\u00e1s de lo que deber\u00eda y no se cierra bien, o que no se crea como deber\u00eda. En estos casos pueden usar la funci\u00f3n graphics.off() antes y despu\u00e9s del c\u00f3digo anterior (especialmente antes) para limpiar cualquier cosa abierta. Solo tengan en cuenta que esto va a vaciarles los plots que tengan guardados en el panel Plots de RStudio.","title":"Crear plots en PDFs"},{"location":"practicos/TP08b_R/#la-verdad-de-la-funcion-plot","text":"Nosotros acabamos de ver unos plots hechos con la funci\u00f3n plot() , que es la forma de plotear por defecto en R . Sin embargo plot no solo plotea cosas pas\u00e1ndole un X y un Y, sino que tambi\u00e9n es una funci\u00f3n que de pasarle ciertos tipos de variables (como puede ser una regresi\u00f3n log\u00edstica) usa un plot interno de dichas variables. El paquete nplr trae sus propios plots que se van a hacer mediante plot(regresion_logistica) . Esto no es \u00fanico de este paquete y existen otras librer\u00edas, por ejemplo de filogenia, que tienen este mismo funcionamiento, donde plot hace \u00e1rboles filogen\u00e9ticos.","title":"La verdad de la funci\u00f3n plot"},{"location":"practicos/TP08b_R/#google","text":"Es muy importante al momento de programar saber buscar funcionalidades que uno quiere usar en sus programas. 4) Busquen en internet: C\u00f3mo se calcula el m\u00e1ximo de los elementos de un vector de n\u00fameros en R C\u00f3mo se calcula el m\u00ednimo de los elementos de un vector de n\u00fameros en R C\u00f3mo se calcula el promedio de los elementos de un vector de n\u00fameros en R C\u00f3mo se redondea los decimales de un n\u00famero en R","title":"Google"},{"location":"practicos/TP08b_R/#paso-5-ejercicio","text":"5) Creen un nuevo script de R , copien el siguiente c\u00f3digo y gu\u00e1rdenlo en su carpeta de trabajo. Vayan avanzando por el script y cambien las secciones que dicen @@EDITAR@@ por lo que corresponda (esto puede ser un valor, una variable, una operaci\u00f3n matem\u00e1tica, una comparaci\u00f3n o una funci\u00f3n de R ). Warnings en el c\u00f3digo Al ejecutar el siguiente c\u00f3digo les va a aparecer por consola varios Warnings de nplr sobre el fiteo del modelo y la predicci\u00f3n del IC 50. Los Warnings son advertencias, las cuales informan eventos que pueden o no causar problemas. Si bien es importante prestarle atenci\u00f3n a estos Warnings cuando aparecen, en este caso ya est\u00e1n contemplados y pueden ignorarlos. #Aca hay que poner el Path Absoluto que apunta a su carpeta de trabajo #Por ej: \"/home/ibioinfo/Documentos/data_TP8b\" setwd ( @@ EDITAR @@ ) library ( data.table ) library ( nplr ) #Leo los datos de las velocidades de reaccion dt_velocidades_de_reaccion <- @@ EDITAR @@ #Quiero calcular la velocidad de reaccion base, es decir, la velocidad de reaccion sin compuestos #Esto es cuando la concentracion del compuesto es 0 #Nosotros tenemos uno de esos casos para cada compuesto, o sea, tenemos 22 versiones del experimento sin compuesto #Vamos a calcular la velocidad de reaccion base como el promedio de esas 22 velocidades velocidades_reaccion_sin_compuesto <- dt_velocidades_de_reaccion [ @@ EDITAR @@ ] $ velocidad velocidad_reaccion_base <- mean ( velocidades_reaccion_sin_compuesto ) #Ahora que ya las use, voy a sacar las filas que no tengan concentracion de compuesto #ya que no tiene sentido analizarlas para el IC 50 dt_velocidades_de_reaccion <- dt_velocidades_de_reaccion [ concentracion > 0 ] #Quiero calcular la actividad para cada combinacion de compuesto y concentracion #La actividad es la relacion entre la velocidad de reaccion y la velocidad de reaccion base (es decir, la division) dt_velocidades_de_reaccion $ actividad <- @@ EDITAR @@ #El *for* de mas adelante va a tener 2 salidas, un pdf con los plots y un tsv con los datos #Tengo que inicializar ambos #Abro el pdf (toda imagen que se plotee hasta que se cierre el pdf va a ir a el) pdf ( \"05_IC50_plots.pdf\" , width = 7 , height = 7 ) #Creo la tabla vacia dt_IC50 <- data.table ( compuesto = character (), actividad_minima = numeric (), actividad_maxima = numeric (), IC50 = numeric ()) #Recorro todos los compuestos 1 a la vez y calculo el IC 50 para cada uno unique_compuestos <- @@ EDITAR @@ for ( compuesto_for in unique_compuestos ) { # compuesto_for <- unique_compuestos[1] #Por cada compuesto quiero calcular el IC 50 y plotearlo #Para eso lo primero que necesito hacer es filtrar los datos de *dt_velocidades_de_reaccion*, para quedarme solo #con aquellas concentraciones y actividades que correspondan al compuesto de la iteracion actual del *for* sub_dt_velocidades_de_reaccion <- @@ EDITAR @@ #Calculo la regresion sigmoidea usando los datos de *sub_dt_parsed_formatted_data* y considerando a #*concentracion* como el X y a *actividad* como el Y regresion_sigmoidea <- nplr ( x = sub_dt_velocidades_de_reaccion $ concentracion , y = sub_dt_velocidades_de_reaccion $ actividad ) #Esto es una funcion de nplr que calcula el X correspondiente a Y = 0.5, es decir, el IC 50 estimacion_IC50 <- getEstimates ( regresion_sigmoidea , targets = 0.5 ) #Hay casos donde no puede calcularlo, pero en vez de devolver NA calcula el X para el Y mas cercano a 0.5 #Yo no quiero eso, quiero solo los X cuando Y es 0.5, y sino devolver NA if ( estimacion_IC50 $ y == 0.5 ) { IC50 <- estimacion_IC50 $ x } else { #Aca estoy asignando a mano el valor NA (sin comillas), o sea, el valor \"vacio\" IC50 <- NA } #Calculo la actividad minima y maxima para guardarla en el output actividad_minima <- min ( sub_dt_velocidades_de_reaccion $ actividad ) actividad_maxima <- @@ EDITAR @@ #Creo una nueva fila para agregar a mi tabla de IC 50 #Esta fila corresponde al compuesto de esta iteracion de los *fors*, asi como #el IC 50 que acabo de calcular new_row_dt_IC50 <- data.table ( @@ EDITAR @@ ) #Agrego la nueva fila recien creada a mi tabla en donde guardo todas las velocidades dt_IC50 <- @@ EDITAR @@ #Ploteo la regresion (les recomiendo poner el numero de compuesto y el IC 50 en el titulo) titulo_plot <- @@ EDITAR @@ plot ( regresion_sigmoidea , main = titulo_plot , xlab = \"Log10 Concentracion (micromolar)\" , ylab = \"Actividad\" , ylim = c ( 0 , 1.5 ), showGOF = F , xaxt = \"n\" ) #Reescribo el eje X para que se entienda que es logaritmico axis ( side = 1 , at = c ( 0 , 0.5 , 1 , 1.5 , 2 ), labels = c ( expression ( 10 ^ 0 ), expression ( 10 ^ 0.5 ), expression ( 10 ^ 1 ), expression ( 10 ^ 1.5 ), expression ( 10 ^ 2 ))) } #Cierro el pdf dev.off () #Redondeo los decimales extras de los numeros dt_IC50 $ IC50 <- round ( dt_IC50 $ IC50 , 4 ) dt_IC50 $ actividad_minima <- @@ EDITAR @@ dt_IC50 $ actividad_maxima <- @@ EDITAR @@ #Escribo los datos en una nueva tabla write.table ( dt_IC50 , file = \"05_IC50_data.tsv\" , col.names = T , row.names = F , sep = \"\\t\" , quote = T ) Si todo sali\u00f3 bien, el archivo 05_IC50_data.tsv deber\u00eda ser una tabla del estilo: compuesto actividad_minima actividad_maxima IC50 \"Umbrella1\" 0.1708 0.8627 5.2665 \"Umbrella2\" 0.3451 0.7292 2.3456 \"Umbrella3\" 0.125 0.1688 NA \"Umbrella4\" 0.1595 0.7243 2.8252 ... ... ... ... Detr\u00e1s de escenas del armado de este TP Al momento de hacer este TP tuvimos que analizar nosotros los mismos datos que ahora est\u00e1n utilizando ustedes y no ten\u00edamos mucha experiencia con nplr . En las primeras versiones de este TP no estaba la condici\u00f3n if (estimacion_IC50$y == 0.5) , pero mirando los datos de la tabla vs los datos del plot nos dimos cuenta que algo no cerraba. Por ejemplo, el IC 50 en el \"Umbrella22\" daba 0.6851, pero miren el plot, no ten\u00eda sentido eso. Fuimos al for y reemplazamos la primera l\u00ednea comentada por # compuesto_for <- unique_compuestos[22] , seleccionamos solo la \u00faltima parte (sin el # ) y la corrimos con Ctrl + Enter , lo que en este caso hizo que compuesto_for sea \"Umbrella22\". Ah\u00ed fuimos paso a paso por el for viendo que devolv\u00eda cada funci\u00f3n. Al ejecutar estimacion_IC50 <- getEstimates(regresion_sigmoidea, targets = 0.5) el programa nos tir\u00f3 el siguiente Warning: Warning : One ( or more ) of the values were greater or equal to the estimated top asymptote. These values have been replaced by the maximal possible value the model can estimate. Miramos entonces adentro de la variable estimacion_IC50 y vimos que estimacion_IC50$y era 0.004, lo que significaba que en esta iteraci\u00f3n no est\u00e1bamos calculando el IC 50 , sino el IC 0.4 , que no es lo que quer\u00edamos. A partir de esto pusimos el if y le asignamos NA a IC 50 cuando el y no era 0.5. Lo comentamos m\u00e1s que nada para mostrar que el an\u00e1lisis de datos es bastante prueba y error y que es importante pensar si lo que est\u00e1n viendo tiene sentido. Bienvenidos a la Bioinform\u00e1tica","title":"Paso 5 - Ejercicio"},{"location":"practicos/TP08b_R/#paso-6-conclusiones","text":"Ahora que tenemos todos los datos que necesitamos es momento de analizarlos. Viendo el .pdf y la tabla generados en el paso anterior respondan: 1) \u00bfPor qu\u00e9 hay casos donde el IC 50 di\u00f3 NA ? 2) En base a los plots obtenidos, \u00bfLes parecen suficientes nuestros datos para estar seguros de los IC 50 calculados? \u00bfCu\u00e1l es un compuesto donde est\u00e1n bastantes seguros de su IC 50 ? \u00bfCu\u00e1l es un compuesto donde desconf\u00edan del IC 50 calculado? 3) \u00bfQu\u00e9 experimentos har\u00edan para tener la curva completa en \"Umbrella1\"? \u00bfY en \"Umbrella8\"? 4) En base a lo observado, nombren dos o tres compuestos que recomendar\u00edan para inhibir a la enzima Z . \u00bfPor qu\u00e9 los eligieron?","title":"Paso 6 - Conclusiones"},{"location":"practicos/TP08b_R/#ejercicio-adicional-1-paso-2-limpiar-y-parsear-el-archivo","text":"Leer el Paso 2 para entender el objetivo de este ejercicio.","title":"Ejercicio Adicional 1 - Paso 2"},{"location":"practicos/TP08b_R/#herramientas_1","text":"","title":"Herramientas"},{"location":"practicos/TP08b_R/#leer-y-escribir-texto-plano","text":"Por \"texto plano\" nos referimos a leer un archivo de texto que no tiene un formato definido (o sea no es un .csv o .tsv , por ejemplo). Esto puede ser algo como un libro, notas, o una tabla que por alguna raz\u00f3n no la queremos leer como tabla. La forma m\u00e1s directa de leer texto plano en R es la funci\u00f3n readLines() , a la cual hay que pasarle el path del archivo a leer. Esta funci\u00f3n va a devolver un vector en el cual cada elemento es una l\u00ednea del archivo le\u00eddo. Se usa: nuevo_vector <- readLines ( con = \"ARCHIVO\" ) Por otro lado tambi\u00e9n existe la funci\u00f3n inversa, que nos permite escribir un vector en un archivo de texto, donde cada elemento del vector va a ser una l\u00ednea de texto en el archivo. Esta funci\u00f3n es writeLines() y se usa: writeLines ( vector_con_texto , con = \"ARCHIVO_SALIDA\" ) La funci\u00f3n writeLines() tambi\u00e9n se puede usar de una forma similar a print si no se le pasa el par\u00e1metro con .","title":"Leer y escribir texto plano"},{"location":"practicos/TP08b_R/#extraer-nombres-columnas","text":"Hay varias razones por lo cual es \u00fatil extraer un vector con el nombre de las columnas de una tabla, pero hoy lo vamos a hacer para extraer informaci\u00f3n de dichos nombres. La funci\u00f3n colnames() nos devuelve un vector con el nombre de las columnas de una tabla en el orden en el que aparecen en dicha tabla. Por ej: columnas_iris <- colnames ( iris ) print ( columnas_iris )","title":"Extraer nombres columnas"},{"location":"practicos/TP08b_R/#extraer-substrings","text":"Muchas veces es \u00fatil extraer pedazos de strings y ya vimos una forma de hacer esto con split . Sin embargo, hay veces cuando no sabemos el caracter que delimita el texto que queremos extraer, pero s\u00ed sabemos su posici\u00f3n en la cadena completa. En estos casos podemos usar la funci\u00f3n substring : variable_string <- c ( \"123456789\" ) segundo_caracter <- substring ( variable_string , 2 , 2 ) tercer_a_quinto_caracteres <- substring ( variable_string , 3 , 5 ) septimo_caracter_en_adelante <- substring ( variable_string , 7 )","title":"Extraer substrings"},{"location":"practicos/TP08b_R/#usar-una-variable-para-acceder-a-una-columna-de-un-data-table","text":"A veces pasa que quiero acceder a una variable de una tabla, pero no se previamente a cual. Aca nos va a ser \u00fatil otra forma de acceder a las columnas de las tablas, por ejemplo: # Los 3 bloques siguientes devuelven lo mismo iris $ Species iris [[ \"Species\" ]] columna <- \"Species\" iris [[ columna ]]","title":"Columna variable"},{"location":"practicos/TP08b_R/#ejercicio","text":"library ( @@ EDITAR @@ ) #### Paso 2a - LIMPIAR DATOS #### #Uso readLines para cargar el archivo de texto plano plain_text_data <- readLines ( con = \"00_datos_filtermax.txt\" ) #La fila 2 es el header #Las filas 3 a 6 son los datos #Las demas no me interesan plain_text_data <- plain_text_data [ c ( 2 : 6 )] #Escribo los datos en un nuevo archivo writeLines ( plain_text_data , con = \"01_datos_filtermax_limpios.tsv\" ) #### Paso 2b - PARSEAR DATOS #### #Uso fread para cargar la tabla con los datos como salen de FilterMax (pero sin lineas extras) #Aca es importante recordar que ten\u00edamos NAs en nuestros datos y que estaban escritos como *nada*, es decir, \"\" clean_data <- @@ EDITAR @@ #Viendo clean_data pueden ver una columna extra al final llamada V387 (debido a la cantidad de tabs al final del archivo) #Ese es el nombre que le da data.tables por defecto a las columnas sin nombre (esta es la columna 387) #Para que no moleste la sacamos clean_data <- clean_data [, @@ EDITAR @@ ] #Los numeros (columnas de la placa well) son los compuestos #Las letras (filas de la placa well) son las diferentes concentraciones #Queremos poner los mismos datos en una tabla donde nos sea mas facil filtrar un dato espec\u00edfico #Creo la tabla vacia donde voy a guardar estos datos dt_parsed_data <- data.table ( time = @@ EDITAR @@ , temperature = numeric () fila = @@ EDITAR @@ , columna = numeric (), signal = @@ EDITAR @@ ) #Hay varias formas de hacer esto con paquetes extras o con codigos dificiles, pero por ahora vamos a #usar una forma un poco menos eficiente pero que se entiende un poco mas #Quiero crear una lista con todos los nombres de los wells wells_names <- colnames ( clean_data ) #Ahora tengo lo que necesito, pero las primeras dos posiciones son Time y Temperature #Las saco del vector de los nombres wells_names <- wells_names [ - c ( 1 : 2 )] #Voy a recorrer cada nombre de columna y extraer a que fila y a que columna del well corresponde #Luego voy a guardar las cuatro signals de esa columna de la tabla con la informacion que acabo de conseguir for ( well_name_for in wells_names ) { # well_name_for <- wells_names[1] #Uso substring para extraer la letra de la fila en el well fila_for <- substring ( @@ EDITAR @@ ) #Uso substring para extraer el numero de la columna en el well #Uso un patr\u00f3n que funcione para cualquiera de los wells por m\u00e1s que el n\u00famero tenga 1 o 2 decimales columna_for <- substring ( @@ EDITAR @@ ) #Quiero guardar la columna como numero, asi que transformo la variable character en un numeric #Es decir, paso de \"1\" a 1 (por ej) columna_for <- as.numeric ( columna_for ) #Creo nuevas fila para agregar a mi tabla de datos parseados #Aca fila y columna van a ser un valor \u00fanico #Por otro lado, time, temperature y signal van a ser vectores de 4 valores (son las columnas de clean_data) #La columna Temperature puede ser que se escriba un poco rara por problemas de caracteres dt_new_rows_in_parsed_data <- data.table ( time = clean_data $ Time , temperature = clean_data $ `Temperature(C)` , fila = fila_for , columna = columna_for , signal = @@ EDITAR @@ ) #Agrego las nuevas filas recien creadas a mi tabla en donde guardo los datos parseados dt_parsed_data <- @@ EDITAR @@ } #Escribo los datos en una nueva tabla llamada \"02_datos_filtermax_parseados_NUEVO.tsv\" write.table ( @@ EDITAR @@ ) Pueden comparar 02_datos_filtermax_parseados.tsv con 02_datos_filtermax_parseados_NUEVO.tsv y si todo sali\u00f3 bien deber\u00edan ser id\u00e9nticos.","title":"Ejercicio"},{"location":"practicos/TP08b_R/#bibliografia","text":"","title":"Bibliograf\u00eda"},{"location":"practicos/TP08b_R/#consola-de-r","text":"Comando help()","title":" Consola de R"},{"location":"practicos/TP09_Desorden/","text":"TP 9 . Predicci\u00f3n de Desorden Videos de la clase grabada Introducci\u00f3n al TP Puesta en com\u00fan del TP Atenci\u00f3n: Este TP tiene informe. Materiales PARTE I: Predicci\u00f3n de Desorden Recursos online ProViz http://slim.icr.ac.uk/proviz/ IUPred2A https://iupred2a.elte.hu/plot DisProt https://www.disprot.org Objetivos Interpretar alineamientos m\u00faltiples de secuencias Identificar regiones ordenadas y desordenadas en alineamientos m\u00faltiples de secuencia Familiarizarse con la base de datos DisProt Entender las t\u00e9cnicas experimentales que permiten la identificaci\u00f3n de regiones desordenadas Familiarizarse con distintos m\u00e9todos de predicci\u00f3n de desorden (s\u00f3lo en ejercicios adicionales) Interpretaci\u00f3n de los resultados de los distintos m\u00e9todos de predicci\u00f3n de desorden (s\u00f3lo en ejercicios adicionales) M\u00e9todos de predicci\u00f3n de desorden Uno de los mayores desaf\u00edos en el campo de las prote\u00ednas es la predicci\u00f3n de la estructura tridimensional a partir de la estructura primaria incluyendo aquellas prote\u00ednas que son total o parcialmente desordenadas. Mientras que las prote\u00ednas globulares adquieren una \u00fanica estructura nativa, las prote\u00ednas intr\u00ednsecamente desordenadas (IDPs, del ingl\u00e9s intrinsically disordered proteins ) son un conjunto de estructuras tridimensionales. Tambi\u00e9n pueden existir regiones desordenadas conectando dos dominios globulares, como los loops ; o incluso regiones m\u00e1s largas, que abarcan m\u00e1s de 30 residuos de longitud, que reciben el nombre de IDRs (del ingl\u00e9s intrinsically disordered regions ). En el a\u00f1o 2020, AlphaFold2 gana la competici\u00f3n de predicci\u00f3n de estructuras (CASP14) con un amplio margen prediciendo estructuras con muy alta precisi\u00f3n. Sin embargo, a\u00fan la predicci\u00f3n de conjunto de estructuras para prote\u00ednas desordenadas no se ha resuelto. La predicci\u00f3n de IDRs/IDPs a partir de la secuencia de amino\u00e1cidos permite un an\u00e1lisis r\u00e1pido y abarcativo de distintas prote\u00ednas permitiendo establecer hip\u00f3tesis sobre la presencia de desorden en las prote\u00ednas (Dunker et al., 2008; van der Lee et al., 2014). La importancia que adquirieron las IDRs/IDPs en los \u00faltimos a\u00f1os llev\u00f3 al desarrollo de numerosos m\u00e9todos de predicci\u00f3n, pero en general se basan en tres estrategias de predicci\u00f3n de desorden: a partir de composici\u00f3n de secuencia, a partir de machine learning sobre estructuras determinadas por cristalograf\u00eda de rayos X y a partir de meta-predictores que integran los resultados predichos por diferentes m\u00e9todos. Entre los algoritmos que se basan en composici\u00f3n de secuencia podemos nombrar IUPred (Doszt\u00e1nyi et al., 2005; Erd\u00f6s et al., 2021), que aplica un campo de energ\u0131\u0301a desarrollado a partir de un gran n\u00famero de prote\u00ednas con estructura determinada obtenidas de PDB. El primer algoritmo en machine learning fue PONDR (Obradovic et al., 2003; Romero et al., 1997), entrenado a partir de un grupo estructuras de prote\u00ednas globulares y atributos de secuencia asociados a residuos no resueltos en dichas estructuras, que corresponden a regiones flexibles dentro del cristal. GlobPlot (Linding et al., 2003) fue entrenado estudiando la tendencia de un residuo a adquirir determinada estructura secundaria, h\u00e9lices \u03b1 o l\u00e1minas \u03b2. Ejercicios Ejercicio 1. Visualizaci\u00f3n de Alineamientos en ProViz Antes de empezar, piensen ... \u00bfPorqu\u00e9 es importante visualizar un MSA? \u00bfQu\u00e9 informaci\u00f3n podemos obtener de los MSA? ProViz es una herramienta que permite visualizar alineamientos y estructura de dominios de una prote\u00edna online. Ingresa a la web de ProViz http://slim.icr.ac.uk/proviz/ , y busca la prote\u00edna p53 ingresando su Accession Number en la ventana \u201csearch\u201d (Accession Number: P04637): Selecciona la prote\u00edna que se llama: Cellular tumor antigen p53 (TP53) Homo sapiens (Human) . Es la primera de la lista. IMPORTANTE Para responder las preguntas debajo, aseg\u00farate de que en el panel superior de la p\u00e1gina, en alignments , est\u00e9 seleccionada la opci\u00f3n QFO . (Puedes investigar qu\u00e9 pasa si cambian a otras opciones, como mammalian o vertebrates ). En Options a la izquierda haz click en Show/hide gaps . Aparecen m\u00e1s posiciones con gaps en el alineamiento que antes estaban ocultas. 1. \u00bfQu\u00e9 regiones parecen estar mejor alineadas (indicar aproximadamente de qu\u00e9 posici\u00f3n a qu\u00e9 posici\u00f3n de la primera secuencia)? 2. \u00bfExiste diferencia en la composici\u00f3n de secuencia entre las regiones mejor alineadas y las no tan bien alineadas? 3. \u00bfSe observan diferencias en el grado de conservaci\u00f3n de estas regiones? 4. \u00bfA qu\u00e9 pueden deberse las diferencias observadas? Ejercicio 2. Predicci\u00f3n de desorden a partir de la secuencia Ingresa en la web de IUPred2A https://iupred2a.elte.hu e ingresa la prote\u00edna p53 (puede ingresarse la secuencia de amino\u00e1cidos, el Uniprot ID - P53_HUMAN o el accession number - P04637). Score IUPred El algoritmo IUPred considera que un residuo es: Desordenado cuando el valor de IUPred es mayor o igual a 0.5 Ordenado cuando es menor a 0.5 Nota: Esta es una convenci\u00f3n. El umbral lo puede decir el usuario a su propia conveniencia. 1. Anota las posiciones iniciales y finales de las regiones predichas como desordenadas. \u00bfSe correlacionan las regiones predichas como ordenadas o desordenadas con las diferencias observadas en el ejercicio anterior? 2. Imaginemos que queremos correr la predicci\u00f3n de desorden para cientos de prote\u00ednas, o que queremos contar el porcentaje de amino\u00e1cidos que se encuentran en regiones desordenadas: \u00bfLe parece que el visualizador online ser\u00eda una herramienta \u00fatil para hacerlo? \u00a1Claro que no! Por suerte, el algoritmo IUPred puede tambi\u00e9n correrse de manera local y adem\u00e1s es r\u00e1pido. Abre una terminal y ve al directorio d\u00f3nde est\u00e1 IUPred cd ~/Tools/IUPred/ # Primero corremos IUPred sin ninguna opci\u00f3n para ver c\u00f3mo es su uso: ./iupred2a.py Deber\u00eda aparecer lo siguiente: Usage: ./iupred2a.py ( options ) ( seqfile ) ( iupred type ) Available types: \"long\" , \"short\" , \"glob\" Options -d str - Location of data directory ( default = './' ) -a - Enable ANCHOR2 predition El archivo con la secuencia de p53 ( P53_HUMAN.seq ) est\u00e1 guardado en el mismo directorio que IUPred. En base a esto, el comando a utilizar es el siguiente ./iupred2a.py -a P53_HUMAN.seq long > P53_HUMAN.iupred 3. Explora el archivo generado ( P53_HUMAN.iupred ) y responde. \u00bfC\u00f3mo es el formato de los datos? \u00bfLas columnas tienen nombre? \u00bfSer\u00e1n interpretadas correctamente por R? 4. Crea un script en R. Para esto, abre RStudio y elije: New --> RScript Recuerda ver en qu\u00e9 directorio est\u00e1s trabajando y configurarlo para trabajar en el directorio deseado, por si no lo recuerdas las funciones eran: getwd() : Devuelve el directorio de trabajo setwd() : Configura el directorio de trabajo 4a. \u00a1A cargar los datos! \u00bfTe acord\u00e1s c\u00f3mo se hac\u00eda? Se utilizaba la funci\u00f3n fread() . Vamos a modificar algunos argumentos para que lea correctamente el archivo. Si quer\u00e9s saber qu\u00e9 es cada argumento siempre se puede revisar el uso de las funciones con help(fread) library ( data.table ) fileIN <- \"~/Tools/IUPred/P53_HUMAN.iupred\" header <- c ( \"Posicion\" , \"Aminoacido\" , \"Iupred\" , \"Anchor\" ) p53 <- fread ( file = fileIN , header = T , sep = \"\\t\" , col.names = header , skip = \"POS\" ) Asegurate que los datos se cargaron correctamente, esperamos una tabla con 4 columnas. 4b. Ahora quisi\u00e9ramos clasificar las posiciones en pase a la predicci\u00f3n realizada por IUPred como Orden y Desorden . \u00bfSe te ocurre c\u00f3mo hacerlo? Primero crearemos una columna en el data.table: umbral <- 0.5 p53 $ Prediccion <- \"\" p53 [ Iupred >= umbral ] $ Prediccion <- \"Desorden\" p53 [ Iupred < umbral ] $ Prediccion <- \"Orden\" Para obtener un gr\u00e1fico similar al que brinda el servidor de IUPred, utilizaremos la librer\u00eda ggplot2 : library ( ggplot2 ) plot_p53 <- ggplot ( p53 , aes ( x = Posicion , y = Iupred )) + scale_x_continuous ( n.breaks = 20 , expand = c ( 0.01 , 0.01 )) + scale_y_continuous ( n.breaks = 10 , limits = c ( 0 , 1 ), expand = c ( 0 , 0.01 )) + geom_line ( color = \"navyblue\" ) + geom_point ( aes ( color = Prediccion )) + geom_hline ( yintercept = 0.5 , lty = \"dotted\" , size = 1 ) + theme_linedraw () plot_p53 Deber\u00eda obtener un gr\u00e1fico como el siguiente: Ahora, quisi\u00e9ramos evaluar el porcentaje de residuos predichos ordenados y desordenados. Por suerte, R tiene una funci\u00f3n que \u201ccuenta\u201d por nosotros: cuentaTotal <- table ( p53 $ Prediccion ) porcentaje <- 100 * cuentaTotal / length ( p53 $ Posicion ) print ( cuentaTotal ) print ( porcentaje ) 4c. En base a los valores obtenidos, \u00bfdir\u00eda que la prote\u00edna p53 es altamente desordenada? 4d. Por \u00faltimo, analizaremos la composici\u00f3n de amino\u00e1cidos de p53. Pero antes: \u00bfQu\u00e9 residuos espera ver enriquecidos en las regiones desordenadas y cuales en las ordenadas ? \u00bfPor qu\u00e9? Vamos a graficar el porcentaje de cada amino\u00e1cido predicho como ordenado o desordenado en la secuencia de p53 aminoacidos <- table ( p53 $ Aminoacido , p53 $ Prediccion ) print ( aminoacidos ) \u00bfQu\u00e9 hizo la funci\u00f3n table en este caso? Para calcular el porcentaje de amino\u00e1cidos: aminoacidos_porcentaje <- 100 * aminoacidos / length ( p53 $ Posicion ) Ahora vamos a convertir la tabla en un data.table para graficar con ggplot2 : aminoacidos_df <- as.data.table ( aminoacidos_porcentaje ) colnames ( aminoacidos_df ) <- c ( \"Aminoacidos\" , \"Prediccion\" , \"Porcentaje\" ) plot_aa <- ggplot ( aminoacidos_df , aes ( x = Aminoacidos , y = Porcentaje , fill = Prediccion )) + geom_col ( position = \"dodge\" ) + scale_y_continuous ( n.breaks = 10 , limits = c ( 0 , 10 ), expand = c ( 0 , 0.01 )) + theme_bw () ggsave ( filename = \"aminoacidos.png\" , plot = plot_aa , device = \"png\" , dpi = 150 , width = 10 , height = 5 , units = \"cm\" ) Deber\u00edas obtener un gr\u00e1fico como el siguiente: \u00bfQu\u00e9 amino\u00e1cidos son los m\u00e1s abundantes en las regiones desordenadas? \u00bfLa abundancia de los amino\u00e1cidos coincide con lo esperado? PARTE II: Base de Datos Disprot La base de datos DisProt es una colecci\u00f3n de evidencia de desorden experimental recolectada de la literatura y curada manualmente. La evidencia corresponde a una regi\u00f3n proteica, e incluye por lo menos: un experimento, el art\u00edculo cient\u00edfico correspondiente a ese experimento, el inicio y final de la regi\u00f3n desordenada en la secuencia proteica un t\u00e9rmino de anotaci\u00f3n que corresponde a la Ontolog\u00eda de desorden. Cada una de las entradas en la base de datos posee un identificador \u00fanico La ontolog\u00eda de desorden est\u00e1 organizada en tres categor\u00edas diferentes: Estado estructural ( Structural State ): Orden o Desorden ( Order or Disorder ) Transici\u00f3n estructural ( Structural Transition ): Transiciones que pueden ocurrir entre diferentes estados estructurales ( Disorder to order ) Funci\u00f3n de desorden ( Disorder Function ): La funci\u00f3n de una regi\u00f3n incluyendo t\u00e9rminos espec\u00edficos a desorden. En Disprot tambi\u00e9n se incluye la funci\u00f3n molecular Molecular function de cada regi\u00f3n. Ejercicio 1. Base de datos DisProt La prote\u00edna p53 es una prote\u00edna supresora de tumores, es decir que su mutaci\u00f3n favorece el crecimiento tumoral. p53 es uno de los genes m\u00e1s mutados en el c\u00e1ncer humano, y act\u00faa como un factor de transcripci\u00f3n que se expresa en todos los tejidos. Cumple un rol principal en el ciclo celular y es el regulador principal de la apoptosis. Es esencial para inducir la respuesta celular ante el da\u00f1o al ADN, deteniendo el ciclo celular cuando las c\u00e9lulas no pueden reparar el ADN da\u00f1ado por agentes genot\u00f3xicos. Si falla p53 podr\u00edan facilitar la formaci\u00f3n de tumores celulares y en consecuencia producir c\u00e1ncer. Alrededor de un 50% de los tumores humanos identificados poseen mutaciones en la prote\u00edna p53. Esta prote\u00edna, por su importancia para la salud humana, es una de las prote\u00ednas m\u00e1s estudiadas en cuanto a su estructura y funci\u00f3n. Ingresa a la p\u00e1gina web de DisProt y encuentra la prote\u00edna p53 (P04637). La b\u00fasqueda puede realizarse utilizando el Accession Number o por palabras claves. El identificador de DisProt que deber\u00edan encontrar es DP00086. Una vez encontrado haz click en el identificador de Disprot. a. Si Disprot consensus est\u00e1 colapsado, expandelo: \u00bfQu\u00e9 tipo de informaci\u00f3n observa en la p\u00e1gina? b. Expande Structural state y luego expande Disorder : \u00bfA qu\u00e9 corresponden los segmentos coloreados? \u00bfQu\u00e9 tipo de evidencia poseen dichos fragmentos? c. Pensando en el rol de las regiones desordenadas. i. Expande Molecular Function : \u00bfQu\u00e9 tipo de funciones est\u00e1n indicadas para cada regi\u00f3n? \u00bfQu\u00e9 t\u00e9cnicas se usaron para identificarlas? ii. Expande Disorder Function : \u00bfQu\u00e9 tipo de funciones est\u00e1n indicadas? \u00bfCu\u00e1ntos experimentos y que tipo de t\u00e9cnicas se realizaron para identificar cada una? d. Expande Domains . Sabiendo que ... Los dominios Pfam son asignados a partir de un perfil de HMMs creado de un alineamiento de prote\u00ednas representativas Gene3D contiene anotaciones de dominios estructurados. \u00bfSe observa alg\u00fan dominio conservado que NO adquiera una estructura globular? e. \u00bfLa evidencia experimental recolectada coincide con las predicciones realizadas en el Ejercicio 1 y en el Ejercicio 2 ? PARTE III: An\u00e1lisis de alineamientos m\u00faltiples de secuencia de prote\u00ednas - Visualizando alineamientos con JalView Software JalView: https://www.jalview.org/ Recursos Online Pfam: https://pfam.xfam.org/ Objetivos Aprender a utilizar Jalview para visualizar un MSA y familiarizarse con el manejo de programas de visualizaci\u00f3n de alineamientos. Interpretar alineamientos m\u00faltiples de secuencias. Identificar regiones de secuencia conservadas y asociarlas a diferentes elementos funcionales de las prote\u00ednas. Visualizar y analizar los patrones de sustituci\u00f3n aminoac\u00eddica encontrados en prote\u00ednas modulares. Correlacionar con sus conocimientos sobre matrices de sustituci\u00f3n Ejercicios Ejercicio 1. Identificando M\u00f3dulos en Prote\u00ednas Utilizando su c\u00f3digo UNIPROT (P04637), busca la prote\u00edna p53 humana (P53_HUMAN) en la base de datos Pfam https://pfam.xfam.org/ La base de datos Pfam es una colecci\u00f3n de familias de dominios de prote\u00ednas construida en base a alineamientos m\u00faltiples de secuencia y modelos ocultos de markov (HMMs). Las prote\u00ednas est\u00e1n compuestas por una o m\u00e1s regiones funcionales o dominios, que combinados de distintas maneras crean la diversidad proteica que se encuentra en las prote\u00ednas naturales. 1a. \u00bfPor qu\u00e9 es necesario identificar dominios en las prote\u00ednas? Para buscar la prote\u00edna p53 puedes hacerlo ingresando en VIEW A SEQUENCE el accession number (P04637) o el uniprot ID (P53_HUMAN) 1b. \u00bfQu\u00e9 longitud tiene la prote\u00edna p53 humana? 1c. Observar el esquema de p53: \u00bfPuedes identificar qu\u00e9 dominios Pfam tiene p53? \u00bfQu\u00e9 nombres y qu\u00e9 funciones tienen? En algunos casos esta informaci\u00f3n est\u00e1 en la pesta\u00f1a de Pfam que aparece en la nueva ventana que se abre al hacer click en el nombre del dominio. 1d. \u00bfEn qu\u00e9 regiones de la secuencia se encuentran estos dominios? Anotar de qu\u00e9 residuo a qu\u00e9 residuo abarca cada dominio, para usar m\u00e1s adelante. 1e. \u00bfCreen que estos dominios corresponden un\u00edvocamente a dominios globulares? 1f. \u00bfA qu\u00e9 cree que corresponden las regiones marcadas como Disorder y Low Complexity en p53? 1g. \u00bfSe corresponden las regiones identificadas como Disorder en Pfam con las predichas por IUPred en el Ejercicio 2 de la parte I de predicci\u00f3n de desorden? \u00bfQu\u00e9 utiliza Pfam para poder identificar las regiones como Disorder (Esta informaci\u00f3n est\u00e1 en el HELP de Pfam en Guide to Graphics )? JalView, software de visualizaci\u00f3n de alineamientos Para poder visualizar alineamientos m\u00faltiples de secuencias (MSA, de sus siglas en ingl\u00e9s: Multiple Sequence Alignment) utilizaremos el visualizador de alineamientos JalView desarrollado en JAVA. Jalview permite generar alineamientos, manipularlos, editarlos y anotarlos. Tiene una interfaz que permite acceder remotamente numerosas herramientas como programas para realizar alineamientos m\u00faltiples de secuencia y predictores de estructura secundaria. A lo largo de la gu\u00eda de ejercicios, introduciremos este programa usandolo para visualizar alineamientos m\u00faltiples de secuencias (MSAs) de prote\u00ednas modulares y discutir caracter\u00edsticas de secuencia asociadas a los dominios y motivos funcionales encontrados en las prote\u00ednas. JalView es un programa que se ofrece de manera gratuita, y est\u00e1 disponible para descargar e instalar en tu propia computadora en https://www.jalview.org/ Existen un alto n\u00famero de gu\u00edas y tutoriales disponibles online que pueden encontrar en: https://www.jalview.org/training Los desarrolladores de JalView crearon numerosos videos de entrenamiento disponibles en el Canal de YouTube de JalView Ejercicio 2. Usando JalView para analizar un MSA de p53 2a. Abre Jalview Para abrir Jalview vayan al directorio: ~/Tools/Jalview/ y corran el archivo jalview.sh : bash jalview.sh Abran en Jalview el conjunto de secuencias de p53 que se encuentra en el archivo p53.fasta : File \u2192 Input Alignment \u2192 From File 2c. Para realizar el alineamiento utilizaremos el programa Clustal, al cual accederemos de manera remota desde JalView de la siguiente manera: Web Service \u2192 Alignment \u2192 Clustal \u2192 With defaults Si no llegara a funcionar, pues Internet, Virtualidad, la vida... Tienen las secuencias ya alineadas en el archivo p53_aligned.fasta 2d. Inspecciona el alineamiento visualmente y reconoce algunas caracter\u00edsticas de las secuencias. Si no se muestran todos los residuos y algunos aparecen como . ve a: Format \u2192 Show Non-Conserved a. Algunas secuencias son m\u00e1s cortas que otras \u00bfpor qu\u00e9 crees que es esto? b. \u00bfSi quieren construir un alineamiento de alta calidad, preservar\u00edan o descartar\u00edan estas secuencias? c. Remuevan las secuencias que no corresponden a prote\u00ednas completas. Para ello seleccionar las secuencias haciendo click sobre el nombre de la misma en el panel izquierdo, la secuencia se marcar\u00e1 con una caja roja punteada. Remover la secuencia seleccionada utilizando la tecla Backspace o Del d. \u00bfExisten regiones del alineamiento que no est\u00e9n alineadas correctamente? Para editar el alineamiento, primero asegurate de realizar: Select \u2192 Deselect All Eliminar gaps: Seleccione con el mouse el gap o arrastrando sobre el grupo de gaps que desea eliminar y presione o Backspace o bien Del Agregar gaps: Presione F2 . En la primera posici\u00f3n del alineamiento en la primera secuencia aparecer\u00e1 un cursor de color negro. Col\u00f3quelo en la posici\u00f3n donde desee ingresar un gap y presione la barra espaciadora. Ejercicio 3. An\u00e1lisis de distintas propiedades del MSA utilizando el men\u00fa COLOUR. Este men\u00fa permite colorear el alineamiento con diferentes paletas de colores que permiten visualizar determinadas caracter\u00edsticas fisicoqu\u00edmicas o relacionadas con la conservaci\u00f3n o identidad de secuencia que facilitan el an\u00e1lisis de la informaci\u00f3n contenida en el MSA. Por ejemplo: Percentage identity colorea los residuos seg\u00fan el porcentaje de identidad en la columna. Hydrophobicity colorea los residuos seg\u00fan el grado de hidrofobicidad. Tambi\u00e9n es posible disminuir la intensidad de los colores seg\u00fan el grado de conservaci\u00f3n ( By conservation ) o filtrar los colores seg\u00fan el porcentaje de identidad ( Above identity threshold ) a partir de un umbral deseado. 3a. Seleccione para colorear el alineamiento desde el men\u00fa la opci\u00f3n: Colour \u2192 Clustalx Este esquema es muy com\u00fanmente utilizado para la visualizaci\u00f3n de MSAs y permite representar informaci\u00f3n importante contenida en los patrones de sustituci\u00f3n de un MSA. Observando el alineamiento intente identificar: a. \u00bfCu\u00e1l es la base del esquema de color \u201cClustalX\u201d provisto por Jalview? Nota: Google provee respuestas pero... pueden ir directamente al esquema de colores de ClustalX b. \u00bfCu\u00e1ntos colores existen? c. \u00bfQu\u00e9 propiedades fisicoqu\u00edmicas representa cada grupo de color? d. La ciste\u00edna cumple un rol estructural importante en algunas prote\u00ednas (\u00bfcu\u00e1l?). \u00bfQu\u00e9 observa respecto de la coloraci\u00f3n de la ciste\u00edna? \u00bfEs siempre igual? \u00bfA qu\u00e9 se debe el cambio en la representaci\u00f3n? En ProViz la ciste\u00edna estaba siempre coloreada del mismo color, pero en el esquema de colores de ClustalX no lo est\u00e1. e. \u00bfEn qu\u00e9 situaciones los residuos no est\u00e1n coloreados? f. Hay residuos que siempre est\u00e1n coloreados? \u00bfCu\u00e1les son y a qu\u00e9 cree que se debe? 3b. Manteniendo el esquema de color Clustal, es posible filtrar regiones de acuerdo al % identidad en el alineamiento m\u00faltiple. Para ello, aplique el filtro de identidad yendo a: Colour \u2192 Above identity threshold Se abrir\u00e1 una ventana en la cual podr\u00e1 seleccionar el % identidad del filtro en escala de 0 a 100%. Explore los cambios en todo el alineamiento al variar la escala de 0 a 100%. Utilizando el filtro, respondan: a. \u00bfQu\u00e9 regiones muestran una identidad de secuencia mayor al 80% en el MSA de p53? \u00bfY al 100%? Anote los l\u00edmites de estas regiones y responda: \u00bfQu\u00e9 correlaci\u00f3n observa con la informaci\u00f3n obtenida de Pfam? Con la identidad al 80%, observe en las columnas del MSA que sustituciones ocurren. Estas susticiones son un reflejo de la historia evolutiva de la prote\u00edna y contienen mucha informaci\u00f3n funcional. Observando detenidamente, responda: b. \u00bfQu\u00e9 tipos de sustituciones observa? c. \u00bfQu\u00e9 relaci\u00f3n guardan estas sustituciones con las matrices PAM y BLOSUM utilizadas para construir alineamientos de prote\u00ednas? d. En base a este alineamiento analice las regiones desordenadas y ordenadas ya reconocidas en p53. Compare sus observaciones en este alineamiento con el alineamiento visualizado en ProViz en el Ejercicio 1 de la PARTE I . \u00bfPuede distinguir las mismas regiones? \u00bfVe diferencias en la composici\u00f3n de secuencia en cada regi\u00f3n entre los dos alineamientos? \u00bfSe observan diferencias en el grado de conservaci\u00f3n entre los dos alineamientos? \u00bfLas especies a las que corresponde cada secuencia son las mismas en los alineamientos? \u00bfCu\u00e1l posee organismos m\u00e1s distantes? Discuta qu\u00e9 ventajas considera que tiene trabajar con un alineamiento propio respecto de trabajar con el alineamiento de ProViz. Ejercicio a informar Fecha l\u00edmite de entrega: Viernes, 07 de Octubre 2022, 23:59hs. Enunciado El aislamiento que le proporcionaron est\u00e1 avanzando r\u00e1pidamente en latinoam\u00e9rica!. Dada la importancia de la prote\u00edna N de la nucleoc\u00e1pside en la replicaci\u00f3n viral, su jefe considera que es un blanco posible de drogas. La prote\u00edna N forma la nucleoc\u00e1pside viral de SARS-CoV2 y empaqueta el genoma viral de ARN formando una ribonucleoc\u00e1pside. La estructura de la prote\u00edna es altamente desordenada y posee dos dominios globulares peque\u00f1os en el N-terminal (Dominio N) y C terminal (Dominio C). Usando IUPred, identifique las regiones desordenadas y globulares. \u00bfPuede identificar f\u00e1cilmente los dominios globulares con el umbral de 0.5? \u00bfy con el umbral de 0.4? Justifique los resultados en base al funcionamiento del algoritmo. Si desear\u00eda cristalizar el dominio N \u00bfQu\u00e9 regiones no incluir\u00eda? Analice la proporci\u00f3n de residuos predichos como ordenados y como desordenados utilizando cada uno de los umbrales. \u00bfSe correlaciona esto con lo estudiado en la literatura? Extra! (y por ende opcional) 1. Como se vi\u00f3 en la clase te\u00f3rica, IUPred puede correrse utilizando como argumento short o long . Realice el gr\u00e1fico del perfil de IUPred nuevamente utilizando short . \u00bfQu\u00e9 diferencias observa en los gr\u00e1ficos usando Iupred short o long ? En base a sus conocimientos de IUPred, explique brevemente y de manera abarcativa las diferencias observadas.","title":"TP 9 - Predicci\u00f3n de Desorden"},{"location":"practicos/TP09_Desorden/#tp-9-prediccion-de-desorden","text":"","title":"data-toc-label"},{"location":"practicos/TP09_Desorden/#videos-de-la-clase-grabada","text":"Introducci\u00f3n al TP Puesta en com\u00fan del TP Atenci\u00f3n: Este TP tiene informe. Materiales","title":"Videos de la clase grabada"},{"location":"practicos/TP09_Desorden/#parte-i-prediccion-de-desorden","text":"","title":"PARTE I: Predicci\u00f3n de Desorden"},{"location":"practicos/TP09_Desorden/#recursos-online","text":"ProViz http://slim.icr.ac.uk/proviz/ IUPred2A https://iupred2a.elte.hu/plot DisProt https://www.disprot.org","title":"Recursos online"},{"location":"practicos/TP09_Desorden/#objetivos","text":"Interpretar alineamientos m\u00faltiples de secuencias Identificar regiones ordenadas y desordenadas en alineamientos m\u00faltiples de secuencia Familiarizarse con la base de datos DisProt Entender las t\u00e9cnicas experimentales que permiten la identificaci\u00f3n de regiones desordenadas Familiarizarse con distintos m\u00e9todos de predicci\u00f3n de desorden (s\u00f3lo en ejercicios adicionales) Interpretaci\u00f3n de los resultados de los distintos m\u00e9todos de predicci\u00f3n de desorden (s\u00f3lo en ejercicios adicionales)","title":"Objetivos"},{"location":"practicos/TP09_Desorden/#metodos-de-prediccion-de-desorden","text":"Uno de los mayores desaf\u00edos en el campo de las prote\u00ednas es la predicci\u00f3n de la estructura tridimensional a partir de la estructura primaria incluyendo aquellas prote\u00ednas que son total o parcialmente desordenadas. Mientras que las prote\u00ednas globulares adquieren una \u00fanica estructura nativa, las prote\u00ednas intr\u00ednsecamente desordenadas (IDPs, del ingl\u00e9s intrinsically disordered proteins ) son un conjunto de estructuras tridimensionales. Tambi\u00e9n pueden existir regiones desordenadas conectando dos dominios globulares, como los loops ; o incluso regiones m\u00e1s largas, que abarcan m\u00e1s de 30 residuos de longitud, que reciben el nombre de IDRs (del ingl\u00e9s intrinsically disordered regions ). En el a\u00f1o 2020, AlphaFold2 gana la competici\u00f3n de predicci\u00f3n de estructuras (CASP14) con un amplio margen prediciendo estructuras con muy alta precisi\u00f3n. Sin embargo, a\u00fan la predicci\u00f3n de conjunto de estructuras para prote\u00ednas desordenadas no se ha resuelto. La predicci\u00f3n de IDRs/IDPs a partir de la secuencia de amino\u00e1cidos permite un an\u00e1lisis r\u00e1pido y abarcativo de distintas prote\u00ednas permitiendo establecer hip\u00f3tesis sobre la presencia de desorden en las prote\u00ednas (Dunker et al., 2008; van der Lee et al., 2014). La importancia que adquirieron las IDRs/IDPs en los \u00faltimos a\u00f1os llev\u00f3 al desarrollo de numerosos m\u00e9todos de predicci\u00f3n, pero en general se basan en tres estrategias de predicci\u00f3n de desorden: a partir de composici\u00f3n de secuencia, a partir de machine learning sobre estructuras determinadas por cristalograf\u00eda de rayos X y a partir de meta-predictores que integran los resultados predichos por diferentes m\u00e9todos. Entre los algoritmos que se basan en composici\u00f3n de secuencia podemos nombrar IUPred (Doszt\u00e1nyi et al., 2005; Erd\u00f6s et al., 2021), que aplica un campo de energ\u0131\u0301a desarrollado a partir de un gran n\u00famero de prote\u00ednas con estructura determinada obtenidas de PDB. El primer algoritmo en machine learning fue PONDR (Obradovic et al., 2003; Romero et al., 1997), entrenado a partir de un grupo estructuras de prote\u00ednas globulares y atributos de secuencia asociados a residuos no resueltos en dichas estructuras, que corresponden a regiones flexibles dentro del cristal. GlobPlot (Linding et al., 2003) fue entrenado estudiando la tendencia de un residuo a adquirir determinada estructura secundaria, h\u00e9lices \u03b1 o l\u00e1minas \u03b2.","title":"M\u00e9todos de predicci\u00f3n de desorden"},{"location":"practicos/TP09_Desorden/#ejercicios","text":"","title":"Ejercicios"},{"location":"practicos/TP09_Desorden/#ejercicio-1-visualizacion-de-alineamientos-en-proviz","text":"Antes de empezar, piensen ... \u00bfPorqu\u00e9 es importante visualizar un MSA? \u00bfQu\u00e9 informaci\u00f3n podemos obtener de los MSA? ProViz es una herramienta que permite visualizar alineamientos y estructura de dominios de una prote\u00edna online. Ingresa a la web de ProViz http://slim.icr.ac.uk/proviz/ , y busca la prote\u00edna p53 ingresando su Accession Number en la ventana \u201csearch\u201d (Accession Number: P04637): Selecciona la prote\u00edna que se llama: Cellular tumor antigen p53 (TP53) Homo sapiens (Human) . Es la primera de la lista. IMPORTANTE Para responder las preguntas debajo, aseg\u00farate de que en el panel superior de la p\u00e1gina, en alignments , est\u00e9 seleccionada la opci\u00f3n QFO . (Puedes investigar qu\u00e9 pasa si cambian a otras opciones, como mammalian o vertebrates ). En Options a la izquierda haz click en Show/hide gaps . Aparecen m\u00e1s posiciones con gaps en el alineamiento que antes estaban ocultas. 1. \u00bfQu\u00e9 regiones parecen estar mejor alineadas (indicar aproximadamente de qu\u00e9 posici\u00f3n a qu\u00e9 posici\u00f3n de la primera secuencia)? 2. \u00bfExiste diferencia en la composici\u00f3n de secuencia entre las regiones mejor alineadas y las no tan bien alineadas? 3. \u00bfSe observan diferencias en el grado de conservaci\u00f3n de estas regiones? 4. \u00bfA qu\u00e9 pueden deberse las diferencias observadas?","title":"Ejercicio 1"},{"location":"practicos/TP09_Desorden/#ejercicio-2-prediccion-de-desorden-a-partir-de-la-secuencia","text":"Ingresa en la web de IUPred2A https://iupred2a.elte.hu e ingresa la prote\u00edna p53 (puede ingresarse la secuencia de amino\u00e1cidos, el Uniprot ID - P53_HUMAN o el accession number - P04637). Score IUPred El algoritmo IUPred considera que un residuo es: Desordenado cuando el valor de IUPred es mayor o igual a 0.5 Ordenado cuando es menor a 0.5 Nota: Esta es una convenci\u00f3n. El umbral lo puede decir el usuario a su propia conveniencia. 1. Anota las posiciones iniciales y finales de las regiones predichas como desordenadas. \u00bfSe correlacionan las regiones predichas como ordenadas o desordenadas con las diferencias observadas en el ejercicio anterior? 2. Imaginemos que queremos correr la predicci\u00f3n de desorden para cientos de prote\u00ednas, o que queremos contar el porcentaje de amino\u00e1cidos que se encuentran en regiones desordenadas: \u00bfLe parece que el visualizador online ser\u00eda una herramienta \u00fatil para hacerlo? \u00a1Claro que no! Por suerte, el algoritmo IUPred puede tambi\u00e9n correrse de manera local y adem\u00e1s es r\u00e1pido. Abre una terminal y ve al directorio d\u00f3nde est\u00e1 IUPred cd ~/Tools/IUPred/ # Primero corremos IUPred sin ninguna opci\u00f3n para ver c\u00f3mo es su uso: ./iupred2a.py Deber\u00eda aparecer lo siguiente: Usage: ./iupred2a.py ( options ) ( seqfile ) ( iupred type ) Available types: \"long\" , \"short\" , \"glob\" Options -d str - Location of data directory ( default = './' ) -a - Enable ANCHOR2 predition El archivo con la secuencia de p53 ( P53_HUMAN.seq ) est\u00e1 guardado en el mismo directorio que IUPred. En base a esto, el comando a utilizar es el siguiente ./iupred2a.py -a P53_HUMAN.seq long > P53_HUMAN.iupred 3. Explora el archivo generado ( P53_HUMAN.iupred ) y responde. \u00bfC\u00f3mo es el formato de los datos? \u00bfLas columnas tienen nombre? \u00bfSer\u00e1n interpretadas correctamente por R? 4. Crea un script en R. Para esto, abre RStudio y elije: New --> RScript Recuerda ver en qu\u00e9 directorio est\u00e1s trabajando y configurarlo para trabajar en el directorio deseado, por si no lo recuerdas las funciones eran: getwd() : Devuelve el directorio de trabajo setwd() : Configura el directorio de trabajo 4a. \u00a1A cargar los datos! \u00bfTe acord\u00e1s c\u00f3mo se hac\u00eda? Se utilizaba la funci\u00f3n fread() . Vamos a modificar algunos argumentos para que lea correctamente el archivo. Si quer\u00e9s saber qu\u00e9 es cada argumento siempre se puede revisar el uso de las funciones con help(fread) library ( data.table ) fileIN <- \"~/Tools/IUPred/P53_HUMAN.iupred\" header <- c ( \"Posicion\" , \"Aminoacido\" , \"Iupred\" , \"Anchor\" ) p53 <- fread ( file = fileIN , header = T , sep = \"\\t\" , col.names = header , skip = \"POS\" ) Asegurate que los datos se cargaron correctamente, esperamos una tabla con 4 columnas. 4b. Ahora quisi\u00e9ramos clasificar las posiciones en pase a la predicci\u00f3n realizada por IUPred como Orden y Desorden . \u00bfSe te ocurre c\u00f3mo hacerlo? Primero crearemos una columna en el data.table: umbral <- 0.5 p53 $ Prediccion <- \"\" p53 [ Iupred >= umbral ] $ Prediccion <- \"Desorden\" p53 [ Iupred < umbral ] $ Prediccion <- \"Orden\" Para obtener un gr\u00e1fico similar al que brinda el servidor de IUPred, utilizaremos la librer\u00eda ggplot2 : library ( ggplot2 ) plot_p53 <- ggplot ( p53 , aes ( x = Posicion , y = Iupred )) + scale_x_continuous ( n.breaks = 20 , expand = c ( 0.01 , 0.01 )) + scale_y_continuous ( n.breaks = 10 , limits = c ( 0 , 1 ), expand = c ( 0 , 0.01 )) + geom_line ( color = \"navyblue\" ) + geom_point ( aes ( color = Prediccion )) + geom_hline ( yintercept = 0.5 , lty = \"dotted\" , size = 1 ) + theme_linedraw () plot_p53 Deber\u00eda obtener un gr\u00e1fico como el siguiente: Ahora, quisi\u00e9ramos evaluar el porcentaje de residuos predichos ordenados y desordenados. Por suerte, R tiene una funci\u00f3n que \u201ccuenta\u201d por nosotros: cuentaTotal <- table ( p53 $ Prediccion ) porcentaje <- 100 * cuentaTotal / length ( p53 $ Posicion ) print ( cuentaTotal ) print ( porcentaje ) 4c. En base a los valores obtenidos, \u00bfdir\u00eda que la prote\u00edna p53 es altamente desordenada? 4d. Por \u00faltimo, analizaremos la composici\u00f3n de amino\u00e1cidos de p53. Pero antes: \u00bfQu\u00e9 residuos espera ver enriquecidos en las regiones desordenadas y cuales en las ordenadas ? \u00bfPor qu\u00e9? Vamos a graficar el porcentaje de cada amino\u00e1cido predicho como ordenado o desordenado en la secuencia de p53 aminoacidos <- table ( p53 $ Aminoacido , p53 $ Prediccion ) print ( aminoacidos ) \u00bfQu\u00e9 hizo la funci\u00f3n table en este caso? Para calcular el porcentaje de amino\u00e1cidos: aminoacidos_porcentaje <- 100 * aminoacidos / length ( p53 $ Posicion ) Ahora vamos a convertir la tabla en un data.table para graficar con ggplot2 : aminoacidos_df <- as.data.table ( aminoacidos_porcentaje ) colnames ( aminoacidos_df ) <- c ( \"Aminoacidos\" , \"Prediccion\" , \"Porcentaje\" ) plot_aa <- ggplot ( aminoacidos_df , aes ( x = Aminoacidos , y = Porcentaje , fill = Prediccion )) + geom_col ( position = \"dodge\" ) + scale_y_continuous ( n.breaks = 10 , limits = c ( 0 , 10 ), expand = c ( 0 , 0.01 )) + theme_bw () ggsave ( filename = \"aminoacidos.png\" , plot = plot_aa , device = \"png\" , dpi = 150 , width = 10 , height = 5 , units = \"cm\" ) Deber\u00edas obtener un gr\u00e1fico como el siguiente: \u00bfQu\u00e9 amino\u00e1cidos son los m\u00e1s abundantes en las regiones desordenadas? \u00bfLa abundancia de los amino\u00e1cidos coincide con lo esperado?","title":"Ejercicio 2"},{"location":"practicos/TP09_Desorden/#parte-ii-base-de-datos-disprot","text":"La base de datos DisProt es una colecci\u00f3n de evidencia de desorden experimental recolectada de la literatura y curada manualmente. La evidencia corresponde a una regi\u00f3n proteica, e incluye por lo menos: un experimento, el art\u00edculo cient\u00edfico correspondiente a ese experimento, el inicio y final de la regi\u00f3n desordenada en la secuencia proteica un t\u00e9rmino de anotaci\u00f3n que corresponde a la Ontolog\u00eda de desorden. Cada una de las entradas en la base de datos posee un identificador \u00fanico La ontolog\u00eda de desorden est\u00e1 organizada en tres categor\u00edas diferentes: Estado estructural ( Structural State ): Orden o Desorden ( Order or Disorder ) Transici\u00f3n estructural ( Structural Transition ): Transiciones que pueden ocurrir entre diferentes estados estructurales ( Disorder to order ) Funci\u00f3n de desorden ( Disorder Function ): La funci\u00f3n de una regi\u00f3n incluyendo t\u00e9rminos espec\u00edficos a desorden. En Disprot tambi\u00e9n se incluye la funci\u00f3n molecular Molecular function de cada regi\u00f3n.","title":"PARTE II: Base de Datos Disprot"},{"location":"practicos/TP09_Desorden/#ejercicio-1-base-de-datos-disprot","text":"La prote\u00edna p53 es una prote\u00edna supresora de tumores, es decir que su mutaci\u00f3n favorece el crecimiento tumoral. p53 es uno de los genes m\u00e1s mutados en el c\u00e1ncer humano, y act\u00faa como un factor de transcripci\u00f3n que se expresa en todos los tejidos. Cumple un rol principal en el ciclo celular y es el regulador principal de la apoptosis. Es esencial para inducir la respuesta celular ante el da\u00f1o al ADN, deteniendo el ciclo celular cuando las c\u00e9lulas no pueden reparar el ADN da\u00f1ado por agentes genot\u00f3xicos. Si falla p53 podr\u00edan facilitar la formaci\u00f3n de tumores celulares y en consecuencia producir c\u00e1ncer. Alrededor de un 50% de los tumores humanos identificados poseen mutaciones en la prote\u00edna p53. Esta prote\u00edna, por su importancia para la salud humana, es una de las prote\u00ednas m\u00e1s estudiadas en cuanto a su estructura y funci\u00f3n. Ingresa a la p\u00e1gina web de DisProt y encuentra la prote\u00edna p53 (P04637). La b\u00fasqueda puede realizarse utilizando el Accession Number o por palabras claves. El identificador de DisProt que deber\u00edan encontrar es DP00086. Una vez encontrado haz click en el identificador de Disprot. a. Si Disprot consensus est\u00e1 colapsado, expandelo: \u00bfQu\u00e9 tipo de informaci\u00f3n observa en la p\u00e1gina? b. Expande Structural state y luego expande Disorder : \u00bfA qu\u00e9 corresponden los segmentos coloreados? \u00bfQu\u00e9 tipo de evidencia poseen dichos fragmentos? c. Pensando en el rol de las regiones desordenadas. i. Expande Molecular Function : \u00bfQu\u00e9 tipo de funciones est\u00e1n indicadas para cada regi\u00f3n? \u00bfQu\u00e9 t\u00e9cnicas se usaron para identificarlas? ii. Expande Disorder Function : \u00bfQu\u00e9 tipo de funciones est\u00e1n indicadas? \u00bfCu\u00e1ntos experimentos y que tipo de t\u00e9cnicas se realizaron para identificar cada una? d. Expande Domains . Sabiendo que ... Los dominios Pfam son asignados a partir de un perfil de HMMs creado de un alineamiento de prote\u00ednas representativas Gene3D contiene anotaciones de dominios estructurados. \u00bfSe observa alg\u00fan dominio conservado que NO adquiera una estructura globular? e. \u00bfLa evidencia experimental recolectada coincide con las predicciones realizadas en el Ejercicio 1 y en el Ejercicio 2 ?","title":"Ejercicio 1"},{"location":"practicos/TP09_Desorden/#parte-iii-analisis-de-alineamientos-multiples-de-secuencia-de-proteinas-visualizando-alineamientos-con-jalview","text":"","title":"Parte III - Alineamientos"},{"location":"practicos/TP09_Desorden/#software","text":"JalView: https://www.jalview.org/","title":"Software"},{"location":"practicos/TP09_Desorden/#recursos-online_1","text":"Pfam: https://pfam.xfam.org/","title":"Recursos Online"},{"location":"practicos/TP09_Desorden/#objetivos_1","text":"Aprender a utilizar Jalview para visualizar un MSA y familiarizarse con el manejo de programas de visualizaci\u00f3n de alineamientos. Interpretar alineamientos m\u00faltiples de secuencias. Identificar regiones de secuencia conservadas y asociarlas a diferentes elementos funcionales de las prote\u00ednas. Visualizar y analizar los patrones de sustituci\u00f3n aminoac\u00eddica encontrados en prote\u00ednas modulares. Correlacionar con sus conocimientos sobre matrices de sustituci\u00f3n","title":"Objetivos"},{"location":"practicos/TP09_Desorden/#ejercicios_1","text":"","title":"Ejercicios"},{"location":"practicos/TP09_Desorden/#ejercicio-1-identificando-modulos-en-proteinas","text":"Utilizando su c\u00f3digo UNIPROT (P04637), busca la prote\u00edna p53 humana (P53_HUMAN) en la base de datos Pfam https://pfam.xfam.org/ La base de datos Pfam es una colecci\u00f3n de familias de dominios de prote\u00ednas construida en base a alineamientos m\u00faltiples de secuencia y modelos ocultos de markov (HMMs). Las prote\u00ednas est\u00e1n compuestas por una o m\u00e1s regiones funcionales o dominios, que combinados de distintas maneras crean la diversidad proteica que se encuentra en las prote\u00ednas naturales. 1a. \u00bfPor qu\u00e9 es necesario identificar dominios en las prote\u00ednas? Para buscar la prote\u00edna p53 puedes hacerlo ingresando en VIEW A SEQUENCE el accession number (P04637) o el uniprot ID (P53_HUMAN) 1b. \u00bfQu\u00e9 longitud tiene la prote\u00edna p53 humana? 1c. Observar el esquema de p53: \u00bfPuedes identificar qu\u00e9 dominios Pfam tiene p53? \u00bfQu\u00e9 nombres y qu\u00e9 funciones tienen? En algunos casos esta informaci\u00f3n est\u00e1 en la pesta\u00f1a de Pfam que aparece en la nueva ventana que se abre al hacer click en el nombre del dominio. 1d. \u00bfEn qu\u00e9 regiones de la secuencia se encuentran estos dominios? Anotar de qu\u00e9 residuo a qu\u00e9 residuo abarca cada dominio, para usar m\u00e1s adelante. 1e. \u00bfCreen que estos dominios corresponden un\u00edvocamente a dominios globulares? 1f. \u00bfA qu\u00e9 cree que corresponden las regiones marcadas como Disorder y Low Complexity en p53? 1g. \u00bfSe corresponden las regiones identificadas como Disorder en Pfam con las predichas por IUPred en el Ejercicio 2 de la parte I de predicci\u00f3n de desorden? \u00bfQu\u00e9 utiliza Pfam para poder identificar las regiones como Disorder (Esta informaci\u00f3n est\u00e1 en el HELP de Pfam en Guide to Graphics )?","title":"Ejercicio 1"},{"location":"practicos/TP09_Desorden/#jalview-software-de-visualizacion-de-alineamientos","text":"Para poder visualizar alineamientos m\u00faltiples de secuencias (MSA, de sus siglas en ingl\u00e9s: Multiple Sequence Alignment) utilizaremos el visualizador de alineamientos JalView desarrollado en JAVA. Jalview permite generar alineamientos, manipularlos, editarlos y anotarlos. Tiene una interfaz que permite acceder remotamente numerosas herramientas como programas para realizar alineamientos m\u00faltiples de secuencia y predictores de estructura secundaria. A lo largo de la gu\u00eda de ejercicios, introduciremos este programa usandolo para visualizar alineamientos m\u00faltiples de secuencias (MSAs) de prote\u00ednas modulares y discutir caracter\u00edsticas de secuencia asociadas a los dominios y motivos funcionales encontrados en las prote\u00ednas. JalView es un programa que se ofrece de manera gratuita, y est\u00e1 disponible para descargar e instalar en tu propia computadora en https://www.jalview.org/ Existen un alto n\u00famero de gu\u00edas y tutoriales disponibles online que pueden encontrar en: https://www.jalview.org/training Los desarrolladores de JalView crearon numerosos videos de entrenamiento disponibles en el Canal de YouTube de JalView","title":"JalView, software de visualizaci\u00f3n de alineamientos"},{"location":"practicos/TP09_Desorden/#ejercicio-2-usando-jalview-para-analizar-un-msa-de-p53","text":"2a. Abre Jalview Para abrir Jalview vayan al directorio: ~/Tools/Jalview/ y corran el archivo jalview.sh : bash jalview.sh Abran en Jalview el conjunto de secuencias de p53 que se encuentra en el archivo p53.fasta : File \u2192 Input Alignment \u2192 From File 2c. Para realizar el alineamiento utilizaremos el programa Clustal, al cual accederemos de manera remota desde JalView de la siguiente manera: Web Service \u2192 Alignment \u2192 Clustal \u2192 With defaults Si no llegara a funcionar, pues Internet, Virtualidad, la vida... Tienen las secuencias ya alineadas en el archivo p53_aligned.fasta 2d. Inspecciona el alineamiento visualmente y reconoce algunas caracter\u00edsticas de las secuencias. Si no se muestran todos los residuos y algunos aparecen como . ve a: Format \u2192 Show Non-Conserved a. Algunas secuencias son m\u00e1s cortas que otras \u00bfpor qu\u00e9 crees que es esto? b. \u00bfSi quieren construir un alineamiento de alta calidad, preservar\u00edan o descartar\u00edan estas secuencias? c. Remuevan las secuencias que no corresponden a prote\u00ednas completas. Para ello seleccionar las secuencias haciendo click sobre el nombre de la misma en el panel izquierdo, la secuencia se marcar\u00e1 con una caja roja punteada. Remover la secuencia seleccionada utilizando la tecla Backspace o Del d. \u00bfExisten regiones del alineamiento que no est\u00e9n alineadas correctamente? Para editar el alineamiento, primero asegurate de realizar: Select \u2192 Deselect All Eliminar gaps: Seleccione con el mouse el gap o arrastrando sobre el grupo de gaps que desea eliminar y presione o Backspace o bien Del Agregar gaps: Presione F2 . En la primera posici\u00f3n del alineamiento en la primera secuencia aparecer\u00e1 un cursor de color negro. Col\u00f3quelo en la posici\u00f3n donde desee ingresar un gap y presione la barra espaciadora.","title":"Ejercicio 2"},{"location":"practicos/TP09_Desorden/#ejercicio-3-analisis-de-distintas-propiedades-del-msa-utilizando-el-menu-colour","text":"Este men\u00fa permite colorear el alineamiento con diferentes paletas de colores que permiten visualizar determinadas caracter\u00edsticas fisicoqu\u00edmicas o relacionadas con la conservaci\u00f3n o identidad de secuencia que facilitan el an\u00e1lisis de la informaci\u00f3n contenida en el MSA. Por ejemplo: Percentage identity colorea los residuos seg\u00fan el porcentaje de identidad en la columna. Hydrophobicity colorea los residuos seg\u00fan el grado de hidrofobicidad. Tambi\u00e9n es posible disminuir la intensidad de los colores seg\u00fan el grado de conservaci\u00f3n ( By conservation ) o filtrar los colores seg\u00fan el porcentaje de identidad ( Above identity threshold ) a partir de un umbral deseado. 3a. Seleccione para colorear el alineamiento desde el men\u00fa la opci\u00f3n: Colour \u2192 Clustalx Este esquema es muy com\u00fanmente utilizado para la visualizaci\u00f3n de MSAs y permite representar informaci\u00f3n importante contenida en los patrones de sustituci\u00f3n de un MSA. Observando el alineamiento intente identificar: a. \u00bfCu\u00e1l es la base del esquema de color \u201cClustalX\u201d provisto por Jalview? Nota: Google provee respuestas pero... pueden ir directamente al esquema de colores de ClustalX b. \u00bfCu\u00e1ntos colores existen? c. \u00bfQu\u00e9 propiedades fisicoqu\u00edmicas representa cada grupo de color? d. La ciste\u00edna cumple un rol estructural importante en algunas prote\u00ednas (\u00bfcu\u00e1l?). \u00bfQu\u00e9 observa respecto de la coloraci\u00f3n de la ciste\u00edna? \u00bfEs siempre igual? \u00bfA qu\u00e9 se debe el cambio en la representaci\u00f3n? En ProViz la ciste\u00edna estaba siempre coloreada del mismo color, pero en el esquema de colores de ClustalX no lo est\u00e1. e. \u00bfEn qu\u00e9 situaciones los residuos no est\u00e1n coloreados? f. Hay residuos que siempre est\u00e1n coloreados? \u00bfCu\u00e1les son y a qu\u00e9 cree que se debe? 3b. Manteniendo el esquema de color Clustal, es posible filtrar regiones de acuerdo al % identidad en el alineamiento m\u00faltiple. Para ello, aplique el filtro de identidad yendo a: Colour \u2192 Above identity threshold Se abrir\u00e1 una ventana en la cual podr\u00e1 seleccionar el % identidad del filtro en escala de 0 a 100%. Explore los cambios en todo el alineamiento al variar la escala de 0 a 100%. Utilizando el filtro, respondan: a. \u00bfQu\u00e9 regiones muestran una identidad de secuencia mayor al 80% en el MSA de p53? \u00bfY al 100%? Anote los l\u00edmites de estas regiones y responda: \u00bfQu\u00e9 correlaci\u00f3n observa con la informaci\u00f3n obtenida de Pfam? Con la identidad al 80%, observe en las columnas del MSA que sustituciones ocurren. Estas susticiones son un reflejo de la historia evolutiva de la prote\u00edna y contienen mucha informaci\u00f3n funcional. Observando detenidamente, responda: b. \u00bfQu\u00e9 tipos de sustituciones observa? c. \u00bfQu\u00e9 relaci\u00f3n guardan estas sustituciones con las matrices PAM y BLOSUM utilizadas para construir alineamientos de prote\u00ednas? d. En base a este alineamiento analice las regiones desordenadas y ordenadas ya reconocidas en p53. Compare sus observaciones en este alineamiento con el alineamiento visualizado en ProViz en el Ejercicio 1 de la PARTE I . \u00bfPuede distinguir las mismas regiones? \u00bfVe diferencias en la composici\u00f3n de secuencia en cada regi\u00f3n entre los dos alineamientos? \u00bfSe observan diferencias en el grado de conservaci\u00f3n entre los dos alineamientos? \u00bfLas especies a las que corresponde cada secuencia son las mismas en los alineamientos? \u00bfCu\u00e1l posee organismos m\u00e1s distantes? Discuta qu\u00e9 ventajas considera que tiene trabajar con un alineamiento propio respecto de trabajar con el alineamiento de ProViz.","title":"Ejercicio 3"},{"location":"practicos/TP09_Desorden/#ejercicio-a-informar","text":"Fecha l\u00edmite de entrega: Viernes, 07 de Octubre 2022, 23:59hs.","title":"Ejercicio a informar"},{"location":"practicos/TP09_Desorden/#enunciado","text":"El aislamiento que le proporcionaron est\u00e1 avanzando r\u00e1pidamente en latinoam\u00e9rica!. Dada la importancia de la prote\u00edna N de la nucleoc\u00e1pside en la replicaci\u00f3n viral, su jefe considera que es un blanco posible de drogas. La prote\u00edna N forma la nucleoc\u00e1pside viral de SARS-CoV2 y empaqueta el genoma viral de ARN formando una ribonucleoc\u00e1pside. La estructura de la prote\u00edna es altamente desordenada y posee dos dominios globulares peque\u00f1os en el N-terminal (Dominio N) y C terminal (Dominio C). Usando IUPred, identifique las regiones desordenadas y globulares. \u00bfPuede identificar f\u00e1cilmente los dominios globulares con el umbral de 0.5? \u00bfy con el umbral de 0.4? Justifique los resultados en base al funcionamiento del algoritmo. Si desear\u00eda cristalizar el dominio N \u00bfQu\u00e9 regiones no incluir\u00eda? Analice la proporci\u00f3n de residuos predichos como ordenados y como desordenados utilizando cada uno de los umbrales. \u00bfSe correlaciona esto con lo estudiado en la literatura? Extra! (y por ende opcional) 1. Como se vi\u00f3 en la clase te\u00f3rica, IUPred puede correrse utilizando como argumento short o long . Realice el gr\u00e1fico del perfil de IUPred nuevamente utilizando short . \u00bfQu\u00e9 diferencias observa en los gr\u00e1ficos usando Iupred short o long ? En base a sus conocimientos de IUPred, explique brevemente y de manera abarcativa las diferencias observadas.","title":"Enunciado"},{"location":"practicos/TP10_Motivos/","text":"TP 10 . Motivos lineales Videos de la clase grabada Introducci\u00f3n al TP Puesta en com\u00fan del TP Atenci\u00f3n: Este TP tiene informe. Materiales Recursos Online Regex101 https://regex101.com UniProt http://www.uniprot.org/ ELM http://elm.eu.org Objetivos Familiarizarse con la simbolog\u00eda utilizada en expresiones regulares Utilizar la simbolog\u00eda para poder realizar b\u00fasquedas basadas en texto Introducci\u00f3n La simbolog\u00eda com\u00fanmente utilizada en expresiones regulares es: S\u00edmbolo Definici\u00f3n . Cualquier amino\u00e1cido es permitido [XY] Solo los amino\u00e1cidos X e Y son permitidos [^XY] Los amino\u00e1cidos X e Y est\u00e1n prohibidos {min,max} N\u00famero m\u00ednimo y m\u00e1ximo de veces que se puede repetir una posici\u00f3n ^X El amino\u00e1cido X se encuentra en el extremo N-terminal X$ El amino\u00e1cido X se encuentra en el extremo C-terminal (AB)|(CD) Se encuentran, o bien, los amino\u00e1cidos AB, o bien, los amino\u00e1cidos CD Estos s\u00edmbolos nos permiten definir patrones que son observados en prote\u00ednas naturales para luego identificarlos en otras prote\u00ednas y ser puestos a prueba experimentalmente. Ejercicios Ejercicio 1. Familiariz\u00e1ndonos con las Expresiones Regulares Los receptores nucleares interact\u00faan con diversas prote\u00ednas mediantes un motivo lineal llamado NRBox ( Nuclear Receptor Box ) (Heery,1997). Existen numerosas estructuras de p\u00e9ptidos unidos a diferentes receptores nucleares (PDBs: 3CS8, 2GPO, 1GWQ, 1RJK, 1M2Z) que permitieron estudiar y entender algunas caracter\u00edsticas de la interacci\u00f3n. La evidencia experimental recolectada de la literatura indica que: El motivo NRBox forma una h\u00e9lice alfa Existen tres leucinas que se encuentran en una misma cara de la h\u00e9lice que interact\u00faan con un bolsillo hidrof\u00f3bico en la superficie del receptor nuclear (Figura 1). Figura 1. Fragmento de la prote\u00edna PGC-1 alfa unido al receptor nuclear PPAR-gamma. Se muestra en naranja el backbone de la prote\u00edna representado en Cartoon y en azul las tres leucinas que median la interacci\u00f3n representadas en Sticks (PDB:3CS8) y que conforman el motivo NRBox. Los siguientes fragmentos de secuencia corresponden a regiones de distintas prote\u00ednas que interact\u00faan con diversos receptores nucleares y cuya interacci\u00f3n se verific\u00f3 de manera experimental por distintos m\u00e9todos. >sp|Q15648|MED1_HUMAN|644-650 SMAGNTKNHPMLMNLLKDNPAQDFSTL >sp|O43593|HAIR_HUMAN|565-571 AKHLLSGLGDRLCRLLRREREALAWAQ >sp|Q16881-4|TRXR1_HUMAN|46-52 GPTLKAYQEGRLQKLLKMNGPEDLPKS >sp|P48552|NRIP1_HUMAN|500-506 DVHQDSIVLTYLEGLLMHQAAGGSGTA >sp|Q9UQ80|PA2G4_HUMAN|353-359 YKSEMEVQDAELKALLQSSASRKTQKK >sp|Q90ZL7|Q90ZL7_DANRE|69-75 VQHADGEKSNVLRKLLKRANSYEDAVM >sp|Q9UBK2|PRGC1_HUMAN|143-149 PPPQEAEEPSLLKKLLLAPANTQLSYN >sp|Q9JL19|NCOA6_MOUSE|1494-1500 MSPAMREAPTSLSQLLDNSGAPNVTIK >sp|Q15596|NCOA2_HUMAN|689-695 HGTSLKEKHKILHRLLQDSSSPVDLAK >sp|Q92793|CBP_HUMAN|69-75 LVPDAASKHKQLSELLRGGSGSSINPG 1. Copie y pegue las secuencias en el recuadro de Test String en regex101 https://regex101.com y pruebe encontrar una expresi\u00f3n regular que permita identificar el motivo que media la interacci\u00f3n de estas prote\u00ednas con los receptores nucleares y que cumpla con la evidencia experimental observada. Regex101 No es una herramienta que se use en bioinform\u00e1tica. Simplemente es un recurso educativo para entender Expresiones Regulares . En R hay funciones como grep o gregexpr que permiten identificar expresiones regulares y en python hay todo una librer\u00eda re dedicada a expresiones regulares. 2. Considerando que el motivo se encuentra en una h\u00e9lice, \u00bfmodificar\u00eda la expresi\u00f3n regular que obtuvo? Ejercicio 2. Base de datos de motivos lineales en Eucariotas (ELMdb) La base de datos ELM ( Eukaryotic Linear Motifs ) es una base de datos que se enfoca principalmente en la anotaci\u00f3n y detecci\u00f3n de motivos lineales (MLs). Para ello cuenta con un repositorio de motivos manualmente anotados, por lo cual est\u00e1 altamente curada y tambi\u00e9n cuenta con una herramienta de predicci\u00f3n de motivos. Esta predicci\u00f3n de motivos se realiza mediante una b\u00fasqueda de patrones de secuencia basada en texto utilizando expresiones regulares. Las instancias anotadas (es decir, probadas experimentalmente) pueden ser: True Positives: Una instancia anotada con evidencia experimental que demuestra que es funcional. False Positives: Una instancia anotada con evidencia experimental que sugiere que es funcional. Pero luego de una inspecci\u00f3n cuidadosa de los anotadores se cree que la instancia en realidad no es funcional. True Negative: Una instancia anotada donde los experimentos muestren que es no funcional. Unknown: No se encontr\u00f3 evidencia suficiente para determinar si la instancia es funcional o no. 1. Busque en ELMdb en la pesta\u00f1a Prediction la prote\u00edna PGC-1-alpha, una de las prote\u00ednas de la lista que usamos en el Ejercicio 1 , utilizando el accession number o uniprot ID (Q9UBK2 - PRGC1_HUMAN). Para cada motivo encontrado, se indica con s\u00edmbolos (descriptos en la parte superior de la p\u00e1gina) si la instancia del motivo es predicha o fue identificada experimentalmente (anotadas o \"True Positives\"). Responda: \u00bfEncuentra el motivo NRBox entre los True positives ? \u00bfCu\u00e1ntas instancias True Positive existen para esta prote\u00edna? \u00bfC\u00f3mo es la estructura de la prote\u00edna donde se encuentran estos motivos? 2. Pegue y copie la siguiente secuencia en ELM y utilice los par\u00e1metros que se indican a continuaci\u00f3n. >seq MEEPQSDPSVEPPLSQETFSDLWKLLPENNVLSPLPSQAMDDLMLSPDDI EQWFTEDPGPDEAPRMPEAAPPVAPAPAAPTPAAPAPAPSWPLSSSVPSQ KTYQGSYGFRLGFLHSGTAKSVTCTYSPALNKMFCQLAKTCPVQLWVDST PPPGTRVRAMAIYKQSQHMTEVVRRCPHHERCSDSDGLAPPQHLIRVEGN LRVEYLDDRNTFRHSVVVPYEPPEVGSDCTTIHYNYMCNSSCMGGMNRRP ILTIITLEDSSGNLLGRNSFEVRVCACPGRDRRTEEENLRKKGEPHHELP PGSTKRALPNNTSSSPQPKKKPLDGEYFTLQIRGRERFEMFRELNEALEL KDAQAGKEPGGSRAHSSHLKSKKGQSTSRHKKLMFKTEGPDSD Aseg\u00farese que los valores de los distintos par\u00e1metros son los siguientes: Cell Compartment: Not specified Motif Probability Cutoff: 100 Taxonomic context: (leave blank) \u00bfCu\u00e1ntas instancias predichas de motivos se encuentran? Para verlo investigue la tabla llamada Filtering Summary . \u00bfCu\u00e1ntas son retenidas luego del filtro? \u00bfQu\u00e9 se puede decir sobre la estructura de la prote\u00edna? \u00bfSe observa alg\u00fan dominio? \u00bfSe observan regiones desordenadas? \u00bfLos predictores estructurales y filtros (SMART, GlobPlot, IUPRED, Secondary Structure) coinciden sobre qu\u00e9 regiones son estructuradas/desordenadas? 3. Por si no se di\u00f3 cuenta, la prote\u00edna utilizada en el ejercicio anterior es p53 de humanos. ELM nos permite fitrar por compartimento celular \u00bfPorqu\u00e9 consideran que esto ser\u00eda \u00fatil? Utilizando el uniprot ID de p53 (P53_HUMAN) busque en la web de Uniprot ( https://www.uniprot.org/ ) las posibles localizaciones subcelulares de esta prote\u00edna y util\u00edcelas como filtro en ELM. Para esto: Abra en una nueva pesta\u00f1a la p\u00e1gina de ELM. Vaya de nuevo a la pesta\u00f1a de predicci\u00f3n. Limpie el formulario con el bot\u00f3n Reset Form . Ingrese el Uniprot ID de la prote\u00edna (P53_human) y asigne en Cell compartment los compartimentos correspondientes utilizando Ctrl para seleccionar m\u00e1s de uno. Realice la predicci\u00f3n y conteste: \u00bfCu\u00e1ntas instancias de motivos se encuentran ahora? \u00bfCu\u00e1ntas instancias de motivos son retenidas luego del filtro? \u00bfA qu\u00e9 se debe esta diferencia con el punto anterior? Investigue el motivo CLV_PCSK_FUR_1 en la predicci\u00f3n realizada s\u00f3lo con la secuencia. \u00bfPor qu\u00e9 cree que fue filtrado? \u00bfCu\u00e1ntas instancias anotadas como true positive posee esta prote\u00edna? Compare la ubicaci\u00f3n de las instancias anotadas con la informaci\u00f3n estructural proveniente de IUPred. \u00bfCu\u00e1ntas instancias de la clase MOD_CK1_1 se encontraron? \u00bfCu\u00e1l es la diferencia entre estas instancias? \u00bfCu\u00e1ntos degrons anotados hay en p53? \u00bfCu\u00e1l es la funci\u00f3n de estos motivos? \u00bfExiste alg\u00fan sitio anotado CDK ( Cyclin Dependent Kinase ) en p53? \u00bfExiste alg\u00fan sitio anotado DOC_CYCLIN_RXL_1 ? \u00bfQu\u00e9 relaci\u00f3n funcional existe entre este sitio y el sitio CDK? 4. Abra una nueva pesta\u00f1a y vaya de nuevo a la pesta\u00f1a de predicci\u00f3n. Manteniendo los compartimentos celulares seleccionados para p53, ingrese el Uniprot ID (P53_HUMAN) y modifique el par\u00e1metro: Motif Probability Cutoff: 0.01 (Recuerde que en el punto anterior este par\u00e1metro era de 100) \u00bfCu\u00e1ntas instancias predichas de motivos se encuentran ahora? \u00bfCu\u00e1ntas instancias de motivos son retenidas luego del filtro? \u00bfPor qu\u00e9 cree que es \u00fatil usar el umbral de probabilidad del motivo? 5. Abra una nueva pesta\u00f1a y vaya de nuevo a la pesta\u00f1a de predicci\u00f3n. Manteniendo los compartimentos celulares seleccionados para p53, ingrese el Uniprot ID (P53_HUMAN) y modifique el par\u00e1metro: Taxonomic Context: Homo sapiens \u00bfCu\u00e1ntas instancias predichas de motivos se encuentran ahora? \u00bfCu\u00e1ntas instancias de motivos son retenidas luego del filtro? \u00bfPor qu\u00e9 cree que es \u00fatil usar el contexto taxon\u00f3mico? 5. Busque la prote\u00edna P53_MOUSE en ELM. \u00bfExisten instancias anotadas? \u00bfExisten instancias asignadas por homolog\u00eda? \u00bfA qu\u00e9 organismo pertenecen? Ejercicio 3. Identificaci\u00f3n de motivos cortos de interacci\u00f3n en p53 en un alineamiento propio. La regi\u00f3n amino terminal de p53 posee un motivo de uni\u00f3n a la E3 ligasa MDM2, el cual est\u00e1 caracterizado por una secuencia conservada que puede representarse por una expresi\u00f3n regular. Entre en la base de datos ELM y busque la expresi\u00f3n regular del motivo con el ID: DEG_MDM2_SWIB_1 . Para esto ingrese el ID en la parte superior derecha donde dice: Search ELM database. La expresi\u00f3n regular se encuentra marcada como \"Pattern\" . A continuaci\u00f3n, busque las ocurrencias de esta expresi\u00f3n regular en las secuencias de p53. Para ello, abra en Jalview el alineamiento de p53 con el cu\u00e1l estuvo trabajando en la clase de TP N\u00b09 - Predicci\u00f3n de desorden . Jalview permite la b\u00fasqueda de motivos por expresiones regulares. Para hacerlo, utilice la funci\u00f3n: Select \u2192 Find En la ventana tipee la expresi\u00f3n regular. Si este procedimiento falla, y tiene la ventana de las secuencias no alineadas abiertas, ci\u00e9rrela. Si a\u00fan as\u00ed falla, identifique el motivo utilizando el filtro de conservaci\u00f3n. \u00bfTodas las secuencias de p53 tienen el motivo de interacci\u00f3n con MDM2? \u00bfTodos los motivos MDM2 tienen la misma longitud de secuencia? \u00bfQu\u00e9 nivel de identidad de secuencia observa en esta regi\u00f3n? \u00bfA qu\u00e9 puede deberse? Ejercicio a informar Fecha l\u00edmite de entrega: Viernes, 14 de Octubre 2022, 23:59hs. Enunciado Su jefe tambi\u00e9n est\u00e1 interesado en que Ud. entienda m\u00e1s sobre los mecanismos de entrada del virus a la c\u00e9lula, la cual est\u00e1 mediada por la enzima convertidora de angiotensina 2 (ACE2) (Uniprot ID: ACE2_HUMAN2, Q9BYF1). Luego de unirse la prote\u00edna Spike a ACE2, se desencadena la entrada del virus SARS-CoV-2 a las c\u00e9lulas pulmonares por un mecanismo llamado endocitosis mediada por receptor, en el cual participan muchos motivos lineales. 1. Seg\u00fan los m\u00e9todos utilizados en el trabajo pr\u00e1ctico de desorden identifique las regiones desordenadas del receptor, e investigue \u00bfEn qu\u00e9 compartimento celular se encuentran esta/s regi\u00f3n/es? 2. Algunos de los motivos conocidos involucrados en la v\u00eda de endocitosis mediada por receptor son: TRG_ENDOCYTIC_2 , LIG_LIR_Gen_1 , LIG_PTB_APO2 . \u00bfEn qu\u00e9 compartimentos celulares deber\u00edan encontrarse prote\u00ednas como ACE2? Estos motivos \u00bfse encuentran en la secuencia humana del receptor? \u00bfCu\u00e1ntas instancias de cada uno de los motivos encuentra, en qu\u00e9 posiciones y cu\u00e1les creen que son buenos candidatos? De los tres motivos \u00bfExisten algunos candidatos que son mejores que otros? Si es as\u00ed, responda \u00bfPor qu\u00e9 son mejores? Atenci\u00f3n Siempre que reporte una regi\u00f3n o instancia de un motivo indique las posiciones de inicio y final de la misma. Para cada respuesta, indicar los algoritmos, base de datos y m\u00e9todos utilizados, y el criterio usado en cada caso para clasificar/identificar. 3. Un criterio para clasificar un buen motivo candidato es que est\u00e9 conservado en >50% de un conjunto de secuencias divergentes. Utilizando las expresiones regulares y el conjunto de secuencias de ACE2 (que se encuentran en el archivo ACE2_secuencias.fasta ), indique cu\u00e1les de las instancias de los motivos seleccionados en (2) son buenos candidatos seg\u00fan su conservaci\u00f3n. Si bien es un alineamiento de prote\u00ednas hom\u00f3logas \u00bfEncuentra variaciones en la secuencia de los motivos en las diferentes secuencias? \u00bfCu\u00e1les? Extra! (y por ende opcional) La presentaci\u00f3n de resultados con figuras que faciliten la compresi\u00f3n es una de las partes m\u00e1s importantes de un informe. Una forma muy linda de visualizar las posiciones de los motivos reportados es marcarlas en un gr\u00e1fico de desorden cambiando el color de los puntos. \u00bfSe animan? El punto 3 se puede hacer utlizando R. Para esto primero va a necesitar instalar la librer\u00eda bioseq (tarda) para poder leer el alineamiento con la funci\u00f3n read_fasta . Luego, se puede utilizar la funci\u00f3n gregexpr para buscar la expresi\u00f3n regular del motivo de inter\u00e9s y cuantificar su presencia en el alineamiento, prestando atenci\u00f3n a la posici\u00f3n que se lo espera encontrar, claro!. gregexpr Esta funci\u00f3n devuelve una lista. Las posiciones de la lista se acceden como lista[[i]] donde i es un n\u00famero. RegEx en alineamientos En un alineamiento de secuencias tenemos gaps que pueden interrumpir la secuencia. Deben modificar la RegEx de manera que esto no suceda. Ejemplo: R.L pasar\u00eda a ser R-*.-*L Materiales","title":"TP 10 - Motivos Lineales"},{"location":"practicos/TP10_Motivos/#tp-10-motivos-lineales","text":"","title":"data-toc-label"},{"location":"practicos/TP10_Motivos/#videos-de-la-clase-grabada","text":"Introducci\u00f3n al TP Puesta en com\u00fan del TP Atenci\u00f3n: Este TP tiene informe. Materiales","title":"Videos de la clase grabada"},{"location":"practicos/TP10_Motivos/#recursos-online","text":"Regex101 https://regex101.com UniProt http://www.uniprot.org/ ELM http://elm.eu.org","title":"Recursos Online"},{"location":"practicos/TP10_Motivos/#objetivos","text":"Familiarizarse con la simbolog\u00eda utilizada en expresiones regulares Utilizar la simbolog\u00eda para poder realizar b\u00fasquedas basadas en texto","title":"Objetivos"},{"location":"practicos/TP10_Motivos/#introduccion","text":"La simbolog\u00eda com\u00fanmente utilizada en expresiones regulares es: S\u00edmbolo Definici\u00f3n . Cualquier amino\u00e1cido es permitido [XY] Solo los amino\u00e1cidos X e Y son permitidos [^XY] Los amino\u00e1cidos X e Y est\u00e1n prohibidos {min,max} N\u00famero m\u00ednimo y m\u00e1ximo de veces que se puede repetir una posici\u00f3n ^X El amino\u00e1cido X se encuentra en el extremo N-terminal X$ El amino\u00e1cido X se encuentra en el extremo C-terminal (AB)|(CD) Se encuentran, o bien, los amino\u00e1cidos AB, o bien, los amino\u00e1cidos CD Estos s\u00edmbolos nos permiten definir patrones que son observados en prote\u00ednas naturales para luego identificarlos en otras prote\u00ednas y ser puestos a prueba experimentalmente.","title":"Introducci\u00f3n"},{"location":"practicos/TP10_Motivos/#ejercicios","text":"","title":"Ejercicios"},{"location":"practicos/TP10_Motivos/#ejercicio-1-familiarizandonos-con-las-expresiones-regulares","text":"Los receptores nucleares interact\u00faan con diversas prote\u00ednas mediantes un motivo lineal llamado NRBox ( Nuclear Receptor Box ) (Heery,1997). Existen numerosas estructuras de p\u00e9ptidos unidos a diferentes receptores nucleares (PDBs: 3CS8, 2GPO, 1GWQ, 1RJK, 1M2Z) que permitieron estudiar y entender algunas caracter\u00edsticas de la interacci\u00f3n. La evidencia experimental recolectada de la literatura indica que: El motivo NRBox forma una h\u00e9lice alfa Existen tres leucinas que se encuentran en una misma cara de la h\u00e9lice que interact\u00faan con un bolsillo hidrof\u00f3bico en la superficie del receptor nuclear (Figura 1). Figura 1. Fragmento de la prote\u00edna PGC-1 alfa unido al receptor nuclear PPAR-gamma. Se muestra en naranja el backbone de la prote\u00edna representado en Cartoon y en azul las tres leucinas que median la interacci\u00f3n representadas en Sticks (PDB:3CS8) y que conforman el motivo NRBox. Los siguientes fragmentos de secuencia corresponden a regiones de distintas prote\u00ednas que interact\u00faan con diversos receptores nucleares y cuya interacci\u00f3n se verific\u00f3 de manera experimental por distintos m\u00e9todos. >sp|Q15648|MED1_HUMAN|644-650 SMAGNTKNHPMLMNLLKDNPAQDFSTL >sp|O43593|HAIR_HUMAN|565-571 AKHLLSGLGDRLCRLLRREREALAWAQ >sp|Q16881-4|TRXR1_HUMAN|46-52 GPTLKAYQEGRLQKLLKMNGPEDLPKS >sp|P48552|NRIP1_HUMAN|500-506 DVHQDSIVLTYLEGLLMHQAAGGSGTA >sp|Q9UQ80|PA2G4_HUMAN|353-359 YKSEMEVQDAELKALLQSSASRKTQKK >sp|Q90ZL7|Q90ZL7_DANRE|69-75 VQHADGEKSNVLRKLLKRANSYEDAVM >sp|Q9UBK2|PRGC1_HUMAN|143-149 PPPQEAEEPSLLKKLLLAPANTQLSYN >sp|Q9JL19|NCOA6_MOUSE|1494-1500 MSPAMREAPTSLSQLLDNSGAPNVTIK >sp|Q15596|NCOA2_HUMAN|689-695 HGTSLKEKHKILHRLLQDSSSPVDLAK >sp|Q92793|CBP_HUMAN|69-75 LVPDAASKHKQLSELLRGGSGSSINPG 1. Copie y pegue las secuencias en el recuadro de Test String en regex101 https://regex101.com y pruebe encontrar una expresi\u00f3n regular que permita identificar el motivo que media la interacci\u00f3n de estas prote\u00ednas con los receptores nucleares y que cumpla con la evidencia experimental observada. Regex101 No es una herramienta que se use en bioinform\u00e1tica. Simplemente es un recurso educativo para entender Expresiones Regulares . En R hay funciones como grep o gregexpr que permiten identificar expresiones regulares y en python hay todo una librer\u00eda re dedicada a expresiones regulares. 2. Considerando que el motivo se encuentra en una h\u00e9lice, \u00bfmodificar\u00eda la expresi\u00f3n regular que obtuvo?","title":"Ejercicio 1. Familiariz\u00e1ndonos con las Expresiones Regulares"},{"location":"practicos/TP10_Motivos/#ejercicio-2-base-de-datos-de-motivos-lineales-en-eucariotas-elmdb","text":"La base de datos ELM ( Eukaryotic Linear Motifs ) es una base de datos que se enfoca principalmente en la anotaci\u00f3n y detecci\u00f3n de motivos lineales (MLs). Para ello cuenta con un repositorio de motivos manualmente anotados, por lo cual est\u00e1 altamente curada y tambi\u00e9n cuenta con una herramienta de predicci\u00f3n de motivos. Esta predicci\u00f3n de motivos se realiza mediante una b\u00fasqueda de patrones de secuencia basada en texto utilizando expresiones regulares. Las instancias anotadas (es decir, probadas experimentalmente) pueden ser: True Positives: Una instancia anotada con evidencia experimental que demuestra que es funcional. False Positives: Una instancia anotada con evidencia experimental que sugiere que es funcional. Pero luego de una inspecci\u00f3n cuidadosa de los anotadores se cree que la instancia en realidad no es funcional. True Negative: Una instancia anotada donde los experimentos muestren que es no funcional. Unknown: No se encontr\u00f3 evidencia suficiente para determinar si la instancia es funcional o no. 1. Busque en ELMdb en la pesta\u00f1a Prediction la prote\u00edna PGC-1-alpha, una de las prote\u00ednas de la lista que usamos en el Ejercicio 1 , utilizando el accession number o uniprot ID (Q9UBK2 - PRGC1_HUMAN). Para cada motivo encontrado, se indica con s\u00edmbolos (descriptos en la parte superior de la p\u00e1gina) si la instancia del motivo es predicha o fue identificada experimentalmente (anotadas o \"True Positives\"). Responda: \u00bfEncuentra el motivo NRBox entre los True positives ? \u00bfCu\u00e1ntas instancias True Positive existen para esta prote\u00edna? \u00bfC\u00f3mo es la estructura de la prote\u00edna donde se encuentran estos motivos? 2. Pegue y copie la siguiente secuencia en ELM y utilice los par\u00e1metros que se indican a continuaci\u00f3n. >seq MEEPQSDPSVEPPLSQETFSDLWKLLPENNVLSPLPSQAMDDLMLSPDDI EQWFTEDPGPDEAPRMPEAAPPVAPAPAAPTPAAPAPAPSWPLSSSVPSQ KTYQGSYGFRLGFLHSGTAKSVTCTYSPALNKMFCQLAKTCPVQLWVDST PPPGTRVRAMAIYKQSQHMTEVVRRCPHHERCSDSDGLAPPQHLIRVEGN LRVEYLDDRNTFRHSVVVPYEPPEVGSDCTTIHYNYMCNSSCMGGMNRRP ILTIITLEDSSGNLLGRNSFEVRVCACPGRDRRTEEENLRKKGEPHHELP PGSTKRALPNNTSSSPQPKKKPLDGEYFTLQIRGRERFEMFRELNEALEL KDAQAGKEPGGSRAHSSHLKSKKGQSTSRHKKLMFKTEGPDSD Aseg\u00farese que los valores de los distintos par\u00e1metros son los siguientes: Cell Compartment: Not specified Motif Probability Cutoff: 100 Taxonomic context: (leave blank) \u00bfCu\u00e1ntas instancias predichas de motivos se encuentran? Para verlo investigue la tabla llamada Filtering Summary . \u00bfCu\u00e1ntas son retenidas luego del filtro? \u00bfQu\u00e9 se puede decir sobre la estructura de la prote\u00edna? \u00bfSe observa alg\u00fan dominio? \u00bfSe observan regiones desordenadas? \u00bfLos predictores estructurales y filtros (SMART, GlobPlot, IUPRED, Secondary Structure) coinciden sobre qu\u00e9 regiones son estructuradas/desordenadas? 3. Por si no se di\u00f3 cuenta, la prote\u00edna utilizada en el ejercicio anterior es p53 de humanos. ELM nos permite fitrar por compartimento celular \u00bfPorqu\u00e9 consideran que esto ser\u00eda \u00fatil? Utilizando el uniprot ID de p53 (P53_HUMAN) busque en la web de Uniprot ( https://www.uniprot.org/ ) las posibles localizaciones subcelulares de esta prote\u00edna y util\u00edcelas como filtro en ELM. Para esto: Abra en una nueva pesta\u00f1a la p\u00e1gina de ELM. Vaya de nuevo a la pesta\u00f1a de predicci\u00f3n. Limpie el formulario con el bot\u00f3n Reset Form . Ingrese el Uniprot ID de la prote\u00edna (P53_human) y asigne en Cell compartment los compartimentos correspondientes utilizando Ctrl para seleccionar m\u00e1s de uno. Realice la predicci\u00f3n y conteste: \u00bfCu\u00e1ntas instancias de motivos se encuentran ahora? \u00bfCu\u00e1ntas instancias de motivos son retenidas luego del filtro? \u00bfA qu\u00e9 se debe esta diferencia con el punto anterior? Investigue el motivo CLV_PCSK_FUR_1 en la predicci\u00f3n realizada s\u00f3lo con la secuencia. \u00bfPor qu\u00e9 cree que fue filtrado? \u00bfCu\u00e1ntas instancias anotadas como true positive posee esta prote\u00edna? Compare la ubicaci\u00f3n de las instancias anotadas con la informaci\u00f3n estructural proveniente de IUPred. \u00bfCu\u00e1ntas instancias de la clase MOD_CK1_1 se encontraron? \u00bfCu\u00e1l es la diferencia entre estas instancias? \u00bfCu\u00e1ntos degrons anotados hay en p53? \u00bfCu\u00e1l es la funci\u00f3n de estos motivos? \u00bfExiste alg\u00fan sitio anotado CDK ( Cyclin Dependent Kinase ) en p53? \u00bfExiste alg\u00fan sitio anotado DOC_CYCLIN_RXL_1 ? \u00bfQu\u00e9 relaci\u00f3n funcional existe entre este sitio y el sitio CDK? 4. Abra una nueva pesta\u00f1a y vaya de nuevo a la pesta\u00f1a de predicci\u00f3n. Manteniendo los compartimentos celulares seleccionados para p53, ingrese el Uniprot ID (P53_HUMAN) y modifique el par\u00e1metro: Motif Probability Cutoff: 0.01 (Recuerde que en el punto anterior este par\u00e1metro era de 100) \u00bfCu\u00e1ntas instancias predichas de motivos se encuentran ahora? \u00bfCu\u00e1ntas instancias de motivos son retenidas luego del filtro? \u00bfPor qu\u00e9 cree que es \u00fatil usar el umbral de probabilidad del motivo? 5. Abra una nueva pesta\u00f1a y vaya de nuevo a la pesta\u00f1a de predicci\u00f3n. Manteniendo los compartimentos celulares seleccionados para p53, ingrese el Uniprot ID (P53_HUMAN) y modifique el par\u00e1metro: Taxonomic Context: Homo sapiens \u00bfCu\u00e1ntas instancias predichas de motivos se encuentran ahora? \u00bfCu\u00e1ntas instancias de motivos son retenidas luego del filtro? \u00bfPor qu\u00e9 cree que es \u00fatil usar el contexto taxon\u00f3mico? 5. Busque la prote\u00edna P53_MOUSE en ELM. \u00bfExisten instancias anotadas? \u00bfExisten instancias asignadas por homolog\u00eda? \u00bfA qu\u00e9 organismo pertenecen?","title":"Ejercicio 2. Base de datos de motivos lineales en Eucariotas (ELMdb)"},{"location":"practicos/TP10_Motivos/#ejercicio-3-identificacion-de-motivos-cortos-de-interaccion-en-p53-en-un-alineamiento-propio","text":"La regi\u00f3n amino terminal de p53 posee un motivo de uni\u00f3n a la E3 ligasa MDM2, el cual est\u00e1 caracterizado por una secuencia conservada que puede representarse por una expresi\u00f3n regular. Entre en la base de datos ELM y busque la expresi\u00f3n regular del motivo con el ID: DEG_MDM2_SWIB_1 . Para esto ingrese el ID en la parte superior derecha donde dice: Search ELM database. La expresi\u00f3n regular se encuentra marcada como \"Pattern\" . A continuaci\u00f3n, busque las ocurrencias de esta expresi\u00f3n regular en las secuencias de p53. Para ello, abra en Jalview el alineamiento de p53 con el cu\u00e1l estuvo trabajando en la clase de TP N\u00b09 - Predicci\u00f3n de desorden . Jalview permite la b\u00fasqueda de motivos por expresiones regulares. Para hacerlo, utilice la funci\u00f3n: Select \u2192 Find En la ventana tipee la expresi\u00f3n regular. Si este procedimiento falla, y tiene la ventana de las secuencias no alineadas abiertas, ci\u00e9rrela. Si a\u00fan as\u00ed falla, identifique el motivo utilizando el filtro de conservaci\u00f3n. \u00bfTodas las secuencias de p53 tienen el motivo de interacci\u00f3n con MDM2? \u00bfTodos los motivos MDM2 tienen la misma longitud de secuencia? \u00bfQu\u00e9 nivel de identidad de secuencia observa en esta regi\u00f3n? \u00bfA qu\u00e9 puede deberse?","title":"Ejercicio 3. Identificaci\u00f3n de motivos cortos de interacci\u00f3n en p53 en un alineamiento propio."},{"location":"practicos/TP10_Motivos/#ejercicio-a-informar","text":"Fecha l\u00edmite de entrega: Viernes, 14 de Octubre 2022, 23:59hs.","title":"Ejercicio a informar"},{"location":"practicos/TP10_Motivos/#enunciado","text":"Su jefe tambi\u00e9n est\u00e1 interesado en que Ud. entienda m\u00e1s sobre los mecanismos de entrada del virus a la c\u00e9lula, la cual est\u00e1 mediada por la enzima convertidora de angiotensina 2 (ACE2) (Uniprot ID: ACE2_HUMAN2, Q9BYF1). Luego de unirse la prote\u00edna Spike a ACE2, se desencadena la entrada del virus SARS-CoV-2 a las c\u00e9lulas pulmonares por un mecanismo llamado endocitosis mediada por receptor, en el cual participan muchos motivos lineales. 1. Seg\u00fan los m\u00e9todos utilizados en el trabajo pr\u00e1ctico de desorden identifique las regiones desordenadas del receptor, e investigue \u00bfEn qu\u00e9 compartimento celular se encuentran esta/s regi\u00f3n/es? 2. Algunos de los motivos conocidos involucrados en la v\u00eda de endocitosis mediada por receptor son: TRG_ENDOCYTIC_2 , LIG_LIR_Gen_1 , LIG_PTB_APO2 . \u00bfEn qu\u00e9 compartimentos celulares deber\u00edan encontrarse prote\u00ednas como ACE2? Estos motivos \u00bfse encuentran en la secuencia humana del receptor? \u00bfCu\u00e1ntas instancias de cada uno de los motivos encuentra, en qu\u00e9 posiciones y cu\u00e1les creen que son buenos candidatos? De los tres motivos \u00bfExisten algunos candidatos que son mejores que otros? Si es as\u00ed, responda \u00bfPor qu\u00e9 son mejores? Atenci\u00f3n Siempre que reporte una regi\u00f3n o instancia de un motivo indique las posiciones de inicio y final de la misma. Para cada respuesta, indicar los algoritmos, base de datos y m\u00e9todos utilizados, y el criterio usado en cada caso para clasificar/identificar. 3. Un criterio para clasificar un buen motivo candidato es que est\u00e9 conservado en >50% de un conjunto de secuencias divergentes. Utilizando las expresiones regulares y el conjunto de secuencias de ACE2 (que se encuentran en el archivo ACE2_secuencias.fasta ), indique cu\u00e1les de las instancias de los motivos seleccionados en (2) son buenos candidatos seg\u00fan su conservaci\u00f3n. Si bien es un alineamiento de prote\u00ednas hom\u00f3logas \u00bfEncuentra variaciones en la secuencia de los motivos en las diferentes secuencias? \u00bfCu\u00e1les? Extra! (y por ende opcional) La presentaci\u00f3n de resultados con figuras que faciliten la compresi\u00f3n es una de las partes m\u00e1s importantes de un informe. Una forma muy linda de visualizar las posiciones de los motivos reportados es marcarlas en un gr\u00e1fico de desorden cambiando el color de los puntos. \u00bfSe animan? El punto 3 se puede hacer utlizando R. Para esto primero va a necesitar instalar la librer\u00eda bioseq (tarda) para poder leer el alineamiento con la funci\u00f3n read_fasta . Luego, se puede utilizar la funci\u00f3n gregexpr para buscar la expresi\u00f3n regular del motivo de inter\u00e9s y cuantificar su presencia en el alineamiento, prestando atenci\u00f3n a la posici\u00f3n que se lo espera encontrar, claro!. gregexpr Esta funci\u00f3n devuelve una lista. Las posiciones de la lista se acceden como lista[[i]] donde i es un n\u00famero. RegEx en alineamientos En un alineamiento de secuencias tenemos gaps que pueden interrumpir la secuencia. Deben modificar la RegEx de manera que esto no suceda. Ejemplo: R.L pasar\u00eda a ser R-*.-*L Materiales","title":"Enunciado"},{"location":"practicos/TP11_Modelado_Por_Homologia/","text":"TP 11 . Modelado por Homolog\u00eda Videos de la clase grabada Introducci\u00f3n al TP Resultados Verify y Procheck Puesta en com\u00fan del TP Atenci\u00f3n: Este TP tiene informe. Materiales Ejercicio 1. Modelado mistery protein. Luego de dos a\u00f1os y numerosos intentos fallidos, usted logra determinar por resonancia magn\u00e9tica nuclear una regi\u00f3n de una prote\u00edna misteriosa y deposita la estructura en la base de datos de prote\u00ednas PDB (PDB: 1F46). A\u00f1os despu\u00e9s ocurre una pandemia de una enfermedad respiratoria causada por Actinobacillus pleuropneumoniae que est\u00e1 causando un r\u00e1pido aumento en la mortalidad de la poblaci\u00f3n porcina, trayendo terribles consecuencias en la actividad econ\u00f3mica mundial. Una vez que se logr\u00f3 aislar la cepa responsable, se cree que una prote\u00edna que comparte casi el 25 % de identidad con su prote\u00edna misteriosa es un posible blanco para el dise\u00f1o de una droga. Sin embargo, se desconoce la estructura de la misma. Como usted es el \u00fanico experto en esa prote\u00edna en el mundo, la Asociaci\u00f3n del Centro M\u00e9dico Epidemiol\u00f3gico (ACME) se pone en contacto con usted en busca de una soluci\u00f3n. Para solucionar el problema, Ud. decide primero intentar un modelado por homolog\u00eda de la nueva prote\u00edna. 1. Ingrese la secuencia de la prote\u00edna misteriosa patog\u00e9nica en HHPred >Pathogenic Mistery Protein MELHILFFILAGLLIAVLISFSLWSARREKSRIFSNTFSTRPPSTPINNIVSDVPPSLNPQSYAQT TGQHGETEADNPVQIQQEVESSLREIKINLPGQDSAAYQSKVEETPIYSGQPVLPVQPQYQTQVQY QTQPQHIEPAFTQAPQSPIAEATSVLEQSVEELERQAAQGDVDIYSDASVRVELAKNSMQADSVAE QKPVAENNMLTLYVVAPEGQQFRGDYVVQSLEALGFQYGEYQIFHRHQHMGNSASPVIFSVANMMQ PGIFDLTKIEHFSTVGLVLFMHLPSEGNDVVNFKLLLKTTENLAQALGGFVLNEHREIFDENSRQS YLARVS 2. Haga click en Submit en la parte inferior de la p\u00e1gina y seleccione el hit que le parezca m\u00e1s conveniente: \u00bfpor qu\u00e9 es el m\u00e1s conveniente? \u00bfCu\u00e1l es el PDB ID y a qu\u00e9 cadena corresponde? \u00bfQue e-value tiene? \u00bfque porcentaje de identidad y qu\u00e9 porcentaje de similitud posee con su prote\u00edna misteriosa (en la pate inferior est\u00e1 el alineamiento)? Luego seleccione en la parte superior Model using selection . \u00bfQu\u00e9 se muestra en la nueva ventana? (Mueva la barra inferior para ver que hay en la ventana). 3. Haga click en Forward to Modeller y luego en Submit . (De ser necesario ingrese la siguiente key: MODELIRANJE en el recuadro que dice Modeller key y luego haga click en Submit). \u00bfQu\u00e9 aparece en la nueva ventana? 4. Descargue el archivo PDB ( Download PDB File ) 5. La herramienta Verify3D permite determinar la compatibilidad de un modelo 3D de una prote\u00edna con su secuencia aminoac\u00eddica en base a cu\u00e1l es el ambiente en el cual se encuentra cada residuo y la compatibilidad con la estructura secundaria en la que se encuentra. Vaya a la web de UCLA-DOE LAB , suba el archivo PDB obtenido en el paso anterior y clickee en Run programs . Seleccione Verify3D y espere por los resultados. El gr\u00e1fico reporta la calidad del modelo por posici\u00f3n y en \u00e9l se observan tres regiones: 1. Posiciones con score menor a cero est\u00e1n mal modeladas, 2. Posiciones con score entre cero y 0.2 est\u00e1n pobremente modeladas, 3. Posiciones con score mayor a 0.2 est\u00e1n modeladas con buena calidad . Verify 3D asigna como aceptado a un modelo con m\u00e1s del 80% de las posiciones posiciones con un score promedio en el \u00e1rea bien modelada . Observe el resultado obtenido (Si tarda haga click en el bot\u00f3n Check status ) y responda: \u00bfCu\u00e1l es el porcentaje de residuos con un score promedio en el \u00e1rea de bien modelados ? \u00bfQu\u00e9 regi\u00f3n est\u00e1 pobremente modelada seg\u00fan Verify 3D ? 6. La herramienta Procheck permite analizar la calidad de la geometr\u00eda de los residuos en una estructura proteica dada en comparaci\u00f3n a par\u00e1metros estereoqu\u00edmicos derivados de estructuras tridimensionales de alta resoluci\u00f3n ya conocidas. En la parte superior de la p\u00e1gina de los resultados de Verify 3D vaya a Control Panel Seleccione Procheck y espere por los resultados. a. Investigue el Ramachandran Plot . Reconozca las regiones a los distintos elementos de estructura secundaria y responda: \u00bfCu\u00e1ntas estructuras se utilizaron para construir este Ramachandran? \u00bfQu\u00e9 residuos no est\u00e1n en el \u00e1rea esperada? \u00bfQu\u00e9 criterio se utiliza para considerar que el modelo es de buena calidad? \u00bfQu\u00e9 porcentaje de residuos en la estructura modelada se encuentran en las regiones m\u00e1s favorecidas? \u00bfQu\u00e9 residuo est\u00e1 representado como tri\u00e1ngulos? \u00bfA qu\u00e9 cre\u00e9s que se debe? b. Mirando el PDF en \"All Ramachandrans\", investigue los gr\u00e1ficos de ramachandran para todos los residuos. \u00bfCu\u00e1ntas estructuras se utilizaron para construir este Ramachandran? \u00bfQu\u00e9 residuos no est\u00e1n en el \u00e1rea esperada? Observe el ramachandran te\u00f3rico de la Glicina \u00bfQu\u00e9 diferencias observa respecto al resto? \u00bfy el de la prolina? c. Investigue los gr\u00e1ficos de las longitudes de enlace en la cadena principal (M/c bond lengths) y los \u00e1ngulos de uni\u00f3n de la cadena principal (M/c bond angles). \u00bfExisten amino\u00e1cidos que se alejen significativamente de los resultados esperados? 7. En base a los resultados obtenidos por Verify 3D y ProCheck responda: \u00bfEs bueno el modelo? \u00bfPor qu\u00e9? 8. Abra chimera y busque el modelo que determin\u00f3 usted a\u00f1os atr\u00e1s: File \u2192 Fetch by ID \u2192 1F46 Si no funciona, el pdb se encuentra en su carpeta de datos y puede utilizar: File \u2192 Open 9. Luego, cargue en la misma ventana de Chimera la estructura de la prote\u00edna misteriosa patog\u00e9nica File \u2192 Open 10. Para tener una noci\u00f3n de cu\u00e1n similar es la estructura de dos prote\u00ednas, podemos realizar un Alineamiento Estructural , que consiste en superponer las estructuras de ambas prote\u00ednas en el espacio intentando alinear sus cadenas aminoac\u00eddicas. Alinear estructuras en chimera es muy f\u00e1cil, s\u00f3lo requiere un comando. Vaya a Tools \u2192 Structure Comparison \u2192 MatchMaker Se abrir\u00e1 una nueva ventana. En Structure(s) to match (el panel de la derecha) seleccione la estructura que ser\u00e1 superpuesta y alineada con la que se eligi\u00f3 como referencia, es decir el modelo. En Chain Pairing elija: Specific chain in reference structure with best aligning chain in match structure En Reference structure (el panel de la izquierda) seleccione la cadena correcta de la estructura utilizada como molde. En Matching asegur\u00e9se que Iterate by pruning long atom pairs untilo no pair exceeds est\u00e1 clickeado. Piense, \u00bfPorqu\u00e9 est\u00e1 utilizando el PDB:1F46? Observe el resultado del alineamiento: \u00bfSon parecidas las estructuras? \u00bfEn donde se observan las mayores diferencias? Vaya a Favorites \u2192 Reply Log \u00bfCu\u00e1l es el RMSD global reportado? \u00bfy con pruned atoms ? 11. Para ver c\u00f3mo se corresponde el grado de similitud estructural con el grado de similitud en secuencia podemos realizar un alineamiento de ambas secuencias guiado por el alineamiento estructural. Para esto, vaya a: Tools \u2192 Structure comparison \u2192 \u201cMatch->Align\u201d Ahora, observando la estructura y el alineamiento responda: I. \u00bfQu\u00e9 son las regiones marcadas en rosa en el alineamiento? II. \u00bfEste alineamiento, identifica regiones que no alinean estructuralmente? \u00bfA qu\u00e9 se debe? III. En la parte superior de la ventana del alineamiento de secuencia vaya a Headers y seleccione RMSD: ca \u00bfQu\u00e9 regiones poseen mayor RMSD? \u00bfA qu\u00e9 elementos estructurales corresponden? Para responder esto, seleccione estas regiones con el mouse en el alineamiento y visual\u00edcelas en la estructura alineada. 12. Para cuantificar el alineamiento de secuencia obtenido, podemos calcular el % de identidad de secuencia. Para ello, en la ventana del alineamiento de secuencias vaya a: Info \u2192 Percent identity . Seleccione una estructura en Compare y la otra estructura en with . En Divide by seleccione longer sequence length . Presiona en Ok. \u00bfQu\u00e9 valor de identidad de secuencia obtiene? \u00bfPorque cree que difiere del reportado anteriormente? En la parte superior de la ventana del alineamiento de secuencia vaya a Headers y seleccione Conservation \u00bfLas sustituciones observadas en las secuencias son conservativas? En base a los resultados obtenidos. \u00bfIntentar\u00eda obtener experimentalmente la estructura de la nueva prote\u00edna, o confiar\u00eda en el modelo? Ejercicio 2. Modelado por homolog\u00eda de una prote\u00edna de Rana. Usted es un famoso ec\u00f3logo que desde siempre sinti\u00f3 un especial inter\u00e9s por las ranas. Durante un viaje de campa\u00f1a se encontr\u00f3 con unas ranas muy inusuales que pose\u00edan una fascinante coloraci\u00f3n azul. Luego de a\u00f1os de investigaci\u00f3n y muchos subsidios invertidos, su becario descubri\u00f3 que esta coloraci\u00f3n se debe a la existencia de una prote\u00edna en la linfa de las ranas que es capaz de conjugar biliverdina. Luego de aislar la prote\u00edna, obtiene su secuencia: >Hypsiboas_punctatus_BP MRVLLILGVVVLSTLAFAHHEEGHHDDEDLKDDHDPFLPEDHKKALFVYQKPALNNINFA FKMYRQLARDHPTENIVISPVSISSALALLSLGAKGHTHSQIVERLGYNTSEIPEQQIHE SFHKQLDVVDDKDRDLEFEHGNALFTCKEHKIHQTFLDDAKKFYHSEVIPTDFKNTEEAK NQINSYVEKSTHGKITNILDSVDQDAMIALINFIYLRANWQHPFDEKLTKEGDFHVDKDT TVKVPFMRRRGIYKMAYTDDIIMVTIPYNGSVEMFLAMTKMGKLSELEQNLNRERSLKWR EIMQYQLIDLSLPKLSVSGILNLKETLSKLGIVDVFSNHADLSGITDESHLKVSKAIHKA MMSFDEHGTEAAPATAAEADPLMLPPHFKFDYPFIFRVQDLKTKNPLLVGRIANPQK Utilizando la secuencia, el becario busca en las bases de datos y descubre que su prote\u00edna es hom\u00f3loga a una superfamilia de prote\u00ednas conocidas como serpinas compartiendo un 43% de identidad de secuencia con la prote\u00edna de humanos. Para entender las diferencias con la prote\u00edna de humanos, estuvo muy interesado en obtener la estructura tridimensional de la prote\u00edna de rana. Sin embargo, todos los intentos de cristalizaci\u00f3n fallaron rotundamente. Su subsidio se est\u00e1 terminando r\u00e1pidamente pero afortunadamente, un becario muy interesado en bioinform\u00e1tica y el modelado por homolog\u00eda lo salva de su desesperaci\u00f3n. Utilizando la herramienta HHPred el becario encontr\u00f3 que el mejor template era: 3NE4, Chain A, correspondiente al inhibidor de tripsina humano (Alpha-1-antitrypsin, P01009). Utilizando herramientas de modelado desarrolla un modelo 3D y le asegura que el modelo es de muy buena calidad. Desconfiando de los resultados de su becario, Ud. decide analizar la calidad del modelo obtenido. Para esto utiliza todas las herramientas que conoce: 1. Utilice el modelo creado por su becario ( Hypsiboas_punctatus_BP.pdb ) que se encuentra en los materiales. Utilice las herramientas aprendidas en el punto anterior ( Verify3D ) e investigue los resultados obtenidos. \u00bfLe parece que su becario estaba en lo cierto, o equivocado? 2. Para explicar las diferencias obtenidas analice las estructuras como se indica en los puntos siguientes (a, b y c) usando Chimera y IUPred : a. Utilizando el modelo generado y el PDB (3NE4) utilizado como molde realice un alineamiento estructural en Chimera ( Tools \u2192 Structure Comparison \u2192 MatchMaker ). \u00bfCu\u00e1l es el RMSD global? \u00bfQu\u00e9 diferencias observa en las estructuras alineadas? \u00bfTiene relaci\u00f3n con lo obtenido por Verify3D ? b. En Chimera observe el alineamiento de secuencia ( Tools \u2192 Structure Comparison Match -> Align ). Cuando se quiere obtener una estructura de una prote\u00edna a veces ocurre que hay regiones o residuos que no se pueden \"resolver\" y no se les puede asignar una estructura. Estos residuos se conocen como Missing residues y en el alineamiento de secuencia en chimera est\u00e1n resaltados de una manera especial. \u00bfPuede identificar como est\u00e1n destacados? \u00bfA qu\u00e9 regi\u00f3n corresponde en la prote\u00edna modelada? \u00bfEn qu\u00e9 regiones hay mayor n\u00famero de Gaps? Observe el RMSD por posici\u00f3n utilizando el RMSD:ca. \u00bfEn qu\u00e9 regiones se observan las mayores diferencias? \u00bfA qu\u00e9 estructura corresponde? \u00bfPor qu\u00e9 cree que ocurre esto? c . Ingrese la secuencia de la rana en IUPRed2A . \u00bfQu\u00e9 relaci\u00f3n encuentra con lo obtenido por Verify3D? 3. En base a los resultados de su an\u00e1lisis, responda: \u00bfPudo explicar todas las regiones de menor calidad reportadas por Verify3D ? Ud. Se sac\u00f3 un nuevo subsidio donde tiene plata para seguir haciendo estudios estructurales de esta prote\u00edna: le dar\u00eda alguna indicaci\u00f3n a su nuevo becario, para que tenga m\u00e1s suerte al intentar cristalizarla? Ejercicio a informar Fecha L\u00edmite de Entrega: Viernes, 21 de Octubre 2022, 23:59hs Enunciado Su jefe sigue interesado en la prote\u00edna N que forma la nucleoc\u00e1pside viral de SARS-CoV2 y empaqueta el genoma viral de ARN formando una ribonucleoc\u00e1pside. Usted ya comprob\u00f3 que la estructura de la prote\u00edna N es altamente desordenada y posee dos dominios globulares peque\u00f1os en el N-terminal (Dominio N) y C terminal (Dominio C). Dada la importancia de la prote\u00edna en la replicaci\u00f3n viral, consideran que es un blanco posible de drogas. Por lo tanto, decide realizar un modelado por homolog\u00eda del dominio N-terminal de la prote\u00edna N del aislamiento original utilizando las herramientas que conoce. 1. Dise\u00f1e por homolog\u00eda el dominio N-terminal. Eval\u00fae si su modelo es bueno y recuerde incluir el molde que seleccion\u00f3 para crearlo justificando la elecci\u00f3n e indicando a qu\u00e9 virus pertenece. 2. Elija una estructura contra la cual comparar\u00e1 su modelo y justifique brevemente la elecci\u00f3n. Recuerde reportar el RMSD global y que regiones alinean mejor. 3. Seg\u00fan este an\u00e1lisis, si desear\u00eda cristalizar el dominio N \u00bfQu\u00e9 regiones no incluir\u00eda?","title":"TP 11 - Modelado por Homolog\u00eda"},{"location":"practicos/TP11_Modelado_Por_Homologia/#tp-11-modelado-por-homologia","text":"","title":"data-toc-label"},{"location":"practicos/TP11_Modelado_Por_Homologia/#videos-de-la-clase-grabada","text":"Introducci\u00f3n al TP Resultados Verify y Procheck Puesta en com\u00fan del TP Atenci\u00f3n: Este TP tiene informe. Materiales","title":"Videos de la clase grabada"},{"location":"practicos/TP11_Modelado_Por_Homologia/#ejercicio-1-modelado-mistery-protein","text":"Luego de dos a\u00f1os y numerosos intentos fallidos, usted logra determinar por resonancia magn\u00e9tica nuclear una regi\u00f3n de una prote\u00edna misteriosa y deposita la estructura en la base de datos de prote\u00ednas PDB (PDB: 1F46). A\u00f1os despu\u00e9s ocurre una pandemia de una enfermedad respiratoria causada por Actinobacillus pleuropneumoniae que est\u00e1 causando un r\u00e1pido aumento en la mortalidad de la poblaci\u00f3n porcina, trayendo terribles consecuencias en la actividad econ\u00f3mica mundial. Una vez que se logr\u00f3 aislar la cepa responsable, se cree que una prote\u00edna que comparte casi el 25 % de identidad con su prote\u00edna misteriosa es un posible blanco para el dise\u00f1o de una droga. Sin embargo, se desconoce la estructura de la misma. Como usted es el \u00fanico experto en esa prote\u00edna en el mundo, la Asociaci\u00f3n del Centro M\u00e9dico Epidemiol\u00f3gico (ACME) se pone en contacto con usted en busca de una soluci\u00f3n. Para solucionar el problema, Ud. decide primero intentar un modelado por homolog\u00eda de la nueva prote\u00edna. 1. Ingrese la secuencia de la prote\u00edna misteriosa patog\u00e9nica en HHPred >Pathogenic Mistery Protein MELHILFFILAGLLIAVLISFSLWSARREKSRIFSNTFSTRPPSTPINNIVSDVPPSLNPQSYAQT TGQHGETEADNPVQIQQEVESSLREIKINLPGQDSAAYQSKVEETPIYSGQPVLPVQPQYQTQVQY QTQPQHIEPAFTQAPQSPIAEATSVLEQSVEELERQAAQGDVDIYSDASVRVELAKNSMQADSVAE QKPVAENNMLTLYVVAPEGQQFRGDYVVQSLEALGFQYGEYQIFHRHQHMGNSASPVIFSVANMMQ PGIFDLTKIEHFSTVGLVLFMHLPSEGNDVVNFKLLLKTTENLAQALGGFVLNEHREIFDENSRQS YLARVS 2. Haga click en Submit en la parte inferior de la p\u00e1gina y seleccione el hit que le parezca m\u00e1s conveniente: \u00bfpor qu\u00e9 es el m\u00e1s conveniente? \u00bfCu\u00e1l es el PDB ID y a qu\u00e9 cadena corresponde? \u00bfQue e-value tiene? \u00bfque porcentaje de identidad y qu\u00e9 porcentaje de similitud posee con su prote\u00edna misteriosa (en la pate inferior est\u00e1 el alineamiento)? Luego seleccione en la parte superior Model using selection . \u00bfQu\u00e9 se muestra en la nueva ventana? (Mueva la barra inferior para ver que hay en la ventana). 3. Haga click en Forward to Modeller y luego en Submit . (De ser necesario ingrese la siguiente key: MODELIRANJE en el recuadro que dice Modeller key y luego haga click en Submit). \u00bfQu\u00e9 aparece en la nueva ventana? 4. Descargue el archivo PDB ( Download PDB File ) 5. La herramienta Verify3D permite determinar la compatibilidad de un modelo 3D de una prote\u00edna con su secuencia aminoac\u00eddica en base a cu\u00e1l es el ambiente en el cual se encuentra cada residuo y la compatibilidad con la estructura secundaria en la que se encuentra. Vaya a la web de UCLA-DOE LAB , suba el archivo PDB obtenido en el paso anterior y clickee en Run programs . Seleccione Verify3D y espere por los resultados. El gr\u00e1fico reporta la calidad del modelo por posici\u00f3n y en \u00e9l se observan tres regiones: 1. Posiciones con score menor a cero est\u00e1n mal modeladas, 2. Posiciones con score entre cero y 0.2 est\u00e1n pobremente modeladas, 3. Posiciones con score mayor a 0.2 est\u00e1n modeladas con buena calidad . Verify 3D asigna como aceptado a un modelo con m\u00e1s del 80% de las posiciones posiciones con un score promedio en el \u00e1rea bien modelada . Observe el resultado obtenido (Si tarda haga click en el bot\u00f3n Check status ) y responda: \u00bfCu\u00e1l es el porcentaje de residuos con un score promedio en el \u00e1rea de bien modelados ? \u00bfQu\u00e9 regi\u00f3n est\u00e1 pobremente modelada seg\u00fan Verify 3D ? 6. La herramienta Procheck permite analizar la calidad de la geometr\u00eda de los residuos en una estructura proteica dada en comparaci\u00f3n a par\u00e1metros estereoqu\u00edmicos derivados de estructuras tridimensionales de alta resoluci\u00f3n ya conocidas. En la parte superior de la p\u00e1gina de los resultados de Verify 3D vaya a Control Panel Seleccione Procheck y espere por los resultados. a. Investigue el Ramachandran Plot . Reconozca las regiones a los distintos elementos de estructura secundaria y responda: \u00bfCu\u00e1ntas estructuras se utilizaron para construir este Ramachandran? \u00bfQu\u00e9 residuos no est\u00e1n en el \u00e1rea esperada? \u00bfQu\u00e9 criterio se utiliza para considerar que el modelo es de buena calidad? \u00bfQu\u00e9 porcentaje de residuos en la estructura modelada se encuentran en las regiones m\u00e1s favorecidas? \u00bfQu\u00e9 residuo est\u00e1 representado como tri\u00e1ngulos? \u00bfA qu\u00e9 cre\u00e9s que se debe? b. Mirando el PDF en \"All Ramachandrans\", investigue los gr\u00e1ficos de ramachandran para todos los residuos. \u00bfCu\u00e1ntas estructuras se utilizaron para construir este Ramachandran? \u00bfQu\u00e9 residuos no est\u00e1n en el \u00e1rea esperada? Observe el ramachandran te\u00f3rico de la Glicina \u00bfQu\u00e9 diferencias observa respecto al resto? \u00bfy el de la prolina? c. Investigue los gr\u00e1ficos de las longitudes de enlace en la cadena principal (M/c bond lengths) y los \u00e1ngulos de uni\u00f3n de la cadena principal (M/c bond angles). \u00bfExisten amino\u00e1cidos que se alejen significativamente de los resultados esperados? 7. En base a los resultados obtenidos por Verify 3D y ProCheck responda: \u00bfEs bueno el modelo? \u00bfPor qu\u00e9? 8. Abra chimera y busque el modelo que determin\u00f3 usted a\u00f1os atr\u00e1s: File \u2192 Fetch by ID \u2192 1F46 Si no funciona, el pdb se encuentra en su carpeta de datos y puede utilizar: File \u2192 Open 9. Luego, cargue en la misma ventana de Chimera la estructura de la prote\u00edna misteriosa patog\u00e9nica File \u2192 Open 10. Para tener una noci\u00f3n de cu\u00e1n similar es la estructura de dos prote\u00ednas, podemos realizar un Alineamiento Estructural , que consiste en superponer las estructuras de ambas prote\u00ednas en el espacio intentando alinear sus cadenas aminoac\u00eddicas. Alinear estructuras en chimera es muy f\u00e1cil, s\u00f3lo requiere un comando. Vaya a Tools \u2192 Structure Comparison \u2192 MatchMaker Se abrir\u00e1 una nueva ventana. En Structure(s) to match (el panel de la derecha) seleccione la estructura que ser\u00e1 superpuesta y alineada con la que se eligi\u00f3 como referencia, es decir el modelo. En Chain Pairing elija: Specific chain in reference structure with best aligning chain in match structure En Reference structure (el panel de la izquierda) seleccione la cadena correcta de la estructura utilizada como molde. En Matching asegur\u00e9se que Iterate by pruning long atom pairs untilo no pair exceeds est\u00e1 clickeado. Piense, \u00bfPorqu\u00e9 est\u00e1 utilizando el PDB:1F46? Observe el resultado del alineamiento: \u00bfSon parecidas las estructuras? \u00bfEn donde se observan las mayores diferencias? Vaya a Favorites \u2192 Reply Log \u00bfCu\u00e1l es el RMSD global reportado? \u00bfy con pruned atoms ? 11. Para ver c\u00f3mo se corresponde el grado de similitud estructural con el grado de similitud en secuencia podemos realizar un alineamiento de ambas secuencias guiado por el alineamiento estructural. Para esto, vaya a: Tools \u2192 Structure comparison \u2192 \u201cMatch->Align\u201d Ahora, observando la estructura y el alineamiento responda: I. \u00bfQu\u00e9 son las regiones marcadas en rosa en el alineamiento? II. \u00bfEste alineamiento, identifica regiones que no alinean estructuralmente? \u00bfA qu\u00e9 se debe? III. En la parte superior de la ventana del alineamiento de secuencia vaya a Headers y seleccione RMSD: ca \u00bfQu\u00e9 regiones poseen mayor RMSD? \u00bfA qu\u00e9 elementos estructurales corresponden? Para responder esto, seleccione estas regiones con el mouse en el alineamiento y visual\u00edcelas en la estructura alineada. 12. Para cuantificar el alineamiento de secuencia obtenido, podemos calcular el % de identidad de secuencia. Para ello, en la ventana del alineamiento de secuencias vaya a: Info \u2192 Percent identity . Seleccione una estructura en Compare y la otra estructura en with . En Divide by seleccione longer sequence length . Presiona en Ok. \u00bfQu\u00e9 valor de identidad de secuencia obtiene? \u00bfPorque cree que difiere del reportado anteriormente? En la parte superior de la ventana del alineamiento de secuencia vaya a Headers y seleccione Conservation \u00bfLas sustituciones observadas en las secuencias son conservativas? En base a los resultados obtenidos. \u00bfIntentar\u00eda obtener experimentalmente la estructura de la nueva prote\u00edna, o confiar\u00eda en el modelo?","title":"Ejercicio 1. Modelado mistery protein."},{"location":"practicos/TP11_Modelado_Por_Homologia/#ejercicio-2-modelado-por-homologia-de-una-proteina-de-rana","text":"Usted es un famoso ec\u00f3logo que desde siempre sinti\u00f3 un especial inter\u00e9s por las ranas. Durante un viaje de campa\u00f1a se encontr\u00f3 con unas ranas muy inusuales que pose\u00edan una fascinante coloraci\u00f3n azul. Luego de a\u00f1os de investigaci\u00f3n y muchos subsidios invertidos, su becario descubri\u00f3 que esta coloraci\u00f3n se debe a la existencia de una prote\u00edna en la linfa de las ranas que es capaz de conjugar biliverdina. Luego de aislar la prote\u00edna, obtiene su secuencia: >Hypsiboas_punctatus_BP MRVLLILGVVVLSTLAFAHHEEGHHDDEDLKDDHDPFLPEDHKKALFVYQKPALNNINFA FKMYRQLARDHPTENIVISPVSISSALALLSLGAKGHTHSQIVERLGYNTSEIPEQQIHE SFHKQLDVVDDKDRDLEFEHGNALFTCKEHKIHQTFLDDAKKFYHSEVIPTDFKNTEEAK NQINSYVEKSTHGKITNILDSVDQDAMIALINFIYLRANWQHPFDEKLTKEGDFHVDKDT TVKVPFMRRRGIYKMAYTDDIIMVTIPYNGSVEMFLAMTKMGKLSELEQNLNRERSLKWR EIMQYQLIDLSLPKLSVSGILNLKETLSKLGIVDVFSNHADLSGITDESHLKVSKAIHKA MMSFDEHGTEAAPATAAEADPLMLPPHFKFDYPFIFRVQDLKTKNPLLVGRIANPQK Utilizando la secuencia, el becario busca en las bases de datos y descubre que su prote\u00edna es hom\u00f3loga a una superfamilia de prote\u00ednas conocidas como serpinas compartiendo un 43% de identidad de secuencia con la prote\u00edna de humanos. Para entender las diferencias con la prote\u00edna de humanos, estuvo muy interesado en obtener la estructura tridimensional de la prote\u00edna de rana. Sin embargo, todos los intentos de cristalizaci\u00f3n fallaron rotundamente. Su subsidio se est\u00e1 terminando r\u00e1pidamente pero afortunadamente, un becario muy interesado en bioinform\u00e1tica y el modelado por homolog\u00eda lo salva de su desesperaci\u00f3n. Utilizando la herramienta HHPred el becario encontr\u00f3 que el mejor template era: 3NE4, Chain A, correspondiente al inhibidor de tripsina humano (Alpha-1-antitrypsin, P01009). Utilizando herramientas de modelado desarrolla un modelo 3D y le asegura que el modelo es de muy buena calidad. Desconfiando de los resultados de su becario, Ud. decide analizar la calidad del modelo obtenido. Para esto utiliza todas las herramientas que conoce: 1. Utilice el modelo creado por su becario ( Hypsiboas_punctatus_BP.pdb ) que se encuentra en los materiales. Utilice las herramientas aprendidas en el punto anterior ( Verify3D ) e investigue los resultados obtenidos. \u00bfLe parece que su becario estaba en lo cierto, o equivocado? 2. Para explicar las diferencias obtenidas analice las estructuras como se indica en los puntos siguientes (a, b y c) usando Chimera y IUPred : a. Utilizando el modelo generado y el PDB (3NE4) utilizado como molde realice un alineamiento estructural en Chimera ( Tools \u2192 Structure Comparison \u2192 MatchMaker ). \u00bfCu\u00e1l es el RMSD global? \u00bfQu\u00e9 diferencias observa en las estructuras alineadas? \u00bfTiene relaci\u00f3n con lo obtenido por Verify3D ? b. En Chimera observe el alineamiento de secuencia ( Tools \u2192 Structure Comparison Match -> Align ). Cuando se quiere obtener una estructura de una prote\u00edna a veces ocurre que hay regiones o residuos que no se pueden \"resolver\" y no se les puede asignar una estructura. Estos residuos se conocen como Missing residues y en el alineamiento de secuencia en chimera est\u00e1n resaltados de una manera especial. \u00bfPuede identificar como est\u00e1n destacados? \u00bfA qu\u00e9 regi\u00f3n corresponde en la prote\u00edna modelada? \u00bfEn qu\u00e9 regiones hay mayor n\u00famero de Gaps? Observe el RMSD por posici\u00f3n utilizando el RMSD:ca. \u00bfEn qu\u00e9 regiones se observan las mayores diferencias? \u00bfA qu\u00e9 estructura corresponde? \u00bfPor qu\u00e9 cree que ocurre esto? c . Ingrese la secuencia de la rana en IUPRed2A . \u00bfQu\u00e9 relaci\u00f3n encuentra con lo obtenido por Verify3D? 3. En base a los resultados de su an\u00e1lisis, responda: \u00bfPudo explicar todas las regiones de menor calidad reportadas por Verify3D ? Ud. Se sac\u00f3 un nuevo subsidio donde tiene plata para seguir haciendo estudios estructurales de esta prote\u00edna: le dar\u00eda alguna indicaci\u00f3n a su nuevo becario, para que tenga m\u00e1s suerte al intentar cristalizarla?","title":"Ejercicio 2. Modelado por homolog\u00eda de una prote\u00edna de Rana."},{"location":"practicos/TP11_Modelado_Por_Homologia/#ejercicio-a-informar","text":"Fecha L\u00edmite de Entrega: Viernes, 21 de Octubre 2022, 23:59hs","title":"Ejercicio a informar"},{"location":"practicos/TP11_Modelado_Por_Homologia/#enunciado","text":"Su jefe sigue interesado en la prote\u00edna N que forma la nucleoc\u00e1pside viral de SARS-CoV2 y empaqueta el genoma viral de ARN formando una ribonucleoc\u00e1pside. Usted ya comprob\u00f3 que la estructura de la prote\u00edna N es altamente desordenada y posee dos dominios globulares peque\u00f1os en el N-terminal (Dominio N) y C terminal (Dominio C). Dada la importancia de la prote\u00edna en la replicaci\u00f3n viral, consideran que es un blanco posible de drogas. Por lo tanto, decide realizar un modelado por homolog\u00eda del dominio N-terminal de la prote\u00edna N del aislamiento original utilizando las herramientas que conoce. 1. Dise\u00f1e por homolog\u00eda el dominio N-terminal. Eval\u00fae si su modelo es bueno y recuerde incluir el molde que seleccion\u00f3 para crearlo justificando la elecci\u00f3n e indicando a qu\u00e9 virus pertenece. 2. Elija una estructura contra la cual comparar\u00e1 su modelo y justifique brevemente la elecci\u00f3n. Recuerde reportar el RMSD global y que regiones alinean mejor. 3. Seg\u00fan este an\u00e1lisis, si desear\u00eda cristalizar el dominio N \u00bfQu\u00e9 regiones no incluir\u00eda?","title":"Enunciado"},{"location":"practicos/TP12a_Clustering/","text":"TP 12a . Data Mining - Clustering Materiales Software a usar R (ya instalado en la VM). RStudio (ya instalado en la VM) Recursos Online Introducci\u00f3n a R , TP 8 de esta materia: Parte 1 y Parte 2 Clustering jer\u00e1rquico en R Detalles del c\u00e1lculo de Silhouette (y mucho m\u00e1s) Objetivos Familiarizarse con el funcionamiento del clustering jer\u00e1rquico aglomerativo . Familiarizarse con el m\u00e9todo de clustering particional K-means . Explorar algunas medidas de calidad de los clusters, como la silueta o silhouette . Introducci\u00f3n al Tema Hoy vamos a retomar el trabajo con R . Recomendamos repasar o tener a mano el TP 8 de esta materia por si necesitan recordar como hacer ciertos comandos ( Parte 1 y Parte 2 ). Como mencionamos en el TP 8 , es cada vez m\u00e1s normal que experimentos biol\u00f3gicos nos permitan analizar miles a millones de interacciones biol\u00f3gicas a la vez, lo que resulta en tablas con millones de datos. Esto hace necesario entonces saber utilizar herramientas que nos permitan extraer, o minar , informaci\u00f3n de estos enormes conjuntos de datos. A este proceso lo vamos a denominar Data Mining . En este TP nos vamos a enfocar en m\u00e9todos de clustering, los cuales nos permiten agrupar elementos analizados en base a datos observados sobre ellos. Esto tiene muchas utilidades, como puede ser entender mejor las diferencias entre grupos conocidos, encontrar diferentes grupos dentro del conjunto datos analizado, o remover datos redundantes, entre otros. Si bien este TP vamos a enfocarnos m\u00e1s que nada en aprender las t\u00e9cnicas, el objetivo final de este proceso es identificar agrupamientos naturales en los datos con alguna relevancia biol\u00f3gica. Ejercicio 1 - Clustering Jer\u00e1rquico Manual Para empezar este TP vamos a realizar un peque\u00f1o clustering jer\u00e1rquico a mano para repasar el concepto. Supongamos que tenemos cuatro genes (A, B, C y D) para los cuales medimos el nivel de expresi\u00f3n a las 0hs, 1hs y 2hs luego de alg\u00fan tratamiento: gen t_0h t_1h t_2h genA 2 4 8 genB -1 -1 -2 genC -2 0 1 genD 0 -1 -6 Queremos entonces agrupar a los diferentes genes por como var\u00edan sus niveles de expresi\u00f3n cuando se aplica dicho tratamiento. Para hacer esto vamos a: Calcular la distancia euclidiana entre los diferentes genes Construir una matriz de distancias Agruparlos usando clustering jer\u00e1rquico donde el criterio de agregaci\u00f3n va a ser \"vecino m\u00e1s lejano\" o complete linkage Repetir todo lo anterior, pero estandarizando previamente los datos de niveles de expresi\u00f3n Si no entienden algunos de estos conceptos pueden leer un poco m\u00e1s sobre ellos a continuaci\u00f3n (y m\u00e1s todav\u00eda en la te\u00f3rica): Distancia euclidiana Es una de las varias formas de calcular una distancia entre dos vectores de datos, lo cual es necesario al momento de calcular una matriz de distancias. Por ejemplo, suponiendo que tenemos 2 vectores de forma \\(V = (x, y, z)\\) la distancia euclidiana entre ellos se calcula como: \\[ distanciaEuclidiana(V_1, V_2) = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2 + (z_1 - z_2)^2} \\] Aplicando esto a nuestros datos, la distancia entre los genes A y B se calcula como: \\[ distanciaEuclidiana(genA, genB) = \\sqrt{(2 - (-1))^2 + (4 - (-1))^2 + (8 - (-2))^2} = 11,58 \\] Matriz de distancias Es una matriz donde tanto las filas como las columnas representan un mismo conjunto de elementos y en cada intersecci\u00f3n se pone la distancia (en nuestro caso euclidiana) entre dos elementos espec\u00edficos. Es la base de muchos m\u00e9todos de clustering. Para nuestros datos la matriz de distancias entre los cuatro genes es: genA genB genC genD genA 0 genB 11,58 0 genC 9 3,32 0 genD 15 4,12 7,35 0 Como el orden de los elementos es igual para las filas que para las columnas, en la diagonal se compara cada elemento contra s\u00ed mismo por lo que la distancia es 0. Por otro lado, estamos llenando solo la mitad de la matriz ya que las matrices de distancia son matrices sim\u00e9tricas, es decir, que el tri\u00e1ngulo superior derecho de la matriz va a ser un reflejo del tri\u00e1ngulo inferior izquierdo. Clustering jer\u00e1rquico El clustering jer\u00e1rquico es una forma de agrupar elementos dependiendo de que tan similares son entre ellos. Usa un algoritmo bastante sencillo de entender que se basa en una matriz de distancias: Sin considerar a la diagonal, encontrar el par de elementos (fila, columna) que son m\u00e1s similares entre s\u00ed (el menor n\u00famero en la matriz de distancias). En nuestra matriz de distancias los elementos m\u00e1s parecidos son \"genB\" y \"genC\" ya que tienen la menor similitud (3,32) Dejar constancia de dicha similitud y reconstruir la matriz, reemplazando ambos elementos por uno nuevo (saco los elementos \"genB\" y \"genC\" y agrego el elemento \"genB+C\" ) Al momento de calcular la nueva distancia entre este nuevo elemento ( \"genB+C\" ) y el resto de los elementos de la matriz, usar alg\u00fan criterio de agregaci\u00f3n (por ejemplo: single linkage , average linkage o complete linkage ) Volver al paso 1 hasta que todos los elementos est\u00e9n unidos entre s\u00ed Una vez hecho esto puedo dibujar el clustering jer\u00e1rquico teniendo en cuenta qu\u00e9 elementos se juntaron con qu\u00e9 elementos. Criterios de agregaci\u00f3n Los criterios de agregaci\u00f3n indican que operaci\u00f3n hay que hacer al momento de calcular la distancia entre un nuevo elemento creado en una matriz de distancias y los ya existentes. Cada uno tiene sus ventajas y desventajas. Siguiendo con nuestro ejemplo, si queremos calcular la distancia entre el nuevo elemento \"genB+C\" y el \"genA\" : Single Linkage: la nueva distancia es la menor entre las distancias \\(dist(genA, genB)\\) y \\(dist(genA, genC)\\) Complete Linkage: la nueva distancia es la mayor entre las distancias \\(dist(genA, genB)\\) y \\(dist(genA, genC)\\) Average Linkage: la nueva distancia es el promedio de las distancias \\(dist(genA, genB)\\) y \\(dist(genA, genC)\\) Para agilizar un poco este Ejercicio les vamos a dar una planilla de Google Sheets que contiene la base de lo que vamos a necesitar. Abran esta planilla de Google Sheets y hagan una copia. Leyendo la siguiente informaci\u00f3n, traten de entender que hacen las diferentes partes de dicha planilla (desde ya, hay partes vac\u00edas que vamos a completar). Pesta\u00f1a Plot Se\u00f1al Columnas A - D: contienen nuestros datos Columnas F y G: contienen el promedio y la desviaci\u00f3n est\u00e1ndar de cada gen (vac\u00edo, ahora lo hacemos) Columnas I - L: contienen nuestros datos estandarizados (vac\u00edo, ahora lo hacemos) Plot izquierdo: plot de la evoluci\u00f3n de los niveles de expresi\u00f3n a los 3 tiempos para los 4 genes Plot derecho: plot de la evoluci\u00f3n de los niveles de expresi\u00f3n estandarizados a los 3 tiempos para los 4 genes (se hace solo al llenar datos) Pesta\u00f1a Clustering Columnas A - D: contienen nuestros datos Columnas F - J: contienen el c\u00e1lculo de las distancias euclidianas entre las filas Columnas L - P: contienen la matriz de distancias para nuestros datos (y matrices m\u00e1s chicas donde se van a ir escribiendo los varios pasos al hacer el clustering a mano) Pesta\u00f1a Clustering Estandarizado Igual que Clustering , pero para datos estandarizados (vac\u00edo, ahora lo hacemos) Mirando el Plot izquierdo de la pesta\u00f1a Plot Se\u00f1al , \u00bfde qu\u00e9 forma les parece que se van a agrupar los cuatro genes en el clustering jer\u00e1rquico ? Ahora vamos a calcular el clustering jer\u00e1rquico : Vayan a la pesta\u00f1a Clustering . Usando la matriz de distancias ubicada en las Columnas L - P , calculen a mano el clustering jer\u00e1rquico para nuestros datos usando complete linkage . Hagan un esquema del dendrograma o \u00e1rbol de similitud que resulta de este clustering. Pueden usar la herramienta Dibujo de Google Sheets (no se preocupen por el largo de las ramas, solo nos importa c\u00f3mo se unen los genes). \u00bfDio similar a lo que hab\u00edan propuesto en el punto 2 ? Queremos ahora calcular nuestros datos estandarizados donde vamos a estandarizar por gen, rest\u00e1ndole a cada dato el promedio de los tres tiempos para ese gen y dividiendo el resultado por la desviaci\u00f3n est\u00e1ndar de los tres tiempos para ese gen. Es decir: \\[ datoEstandarizado(genA, t_0) = \\frac{dato(genA, t_0) - promedio(genA)}{desviacionEstandar(genA)} \\] Para hacer esto: En la pesta\u00f1a Plot Se\u00f1al , completen las columnas F y G para que calculen el promedio y la desviaci\u00f3n est\u00e1ndar para los tres tiempos de cada uno de los cuatro genes. En la pesta\u00f1a Plot Se\u00f1al , completen las columnas J a L para que calculen los valores estandarizados de los datos en base a la f\u00f3rmula anterior. Tip - Copiar y pegar una f\u00f3rmula en Google Sheets manteniendo una parte constante En Google Sheets, as\u00ed como en Excell y otras hojas de c\u00e1lculo, es posible \"arrastrar\" una f\u00f3rmula, por lo que podr\u00edan calcular el dato estandarizado para un solo n\u00famero (por ejemplo celda J2 ) y luego copiar dicha f\u00f3rmula al resto de las celdas. Sin embargo, de usar este m\u00e9todo para calcular los valores estandarizados tendr\u00edamos problemas, ya que se mover\u00eda tambi\u00e9n la referencia en la f\u00f3rmula a las celdas del promedio y la desviaci\u00f3n est\u00e1ndar (las cuales queremos que se muevan con la f\u00f3rmula para abajo, pero no para la derecha). Por suerte es posible controlar esto agreg\u00e1ndole el s\u00edmbolo $ adelante de la fila o columna. Es decir, si la f\u00f3rmula apunta a F2 y no queremos que se mueva horizontalmente (es decir, no queremos que cambie la F ), podemos agregar el s\u00edmbolo $ en la f\u00f3rmula con lo que quedar\u00eda $F2 . Si ahora arrastramos (o copiamos y pegamos) dicha f\u00f3rmula, el 2 puede cambiar, pero la F se va a mantener siempre como F . Una vez calculados los datos estandarizados deber\u00eda aparecerles el plot en el Plot derecho . \u00bfDe qu\u00e9 forma les parece que se van a agrupar los cuatro genes en el clustering jer\u00e1rquico usando los datos estandarizados? El pr\u00f3ximo paso es calcular la matriz de distancias para nuestros datos estandarizados: Copien los datos reci\u00e9n calculados a la pesta\u00f1a Clustering Estandarizado (tengan en cuenta al copiar y pegar los datos que queremos los valores, no las f\u00f3rmulas). En la columna J , calculen las distancias euclidianas entre los diferentes genes. Copien a mano las distancias reci\u00e9n calculadas a las posiciones correspondientes de la matriz de distancias en las Columnas L - P . Por \u00faltimo vamos a calcular el clustering jer\u00e1rquico para nuestros datos estandarizados: Aseg\u00farense que est\u00e1n en la pesta\u00f1a Clustering Estandarizado . Usando la matriz de distancias ubicada en las Columnas L - P , calculen a mano el clustering jer\u00e1rquico para nuestros datos estandarizados usando complete linkage . Hagan un esquema del dendrograma o \u00e1rbol de similitud que resulta de este clustering. Pueden usar la herramienta Dibujo de Google Sheets (no se preocupen por el largo de las ramas, solo nos importa c\u00f3mo se unen los genes). \u00bfDio similar a lo que hab\u00edan propuesto en el punto 4.c ? Comparando los clusterings obtenidos con los datos estandarizados y sin estandarizar. \u00bfQu\u00e9 diferencias observan? \u00bfCu\u00e1l de los dos clusterings les parece mejor para este escenario donde quer\u00edamos evaluar c\u00f3mo afecta un tratamiento los niveles de expresi\u00f3n de diferentes genes? \u00bfLes parece qu\u00e9 es siempre correcto estandarizar los datos de esta forma o se les ocurre escenarios donde no es as\u00ed? Ejercicio 2 - Clustering Jer\u00e1rquico con R En este Ejercicio vamos a hacer lo mismo que hicimos en el Ejercicio 1 , pero ahora lo vamos a hacer usando R . Les recomendamos que creen un script nuevo donde vayan poniendo las diferentes l\u00edneas de c\u00f3digo que van ejecutando. Datos sin estandarizar Leer los datos Los datos originales los tienen en el archivo tabla_ejemplo.tsv que se encuentra en sus materiales de trabajo. 1) Usen la funci\u00f3n fread para cargar los datos de tabla_ejemplo.tsv en una nueva variable llamada dt_tabla_ejemplo (recuerden que van a tener que cargar el paquete data.table y setear el working directory ) Pasar los datos a una matriz Queremos crear una matriz de distancias, las cuales se calculan usando la funci\u00f3n dist . Para que la matriz de distancias tenga los nombres de los genes en las filas y columnas necesitamos que la tabla que le pasemos tambi\u00e9n cumpla esta condici\u00f3n, cosa que los Data Tables no hacen (ya que no pueden tener nombres en las filas). Por esta raz\u00f3n vamos a transformar nuestro Data Table en una matriz. En R las matrices son un tipo de variable ( matrix ) y son b\u00e1sicamente vectores de dos dimensiones. Hay varias formas de crear una matriz, por ejemplo: matriz_ejemplo <- matrix ( c ( 1 : 9 ), nrow = 3 , ncol = 3 , byrow = T ) #Si quisieramos ver por consola algun dato de la matriz podemos hacer: matriz_ejemplo #imprimo toda la matriz matriz_ejemplo [ 1 , ] #imprimo la primera fila matriz_ejemplo [, 1 ] #imprimo la primera columna matriz_ejemplo [ 2 , 3 ] #imprimo el elemento ubicado en la fila 2 y la columna 3 Ahora bien, en nuestro caso no queremos crear una matriz de 0, sino que queremos transformar nuestro Data Table en una matriz, para lo cual tenemos que hacer: matriz_datos <- as.matrix ( dt_tabla_ejemplo , rownames = 1 ) Donde rownames = 1 le est\u00e1 indicando a R que los valores de la primera columna de dt_tabla_ejemplo van a ser usados como los nombres de cada fila de la matriz. 2) Corran el c\u00f3digo anterior (sin el ejemplo) e impriman matriz_datos por consola. Van a ver que es similar a como se imprim\u00eda el Data Table , solo que las filas tienen nombre. Traten ahora de acceder a los valores de la primera columna de matriz_datos , \u00bfc\u00f3mo tienen que hacer para lograrlo? Crear la matriz de distancias Ahora que tenemos una matriz con los nombres de los genes en las filas y las columnas, queremos usar la funci\u00f3n dist para calcular la matriz de distancias. El c\u00f3digo es: matriz_distancias <- dist ( matriz_datos , method = \"euclidean\" , diag = T ) Donde method = \"euclidean\" le est\u00e1 diciendo a la funci\u00f3n dist que tiene que calcular las distancias euclidianas entre filas y diag = T hace que deje la diagonal de ceros en el output. 3) Corran el c\u00f3digo anterior e impriman matriz_distancias por consola. \u00bfCoinciden los datos con la matriz de distancias vista en el Ejercicio 1 ? Hacer el clustering jer\u00e1rquico El clustering jer\u00e1rquico se hace con la funci\u00f3n hclust , la cual se usa: clustering_jerarquico <- hclust ( matriz_distancias , method = \"complete\" ) Donde method = \"complete\" est\u00e1 indic\u00e1ndole a la funci\u00f3n que criterio de agregaci\u00f3n usar al momento de combinar elementos. Pueden usar help(hclust) para ver otros posibles criterios. 4) Corran el c\u00f3digo anterior e impriman clustering_jerarquico por consola. \u00bfDa alguna informaci\u00f3n \u00fatil a simple vista? 5) Usen la funci\u00f3n plot para plotear clustering_jerarquico . Usen el par\u00e1metro main para cambiarle el t\u00edtulo al plot indicando que es un clustering jer\u00e1rquico , que usa complete linkage y que usa datos sin estandarizar. Asignando clusters Cuando uno mira el \u00e1rbol creado en el punto 5) es com\u00fan detectar que ciertos genes son m\u00e1s similares entre s\u00ed que otros y suponer que entonces pertenecen a un mismo grupo. Esto se puede calcular computacionalmente \"cortando\" el \u00e1rbol usando un cierto umbral de similitud y agrupando en un mismo cluster a aquellos elementos que queden por debajo de ese umbral. Esto se puede hacer de dos formas, o determinando el umbral de similitud o determinando la cantidad de clusters a crear. clusters_porAltura <- cutree ( clustering_jerarquico , h = @@ EDITAR @@ ) clusters_porCantidad <- cutree ( clustering_jerarquico , k = @@ EDITAR @@ ) Donde h es el par\u00e1metro que recibe la altura de similitud a la cual cortar (eje y en el plot anterior) y k es el par\u00e1metro que recibe la cantidad de clusters a crear. Hay que usar uno o el otro. 6) Bas\u00e1ndose en el plot creado en el punto 5) , corran el c\u00f3digo anterior cambiando @@EDITAR@@ por el n\u00famero correspondiente para agrupar los genes como le parezca mejor. Impriman las variables clusters_porAltura y clusters_porCantidad para confirmar que los genes se agruparon como ustedes quer\u00edan. Extraer esta informaci\u00f3n a un Data Table La variable clusters_porAltura es un vector con nombres, por lo que si quisi\u00e9ramos extraer su informaci\u00f3n y guardarla en un Data Table , tendr\u00edamos que hacer: dt_clusters_porAltura <- data.table ( gen = names ( genes_clusters_porAltura ), cluster = genes_clusters_porAltura ) Datos estandarizados Estandarizar los datos El primer paso para trabajar con estos datos es estandarizarlos como hicimos en el Ejercicio 1 . Si bien podr\u00edamos calcular a mano el promedio (funci\u00f3n mean ) y la desviaci\u00f3n estandar (funci\u00f3n sd ) de cada fila y luego hacer las cuentas, existe ya en R una funci\u00f3n que hace esta estandarizaci\u00f3n por nosotros. Esta funci\u00f3n es scale , pero un problema que tenemos es que dicha funci\u00f3n estandariza por columna, no por fila. Por suerte es bastante f\u00e1cil en R transponer una matriz (lo que b\u00e1sicamente cambia filas por columnas y viceversa). Esto se hace usando la funci\u00f3n t . #Transpongo la matriz de datos t_matriz_datos <- t ( matriz_datos ) #Estandarizo los datos por columna (que ahora son los tres tiempos de cada gen) #*scale* va a devolver una variable que tiene mas informacion que una matriz, pero funciona como matriz t_matriz_datos_ST <- scale ( t_matriz_datos ) #Vuelvo a transponer la matriz, lo cual la pone en el orden de antes, ahora estandarizada matriz_datos_ST <- t ( t_matriz_datos_ST ) 7) Corran el c\u00f3digo anterior e impriman matriz_datos_ST por consola. \u00bfCoinciden los datos estandarizados con los obtenidos en el Ejercicio 1 ? Hacer el resto del an\u00e1lisis 8) Vuelvan a hacer los pasos 3) a 6) usando la nueva matriz de datos estandarizados, matriz_datos_ST . Vayan creando nuevas variables en cada caso para no sobrescribir las anteriores (recomendamos usar los mismos nombres y agregarles el sufijo _ST ). Ejercicio 3 - K-means y Silhouette K-means Otro m\u00e9todo muy popular para agrupar elementos es el K-means . A diferencia del clustering jer\u00e1rquico , \u00e9ste no crea un \u00e1rbol de similitud, sino que utiliza un m\u00e9todo iterativo para asignar directamente cada elemento a diferentes grupos. Otra caracter\u00edstica del K-means es que hay que pasarle el n\u00famero de clusters a crear. La funci\u00f3n kmeans viene con R y se usa: #Esta funcion controla el aspecto azaroso de kmeans para que nos de igual a todos set.seed ( 1 ) #Corro la funcion kmeans para los datos sin estandarizar pidiendole 3 clusters clustering_kmeans_k2_ST <- kmeans ( matriz_datos_ST , centers = 2 ) #Extraigo los clusters calculados clusters_kmeans_k2_ST <- clustering_kmeans_k2_ST $ cluster Donde centers = 2 le est\u00e1 diciendo a la funci\u00f3n que cree 2 clusters (lo que estoy indicando en el nombre de la variable con _k2 para que no haya confusi\u00f3n m\u00e1s adelante). Tip - Predeterminar el azar La funci\u00f3n kmeans() genera la primera posici\u00f3n de sus centros al azar. Esto hace que si la corren varias veces o en diferentes computadoras va a dar diferentes resultados cada vez. Esto se puede controlar con una funci\u00f3n de R que asigna a mano el valor de la seed , que es el n\u00famero base que usa R al momento de generar azar. Si les interesa hacer esto tienen que ejecutar la siguiente l\u00ednea antes de usar la funci\u00f3n kmeans() : set.seed ( 1 ) P.D.: El azar en las computadoras no existe realmente. Muchos programas usan lista pre-generadas de \"n\u00fameros creados al azar\" y otras usan cosas como \"el quinto decimal de la temperatura del procesador en este momento\", lo que se aproxima suficientemente al azar para funcionar bien. 1) Corran el c\u00f3digo anterior y comparen estos clusters a los obtenidos para los datos estandarizados en el Ejercicio 2 usando clustering jer\u00e1rquico . Silhouette Para cada elemento presente en un agrupamiento se puede calcular un Silhouette coeficient , el cual es un n\u00famero entre -1 y 1 que indica que tan similar es dicho elemento a otros elementos de su mismo cluster y que tan diferente es dicho elemento a los elementos de otros clusters . Cuanto m\u00e1s cerca de 1, mejor asignado esta dicho elemento en su cluster . Es posible entonces calcular el promedio de los Silhouette coefficients de todos los elementos presentes en un agrupamiento, donde promedios m\u00e1s cercanos a 1 van a indicar que el agrupamiento general es mejor. Este m\u00e9todo tiene bastantes usos, pero uno de los m\u00e1s comunes es definir cu\u00e1l es el n\u00famero ideal de clusters a crear con K-means . La funci\u00f3n silhouette no viene por defecto con R . Corran el siguiente c\u00f3digo para instalar el paquete cluster : install.packages ( \"cluster\" ) Esta funci\u00f3n se usa: library ( cluster ) #para silhouette() #Calculo los silhouette coefficients para los datos estandarizados agrupados en 2 clusters usando kmeans #Tengo que pasarle tambien la matriz de distancias correspondiente para que pueda calcular similitud entre elementos silhouette_kmeans_k2_ST <- silhouette ( clusters_kmeans_k2_ST , dist = matriz_distancias_ST ) #La funcion *silhouette* saca los nombres de las filas, por lo cual ahora mis genes estan como numeros #Para recuperar los nombres de las filas (o *rownames*) hago lo siguiente rownames ( silhouette_kmeans_k2_ST ) <- rownames ( matriz_datos_ST ) #Podemos plotear los silhouette coefficients con plot plot ( silhouette_kmeans_k2_ST , main = \"STD - Kmeans - centers = 2\" ) #Y podemos extraer el promedio de los *Silhouette coefficients* promedio_silhouette_kmeans_k2_ST <- summary ( silhouette_kmeans_k2_ST )[[ 1 ]][[ \"Mean\" ]] 2) Corran el c\u00f3digo anterior y vean su salida. 3) Bas\u00e1ndose en los c\u00f3digos usados en 1) y en 2) , vuelvan a agrupar a los cuatro genes en base a sus datos estandarizados pero ahora en 3 clusters. Luego ploteen los Silhouette coefficients de este agrupamiento y calculen su promedio. Guarden estos nuevos datos en variables con diferentes nombres que las anteriores. 4) Comparando lo obtenido en los puntos anteriores, \u00bfqu\u00e9 n\u00famero de clusters resulta en un mejor promedio para los Silhouette coefficients ? \u00bfcoincide esto con lo observado en el dendrograma hecho a partir del clustering jer\u00e1rquico ? Bibliograf\u00eda Consola de R Comando help()","title":"TP 12a - Clustering"},{"location":"practicos/TP12a_Clustering/#tp-12a-data-mining-clustering","text":"Materiales","title":"data-toc-label"},{"location":"practicos/TP12a_Clustering/#software-a-usar","text":"R (ya instalado en la VM). RStudio (ya instalado en la VM)","title":"Software a usar"},{"location":"practicos/TP12a_Clustering/#recursos-online","text":"Introducci\u00f3n a R , TP 8 de esta materia: Parte 1 y Parte 2 Clustering jer\u00e1rquico en R Detalles del c\u00e1lculo de Silhouette (y mucho m\u00e1s)","title":"Recursos Online"},{"location":"practicos/TP12a_Clustering/#objetivos","text":"Familiarizarse con el funcionamiento del clustering jer\u00e1rquico aglomerativo . Familiarizarse con el m\u00e9todo de clustering particional K-means . Explorar algunas medidas de calidad de los clusters, como la silueta o silhouette .","title":"Objetivos"},{"location":"practicos/TP12a_Clustering/#introduccion-al-tema","text":"Hoy vamos a retomar el trabajo con R . Recomendamos repasar o tener a mano el TP 8 de esta materia por si necesitan recordar como hacer ciertos comandos ( Parte 1 y Parte 2 ). Como mencionamos en el TP 8 , es cada vez m\u00e1s normal que experimentos biol\u00f3gicos nos permitan analizar miles a millones de interacciones biol\u00f3gicas a la vez, lo que resulta en tablas con millones de datos. Esto hace necesario entonces saber utilizar herramientas que nos permitan extraer, o minar , informaci\u00f3n de estos enormes conjuntos de datos. A este proceso lo vamos a denominar Data Mining . En este TP nos vamos a enfocar en m\u00e9todos de clustering, los cuales nos permiten agrupar elementos analizados en base a datos observados sobre ellos. Esto tiene muchas utilidades, como puede ser entender mejor las diferencias entre grupos conocidos, encontrar diferentes grupos dentro del conjunto datos analizado, o remover datos redundantes, entre otros. Si bien este TP vamos a enfocarnos m\u00e1s que nada en aprender las t\u00e9cnicas, el objetivo final de este proceso es identificar agrupamientos naturales en los datos con alguna relevancia biol\u00f3gica.","title":"Introducci\u00f3n al Tema"},{"location":"practicos/TP12a_Clustering/#ejercicio-1-clustering-jerarquico-manual","text":"Para empezar este TP vamos a realizar un peque\u00f1o clustering jer\u00e1rquico a mano para repasar el concepto. Supongamos que tenemos cuatro genes (A, B, C y D) para los cuales medimos el nivel de expresi\u00f3n a las 0hs, 1hs y 2hs luego de alg\u00fan tratamiento: gen t_0h t_1h t_2h genA 2 4 8 genB -1 -1 -2 genC -2 0 1 genD 0 -1 -6 Queremos entonces agrupar a los diferentes genes por como var\u00edan sus niveles de expresi\u00f3n cuando se aplica dicho tratamiento. Para hacer esto vamos a: Calcular la distancia euclidiana entre los diferentes genes Construir una matriz de distancias Agruparlos usando clustering jer\u00e1rquico donde el criterio de agregaci\u00f3n va a ser \"vecino m\u00e1s lejano\" o complete linkage Repetir todo lo anterior, pero estandarizando previamente los datos de niveles de expresi\u00f3n Si no entienden algunos de estos conceptos pueden leer un poco m\u00e1s sobre ellos a continuaci\u00f3n (y m\u00e1s todav\u00eda en la te\u00f3rica): Distancia euclidiana Es una de las varias formas de calcular una distancia entre dos vectores de datos, lo cual es necesario al momento de calcular una matriz de distancias. Por ejemplo, suponiendo que tenemos 2 vectores de forma \\(V = (x, y, z)\\) la distancia euclidiana entre ellos se calcula como: \\[ distanciaEuclidiana(V_1, V_2) = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2 + (z_1 - z_2)^2} \\] Aplicando esto a nuestros datos, la distancia entre los genes A y B se calcula como: \\[ distanciaEuclidiana(genA, genB) = \\sqrt{(2 - (-1))^2 + (4 - (-1))^2 + (8 - (-2))^2} = 11,58 \\] Matriz de distancias Es una matriz donde tanto las filas como las columnas representan un mismo conjunto de elementos y en cada intersecci\u00f3n se pone la distancia (en nuestro caso euclidiana) entre dos elementos espec\u00edficos. Es la base de muchos m\u00e9todos de clustering. Para nuestros datos la matriz de distancias entre los cuatro genes es: genA genB genC genD genA 0 genB 11,58 0 genC 9 3,32 0 genD 15 4,12 7,35 0 Como el orden de los elementos es igual para las filas que para las columnas, en la diagonal se compara cada elemento contra s\u00ed mismo por lo que la distancia es 0. Por otro lado, estamos llenando solo la mitad de la matriz ya que las matrices de distancia son matrices sim\u00e9tricas, es decir, que el tri\u00e1ngulo superior derecho de la matriz va a ser un reflejo del tri\u00e1ngulo inferior izquierdo. Clustering jer\u00e1rquico El clustering jer\u00e1rquico es una forma de agrupar elementos dependiendo de que tan similares son entre ellos. Usa un algoritmo bastante sencillo de entender que se basa en una matriz de distancias: Sin considerar a la diagonal, encontrar el par de elementos (fila, columna) que son m\u00e1s similares entre s\u00ed (el menor n\u00famero en la matriz de distancias). En nuestra matriz de distancias los elementos m\u00e1s parecidos son \"genB\" y \"genC\" ya que tienen la menor similitud (3,32) Dejar constancia de dicha similitud y reconstruir la matriz, reemplazando ambos elementos por uno nuevo (saco los elementos \"genB\" y \"genC\" y agrego el elemento \"genB+C\" ) Al momento de calcular la nueva distancia entre este nuevo elemento ( \"genB+C\" ) y el resto de los elementos de la matriz, usar alg\u00fan criterio de agregaci\u00f3n (por ejemplo: single linkage , average linkage o complete linkage ) Volver al paso 1 hasta que todos los elementos est\u00e9n unidos entre s\u00ed Una vez hecho esto puedo dibujar el clustering jer\u00e1rquico teniendo en cuenta qu\u00e9 elementos se juntaron con qu\u00e9 elementos. Criterios de agregaci\u00f3n Los criterios de agregaci\u00f3n indican que operaci\u00f3n hay que hacer al momento de calcular la distancia entre un nuevo elemento creado en una matriz de distancias y los ya existentes. Cada uno tiene sus ventajas y desventajas. Siguiendo con nuestro ejemplo, si queremos calcular la distancia entre el nuevo elemento \"genB+C\" y el \"genA\" : Single Linkage: la nueva distancia es la menor entre las distancias \\(dist(genA, genB)\\) y \\(dist(genA, genC)\\) Complete Linkage: la nueva distancia es la mayor entre las distancias \\(dist(genA, genB)\\) y \\(dist(genA, genC)\\) Average Linkage: la nueva distancia es el promedio de las distancias \\(dist(genA, genB)\\) y \\(dist(genA, genC)\\) Para agilizar un poco este Ejercicio les vamos a dar una planilla de Google Sheets que contiene la base de lo que vamos a necesitar. Abran esta planilla de Google Sheets y hagan una copia. Leyendo la siguiente informaci\u00f3n, traten de entender que hacen las diferentes partes de dicha planilla (desde ya, hay partes vac\u00edas que vamos a completar). Pesta\u00f1a Plot Se\u00f1al Columnas A - D: contienen nuestros datos Columnas F y G: contienen el promedio y la desviaci\u00f3n est\u00e1ndar de cada gen (vac\u00edo, ahora lo hacemos) Columnas I - L: contienen nuestros datos estandarizados (vac\u00edo, ahora lo hacemos) Plot izquierdo: plot de la evoluci\u00f3n de los niveles de expresi\u00f3n a los 3 tiempos para los 4 genes Plot derecho: plot de la evoluci\u00f3n de los niveles de expresi\u00f3n estandarizados a los 3 tiempos para los 4 genes (se hace solo al llenar datos) Pesta\u00f1a Clustering Columnas A - D: contienen nuestros datos Columnas F - J: contienen el c\u00e1lculo de las distancias euclidianas entre las filas Columnas L - P: contienen la matriz de distancias para nuestros datos (y matrices m\u00e1s chicas donde se van a ir escribiendo los varios pasos al hacer el clustering a mano) Pesta\u00f1a Clustering Estandarizado Igual que Clustering , pero para datos estandarizados (vac\u00edo, ahora lo hacemos) Mirando el Plot izquierdo de la pesta\u00f1a Plot Se\u00f1al , \u00bfde qu\u00e9 forma les parece que se van a agrupar los cuatro genes en el clustering jer\u00e1rquico ? Ahora vamos a calcular el clustering jer\u00e1rquico : Vayan a la pesta\u00f1a Clustering . Usando la matriz de distancias ubicada en las Columnas L - P , calculen a mano el clustering jer\u00e1rquico para nuestros datos usando complete linkage . Hagan un esquema del dendrograma o \u00e1rbol de similitud que resulta de este clustering. Pueden usar la herramienta Dibujo de Google Sheets (no se preocupen por el largo de las ramas, solo nos importa c\u00f3mo se unen los genes). \u00bfDio similar a lo que hab\u00edan propuesto en el punto 2 ? Queremos ahora calcular nuestros datos estandarizados donde vamos a estandarizar por gen, rest\u00e1ndole a cada dato el promedio de los tres tiempos para ese gen y dividiendo el resultado por la desviaci\u00f3n est\u00e1ndar de los tres tiempos para ese gen. Es decir: \\[ datoEstandarizado(genA, t_0) = \\frac{dato(genA, t_0) - promedio(genA)}{desviacionEstandar(genA)} \\] Para hacer esto: En la pesta\u00f1a Plot Se\u00f1al , completen las columnas F y G para que calculen el promedio y la desviaci\u00f3n est\u00e1ndar para los tres tiempos de cada uno de los cuatro genes. En la pesta\u00f1a Plot Se\u00f1al , completen las columnas J a L para que calculen los valores estandarizados de los datos en base a la f\u00f3rmula anterior. Tip - Copiar y pegar una f\u00f3rmula en Google Sheets manteniendo una parte constante En Google Sheets, as\u00ed como en Excell y otras hojas de c\u00e1lculo, es posible \"arrastrar\" una f\u00f3rmula, por lo que podr\u00edan calcular el dato estandarizado para un solo n\u00famero (por ejemplo celda J2 ) y luego copiar dicha f\u00f3rmula al resto de las celdas. Sin embargo, de usar este m\u00e9todo para calcular los valores estandarizados tendr\u00edamos problemas, ya que se mover\u00eda tambi\u00e9n la referencia en la f\u00f3rmula a las celdas del promedio y la desviaci\u00f3n est\u00e1ndar (las cuales queremos que se muevan con la f\u00f3rmula para abajo, pero no para la derecha). Por suerte es posible controlar esto agreg\u00e1ndole el s\u00edmbolo $ adelante de la fila o columna. Es decir, si la f\u00f3rmula apunta a F2 y no queremos que se mueva horizontalmente (es decir, no queremos que cambie la F ), podemos agregar el s\u00edmbolo $ en la f\u00f3rmula con lo que quedar\u00eda $F2 . Si ahora arrastramos (o copiamos y pegamos) dicha f\u00f3rmula, el 2 puede cambiar, pero la F se va a mantener siempre como F . Una vez calculados los datos estandarizados deber\u00eda aparecerles el plot en el Plot derecho . \u00bfDe qu\u00e9 forma les parece que se van a agrupar los cuatro genes en el clustering jer\u00e1rquico usando los datos estandarizados? El pr\u00f3ximo paso es calcular la matriz de distancias para nuestros datos estandarizados: Copien los datos reci\u00e9n calculados a la pesta\u00f1a Clustering Estandarizado (tengan en cuenta al copiar y pegar los datos que queremos los valores, no las f\u00f3rmulas). En la columna J , calculen las distancias euclidianas entre los diferentes genes. Copien a mano las distancias reci\u00e9n calculadas a las posiciones correspondientes de la matriz de distancias en las Columnas L - P . Por \u00faltimo vamos a calcular el clustering jer\u00e1rquico para nuestros datos estandarizados: Aseg\u00farense que est\u00e1n en la pesta\u00f1a Clustering Estandarizado . Usando la matriz de distancias ubicada en las Columnas L - P , calculen a mano el clustering jer\u00e1rquico para nuestros datos estandarizados usando complete linkage . Hagan un esquema del dendrograma o \u00e1rbol de similitud que resulta de este clustering. Pueden usar la herramienta Dibujo de Google Sheets (no se preocupen por el largo de las ramas, solo nos importa c\u00f3mo se unen los genes). \u00bfDio similar a lo que hab\u00edan propuesto en el punto 4.c ? Comparando los clusterings obtenidos con los datos estandarizados y sin estandarizar. \u00bfQu\u00e9 diferencias observan? \u00bfCu\u00e1l de los dos clusterings les parece mejor para este escenario donde quer\u00edamos evaluar c\u00f3mo afecta un tratamiento los niveles de expresi\u00f3n de diferentes genes? \u00bfLes parece qu\u00e9 es siempre correcto estandarizar los datos de esta forma o se les ocurre escenarios donde no es as\u00ed?","title":"Ejercicio 1 - Clustering Manual"},{"location":"practicos/TP12a_Clustering/#ejercicio-2-clustering-jerarquico-con-r","text":"En este Ejercicio vamos a hacer lo mismo que hicimos en el Ejercicio 1 , pero ahora lo vamos a hacer usando R . Les recomendamos que creen un script nuevo donde vayan poniendo las diferentes l\u00edneas de c\u00f3digo que van ejecutando.","title":"Ejercicio 2 - Clustering con R"},{"location":"practicos/TP12a_Clustering/#datos-sin-estandarizar","text":"","title":"Datos sin estandarizar"},{"location":"practicos/TP12a_Clustering/#leer-los-datos","text":"Los datos originales los tienen en el archivo tabla_ejemplo.tsv que se encuentra en sus materiales de trabajo. 1) Usen la funci\u00f3n fread para cargar los datos de tabla_ejemplo.tsv en una nueva variable llamada dt_tabla_ejemplo (recuerden que van a tener que cargar el paquete data.table y setear el working directory )","title":"Leer los datos"},{"location":"practicos/TP12a_Clustering/#pasar-los-datos-a-una-matriz","text":"Queremos crear una matriz de distancias, las cuales se calculan usando la funci\u00f3n dist . Para que la matriz de distancias tenga los nombres de los genes en las filas y columnas necesitamos que la tabla que le pasemos tambi\u00e9n cumpla esta condici\u00f3n, cosa que los Data Tables no hacen (ya que no pueden tener nombres en las filas). Por esta raz\u00f3n vamos a transformar nuestro Data Table en una matriz. En R las matrices son un tipo de variable ( matrix ) y son b\u00e1sicamente vectores de dos dimensiones. Hay varias formas de crear una matriz, por ejemplo: matriz_ejemplo <- matrix ( c ( 1 : 9 ), nrow = 3 , ncol = 3 , byrow = T ) #Si quisieramos ver por consola algun dato de la matriz podemos hacer: matriz_ejemplo #imprimo toda la matriz matriz_ejemplo [ 1 , ] #imprimo la primera fila matriz_ejemplo [, 1 ] #imprimo la primera columna matriz_ejemplo [ 2 , 3 ] #imprimo el elemento ubicado en la fila 2 y la columna 3 Ahora bien, en nuestro caso no queremos crear una matriz de 0, sino que queremos transformar nuestro Data Table en una matriz, para lo cual tenemos que hacer: matriz_datos <- as.matrix ( dt_tabla_ejemplo , rownames = 1 ) Donde rownames = 1 le est\u00e1 indicando a R que los valores de la primera columna de dt_tabla_ejemplo van a ser usados como los nombres de cada fila de la matriz. 2) Corran el c\u00f3digo anterior (sin el ejemplo) e impriman matriz_datos por consola. Van a ver que es similar a como se imprim\u00eda el Data Table , solo que las filas tienen nombre. Traten ahora de acceder a los valores de la primera columna de matriz_datos , \u00bfc\u00f3mo tienen que hacer para lograrlo?","title":"Pasarlos a una matriz"},{"location":"practicos/TP12a_Clustering/#crear-la-matriz-de-distancias","text":"Ahora que tenemos una matriz con los nombres de los genes en las filas y las columnas, queremos usar la funci\u00f3n dist para calcular la matriz de distancias. El c\u00f3digo es: matriz_distancias <- dist ( matriz_datos , method = \"euclidean\" , diag = T ) Donde method = \"euclidean\" le est\u00e1 diciendo a la funci\u00f3n dist que tiene que calcular las distancias euclidianas entre filas y diag = T hace que deje la diagonal de ceros en el output. 3) Corran el c\u00f3digo anterior e impriman matriz_distancias por consola. \u00bfCoinciden los datos con la matriz de distancias vista en el Ejercicio 1 ?","title":"Matriz de distancias"},{"location":"practicos/TP12a_Clustering/#hacer-el-clustering-jerarquico","text":"El clustering jer\u00e1rquico se hace con la funci\u00f3n hclust , la cual se usa: clustering_jerarquico <- hclust ( matriz_distancias , method = \"complete\" ) Donde method = \"complete\" est\u00e1 indic\u00e1ndole a la funci\u00f3n que criterio de agregaci\u00f3n usar al momento de combinar elementos. Pueden usar help(hclust) para ver otros posibles criterios. 4) Corran el c\u00f3digo anterior e impriman clustering_jerarquico por consola. \u00bfDa alguna informaci\u00f3n \u00fatil a simple vista? 5) Usen la funci\u00f3n plot para plotear clustering_jerarquico . Usen el par\u00e1metro main para cambiarle el t\u00edtulo al plot indicando que es un clustering jer\u00e1rquico , que usa complete linkage y que usa datos sin estandarizar.","title":"clustering jer\u00e1rquico"},{"location":"practicos/TP12a_Clustering/#asignando-clusters","text":"Cuando uno mira el \u00e1rbol creado en el punto 5) es com\u00fan detectar que ciertos genes son m\u00e1s similares entre s\u00ed que otros y suponer que entonces pertenecen a un mismo grupo. Esto se puede calcular computacionalmente \"cortando\" el \u00e1rbol usando un cierto umbral de similitud y agrupando en un mismo cluster a aquellos elementos que queden por debajo de ese umbral. Esto se puede hacer de dos formas, o determinando el umbral de similitud o determinando la cantidad de clusters a crear. clusters_porAltura <- cutree ( clustering_jerarquico , h = @@ EDITAR @@ ) clusters_porCantidad <- cutree ( clustering_jerarquico , k = @@ EDITAR @@ ) Donde h es el par\u00e1metro que recibe la altura de similitud a la cual cortar (eje y en el plot anterior) y k es el par\u00e1metro que recibe la cantidad de clusters a crear. Hay que usar uno o el otro. 6) Bas\u00e1ndose en el plot creado en el punto 5) , corran el c\u00f3digo anterior cambiando @@EDITAR@@ por el n\u00famero correspondiente para agrupar los genes como le parezca mejor. Impriman las variables clusters_porAltura y clusters_porCantidad para confirmar que los genes se agruparon como ustedes quer\u00edan. Extraer esta informaci\u00f3n a un Data Table La variable clusters_porAltura es un vector con nombres, por lo que si quisi\u00e9ramos extraer su informaci\u00f3n y guardarla en un Data Table , tendr\u00edamos que hacer: dt_clusters_porAltura <- data.table ( gen = names ( genes_clusters_porAltura ), cluster = genes_clusters_porAltura )","title":"Asignando clusters"},{"location":"practicos/TP12a_Clustering/#datos-estandarizados","text":"","title":"Datos estandarizados"},{"location":"practicos/TP12a_Clustering/#estandarizar-los-datos","text":"El primer paso para trabajar con estos datos es estandarizarlos como hicimos en el Ejercicio 1 . Si bien podr\u00edamos calcular a mano el promedio (funci\u00f3n mean ) y la desviaci\u00f3n estandar (funci\u00f3n sd ) de cada fila y luego hacer las cuentas, existe ya en R una funci\u00f3n que hace esta estandarizaci\u00f3n por nosotros. Esta funci\u00f3n es scale , pero un problema que tenemos es que dicha funci\u00f3n estandariza por columna, no por fila. Por suerte es bastante f\u00e1cil en R transponer una matriz (lo que b\u00e1sicamente cambia filas por columnas y viceversa). Esto se hace usando la funci\u00f3n t . #Transpongo la matriz de datos t_matriz_datos <- t ( matriz_datos ) #Estandarizo los datos por columna (que ahora son los tres tiempos de cada gen) #*scale* va a devolver una variable que tiene mas informacion que una matriz, pero funciona como matriz t_matriz_datos_ST <- scale ( t_matriz_datos ) #Vuelvo a transponer la matriz, lo cual la pone en el orden de antes, ahora estandarizada matriz_datos_ST <- t ( t_matriz_datos_ST ) 7) Corran el c\u00f3digo anterior e impriman matriz_datos_ST por consola. \u00bfCoinciden los datos estandarizados con los obtenidos en el Ejercicio 1 ?","title":"Estandarizar los datos"},{"location":"practicos/TP12a_Clustering/#hacer-el-resto-del-analisis","text":"8) Vuelvan a hacer los pasos 3) a 6) usando la nueva matriz de datos estandarizados, matriz_datos_ST . Vayan creando nuevas variables en cada caso para no sobrescribir las anteriores (recomendamos usar los mismos nombres y agregarles el sufijo _ST ).","title":"Hacer el resto del an\u00e1lisis"},{"location":"practicos/TP12a_Clustering/#ejercicio-3-k-means-y-silhouette","text":"","title":"Ejercicio 3 - K-means"},{"location":"practicos/TP12a_Clustering/#k-means","text":"Otro m\u00e9todo muy popular para agrupar elementos es el K-means . A diferencia del clustering jer\u00e1rquico , \u00e9ste no crea un \u00e1rbol de similitud, sino que utiliza un m\u00e9todo iterativo para asignar directamente cada elemento a diferentes grupos. Otra caracter\u00edstica del K-means es que hay que pasarle el n\u00famero de clusters a crear. La funci\u00f3n kmeans viene con R y se usa: #Esta funcion controla el aspecto azaroso de kmeans para que nos de igual a todos set.seed ( 1 ) #Corro la funcion kmeans para los datos sin estandarizar pidiendole 3 clusters clustering_kmeans_k2_ST <- kmeans ( matriz_datos_ST , centers = 2 ) #Extraigo los clusters calculados clusters_kmeans_k2_ST <- clustering_kmeans_k2_ST $ cluster Donde centers = 2 le est\u00e1 diciendo a la funci\u00f3n que cree 2 clusters (lo que estoy indicando en el nombre de la variable con _k2 para que no haya confusi\u00f3n m\u00e1s adelante). Tip - Predeterminar el azar La funci\u00f3n kmeans() genera la primera posici\u00f3n de sus centros al azar. Esto hace que si la corren varias veces o en diferentes computadoras va a dar diferentes resultados cada vez. Esto se puede controlar con una funci\u00f3n de R que asigna a mano el valor de la seed , que es el n\u00famero base que usa R al momento de generar azar. Si les interesa hacer esto tienen que ejecutar la siguiente l\u00ednea antes de usar la funci\u00f3n kmeans() : set.seed ( 1 ) P.D.: El azar en las computadoras no existe realmente. Muchos programas usan lista pre-generadas de \"n\u00fameros creados al azar\" y otras usan cosas como \"el quinto decimal de la temperatura del procesador en este momento\", lo que se aproxima suficientemente al azar para funcionar bien. 1) Corran el c\u00f3digo anterior y comparen estos clusters a los obtenidos para los datos estandarizados en el Ejercicio 2 usando clustering jer\u00e1rquico .","title":"K-means"},{"location":"practicos/TP12a_Clustering/#silhouette","text":"Para cada elemento presente en un agrupamiento se puede calcular un Silhouette coeficient , el cual es un n\u00famero entre -1 y 1 que indica que tan similar es dicho elemento a otros elementos de su mismo cluster y que tan diferente es dicho elemento a los elementos de otros clusters . Cuanto m\u00e1s cerca de 1, mejor asignado esta dicho elemento en su cluster . Es posible entonces calcular el promedio de los Silhouette coefficients de todos los elementos presentes en un agrupamiento, donde promedios m\u00e1s cercanos a 1 van a indicar que el agrupamiento general es mejor. Este m\u00e9todo tiene bastantes usos, pero uno de los m\u00e1s comunes es definir cu\u00e1l es el n\u00famero ideal de clusters a crear con K-means . La funci\u00f3n silhouette no viene por defecto con R . Corran el siguiente c\u00f3digo para instalar el paquete cluster : install.packages ( \"cluster\" ) Esta funci\u00f3n se usa: library ( cluster ) #para silhouette() #Calculo los silhouette coefficients para los datos estandarizados agrupados en 2 clusters usando kmeans #Tengo que pasarle tambien la matriz de distancias correspondiente para que pueda calcular similitud entre elementos silhouette_kmeans_k2_ST <- silhouette ( clusters_kmeans_k2_ST , dist = matriz_distancias_ST ) #La funcion *silhouette* saca los nombres de las filas, por lo cual ahora mis genes estan como numeros #Para recuperar los nombres de las filas (o *rownames*) hago lo siguiente rownames ( silhouette_kmeans_k2_ST ) <- rownames ( matriz_datos_ST ) #Podemos plotear los silhouette coefficients con plot plot ( silhouette_kmeans_k2_ST , main = \"STD - Kmeans - centers = 2\" ) #Y podemos extraer el promedio de los *Silhouette coefficients* promedio_silhouette_kmeans_k2_ST <- summary ( silhouette_kmeans_k2_ST )[[ 1 ]][[ \"Mean\" ]] 2) Corran el c\u00f3digo anterior y vean su salida. 3) Bas\u00e1ndose en los c\u00f3digos usados en 1) y en 2) , vuelvan a agrupar a los cuatro genes en base a sus datos estandarizados pero ahora en 3 clusters. Luego ploteen los Silhouette coefficients de este agrupamiento y calculen su promedio. Guarden estos nuevos datos en variables con diferentes nombres que las anteriores. 4) Comparando lo obtenido en los puntos anteriores, \u00bfqu\u00e9 n\u00famero de clusters resulta en un mejor promedio para los Silhouette coefficients ? \u00bfcoincide esto con lo observado en el dendrograma hecho a partir del clustering jer\u00e1rquico ?","title":"Silhouette"},{"location":"practicos/TP12a_Clustering/#bibliografia","text":"","title":"Bibliograf\u00eda"},{"location":"practicos/TP12a_Clustering/#consola-de-r","text":"Comando help()","title":" Consola de R"},{"location":"practicos/TP12b_Data_Mining/","text":"TP 12b . Data Mining Materiales Software a usar R (ya instalado en la VM). RStudio (ya instalado en la VM) Recursos Online Curso online de R de Coursera (se puede hacer gratis) (en ese caso no da certificado) Data Tables: Introducci\u00f3n oficial y otra p\u00e1gina con m\u00e1s info ggplot2: Vistazo r\u00e1pido , detalles sobre los tipos de plots , cheatsheet e informaci\u00f3n sobre colores y daltonismo dendextend: Detalle del paquete Objetivos Usar m\u00e9todos de clustering junto con herramientas de programaci\u00f3n para resolver problemas biol\u00f3gicos. Familiarizarse en el paquete ggplot2 para hacer plots en R . Introducir paquetes de R que permiten plotear dendrogramas y heatmaps . Introducci\u00f3n al Tema Este TP retoma lo empezado en el TP 12a , donde aprendimos m\u00e9todos de clustering como clustering jer\u00e1rquico o K-means y los aplicamos a un ejemplo m\u00ednimo de una tabla con solo 4 filas. Vamos ahora a utilizar los mismos m\u00e9todos para trabajar con data sets m\u00e1s grandes y tratar de ir entendiendo cu\u00e1ndo, c\u00f3mo y por qu\u00e9 es conveniente agrupar nuestros datos. A su vez vamos a desarrollar algunos temas de R que son muy \u00fatiles, pero para los cuales no nos alcanz\u00f3 el tiempo en los TPs anteriores: plotear usando ggplot2 y utilizar funciones creadas por nosotros. Para hacer esto vamos a utilizar 2 data sets. En el Ejercicio 1 vamos a trabajar con el ya conocido data set iris que tiene 150 filas y viene por defecto con R . En el Ejercicio 2 vamos a trabajar con datos de un estudio de transcript\u00f3mica que nos devolvi\u00f3 9 datos para cada uno de 11.106 genes estudiados. Este trabajo es un segundo paso de lo realizado en el TP 8b cuando busc\u00e1bamos inhibidores para la Enzima Z . Mejores plots: ggplot2 Bases de ggplot2 En el TP 8a mencionamos r\u00e1pidamente al paquete ggplot2 , el cual es uno de las formas m\u00e1s populares de hacer plots en R . Este paquete es bastante complicado y tiene un sinf\u00edn de funcionalidades, pero hoy vamos a darle un vistazo a su funcionalidad b\u00e1sica (el cheatsheet es una forma r\u00e1pida de ver todas las posibilidades que tiene). Un ejemplo muy simple de hacer un plot con la funci\u00f3n ggplot ser\u00eda: library ( ggplot2 ) #Recuerden que *iris* es un *Data Frame* para hacer pruebas que esta siempre cargado en la memoria de R p <- ggplot ( data = iris , aes ( x = Petal.Length , y = Sepal.Length )) + geom_point () print ( p ) p es una variable en la que estoy guardando el plot. Cuando la imprimo (usando print ) el plot va a aparecer en la pesta\u00f1a Plots en RStudio (en el panel de abajo a la derecha). data = iris le est\u00e1 indicando a la funci\u00f3n ggplot de que tabla va a sacar la informaci\u00f3n a plotear. En ggplot se pueden usar Data Frames o Data Tables indistintamente. aes() es una funci\u00f3n que se encuentra dentro de la funci\u00f3n principal de ggplot . Se va a encargar de relacionar las diferentes columnas de la tabla con las diferentes variables del plot. x = Petal.Length est\u00e1 indicando que la variable X en el plot va a ser los datos de la columna Petal.Length . y = Sepal.Length est\u00e1 indicando que la variable Y en el plot va a ser los datos de la columna Sepal.Length . geom_point() est\u00e1 indicando el tipo de plot a realizar. Si leen el cheatsheet van a ver que en este caso estamos haciendo un scatter plot. Ambas funciones del plot est\u00e1n separadas por el s\u00edmbolo + , lo que les puede resultar un poco extra\u00f1o (porque lo es), pero as\u00ed es como funciona ggplot . 1) Corran el c\u00f3digo anterior y vean el plot resultante. Cambiar la est\u00e9tica del plot seg\u00fan variables La funci\u00f3n aes() recibe su nombre de la palabra en ingl\u00e9s aesthetics , o est\u00e9tica. No es de extra\u00f1ar entonces que dentro de dicha funci\u00f3n es donde podemos poner otras variables que determinen los colores, formas o tama\u00f1os de cada punto del plot (entre otras caracter\u00edsticas). 2) Corran el siguiente c\u00f3digo y vean el plot resultante: p <- ggplot ( data = iris , aes ( x = Petal.Length , y = Sepal.Length , color = Species )) + geom_point () print ( p ) En este c\u00f3digo, color = Species le est\u00e1 diciendo a ggplot que modifique el color de los puntos dependiendo del valor de la columna Species . Si recuerdan a iris , esta columna era una columna categ\u00f3rica (o factor ) con 3 valores que podemos ver en el plot. Como le pasamos a color una variable categ\u00f3rica, nos devolvi\u00f3 una escala de colores categ\u00f3rica. 3) Corran el c\u00f3digo anterior, pero ahora reemplacen a Species por Petal.Width , \u00bfqu\u00e9 cambios observan? 4) Es posible tambi\u00e9n modificar varias de estas caracter\u00edsticas a la vez. Corran el siguiente c\u00f3digo y vean el plot resultante: p <- ggplot ( data = iris , aes ( x = Petal.Length , y = Sepal.Length , color = Species , shape = Species , size = Petal.Width )) + geom_point () print ( p ) En este caso agregamos 2 caracter\u00edsticas nuevas, shape (la forma de los puntos) y size (el tama\u00f1o de los puntos) y le asignamos cada uno de ellos a una variable de la tabla. Noten que no hay problema con que una columna modifique m\u00e1s de una caracter\u00edstica a la vez. 5) Tal vez ya lo notaron, pero por el momento no tenemos ning\u00fan control sobre que colores o formas le asigna ggplot a mis tres categor\u00edas. Vamos a mostrarles como hacerlo para este caso espec\u00edfico, pero sepan que las funciones a usar son ligeramente diferentes dependiendo si la variable pasada es discreta o continua. Corran el siguiente c\u00f3digo y vean el plot resultante: #Los colores se pueden escribir en ingles o en hexadecimal #\"#FF0000\" es el color rojo (se podr\u00eda haber puesto \"red\") p <- ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species , shape = Species )) + geom_point () + scale_colour_manual ( values = c ( \"#FF0000\" , \"blue\" , \"green\" )) + scale_shape_manual ( values = c ( 2 , 4 , 1 )) print ( p ) scale_colour_manual() : me permite modificar a mano una escala discreta de colores. El par\u00e1metro values modifica los colores en s\u00ed. scale_shape_manual() : me permite modificar a mano una escala discreta de formas. El par\u00e1metro values modifica las formas, las cuales corresponden a un n\u00famero entero (en el tip a continuaci\u00f3n se muestran las m\u00e1s comunes). Un detalle importante a destacar es que el orden en que se asign\u00f3 cada color a cada categor\u00eda depende del orden en el que aparecen los Levels de la columna Species , la cual es un factor (pueden imprimir iris$Species para ver a lo que nos referimos). Tip - Posibles valores para shape El color interior las formas 21 a 25 depende de la variable fill que no mencionamos todav\u00eda, pero se usa igual que el resto. Tip - Colores y daltonismo El daltonismo ocurre cuando hay un problema con los pigmentos en ciertas c\u00e9lulas nerviosas del ojo que perciben el color. Estas c\u00e9lulas se llaman conos y los hay de tres tipos, los cuales son responsables de ver principalmente al rojo, al verde y al azul respectivamente. La frecuencia del daltonismo es bastante alta, con un 8% de los hombres cauc\u00e1sicos, 5% de los asi\u00e1ticos y 4% de los africanos presentando problemas para distinguir el color rojo del verde. Como la mayor\u00eda de los casos de daltonismo provienen de una mutaci\u00f3n de un gen recesivo ligado al cromosoma X, muy pocas mujeres son dalt\u00f3nicas. Debido al considerable n\u00famero de personas con daltonismo, es buena \u00eddea tener en cuenta esto al momento de elegir colores para cualquier figura que vaya a ser vistas por el p\u00fablico general. Se pueden encontrar decenas de herramientas online que nos ayudan a crear esto, as\u00ed como paquetes de R o paletas de colores. Un ejemplo de una paleta de colores ser\u00eda: Pueden leer m\u00e1s informaci\u00f3n sobre este tema aca . Tip - Asignar colores espec\u00edficos a cada caracter\u00edstica sin depender del orden de los Levels Si bien el c\u00f3digo anterior funciona perfecto, depender del orden de los Levels de un factor al momento de matchear color con un valor dado puede ser peligroso. Una forma de estar seguros que le estamos asignando el color correcto a cada valor es usando vectores con nombres (o named vectors ). Algo mencionamos de estos vectores en el pasado, pero b\u00e1sicamente son vectores donde cada posici\u00f3n tiene un nombre (adem\u00e1s del \u00edndice). En este caso ser\u00eda: categorias <- c ( \"setosa\" , \"versicolor\" , \"virginica\" ) colores <- c ( \"#FF0000\" , \"blue\" , \"green\" ) names ( colores ) <- categorias #Puedo acceder a \"blue\" haciendo `colores[2]` o `colores[\"versicolor\"]` De hacer scale_colour_manual(values = colores) en la funci\u00f3n ggplot nos asegurar\u00edamos que el primer elemento de categorias va a tener el primer color de colores y as\u00ed. 6) Por \u00faltimo, \u00bfqu\u00e9 pasa si no queremos cambiar la est\u00e9tica del plot dependiendo del valor de una variable, sino que simplemente queremos cambiarla y que afecte a todos los puntos por igual? En estos casos hay que modificar dicha caracter\u00edstica dentro de la funci\u00f3n espec\u00edfica del plot. Corran el siguiente c\u00f3digo y vean el plot resultante: p <- ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species )) + geom_point ( size = 2 , shape = 4 ) + scale_colour_manual ( values = c ( \"#FF0000\" , \"blue\" , \"green\" )) print ( p ) Nombres y estilo de los ejes y el plot 7) Ahora que ya modificamos bastante el estilo de los datos, vamos a modificar el resto del plot. Lo primero que vamos a hacer es cambiar el nombre del eje X, el eje Y y el t\u00edtulo del plot. Corran el siguiente c\u00f3digo y vean el plot resultante: p <- ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species , shape = Species )) + geom_point ( size = 2 ) + xlab ( \"Sepal Length\" ) + ylab ( \"Petal Length\" ) + ggtitle ( \"Sepal Length vs Petal Length per Species\" ) + scale_colour_manual ( values = c ( \"#FF0000\" , \"blue\" , \"green\" )) + scale_shape_manual ( values = c ( 2 , 4 , 1 )) print ( p ) xlab() : indica el nombre del eje X ylab() : indica el nombre del eje Y ggtitle() : indica el t\u00edtulo del plot 8) Si bien obtuvimos lo deseado, puede ser que queramos cambiar el tama\u00f1o de los ejes o centrar el t\u00edtulo. Esto lo hacemos con la funci\u00f3n theme() : Corran el siguiente c\u00f3digo y vean el plot resultante: p <- ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species , shape = Species )) + geom_point ( size = 2 ) + xlab ( \"Sepal Length\" ) + ylab ( \"Petal Length\" ) + ggtitle ( \"Sepal Length vs Petal Length per Species\" ) + theme ( plot.title = element_text ( size = 16 , hjust = 0.5 ), axis.title = element_text ( size = 14 ), axis.text = element_text ( size = 12 )) + scale_colour_manual ( values = c ( \"#FF0000\" , \"blue\" , \"green\" )) + scale_shape_manual ( values = c ( 2 , 4 , 1 )) print ( p ) theme() : es la funci\u00f3n que contiene el estilo del texto de los ejes y del t\u00edtulo de un plot. plot.title = element_text(size = 16, hjust = 0.5) : estamos modificando el titulo del plot, donde size modifica el tama\u00f1o de letra y hjust = 0.5 lo centra horizontalmente. axis.title = element_text(size = 14) : estamos modificando los t\u00edtulos de los ejes (es decir, los nombre de los ejes). axis.text = element_text(size = 12) : estamos modificando el tama\u00f1o de los n\u00fameros de los ejes. Noten que dentro de theme() cada l\u00ednea se separa con comas, y reci\u00e9n una vez que termina volvemos a usar el s\u00edmbolo + . Fondo del plot 9) Lo \u00faltimo que nos queda por modificar es el \"fondo\" del plot, es decir, el color de fondo, las l\u00edneas que corresponden a las divisiones de los ejes y el recuadro general del plot. Si bien esto se puede hacer a mano, ggplot viene con algunas opciones ya armadas. Corran el siguiente c\u00f3digo y vean el plot resultante: p <- ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species , shape = Species )) + geom_point ( size = 2 ) + xlab ( \"Sepal Length\" ) + ylab ( \"Petal Length\" ) + ggtitle ( \"Sepal Length vs Petal Length per Species\" ) + theme_bw () + theme ( plot.title = element_text ( size = 16 , hjust = 0.5 ), axis.title = element_text ( size = 14 ), axis.text = element_text ( size = 12 )) + scale_colour_manual ( values = c ( \"#FF0000\" , \"blue\" , \"green\" )) + scale_shape_manual ( values = c ( 2 , 4 , 1 )) print ( p ) theme_bw() es una funci\u00f3n que setea varias opciones de theme() a un estilo espec\u00edfico (en este caso un estilo simple en blanco y negro). La tenemos que usar antes de theme() para asegurarnos que cualquier cambio que hagamos a mano en theme() sobrescriba los de theme_bw() . Otros tipos de plots Si bien la mayor\u00eda de lo que les mencionamos hasta ahora es aplicable al uso general de ggplot , hasta el momento nos enfocamos en un solo tipo de plot, el scatter plot, hecho mediante geom_point() . Debido a que esto es suficiente para lo que necesitamos hacer hoy (y que este TP es de Data Mining ) no vamos a hablar hoy de otros tipos de plots, pero si les interesa pueden verlo con mucho detalle en esta p\u00e1gina o ver un vistazo r\u00e1pido en la cheatsheet . Ejercicio 1 - Agrupando flores por especies Introducci\u00f3n al data set En este ejercicio vamos a trabajar una vez m\u00e1s con el data set iris , el cual es un set de datos que viene por defecto con R y est\u00e1 siempre cargado en memoria. Este data set contiene las medidas de ancho ( width ) y largo ( length ) de los s\u00e9palos y los p\u00e9talos para 3 especies de flores diferentes: setosa, versicolor, y virginica (todas del Genus Iris ). Tiene mediciones de 150 flores, 50 por especie. S\u00e9palo vs p\u00e9talo Antes que nada vamos a familiarizarnos un poco con este data set. 1) Corran el siguiente c\u00f3digo y vean el plot resultante: library ( data.table ) library ( ggplot2 ) #Transformo a iris en un *Data Table* (que aca realmente no hace falta, pero para despues) dt_iris <- as.data.table ( iris ) #Hago un plot comparando el largo de los sepalos y los petalos #Estoy cambiando la forma y el color segun la especie p <- ggplot ( data = dt_iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species )) + geom_point ( size = 2 ) + theme_bw () + xlab ( \"Sepal Length\" ) + ylab ( \"Petal Length\" ) + ggtitle ( \"Sepal Length vs Petal Length per Species\" ) + theme ( plot.title = element_text ( size = 16 , hjust = 0.5 ), axis.title = element_text ( size = 14 ), axis.text = element_text ( size = 12 )) + scale_colour_manual ( values = c ( \"#004D40\" , \"#D81B60\" , \"#FFC107\" )) print ( p ) Podemos ver que con solo plotear el largo de los p\u00e9talos y los s\u00e9palos ya estamos viendo diferencias entre las especies. Es te\u00f3ricamente posible agregar una tercera dimensi\u00f3n para plotear otra de las variables, e incluso agregar la cuarta variable como \"tama\u00f1o\" de los diferentes puntos, pero dichos plots van a resultar considerablemente mas complejos al momento de leerlos. Problema a resolver En este ejercicio vamos a suponer que alguien apret\u00f3 el bot\u00f3n equivocado y borr\u00f3 la columna Species de dicha tabla. Como nos acordamos de que eran tres especies y que ten\u00edan diferencias en sus largos y anchos de p\u00e9talos y s\u00e9palos, queremos entonces usar m\u00e9todos de clustering para tratar de recuperar lo mejor que podamos los tres grupos de flores. Dicho esto vamos a hacer un poco de trampa y vamos a comparar visualmente lo que vamos obteniendo por los m\u00e9todos de clustering con lo que nosotros sabemos es verdad. Por \u00faltimo, c\u00f3mo vamos a tener que hacer varios plots similares, vamos a aprovechar la oportunidad y vamos a usar por primera vez funciones de R creadas por nosotros. Guardar el plot en un PDF Vamos a crear una funci\u00f3n que guarde diferentes plots como PDFs. 2) Copien el siguiente c\u00f3digo y modifiquen la secci\u00f3n que dice @@EDITAR@@ (pueden ver los comentarios para entender mejor ciertas partes del c\u00f3digo). Agreguen todos los par\u00e1metros necesarios para que al correr la funci\u00f3n se replique el plot hecho en el punto 1) y se guarde en un archivo llamado 01_Sepal_vs_Petal_Length_per_Species.pdf . C\u00f3digo C\u00f3digo con comentarios library ( data.table ) library ( ggplot2 ) #### FUNCIONES AUXILIARES #### plotData2PDF_wColor <- function ( data_par , x_colname , y_colname , color_colname , x_label , y_label , plot_title , pdf_file ) { p <- ggplot ( data = data_par , aes_string ( x = x_colname , y = y_colname , color = color_colname )) + geom_point ( size = 2 ) + theme_bw () + xlab ( x_label ) + ylab ( y_label ) + ggtitle ( plot_title ) + theme ( plot.title = element_text ( size = 16 , hjust = 0.5 ), axis.title = element_text ( size = 14 ), axis.text = element_text ( size = 12 )) + scale_colour_manual ( values = c ( \"#004D40\" , \"#D81B60\" , \"#FFC107\" )) pdf ( file = pdf_file , width = 8 , height = 7 ) print ( p ) dev.off () } #### CODIGO PRINCIPAL #### dt_iris <- as.data.table ( iris ) plotData2PDF_wColor ( data_par = dt_iris , @@ EDITAR @@ , pdf_file = \"01_Sepal_vs_Petal_Length_per_Species.pdf\" ) library ( data.table ) library ( ggplot2 ) #Estoy usando comentarios rodeados de cuatro numerales para delimitar secciones de mi c\u00f3digo #Esto no es puramente est\u00e9tico, sino que tambi\u00e9n es aprovechado por *RStudio* para crear una de barra de #navegaci\u00f3n del c\u00f3digo (es la barra horizontal entre el script y la consola) #### FUNCIONES AUXILIARES #### plotData2PDF_wColor <- function ( data_par , x_colname , y_colname , color_colname , x_label , y_label , plot_title , pdf_file ) { #La funci\u00f3n *aes_string()* es similar a *aes()*, solo que en este caso los nombres de las columnas #tienen que ser *strings* (recuerden que con *aes()* se escriben sin comillas) #Esto es ideal para cuando el nombre de la columna utilizar esta guardado en una variable p <- ggplot ( data = data_par , aes_string ( x = x_colname , y = y_colname , color = color_colname )) + geom_point ( size = 2 ) + theme_bw () + xlab ( x_label ) + ylab ( y_label ) + ggtitle ( plot_title ) + theme ( plot.title = element_text ( size = 16 , hjust = 0.5 ), axis.title = element_text ( size = 14 ), axis.text = element_text ( size = 12 )) + scale_colour_manual ( values = c ( \"#004D40\" , \"#D81B60\" , \"#FFC107\" )) #*pdf()* \"abre\" un archivo pdf. Todo lo que se imprima hasta cerrarlo va a ir a \u00e9l, #en vez de a la pesta\u00f1a *Plots* de *RStudio* #8 y 7 indican el ancho y el alto del pdf en pulgadas pdf ( file = pdf_file , width = 8 , height = 7 ) print ( p ) #La funci\u00f3n *dev.off()* cierra el plot abierto, en este caso el pdf. dev.off () } #### CODIGO PRINCIPAL #### dt_iris <- as.data.table ( iris ) plotData2PDF_wColor ( data_par = dt_iris , @@ EDITAR @@ , pdf_file = \"01_Sepal_vs_Petal_Length_per_Species.pdf\" ) 3) Usando la funci\u00f3n que acabamos de crear, vean como se distribuyen los puntos al comparar Sepal.Width contra Petal.Width . Guarden este plot en un archivo llamado 02_Sepal_vs_Petal_Width_per_Species.pdf . Clustering jer\u00e1rquico Lo primero que vamos a hacer entonces es usar un clustering jer\u00e1rquico para agrupar a las 150 filas en 3 grupos seg\u00fan los valores de las 4 medidas. Un problema que tenemos es que por ahora no hay ninguna forma de identificar a una fila espec\u00edfica, as\u00ed que le vamos a agregar un ID num\u00e9rico a cada fila. Debido al orden que tienen las filas de dt_iris , los primeros 50 IDs van a corresponder a flores de la especie setosa, los segundos 50 a versicolor y los \u00faltimos a virginica (aunque supuestamente esto no lo sabemos). 4) Corran el siguiente c\u00f3digo para crear la matriz de datos que vamos a usar al momento de clusterizar. Lean los comentarios en la segunda pesta\u00f1a para entender que estamos haciendo. C\u00f3digo C\u00f3digo con comentarios dt_iris $ row_id <- c ( 1 : dt_iris [, .N ]) setcolorder ( dt_iris , c ( \"row_id\" )) matriz_datos <- as.matrix ( dt_iris [, - c ( \"Species\" )], rownames = 1 ) #Agregamos una nueva columna denominada row_id que tiene un numero entre 1 y 150 #dt_iris[, .N] es una funci\u00f3n de *Data Tables* que me devuelve el numero de filas en la tabla #El numero de filas tambien se puede conseguir haciendo nrow(dt_iris) dt_iris $ row_id <- c ( 1 : dt_iris [, .N ]) #Aca estamos cambiando el orden de las columnas a *dt_iris*. #No hace falta asignar esto a *dt_iris* ya que *setcolorder* modifica la variable misma #Como solo le estamos pasando 1 columna, lo que estamos haciendo es mover esa columna al principio #(al usar as\u00ed *setcolorder* las otras se quedan donde estan) setcolorder ( dt_iris , c ( \"row_id\" )) #Similar a lo que hicimos en el TP anterior, estamos transformando nuestros datos a una matriz #donde la primer columna (en este caso *row_id*) va a transformarse en los nombres de las filas #Estamos sacando a la columna *Species* ya que queremos simular que no tenemos esta informacion #(la columna *Species* va a estar todavia en *dt_iris*, pero no en *matriz_datos*) matriz_datos <- as.matrix ( dt_iris [, - c ( \"Species\" )], rownames = 1 ) 5) Usando lo aprendido en el TP anterior y la matriz de datos reci\u00e9n creada: 5.1) Usen la funci\u00f3n dist() para crear una matriz de distancias euclidianas que muestre tambi\u00e9n la diagonal. 5.2) usen la funci\u00f3n hclust() para crear un clustering jer\u00e1rquico basado en su matriz de distancias usando el criterio de agregaci\u00f3n complete linkage . 5.3) Usen la funci\u00f3n plot() para plotear el clustering jer\u00e1rquico. 5.4) Mirando el plot reci\u00e9n creado, \u00bfles es f\u00e1cil distinguir a simple vista los tres grupos de especies en el clustering jer\u00e1rquico? (recuerden que pueden usar el bot\u00f3n Zoom para agrandar el plot). Mejorar el plot del clustering jer\u00e1rquico 6) Una cosa que vendr\u00eda bien al momento de leer el plot reci\u00e9n creado ser\u00eda colorear cada flor dependiendo de su especie. Si bien esto no es posible en este caso usando solo la funci\u00f3n plot() , hay paquetes de R que nos van a permitir hacer esto: 6.1) Usen la funci\u00f3n install.packages() e instalen la librer\u00eda dendextend (recuerden que al usar install.packages() el nombre del paquete va entre comillas). Luego corran el siguiente c\u00f3digo: C\u00f3digo C\u00f3digo con comentarios library ( dendextend ) #Estoy asumiendo que guardaron la salida de *hclust()* en una variable llamada clustering_jerarquico #De no ser asi, cambien el nombre de la variable a continuacion por lo que corresponda dend <- as.dendrogram ( clustering_jerarquico ) colores_especies <- c ( \"#004D40\" , \"#D81B60\" , \"#FFC107\" ) colors_aux <- rep ( colores_especies , each = 50 ) labels_colors ( dend ) <- colors_aux [ order.dendrogram ( dend )] dend <- dend %>% set ( \"labels_cex\" , 0.6 ) pdf_file <- \"11_Clustering_jerarquico_complete_linkage.pdf\" pdf ( file = pdf_file , width = 18 , height = 6 ) plot ( x = dend , main = \"Clustering Jer\u00e1rquico - Complete Linkage - Color per Species\" ) dev.off () library ( dendextend ) #Estoy asumiendo que guardaron la salida de *hclust()* en una variable llamada clustering_jerarquico #De no ser asi, cambien el nombre de la variable a continuacion por lo que corresponda #Aca estoy transformando la variable *clustering_jerarquico* que es de tipo *hclust* a un *dendrogram*, #que es una variable usada por el paquete *dendextend* dend <- as.dendrogram ( clustering_jerarquico ) #La funcion *labels_colors()* me permite asignar a mano los colores para los 150 labels del dendrograma #Ahora bien, yo se que originalmente en la tabla las primera 50 filas corresponden al color 1 y asi #Lo que estoy haciendo aca es armar una lista de 150 colores ordenada como esta en la tabla original y luego #reordenarlas para que coincidan con el orden de los IDs en el dendrograma colores_especies <- c ( \"#004D40\" , \"#D81B60\" , \"#FFC107\" ) colors_aux <- rep ( colores_especies , each = 50 ) labels_colors ( dend ) <- colors_aux [ order.dendrogram ( dend )] #Esto simplemente es para achicar un poco el texto de los labels para que no choquen entre si #El simbolo %>% cumple una funcion similar al + en ggplot dend <- dend %>% set ( \"labels_cex\" , 0.6 ) #Creo el pdf de salida y guardo el clustering jer\u00e1rquico pdf_file <- \"11_Clustering_jerarquico_complete_linkage.pdf\" pdf ( file = pdf_file , width = 18 , height = 6 ) plot ( x = dend , main = \"Clustering Jer\u00e1rquico - Complete Linkage - Color per Species\" ) dev.off () 6.2) Abran el archivo 11_Clustering_jerarquico_complete_linkage.pdf . \u00bfPueden ahora distinguir los tres grupos de especies en el clustering jer\u00e1rquico? \u00bfCu\u00e1les especies les parecen mejor agrupadas? (los colores de las especies corresponden al color usado en el plot creado en los puntos 1) y 2) ) Single Linkage 7) Hasta el momento s\u00f3lo utilizamos complete linkage al momento de hacer nuestros clustering jer\u00e1rquicos, pero ser\u00eda interesante ver como es el dendrograma resultante de hacer el clustering usando otro criterio de agregaci\u00f3n, por ejemplo el single linkage . Para esto: 7.1) Vuelvan a correr la funci\u00f3n hclust() como en 5.2) , pero ahora usen method = \"single\" y guarden el clustering resultante en una nueva variable. Luego usen el c\u00f3digo de 6.1) editando lo que sea necesario para crear un archivo que contenga al dendrograma hecho a partir del clustering jer\u00e1rquico que usa single linkage como criterio de agregaci\u00f3n. Nombren a este archivo 12_Clustering_jerarquico_single_linkage.pdf . 7.2) \u00bfQu\u00e9 diferencias ven entre este dendrograma y el creado en 6.2) ? \u00bfPueden relacionar estas diferencias con lo que saben de single linkage y complete linkage ? 7.3) Ignorando los colores, \u00bfcu\u00e1l les parece el mejor criterio de agregaci\u00f3n para este caso donde queremos recuperar tres clusters? Hacer clusters y plots Por \u00faltimo vamos a querer recrear el plot generado en los puntos 1) y 2) , pero ahora mostrando informaci\u00f3n tanto de las especies originales (con el color) como de la agrupaci\u00f3n resultante del clustering jer\u00e1rquico (con la forma). Vamos a utilizar los datos del clustering jer\u00e1rquico que usa el criterio de agregaci\u00f3n complete linkage . 8) Lo primero es entonces agregar la informaci\u00f3n del clustering jer\u00e1rquico a nuestro dt_iris ; para ello: 8.1) Usen la cutree para dividir a los datos obtenidos en 5.2) en 3 clusters. 8.2) Asignen esa informaci\u00f3n a una nueva columna en la tabla dt_iris llamada CJ_cluster . 8.3) Por el momento la variable es num\u00e9rica, pero para nosotros los n\u00fameros 1, 2 y 3 son categor\u00edas que te\u00f3ricamente corresponden a las especies (aunque no sabemos qu\u00e9 categor\u00eda corresponde a que especie). Corran el siguiente c\u00f3digo para convertir la columna reci\u00e9n creada en un factor : #En este caso poner los levels a mano no es 100% necesario, pero no viene mal #Recuerden que no sabemos que numero corresponde a que especie #(porque ademas ya vimos que no hay un match perfecto 1 a 1) dt_iris $ CJ_cluster <- factor ( dt_iris $ CJ_cluster , levels = c ( 1 , 2 , 3 )) 9) Ahora queremos hacer un plot similar al creado en el punto 2) , pero donde la columna Species determine el color y la columna CJ_cluster determine la forma de los diferentes puntos del plot; para ello: 9.1) Copien la funci\u00f3n plotData2PDF_wColor() y c\u00e1mbienle en nombre a plotData2PDF_wColorAndShape() . Modifiquen esta nueva funci\u00f3n considerando lo siguiente: Agreguen un par\u00e1metro a la funci\u00f3n el cual va a recibir el nombre de la columna que determina la forma, o shape , de los puntos. Modifiquen la funci\u00f3n aes_string() , agregando la caracter\u00edstica shape y asign\u00e1ndole el valor del par\u00e1metro agregado. Agreguen la funci\u00f3n scale_shape_manual() a ggplot para definir a mano las tres formas. Usen los valores c(2, 4, 1) . 9.2) Usando la funci\u00f3n que acabamos de crear, vean como se distribuyen los puntos al comparar Sepal.Length contra Petal.Length usando la columna Species para determinar el color y la columna CJ_cluster para determinar la forma de los diferentes puntos. Guarden este plot en un archivo llamado 21_Sepal_vs_Petal_Width_per_Species_CJ3.pdf . 9.3) Abran el archivo reci\u00e9n creado. \u00bfCu\u00e1les especies les parecen mejor agrupadas? Entre este plot y el dendrograma creado en 11_Clustering_jerarquico_complete_linkage.pdf \u00bfCu\u00e1l les parece la mejor manera de representar este clustering? \u00bfPor qu\u00e9? Importante - Clustering vs Plot Tengan en cuenta que al momento de clusterizar estamos usando los datos de las cuatro columnas de la tabla. Sin embargo, en este \u00faltimo plot estamos viendo solo la relaci\u00f3n entre dos. Por esta raz\u00f3n, este plot no es realmente representativo del clustering que estamos haciendo. Dicho todo esto, este plot es \u00fatil ya que es mucho m\u00e1s f\u00e1cil de leer que otros plots m\u00e1s complejos, pero debe tomarse como un an\u00e1lisis exploratorio. Kmeans 10) Lo \u00faltimo que vamos a hacer con este data set es volver a crear los clusters pero usando ahora la funci\u00f3n kmeans() . 10.1) Usando lo aprendido en el TP anterior: Usen la funci\u00f3n kmeans() para crear un nuevo clustering. Usen la cantidad de centers que consideren necesarios. Extraigan los clusters del clustering reci\u00e9n creado y as\u00edgnenlos a una nueva columna en dt_iris llamada K3_cluster . Transformen dicha columna en un factor . Usando la funci\u00f3n creada en el punto 9) , vean como se distribuyen los puntos al comparar Sepal.Length contra Petal.Length usando la columna Species para determinar el color y la columna K3_cluster para determinar la forma de los diferentes puntos. Guarden este plot en un archivo llamado 22_Sepal_vs_Petal_Width_per_Species_K3.pdf . 10.2) Abran el archivo reci\u00e9n creado. Bas\u00e1ndose solo en lo que pueden observar en este plot, \u00bfpueden decir algo de si este agrupamiento es mejor, peor o similar al obtenido con el clustering jer\u00e1rquico? (recuerden que \"no\" tambi\u00e9n es una respuesta v\u00e1lida) 10.3) Supongamos ahora que estamos en un escenario real, por lo que no tenemos informaci\u00f3n de a que especie corresponde cada punto. En base a lo visto en el TP anterior, \u00bfse les ocurre alguna forma de evaluar objetivamente cu\u00e1l de ambos es el mejor clustering? Tip - Predeterminar el azar La funci\u00f3n kmeans() genera la primera posici\u00f3n de sus centros al azar. Esto hace que si la corren varias veces o en diferentes computadoras va a dar diferentes resultados cada vez. Esto se puede controlar con una funci\u00f3n de R que asigna a mano el valor de la seed , que es el n\u00famero base que usa R al momento de generar azar. Si les interesa hacer esto tienen que ejecutar la siguiente l\u00ednea antes de usar la funci\u00f3n kmeans() : set.seed ( 1 ) P.D.: El azar en las computadoras no existe realmente. Muchos programas usan lista pre-generadas de \"n\u00fameros creados al azar\" y otras usan cosas como \"el quinto decimal de la temperatura del procesador en este momento\", lo que se aproxima suficientemente al azar para funcionar bien. Ejercicio 2 - Analizando el efecto de dos inhibidores En el TP 8b hicimos un ejercicio donde us\u00e1bamos el equipo FilterMax F5 para analizar 22 inhibidores de una llamada Enzima Z , la cual resulta que era la cruzipa\u00edna, es decir, la ciste\u00edn proteasa principal de Trypanosoma cruzi , el par\u00e1sito causante de la enfermedad de Chagas. En esta segunda fase del experimento se eligieron 2 inhibidores y se realiz\u00f3 un an\u00e1lisis m\u00e1s detallado, estudiando como var\u00eda la expresi\u00f3n de miles de genes en presencia o ausencia de dichos inhibidores. Para esto se hizo un estudio de transcript\u00f3mica (RNA-seq) donde se extrajo el ARN y se lo analiz\u00f3 con Illumina . Luego, cada read encontrado se mape\u00f3 contra el genoma de referencia y se lleg\u00f3 a una tabla de conteo para cada uno de las transcriptos del genoma. Para cada caso ( control , droga 1 y droga 2 ) se realizaron 3 r\u00e9plicas t\u00e9cnicas para obtener resultados m\u00e1s robustos. Nuestro objetivo va a ser entonces obtener una lista de los genes que son m\u00e1s afectados por cada droga. Leer los datos 1) Lean los archivos control_data.tsv , drug1_data.tsv y drug2_data.tsv que se encuentran en sus materiales de trabajo y gu\u00e1rdenlos en diferentes variables llamadas control_data , drug1_data y drug2_data respectivamente. Estandarizar los datos El conteo de reads no se puede comparar entre genes puesto que la expresi\u00f3n basal de cada uno es distinto, por lo cual encontrar 10 reads de un gen puede ser mucho, y encontrar 1000 de otro puede ser poco. Adem\u00e1s cada ensayo de secuenciaci\u00f3n puede tener distinta profundidad con lo que tampoco ser\u00eda viable comparar 10 reads de un ensayo donde en total se mapearon \\(2\\text{x}10^8\\) reads con los mismos 10 de otro ensayo donde se mapearon \\(1\\text{x}10^8\\) (es decir, la mitad). Por esta raz\u00f3n vamos a querer modificar las nueve columnas y transformar el valor a \"conteo por mill\u00f3n\", cuya f\u00f3rmula es: \\[ \\text{RPM or CPM} = \\frac{ReadsDelGen * 10^6}{ReadsTotales} \\] Combinar las r\u00e9plicas Otra cosa que vamos a querer hacer es combinar las tres r\u00e9plicas para cada caso. Esto lo vamos a hacer simplemente promediando los 3 valores de CPM para cada gen en cada tratamiento. 2) En base a los TPs anteriores ya tienen los conocimientos para hacer el estandarizado de datos y la combinaci\u00f3n de r\u00e9plicas usando fors , pero para hacerla un poco m\u00e1s f\u00e1cil les vamos a dar un par de funciones que les van a simplificar bastante este paso (y ya que estamos les mostramos la funci\u00f3n apply() en acci\u00f3n): C\u00f3digo C\u00f3digo con comentarios calcularConteoPorMillon <- function ( vector_cuentas ) { #Dado un vector de *reads*, esta funcion lo transforma en CPM y devuelve el vector vector_cuentas <- vector_cuentas * 1000000 / sum ( vector_cuentas ) return ( vector_cuentas ) } parsearDatos <- function ( dt_par , columnas_a_parsear , nombre_columna_nueva ) { #Dado un *Data Table*, un vector de *strings* con los nombres de las columnas con *reads* a parsear y #un nombre de una columna a crear, esta funcion: # - Transforma los *reads* de las columnas a parsear en CPM # - Calcula el promedio de los CPM por cada fila y lo guarda en una columna nueva con el nombre dado # - Saca las columnas a parsear del *Data Table* # - Devuelve el *Data Table* con los cambios dt_aux <- dt_par [, columnas_a_parsear , with = F ] matrix_aux <- apply ( dt_aux , 2 , calcularConteoPorMillon ) dt_par [[ nombre_columna_nueva ]] <- apply ( matrix_aux , 1 , mean ) dt_par [[ nombre_columna_nueva ]] <- round ( dt_par [[ nombre_columna_nueva ]], 4 ) dt_par <- dt_par [, - columnas_a_parsear , with = F ] return ( dt_par ) } calcularConteoPorMillon <- function ( vector_cuentas ) { #Dado un vector de *reads*, esta funcion lo transforma en CPM y devuelve el vector #Aca estoy asumiendo que sum(vector_cuentas) nunca es 0 (lo que tiene un poco #de sentido ya que si es 0 entonces todas los counts son 0) vector_cuentas <- vector_cuentas * 1000000 / sum ( vector_cuentas ) return ( vector_cuentas ) } parsearDatos <- function ( dt_par , columnas_a_parsear , nombre_columna_nueva ) { #Dado un *Data Table*, un vector de *strings* con los nombres de las columnas con *reads* a parsear y #un nombre de una columna a crear, esta funcion: # - Transforma los *reads* de las columnas a parsear en CPM # - Calcula el promedio de los CPM por cada fila y lo guarda en una columna nueva con el nombre dado # - Saca las columnas a parsear del *Data Table* # - Devuelve el *Data Table* con los cambios #Creo un nuevo *Data Table* que solo contenga las columnas a parsear (y no el ID del gen) dt_aux <- dt_par [, columnas_a_parsear , with = F ] #La funcion *apply* con el parametro 2 va a ejecutar la funcion *calcularConteoPorMillon* para #cada COLUMNA de dt_aux (las tres replicas, en este caso) matrix_aux <- apply ( dt_aux , 2 , calcularConteoPorMillon ) #La funcion *apply* con el parametro 1 va a ejecutar la funcion *mean* para #cada FILA de matrix_aux (cada uno de los genes estudiados) dt_par [[ nombre_columna_nueva ]] <- apply ( matrix_aux , 1 , mean ) dt_par [[ nombre_columna_nueva ]] <- round ( dt_par [[ nombre_columna_nueva ]], 4 ) #Saco las columnas que ya no me interesan de *dt_par* dt_par <- dt_par [, - columnas_a_parsear , with = F ] return ( dt_par ) } 2.1) Corran las funciones anteriores para cargarlas en memoria, luego \u00fasenlas para estandarizar y combinar las r\u00e9plicas del control y las drogas 1 y 2. Un ejemplo de correr esta funci\u00f3n para el caso de control ser\u00eda: control_data <- parsearDatos ( dt_par = control_data , columnas_a_parsear = c ( \"control1\" , \"control2\" , \"control3\" ), nombre_columna_nueva = \"control\" ) 2.2) Ahora que ya tenemos los datos parseados, usen la funci\u00f3n merge() dos veces para combinar los 3 Data Tables en uno solo llamado full_data (si todo sali\u00f3 bien deber\u00eda tener 11.106 filas y 4 columnas). Calcular el Fold Change 3) Algo mencionamos antes, pero concluir que \"hay 10 CPM m\u00e1s al agregarle la droga\" no significa nada en el vac\u00edo. Si en el control era solo 1 CPM, entonces 10 m\u00e1s es mucho. Si en el control eran 10.000 CPM, 10 m\u00e1s es insignificante. Vamos entonces a calcular el fold change, es decir, cuantas veces m\u00e1s (o menos) de CPM fueron observados al agregarle la droga frente a cuando estaba solo el control. Esto lo calculamos como: \\[ \\text{Fold Change} = \\frac{\\text{CPM Droga}}{\\text{CPM Control}} \\] 3.1) Antes de seguir leyendo \u00bfSe les ocurre alg\u00fan caso donde la f\u00f3rmula anterior nos de problemas? Respuesta B\u00e1sicamente hay 2 casos donde el c\u00e1lculo del Fold Change va a dar problemas: Cuando CPM Control = 0 : La divisi\u00f3n no se puede hacer (y de hacerla en R va a dar infinito) Cuando CPM Control ~ 0 : En este caso la divisi\u00f3n se hace, pero el Fold Change va a dar un n\u00famero muy grande (y probablemente varios \u00f3rdenes de magnitud m\u00e1s grande que el resto de los Fold Change calculados). Este Fold Change no se debe a que CPM Droga es realmente mayor, sino a que CPM Control es muy chico, por lo que no es realmente informativo. Estos dos problemas se pueden arreglar agregando un n\u00famero buffer , es decir, un n\u00famero peque\u00f1o que se adiciona al numerador y al denominador. En este caso vamos a usar 0,125 con lo que la f\u00f3rmula quedar\u00eda: \\[ \\text{Fold Change} = \\frac{\\text{CPM Droga} + 0.125}{\\text{CPM Control} + 0.125} \\] 3.2) \u00bfQu\u00e9 pasa ahora en los dos casos problem\u00e1ticos que estamos tratando resolver? \u00bfC\u00f3mo afecta este buffer a los casos \"normales\"? (es decir, cuando tanto el numerador como el denominador son n\u00fameros mayores a 1) 3.3) Usando la f\u00f3rmula con buffer , calculen el Fold Change para ambas drogas y gu\u00e1rdenlos en nuevas columnas de la tabla full_data (p\u00f3nganles nombres que representen la informaci\u00f3n que contienen). Transformar el Fold Change Ahora bien, vamos a analizar como se distribuyen los valores del Fold Change para todas las prote\u00ednas (primera pesta\u00f1a del plot que est\u00e1 abajo). Podemos ver que si bien el Fold Change llega hasta 20 en algunos casos, la gran mayor\u00eda de ellas tienen Fold Changes menores a 4. En el paso siguiente vamos a querer agrupar nuestros genes por como se comportan frente a las drogas 1 y 2 clusterizando con kmeans() y luego plotearlo en un heatmap . En este momento la mayor\u00eda de los datos se encuentran en un peque\u00f1o rango del \"espectro\" de Fold Change, por lo que al momento de agrupar por similitud b\u00e1sicamente van a formar un \u00fanico gran cluster, lo que no da informaci\u00f3n. Por esta raz\u00f3n queremos convertir nuestros datos a una escala logar\u00edtmica. Como Fold Change solo llega hasta 20 vamos a usar una escala logar\u00edtmica en base 2. En R esto se hace usando la funci\u00f3n log() . Por defecto esta funci\u00f3n usa como base a \\(e\\) , es decir, es el logaritmo natural. Sin embargo, se le puede cambiar la base a 2 pas\u00e1ndole el par\u00e1metro base = 2 (ver la segunda pesta\u00f1a en el siguiente plot). 4) Usando la funci\u00f3n log() con el par\u00e1metro necesario, calculen el logaritmo en base 2 de los Fold Change para ambas drogas y gu\u00e1rdenlos en nuevas columnas de la tabla full_data . Fold Change para la Droga 1 Log2(Fold Change) para la Droga 1 Plotear el Heatmap El heatmap es un tipo de plot que no vimos hasta el momento, pero que tal vez conozcan. La versi\u00f3n b\u00e1sica del heatmap nos permite graficar valores num\u00e9ricos como una escala de colores lo que nos permite ver diferencias entre filas r\u00e1pidamente e incluso encontrar filas similares o patrones. A continuaci\u00f3n mostramos un ejemplo que usa los datos estandarizados del Ejercicio 2 del TP 12a (la tabla ejemplo con los 4 genes, matriz_datos_ST ): No solo nos permite ver r\u00e1pidamente que hay 2 grupos de genes, sino que este paquete de heatmap tambi\u00e9n va a agrupar las filas por similitud y mostrar un dendrograma de similitud (todo esto se puede poner o sacar con par\u00e1metros). 5) En nuestro caso tenemos miles de genes, por lo que es complicado usar un heatmap que los muestre a todos por separado. Vamos entonces a clusterizarlos por similitud usando kmeans , lo cual en este caso se puede hacer desde el mismo paquete que hace el heatmap . Al momento de definir clusters no sabemos cu\u00e1ntos son, por lo que vamos a elegir un n\u00famero relativamente grande, sabiendo que eso puede resultar en varios clusters que son muy similares. 5.1) Instalen en R el paquete pheatmap . 5.2) Corran el siguiente c\u00f3digo reemplazando log2_fold_change_drug1_wBuffer y log2_fold_change_drug2_wBuffer por el nombre de las columnas que contienen el logaritmo en base 2 de los Fold Change: library ( pheatmap ) #Como *pheatmap* usa kmeans adentro inicializo la seed para que el plot de igual en todos lados siempre set.seed ( 1 ) #Me quedo solo con las columnas a plotear (en este caso el log 2 de los Fold Change para ambas drogas) plot_data <- full_data [, . ( log2_fold_change_drug1_wBuffer , log2_fold_change_drug2_wBuffer )] #Uso la funcion *pheatmap* para hacer un heatmap mas lindo pheatmap ( mat = plot_data , kmeans_k = 10 , cluster_cols = F ) kmeans_k = 10 le est\u00e1 diciendo que agrupe los datos en 10 clusters, similar a correr kmeans(plot_data, centers = 10) cluster_col = F le est\u00e1 diciendo que no trate de agrupar las columnas por similitud y que no haga un dendrograma asociado 5.3) Mirando los 10 clusters que acabamos de crear, para que clusters de genes se observa: Fold change alto para ambas drogas Fold change bajo para ambas drogas Fold change alto para la droga 1 y bajo la droga 2 Fold change bajo para la droga 1 y alto la droga 2 Calcular genes m\u00e1s afectados 6) Si bien el heatmap nos da una idea global de como actuaron las drogas, nuestro objetivo es entender un poco m\u00e1s de su funcionamiento. Para esto, vamos a analizar la lista de genes que se vieron afectados por ellas. Para obtener esta lista es necesario entonces definir un umbral num\u00e9rico de Fold Change a partir del cual consideramos que el cambio fue \"significativo\" para nosotros. Estos umbrales se pueden elegir en base a conocimientos previos, en base a controles positivos y negativos, o mediante prueba y error (analizando qu\u00e9 y cu\u00e1ntos genes quedan por encima del umbral). Otra cosa a considerar es que en este caso estamos analizando drogas que funcionan como inhibidores, por lo que no nos interesa solo los genes con Fold Change alto, sino que incluso nos interesan m\u00e1s los genes con Fold Change bajo (que debido a como se calcul\u00f3 quiere decir cercanos a 0). En este caso vamos a quedarnos con aquellos genes que cumplan alguna de las siguientes condiciones: \\(log_2(FoldChange) \\geq 1.5\\) (es decir \\(FoldChange \\geq 2.83 = 2^{1.5}\\) ) \\(log_2(FoldChange) \\leq -1.5\\) (es decir \\(FoldChange \\leq \\frac{1}{2.83} = 2^{-1.5}\\) ) O sea, que nos vamos a quedar con aquellos genes que tienen un CPM 2.83 veces m\u00e1s grande o m\u00e1s chico que el control. 6.1) Filtren full_data para quedarnos con aquellas filas donde el logaritmo en base 2 del Fold Change de la droga 1 sea mayor a 1.5 o menor a -1.5. Guarden la lista de los IDs de las prote\u00ednas que cumplen esa condici\u00f3n en una nueva variable. Hagan lo mismo para la droga 2. Tip - Calcular el valor absoluto La funci\u00f3n abs() nos devuelve el valor absoluto de un n\u00famero. Si bien es posible filtrar estos datos usando simplemente un OR , tambi\u00e9n lo pueden hacer usando abs() , lo que prefieran. 6.2) Usen write.table() para generar un nuevo archivo llamado affected_genes_drug1 y guarden en \u00e9l los IDs reci\u00e9n calculados para la droga 1. Tengan en cuenta que queremos solo los IDs, por lo que tienen que cambiar los par\u00e1metros de la funci\u00f3n para que no haya nombres de las filas, nombres de las columnas ni comillas. Hagan lo mismo para la droga 2. Buscar nuestros genes en bases de datos 7) Lo \u00faltimo que vamos a hacer con esta informaci\u00f3n es investigar en bases de datos para tratar de entender un poco m\u00e1s que procesos biol\u00f3gicos est\u00e1n siendo afectados por nuestras drogas. Como estamos trabajando con Trypanosoma cruzi vamos a ir a una p\u00e1gina que se especializa en tripanosom\u00e1tidos llamada TriTrypDB . 7.1) Entren a este link y copien la lista de IDs que acabamos de crear para la droga 1. Hagan click en Get Answer . 7.2) Una vez que se hayan cargados los datos vayan a Analyze Results Gene Onthology Enrichment , aseg\u00farense que este checkeado Biological Process y aprieten Submit (disclaimer: esta parte a veces no anda y hay que probar otro d\u00eda). Tip - Ubicaci\u00f3n del bot\u00f3n Analyze Results 7.3) Esta tabla muestra procesos biol\u00f3gicos relacionados con nuestra lista de genes. A grandes rasgos, \u00bfqu\u00e9 procesos biol\u00f3gicos parecen estar afectados directa o indirectamente por la droga 1? Para responder esto pueden ordenar la tabla obtenida por la columna P-value en forma ascendente o pueden presionar el bot\u00f3n Show Word Cloud que se encuentra arriba de la tabla para ver un Word Cloud de los diferentes procesos biol\u00f3gicos. 7.4) Hagan 7.1) , 7.2) y 7.3) para la droga 2. 7.5) \u00bfQue habr\u00eda que cambiar en lo que hicimos en el punto 6) si s\u00f3lo nos interesaran los procesos biol\u00f3gicos que son inhibidos por nuestras drogas? Bibliograf\u00eda Consola de R Comando help()","title":"Index"},{"location":"practicos/TP12b_Data_Mining/#tp-12b-data-mining","text":"Materiales","title":"data-toc-label"},{"location":"practicos/TP12b_Data_Mining/#software-a-usar","text":"R (ya instalado en la VM). RStudio (ya instalado en la VM)","title":"Software a usar"},{"location":"practicos/TP12b_Data_Mining/#recursos-online","text":"Curso online de R de Coursera (se puede hacer gratis) (en ese caso no da certificado) Data Tables: Introducci\u00f3n oficial y otra p\u00e1gina con m\u00e1s info ggplot2: Vistazo r\u00e1pido , detalles sobre los tipos de plots , cheatsheet e informaci\u00f3n sobre colores y daltonismo dendextend: Detalle del paquete","title":"Recursos Online"},{"location":"practicos/TP12b_Data_Mining/#objetivos","text":"Usar m\u00e9todos de clustering junto con herramientas de programaci\u00f3n para resolver problemas biol\u00f3gicos. Familiarizarse en el paquete ggplot2 para hacer plots en R . Introducir paquetes de R que permiten plotear dendrogramas y heatmaps .","title":"Objetivos"},{"location":"practicos/TP12b_Data_Mining/#introduccion-al-tema","text":"Este TP retoma lo empezado en el TP 12a , donde aprendimos m\u00e9todos de clustering como clustering jer\u00e1rquico o K-means y los aplicamos a un ejemplo m\u00ednimo de una tabla con solo 4 filas. Vamos ahora a utilizar los mismos m\u00e9todos para trabajar con data sets m\u00e1s grandes y tratar de ir entendiendo cu\u00e1ndo, c\u00f3mo y por qu\u00e9 es conveniente agrupar nuestros datos. A su vez vamos a desarrollar algunos temas de R que son muy \u00fatiles, pero para los cuales no nos alcanz\u00f3 el tiempo en los TPs anteriores: plotear usando ggplot2 y utilizar funciones creadas por nosotros. Para hacer esto vamos a utilizar 2 data sets. En el Ejercicio 1 vamos a trabajar con el ya conocido data set iris que tiene 150 filas y viene por defecto con R . En el Ejercicio 2 vamos a trabajar con datos de un estudio de transcript\u00f3mica que nos devolvi\u00f3 9 datos para cada uno de 11.106 genes estudiados. Este trabajo es un segundo paso de lo realizado en el TP 8b cuando busc\u00e1bamos inhibidores para la Enzima Z .","title":"Introducci\u00f3n al Tema"},{"location":"practicos/TP12b_Data_Mining/#mejores-plots-ggplot2","text":"","title":"Mejores plots: ggplot2"},{"location":"practicos/TP12b_Data_Mining/#bases-de-ggplot2","text":"En el TP 8a mencionamos r\u00e1pidamente al paquete ggplot2 , el cual es uno de las formas m\u00e1s populares de hacer plots en R . Este paquete es bastante complicado y tiene un sinf\u00edn de funcionalidades, pero hoy vamos a darle un vistazo a su funcionalidad b\u00e1sica (el cheatsheet es una forma r\u00e1pida de ver todas las posibilidades que tiene). Un ejemplo muy simple de hacer un plot con la funci\u00f3n ggplot ser\u00eda: library ( ggplot2 ) #Recuerden que *iris* es un *Data Frame* para hacer pruebas que esta siempre cargado en la memoria de R p <- ggplot ( data = iris , aes ( x = Petal.Length , y = Sepal.Length )) + geom_point () print ( p ) p es una variable en la que estoy guardando el plot. Cuando la imprimo (usando print ) el plot va a aparecer en la pesta\u00f1a Plots en RStudio (en el panel de abajo a la derecha). data = iris le est\u00e1 indicando a la funci\u00f3n ggplot de que tabla va a sacar la informaci\u00f3n a plotear. En ggplot se pueden usar Data Frames o Data Tables indistintamente. aes() es una funci\u00f3n que se encuentra dentro de la funci\u00f3n principal de ggplot . Se va a encargar de relacionar las diferentes columnas de la tabla con las diferentes variables del plot. x = Petal.Length est\u00e1 indicando que la variable X en el plot va a ser los datos de la columna Petal.Length . y = Sepal.Length est\u00e1 indicando que la variable Y en el plot va a ser los datos de la columna Sepal.Length . geom_point() est\u00e1 indicando el tipo de plot a realizar. Si leen el cheatsheet van a ver que en este caso estamos haciendo un scatter plot. Ambas funciones del plot est\u00e1n separadas por el s\u00edmbolo + , lo que les puede resultar un poco extra\u00f1o (porque lo es), pero as\u00ed es como funciona ggplot . 1) Corran el c\u00f3digo anterior y vean el plot resultante.","title":"Bases de ggplot2"},{"location":"practicos/TP12b_Data_Mining/#cambiar-la-estetica-del-plot-segun-variables","text":"La funci\u00f3n aes() recibe su nombre de la palabra en ingl\u00e9s aesthetics , o est\u00e9tica. No es de extra\u00f1ar entonces que dentro de dicha funci\u00f3n es donde podemos poner otras variables que determinen los colores, formas o tama\u00f1os de cada punto del plot (entre otras caracter\u00edsticas). 2) Corran el siguiente c\u00f3digo y vean el plot resultante: p <- ggplot ( data = iris , aes ( x = Petal.Length , y = Sepal.Length , color = Species )) + geom_point () print ( p ) En este c\u00f3digo, color = Species le est\u00e1 diciendo a ggplot que modifique el color de los puntos dependiendo del valor de la columna Species . Si recuerdan a iris , esta columna era una columna categ\u00f3rica (o factor ) con 3 valores que podemos ver en el plot. Como le pasamos a color una variable categ\u00f3rica, nos devolvi\u00f3 una escala de colores categ\u00f3rica. 3) Corran el c\u00f3digo anterior, pero ahora reemplacen a Species por Petal.Width , \u00bfqu\u00e9 cambios observan? 4) Es posible tambi\u00e9n modificar varias de estas caracter\u00edsticas a la vez. Corran el siguiente c\u00f3digo y vean el plot resultante: p <- ggplot ( data = iris , aes ( x = Petal.Length , y = Sepal.Length , color = Species , shape = Species , size = Petal.Width )) + geom_point () print ( p ) En este caso agregamos 2 caracter\u00edsticas nuevas, shape (la forma de los puntos) y size (el tama\u00f1o de los puntos) y le asignamos cada uno de ellos a una variable de la tabla. Noten que no hay problema con que una columna modifique m\u00e1s de una caracter\u00edstica a la vez. 5) Tal vez ya lo notaron, pero por el momento no tenemos ning\u00fan control sobre que colores o formas le asigna ggplot a mis tres categor\u00edas. Vamos a mostrarles como hacerlo para este caso espec\u00edfico, pero sepan que las funciones a usar son ligeramente diferentes dependiendo si la variable pasada es discreta o continua. Corran el siguiente c\u00f3digo y vean el plot resultante: #Los colores se pueden escribir en ingles o en hexadecimal #\"#FF0000\" es el color rojo (se podr\u00eda haber puesto \"red\") p <- ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species , shape = Species )) + geom_point () + scale_colour_manual ( values = c ( \"#FF0000\" , \"blue\" , \"green\" )) + scale_shape_manual ( values = c ( 2 , 4 , 1 )) print ( p ) scale_colour_manual() : me permite modificar a mano una escala discreta de colores. El par\u00e1metro values modifica los colores en s\u00ed. scale_shape_manual() : me permite modificar a mano una escala discreta de formas. El par\u00e1metro values modifica las formas, las cuales corresponden a un n\u00famero entero (en el tip a continuaci\u00f3n se muestran las m\u00e1s comunes). Un detalle importante a destacar es que el orden en que se asign\u00f3 cada color a cada categor\u00eda depende del orden en el que aparecen los Levels de la columna Species , la cual es un factor (pueden imprimir iris$Species para ver a lo que nos referimos). Tip - Posibles valores para shape El color interior las formas 21 a 25 depende de la variable fill que no mencionamos todav\u00eda, pero se usa igual que el resto. Tip - Colores y daltonismo El daltonismo ocurre cuando hay un problema con los pigmentos en ciertas c\u00e9lulas nerviosas del ojo que perciben el color. Estas c\u00e9lulas se llaman conos y los hay de tres tipos, los cuales son responsables de ver principalmente al rojo, al verde y al azul respectivamente. La frecuencia del daltonismo es bastante alta, con un 8% de los hombres cauc\u00e1sicos, 5% de los asi\u00e1ticos y 4% de los africanos presentando problemas para distinguir el color rojo del verde. Como la mayor\u00eda de los casos de daltonismo provienen de una mutaci\u00f3n de un gen recesivo ligado al cromosoma X, muy pocas mujeres son dalt\u00f3nicas. Debido al considerable n\u00famero de personas con daltonismo, es buena \u00eddea tener en cuenta esto al momento de elegir colores para cualquier figura que vaya a ser vistas por el p\u00fablico general. Se pueden encontrar decenas de herramientas online que nos ayudan a crear esto, as\u00ed como paquetes de R o paletas de colores. Un ejemplo de una paleta de colores ser\u00eda: Pueden leer m\u00e1s informaci\u00f3n sobre este tema aca . Tip - Asignar colores espec\u00edficos a cada caracter\u00edstica sin depender del orden de los Levels Si bien el c\u00f3digo anterior funciona perfecto, depender del orden de los Levels de un factor al momento de matchear color con un valor dado puede ser peligroso. Una forma de estar seguros que le estamos asignando el color correcto a cada valor es usando vectores con nombres (o named vectors ). Algo mencionamos de estos vectores en el pasado, pero b\u00e1sicamente son vectores donde cada posici\u00f3n tiene un nombre (adem\u00e1s del \u00edndice). En este caso ser\u00eda: categorias <- c ( \"setosa\" , \"versicolor\" , \"virginica\" ) colores <- c ( \"#FF0000\" , \"blue\" , \"green\" ) names ( colores ) <- categorias #Puedo acceder a \"blue\" haciendo `colores[2]` o `colores[\"versicolor\"]` De hacer scale_colour_manual(values = colores) en la funci\u00f3n ggplot nos asegurar\u00edamos que el primer elemento de categorias va a tener el primer color de colores y as\u00ed. 6) Por \u00faltimo, \u00bfqu\u00e9 pasa si no queremos cambiar la est\u00e9tica del plot dependiendo del valor de una variable, sino que simplemente queremos cambiarla y que afecte a todos los puntos por igual? En estos casos hay que modificar dicha caracter\u00edstica dentro de la funci\u00f3n espec\u00edfica del plot. Corran el siguiente c\u00f3digo y vean el plot resultante: p <- ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species )) + geom_point ( size = 2 , shape = 4 ) + scale_colour_manual ( values = c ( \"#FF0000\" , \"blue\" , \"green\" )) print ( p )","title":"Est\u00e9tica variable"},{"location":"practicos/TP12b_Data_Mining/#nombres-y-estilo-de-los-ejes-y-el-plot","text":"7) Ahora que ya modificamos bastante el estilo de los datos, vamos a modificar el resto del plot. Lo primero que vamos a hacer es cambiar el nombre del eje X, el eje Y y el t\u00edtulo del plot. Corran el siguiente c\u00f3digo y vean el plot resultante: p <- ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species , shape = Species )) + geom_point ( size = 2 ) + xlab ( \"Sepal Length\" ) + ylab ( \"Petal Length\" ) + ggtitle ( \"Sepal Length vs Petal Length per Species\" ) + scale_colour_manual ( values = c ( \"#FF0000\" , \"blue\" , \"green\" )) + scale_shape_manual ( values = c ( 2 , 4 , 1 )) print ( p ) xlab() : indica el nombre del eje X ylab() : indica el nombre del eje Y ggtitle() : indica el t\u00edtulo del plot 8) Si bien obtuvimos lo deseado, puede ser que queramos cambiar el tama\u00f1o de los ejes o centrar el t\u00edtulo. Esto lo hacemos con la funci\u00f3n theme() : Corran el siguiente c\u00f3digo y vean el plot resultante: p <- ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species , shape = Species )) + geom_point ( size = 2 ) + xlab ( \"Sepal Length\" ) + ylab ( \"Petal Length\" ) + ggtitle ( \"Sepal Length vs Petal Length per Species\" ) + theme ( plot.title = element_text ( size = 16 , hjust = 0.5 ), axis.title = element_text ( size = 14 ), axis.text = element_text ( size = 12 )) + scale_colour_manual ( values = c ( \"#FF0000\" , \"blue\" , \"green\" )) + scale_shape_manual ( values = c ( 2 , 4 , 1 )) print ( p ) theme() : es la funci\u00f3n que contiene el estilo del texto de los ejes y del t\u00edtulo de un plot. plot.title = element_text(size = 16, hjust = 0.5) : estamos modificando el titulo del plot, donde size modifica el tama\u00f1o de letra y hjust = 0.5 lo centra horizontalmente. axis.title = element_text(size = 14) : estamos modificando los t\u00edtulos de los ejes (es decir, los nombre de los ejes). axis.text = element_text(size = 12) : estamos modificando el tama\u00f1o de los n\u00fameros de los ejes. Noten que dentro de theme() cada l\u00ednea se separa con comas, y reci\u00e9n una vez que termina volvemos a usar el s\u00edmbolo + .","title":"Nombres de los ejes"},{"location":"practicos/TP12b_Data_Mining/#fondo-del-plot","text":"9) Lo \u00faltimo que nos queda por modificar es el \"fondo\" del plot, es decir, el color de fondo, las l\u00edneas que corresponden a las divisiones de los ejes y el recuadro general del plot. Si bien esto se puede hacer a mano, ggplot viene con algunas opciones ya armadas. Corran el siguiente c\u00f3digo y vean el plot resultante: p <- ggplot ( data = iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species , shape = Species )) + geom_point ( size = 2 ) + xlab ( \"Sepal Length\" ) + ylab ( \"Petal Length\" ) + ggtitle ( \"Sepal Length vs Petal Length per Species\" ) + theme_bw () + theme ( plot.title = element_text ( size = 16 , hjust = 0.5 ), axis.title = element_text ( size = 14 ), axis.text = element_text ( size = 12 )) + scale_colour_manual ( values = c ( \"#FF0000\" , \"blue\" , \"green\" )) + scale_shape_manual ( values = c ( 2 , 4 , 1 )) print ( p ) theme_bw() es una funci\u00f3n que setea varias opciones de theme() a un estilo espec\u00edfico (en este caso un estilo simple en blanco y negro). La tenemos que usar antes de theme() para asegurarnos que cualquier cambio que hagamos a mano en theme() sobrescriba los de theme_bw() .","title":"Fondo del plot"},{"location":"practicos/TP12b_Data_Mining/#otros-tipos-de-plots","text":"Si bien la mayor\u00eda de lo que les mencionamos hasta ahora es aplicable al uso general de ggplot , hasta el momento nos enfocamos en un solo tipo de plot, el scatter plot, hecho mediante geom_point() . Debido a que esto es suficiente para lo que necesitamos hacer hoy (y que este TP es de Data Mining ) no vamos a hablar hoy de otros tipos de plots, pero si les interesa pueden verlo con mucho detalle en esta p\u00e1gina o ver un vistazo r\u00e1pido en la cheatsheet .","title":"Otros tipos de plots"},{"location":"practicos/TP12b_Data_Mining/#ejercicio-1-agrupando-flores-por-especies","text":"","title":"Ejercicio 1"},{"location":"practicos/TP12b_Data_Mining/#introduccion-al-data-set","text":"En este ejercicio vamos a trabajar una vez m\u00e1s con el data set iris , el cual es un set de datos que viene por defecto con R y est\u00e1 siempre cargado en memoria. Este data set contiene las medidas de ancho ( width ) y largo ( length ) de los s\u00e9palos y los p\u00e9talos para 3 especies de flores diferentes: setosa, versicolor, y virginica (todas del Genus Iris ). Tiene mediciones de 150 flores, 50 por especie. S\u00e9palo vs p\u00e9talo Antes que nada vamos a familiarizarnos un poco con este data set. 1) Corran el siguiente c\u00f3digo y vean el plot resultante: library ( data.table ) library ( ggplot2 ) #Transformo a iris en un *Data Table* (que aca realmente no hace falta, pero para despues) dt_iris <- as.data.table ( iris ) #Hago un plot comparando el largo de los sepalos y los petalos #Estoy cambiando la forma y el color segun la especie p <- ggplot ( data = dt_iris , aes ( x = Sepal.Length , y = Petal.Length , color = Species )) + geom_point ( size = 2 ) + theme_bw () + xlab ( \"Sepal Length\" ) + ylab ( \"Petal Length\" ) + ggtitle ( \"Sepal Length vs Petal Length per Species\" ) + theme ( plot.title = element_text ( size = 16 , hjust = 0.5 ), axis.title = element_text ( size = 14 ), axis.text = element_text ( size = 12 )) + scale_colour_manual ( values = c ( \"#004D40\" , \"#D81B60\" , \"#FFC107\" )) print ( p ) Podemos ver que con solo plotear el largo de los p\u00e9talos y los s\u00e9palos ya estamos viendo diferencias entre las especies. Es te\u00f3ricamente posible agregar una tercera dimensi\u00f3n para plotear otra de las variables, e incluso agregar la cuarta variable como \"tama\u00f1o\" de los diferentes puntos, pero dichos plots van a resultar considerablemente mas complejos al momento de leerlos.","title":"Introducci\u00f3n al data set"},{"location":"practicos/TP12b_Data_Mining/#problema-a-resolver","text":"En este ejercicio vamos a suponer que alguien apret\u00f3 el bot\u00f3n equivocado y borr\u00f3 la columna Species de dicha tabla. Como nos acordamos de que eran tres especies y que ten\u00edan diferencias en sus largos y anchos de p\u00e9talos y s\u00e9palos, queremos entonces usar m\u00e9todos de clustering para tratar de recuperar lo mejor que podamos los tres grupos de flores. Dicho esto vamos a hacer un poco de trampa y vamos a comparar visualmente lo que vamos obteniendo por los m\u00e9todos de clustering con lo que nosotros sabemos es verdad. Por \u00faltimo, c\u00f3mo vamos a tener que hacer varios plots similares, vamos a aprovechar la oportunidad y vamos a usar por primera vez funciones de R creadas por nosotros.","title":"Problema a resolver"},{"location":"practicos/TP12b_Data_Mining/#guardar-el-plot-en-un-pdf","text":"Vamos a crear una funci\u00f3n que guarde diferentes plots como PDFs. 2) Copien el siguiente c\u00f3digo y modifiquen la secci\u00f3n que dice @@EDITAR@@ (pueden ver los comentarios para entender mejor ciertas partes del c\u00f3digo). Agreguen todos los par\u00e1metros necesarios para que al correr la funci\u00f3n se replique el plot hecho en el punto 1) y se guarde en un archivo llamado 01_Sepal_vs_Petal_Length_per_Species.pdf . C\u00f3digo C\u00f3digo con comentarios library ( data.table ) library ( ggplot2 ) #### FUNCIONES AUXILIARES #### plotData2PDF_wColor <- function ( data_par , x_colname , y_colname , color_colname , x_label , y_label , plot_title , pdf_file ) { p <- ggplot ( data = data_par , aes_string ( x = x_colname , y = y_colname , color = color_colname )) + geom_point ( size = 2 ) + theme_bw () + xlab ( x_label ) + ylab ( y_label ) + ggtitle ( plot_title ) + theme ( plot.title = element_text ( size = 16 , hjust = 0.5 ), axis.title = element_text ( size = 14 ), axis.text = element_text ( size = 12 )) + scale_colour_manual ( values = c ( \"#004D40\" , \"#D81B60\" , \"#FFC107\" )) pdf ( file = pdf_file , width = 8 , height = 7 ) print ( p ) dev.off () } #### CODIGO PRINCIPAL #### dt_iris <- as.data.table ( iris ) plotData2PDF_wColor ( data_par = dt_iris , @@ EDITAR @@ , pdf_file = \"01_Sepal_vs_Petal_Length_per_Species.pdf\" ) library ( data.table ) library ( ggplot2 ) #Estoy usando comentarios rodeados de cuatro numerales para delimitar secciones de mi c\u00f3digo #Esto no es puramente est\u00e9tico, sino que tambi\u00e9n es aprovechado por *RStudio* para crear una de barra de #navegaci\u00f3n del c\u00f3digo (es la barra horizontal entre el script y la consola) #### FUNCIONES AUXILIARES #### plotData2PDF_wColor <- function ( data_par , x_colname , y_colname , color_colname , x_label , y_label , plot_title , pdf_file ) { #La funci\u00f3n *aes_string()* es similar a *aes()*, solo que en este caso los nombres de las columnas #tienen que ser *strings* (recuerden que con *aes()* se escriben sin comillas) #Esto es ideal para cuando el nombre de la columna utilizar esta guardado en una variable p <- ggplot ( data = data_par , aes_string ( x = x_colname , y = y_colname , color = color_colname )) + geom_point ( size = 2 ) + theme_bw () + xlab ( x_label ) + ylab ( y_label ) + ggtitle ( plot_title ) + theme ( plot.title = element_text ( size = 16 , hjust = 0.5 ), axis.title = element_text ( size = 14 ), axis.text = element_text ( size = 12 )) + scale_colour_manual ( values = c ( \"#004D40\" , \"#D81B60\" , \"#FFC107\" )) #*pdf()* \"abre\" un archivo pdf. Todo lo que se imprima hasta cerrarlo va a ir a \u00e9l, #en vez de a la pesta\u00f1a *Plots* de *RStudio* #8 y 7 indican el ancho y el alto del pdf en pulgadas pdf ( file = pdf_file , width = 8 , height = 7 ) print ( p ) #La funci\u00f3n *dev.off()* cierra el plot abierto, en este caso el pdf. dev.off () } #### CODIGO PRINCIPAL #### dt_iris <- as.data.table ( iris ) plotData2PDF_wColor ( data_par = dt_iris , @@ EDITAR @@ , pdf_file = \"01_Sepal_vs_Petal_Length_per_Species.pdf\" ) 3) Usando la funci\u00f3n que acabamos de crear, vean como se distribuyen los puntos al comparar Sepal.Width contra Petal.Width . Guarden este plot en un archivo llamado 02_Sepal_vs_Petal_Width_per_Species.pdf .","title":"Guardar el plot en un PDF"},{"location":"practicos/TP12b_Data_Mining/#clustering-jerarquico","text":"Lo primero que vamos a hacer entonces es usar un clustering jer\u00e1rquico para agrupar a las 150 filas en 3 grupos seg\u00fan los valores de las 4 medidas. Un problema que tenemos es que por ahora no hay ninguna forma de identificar a una fila espec\u00edfica, as\u00ed que le vamos a agregar un ID num\u00e9rico a cada fila. Debido al orden que tienen las filas de dt_iris , los primeros 50 IDs van a corresponder a flores de la especie setosa, los segundos 50 a versicolor y los \u00faltimos a virginica (aunque supuestamente esto no lo sabemos). 4) Corran el siguiente c\u00f3digo para crear la matriz de datos que vamos a usar al momento de clusterizar. Lean los comentarios en la segunda pesta\u00f1a para entender que estamos haciendo. C\u00f3digo C\u00f3digo con comentarios dt_iris $ row_id <- c ( 1 : dt_iris [, .N ]) setcolorder ( dt_iris , c ( \"row_id\" )) matriz_datos <- as.matrix ( dt_iris [, - c ( \"Species\" )], rownames = 1 ) #Agregamos una nueva columna denominada row_id que tiene un numero entre 1 y 150 #dt_iris[, .N] es una funci\u00f3n de *Data Tables* que me devuelve el numero de filas en la tabla #El numero de filas tambien se puede conseguir haciendo nrow(dt_iris) dt_iris $ row_id <- c ( 1 : dt_iris [, .N ]) #Aca estamos cambiando el orden de las columnas a *dt_iris*. #No hace falta asignar esto a *dt_iris* ya que *setcolorder* modifica la variable misma #Como solo le estamos pasando 1 columna, lo que estamos haciendo es mover esa columna al principio #(al usar as\u00ed *setcolorder* las otras se quedan donde estan) setcolorder ( dt_iris , c ( \"row_id\" )) #Similar a lo que hicimos en el TP anterior, estamos transformando nuestros datos a una matriz #donde la primer columna (en este caso *row_id*) va a transformarse en los nombres de las filas #Estamos sacando a la columna *Species* ya que queremos simular que no tenemos esta informacion #(la columna *Species* va a estar todavia en *dt_iris*, pero no en *matriz_datos*) matriz_datos <- as.matrix ( dt_iris [, - c ( \"Species\" )], rownames = 1 ) 5) Usando lo aprendido en el TP anterior y la matriz de datos reci\u00e9n creada: 5.1) Usen la funci\u00f3n dist() para crear una matriz de distancias euclidianas que muestre tambi\u00e9n la diagonal. 5.2) usen la funci\u00f3n hclust() para crear un clustering jer\u00e1rquico basado en su matriz de distancias usando el criterio de agregaci\u00f3n complete linkage . 5.3) Usen la funci\u00f3n plot() para plotear el clustering jer\u00e1rquico. 5.4) Mirando el plot reci\u00e9n creado, \u00bfles es f\u00e1cil distinguir a simple vista los tres grupos de especies en el clustering jer\u00e1rquico? (recuerden que pueden usar el bot\u00f3n Zoom para agrandar el plot).","title":"Clustering jer\u00e1rquico"},{"location":"practicos/TP12b_Data_Mining/#mejorar-el-plot-del-clustering-jerarquico","text":"6) Una cosa que vendr\u00eda bien al momento de leer el plot reci\u00e9n creado ser\u00eda colorear cada flor dependiendo de su especie. Si bien esto no es posible en este caso usando solo la funci\u00f3n plot() , hay paquetes de R que nos van a permitir hacer esto: 6.1) Usen la funci\u00f3n install.packages() e instalen la librer\u00eda dendextend (recuerden que al usar install.packages() el nombre del paquete va entre comillas). Luego corran el siguiente c\u00f3digo: C\u00f3digo C\u00f3digo con comentarios library ( dendextend ) #Estoy asumiendo que guardaron la salida de *hclust()* en una variable llamada clustering_jerarquico #De no ser asi, cambien el nombre de la variable a continuacion por lo que corresponda dend <- as.dendrogram ( clustering_jerarquico ) colores_especies <- c ( \"#004D40\" , \"#D81B60\" , \"#FFC107\" ) colors_aux <- rep ( colores_especies , each = 50 ) labels_colors ( dend ) <- colors_aux [ order.dendrogram ( dend )] dend <- dend %>% set ( \"labels_cex\" , 0.6 ) pdf_file <- \"11_Clustering_jerarquico_complete_linkage.pdf\" pdf ( file = pdf_file , width = 18 , height = 6 ) plot ( x = dend , main = \"Clustering Jer\u00e1rquico - Complete Linkage - Color per Species\" ) dev.off () library ( dendextend ) #Estoy asumiendo que guardaron la salida de *hclust()* en una variable llamada clustering_jerarquico #De no ser asi, cambien el nombre de la variable a continuacion por lo que corresponda #Aca estoy transformando la variable *clustering_jerarquico* que es de tipo *hclust* a un *dendrogram*, #que es una variable usada por el paquete *dendextend* dend <- as.dendrogram ( clustering_jerarquico ) #La funcion *labels_colors()* me permite asignar a mano los colores para los 150 labels del dendrograma #Ahora bien, yo se que originalmente en la tabla las primera 50 filas corresponden al color 1 y asi #Lo que estoy haciendo aca es armar una lista de 150 colores ordenada como esta en la tabla original y luego #reordenarlas para que coincidan con el orden de los IDs en el dendrograma colores_especies <- c ( \"#004D40\" , \"#D81B60\" , \"#FFC107\" ) colors_aux <- rep ( colores_especies , each = 50 ) labels_colors ( dend ) <- colors_aux [ order.dendrogram ( dend )] #Esto simplemente es para achicar un poco el texto de los labels para que no choquen entre si #El simbolo %>% cumple una funcion similar al + en ggplot dend <- dend %>% set ( \"labels_cex\" , 0.6 ) #Creo el pdf de salida y guardo el clustering jer\u00e1rquico pdf_file <- \"11_Clustering_jerarquico_complete_linkage.pdf\" pdf ( file = pdf_file , width = 18 , height = 6 ) plot ( x = dend , main = \"Clustering Jer\u00e1rquico - Complete Linkage - Color per Species\" ) dev.off () 6.2) Abran el archivo 11_Clustering_jerarquico_complete_linkage.pdf . \u00bfPueden ahora distinguir los tres grupos de especies en el clustering jer\u00e1rquico? \u00bfCu\u00e1les especies les parecen mejor agrupadas? (los colores de las especies corresponden al color usado en el plot creado en los puntos 1) y 2) )","title":"Mejorar el plot"},{"location":"practicos/TP12b_Data_Mining/#single-linkage","text":"7) Hasta el momento s\u00f3lo utilizamos complete linkage al momento de hacer nuestros clustering jer\u00e1rquicos, pero ser\u00eda interesante ver como es el dendrograma resultante de hacer el clustering usando otro criterio de agregaci\u00f3n, por ejemplo el single linkage . Para esto: 7.1) Vuelvan a correr la funci\u00f3n hclust() como en 5.2) , pero ahora usen method = \"single\" y guarden el clustering resultante en una nueva variable. Luego usen el c\u00f3digo de 6.1) editando lo que sea necesario para crear un archivo que contenga al dendrograma hecho a partir del clustering jer\u00e1rquico que usa single linkage como criterio de agregaci\u00f3n. Nombren a este archivo 12_Clustering_jerarquico_single_linkage.pdf . 7.2) \u00bfQu\u00e9 diferencias ven entre este dendrograma y el creado en 6.2) ? \u00bfPueden relacionar estas diferencias con lo que saben de single linkage y complete linkage ? 7.3) Ignorando los colores, \u00bfcu\u00e1l les parece el mejor criterio de agregaci\u00f3n para este caso donde queremos recuperar tres clusters?","title":"Single Linkage"},{"location":"practicos/TP12b_Data_Mining/#hacer-clusters-y-plots","text":"Por \u00faltimo vamos a querer recrear el plot generado en los puntos 1) y 2) , pero ahora mostrando informaci\u00f3n tanto de las especies originales (con el color) como de la agrupaci\u00f3n resultante del clustering jer\u00e1rquico (con la forma). Vamos a utilizar los datos del clustering jer\u00e1rquico que usa el criterio de agregaci\u00f3n complete linkage . 8) Lo primero es entonces agregar la informaci\u00f3n del clustering jer\u00e1rquico a nuestro dt_iris ; para ello: 8.1) Usen la cutree para dividir a los datos obtenidos en 5.2) en 3 clusters. 8.2) Asignen esa informaci\u00f3n a una nueva columna en la tabla dt_iris llamada CJ_cluster . 8.3) Por el momento la variable es num\u00e9rica, pero para nosotros los n\u00fameros 1, 2 y 3 son categor\u00edas que te\u00f3ricamente corresponden a las especies (aunque no sabemos qu\u00e9 categor\u00eda corresponde a que especie). Corran el siguiente c\u00f3digo para convertir la columna reci\u00e9n creada en un factor : #En este caso poner los levels a mano no es 100% necesario, pero no viene mal #Recuerden que no sabemos que numero corresponde a que especie #(porque ademas ya vimos que no hay un match perfecto 1 a 1) dt_iris $ CJ_cluster <- factor ( dt_iris $ CJ_cluster , levels = c ( 1 , 2 , 3 )) 9) Ahora queremos hacer un plot similar al creado en el punto 2) , pero donde la columna Species determine el color y la columna CJ_cluster determine la forma de los diferentes puntos del plot; para ello: 9.1) Copien la funci\u00f3n plotData2PDF_wColor() y c\u00e1mbienle en nombre a plotData2PDF_wColorAndShape() . Modifiquen esta nueva funci\u00f3n considerando lo siguiente: Agreguen un par\u00e1metro a la funci\u00f3n el cual va a recibir el nombre de la columna que determina la forma, o shape , de los puntos. Modifiquen la funci\u00f3n aes_string() , agregando la caracter\u00edstica shape y asign\u00e1ndole el valor del par\u00e1metro agregado. Agreguen la funci\u00f3n scale_shape_manual() a ggplot para definir a mano las tres formas. Usen los valores c(2, 4, 1) . 9.2) Usando la funci\u00f3n que acabamos de crear, vean como se distribuyen los puntos al comparar Sepal.Length contra Petal.Length usando la columna Species para determinar el color y la columna CJ_cluster para determinar la forma de los diferentes puntos. Guarden este plot en un archivo llamado 21_Sepal_vs_Petal_Width_per_Species_CJ3.pdf . 9.3) Abran el archivo reci\u00e9n creado. \u00bfCu\u00e1les especies les parecen mejor agrupadas? Entre este plot y el dendrograma creado en 11_Clustering_jerarquico_complete_linkage.pdf \u00bfCu\u00e1l les parece la mejor manera de representar este clustering? \u00bfPor qu\u00e9? Importante - Clustering vs Plot Tengan en cuenta que al momento de clusterizar estamos usando los datos de las cuatro columnas de la tabla. Sin embargo, en este \u00faltimo plot estamos viendo solo la relaci\u00f3n entre dos. Por esta raz\u00f3n, este plot no es realmente representativo del clustering que estamos haciendo. Dicho todo esto, este plot es \u00fatil ya que es mucho m\u00e1s f\u00e1cil de leer que otros plots m\u00e1s complejos, pero debe tomarse como un an\u00e1lisis exploratorio.","title":"Hacer clusters y plots"},{"location":"practicos/TP12b_Data_Mining/#kmeans","text":"10) Lo \u00faltimo que vamos a hacer con este data set es volver a crear los clusters pero usando ahora la funci\u00f3n kmeans() . 10.1) Usando lo aprendido en el TP anterior: Usen la funci\u00f3n kmeans() para crear un nuevo clustering. Usen la cantidad de centers que consideren necesarios. Extraigan los clusters del clustering reci\u00e9n creado y as\u00edgnenlos a una nueva columna en dt_iris llamada K3_cluster . Transformen dicha columna en un factor . Usando la funci\u00f3n creada en el punto 9) , vean como se distribuyen los puntos al comparar Sepal.Length contra Petal.Length usando la columna Species para determinar el color y la columna K3_cluster para determinar la forma de los diferentes puntos. Guarden este plot en un archivo llamado 22_Sepal_vs_Petal_Width_per_Species_K3.pdf . 10.2) Abran el archivo reci\u00e9n creado. Bas\u00e1ndose solo en lo que pueden observar en este plot, \u00bfpueden decir algo de si este agrupamiento es mejor, peor o similar al obtenido con el clustering jer\u00e1rquico? (recuerden que \"no\" tambi\u00e9n es una respuesta v\u00e1lida) 10.3) Supongamos ahora que estamos en un escenario real, por lo que no tenemos informaci\u00f3n de a que especie corresponde cada punto. En base a lo visto en el TP anterior, \u00bfse les ocurre alguna forma de evaluar objetivamente cu\u00e1l de ambos es el mejor clustering? Tip - Predeterminar el azar La funci\u00f3n kmeans() genera la primera posici\u00f3n de sus centros al azar. Esto hace que si la corren varias veces o en diferentes computadoras va a dar diferentes resultados cada vez. Esto se puede controlar con una funci\u00f3n de R que asigna a mano el valor de la seed , que es el n\u00famero base que usa R al momento de generar azar. Si les interesa hacer esto tienen que ejecutar la siguiente l\u00ednea antes de usar la funci\u00f3n kmeans() : set.seed ( 1 ) P.D.: El azar en las computadoras no existe realmente. Muchos programas usan lista pre-generadas de \"n\u00fameros creados al azar\" y otras usan cosas como \"el quinto decimal de la temperatura del procesador en este momento\", lo que se aproxima suficientemente al azar para funcionar bien.","title":"Kmeans"},{"location":"practicos/TP12b_Data_Mining/#ejercicio-2-analizando-el-efecto-de-dos-inhibidores","text":"En el TP 8b hicimos un ejercicio donde us\u00e1bamos el equipo FilterMax F5 para analizar 22 inhibidores de una llamada Enzima Z , la cual resulta que era la cruzipa\u00edna, es decir, la ciste\u00edn proteasa principal de Trypanosoma cruzi , el par\u00e1sito causante de la enfermedad de Chagas. En esta segunda fase del experimento se eligieron 2 inhibidores y se realiz\u00f3 un an\u00e1lisis m\u00e1s detallado, estudiando como var\u00eda la expresi\u00f3n de miles de genes en presencia o ausencia de dichos inhibidores. Para esto se hizo un estudio de transcript\u00f3mica (RNA-seq) donde se extrajo el ARN y se lo analiz\u00f3 con Illumina . Luego, cada read encontrado se mape\u00f3 contra el genoma de referencia y se lleg\u00f3 a una tabla de conteo para cada uno de las transcriptos del genoma. Para cada caso ( control , droga 1 y droga 2 ) se realizaron 3 r\u00e9plicas t\u00e9cnicas para obtener resultados m\u00e1s robustos. Nuestro objetivo va a ser entonces obtener una lista de los genes que son m\u00e1s afectados por cada droga.","title":"Ejercicio 2"},{"location":"practicos/TP12b_Data_Mining/#leer-los-datos","text":"1) Lean los archivos control_data.tsv , drug1_data.tsv y drug2_data.tsv que se encuentran en sus materiales de trabajo y gu\u00e1rdenlos en diferentes variables llamadas control_data , drug1_data y drug2_data respectivamente.","title":"Leer los datos"},{"location":"practicos/TP12b_Data_Mining/#estandarizar-los-datos","text":"El conteo de reads no se puede comparar entre genes puesto que la expresi\u00f3n basal de cada uno es distinto, por lo cual encontrar 10 reads de un gen puede ser mucho, y encontrar 1000 de otro puede ser poco. Adem\u00e1s cada ensayo de secuenciaci\u00f3n puede tener distinta profundidad con lo que tampoco ser\u00eda viable comparar 10 reads de un ensayo donde en total se mapearon \\(2\\text{x}10^8\\) reads con los mismos 10 de otro ensayo donde se mapearon \\(1\\text{x}10^8\\) (es decir, la mitad). Por esta raz\u00f3n vamos a querer modificar las nueve columnas y transformar el valor a \"conteo por mill\u00f3n\", cuya f\u00f3rmula es: \\[ \\text{RPM or CPM} = \\frac{ReadsDelGen * 10^6}{ReadsTotales} \\]","title":"Estandarizar los datos"},{"location":"practicos/TP12b_Data_Mining/#combinar-las-replicas","text":"Otra cosa que vamos a querer hacer es combinar las tres r\u00e9plicas para cada caso. Esto lo vamos a hacer simplemente promediando los 3 valores de CPM para cada gen en cada tratamiento. 2) En base a los TPs anteriores ya tienen los conocimientos para hacer el estandarizado de datos y la combinaci\u00f3n de r\u00e9plicas usando fors , pero para hacerla un poco m\u00e1s f\u00e1cil les vamos a dar un par de funciones que les van a simplificar bastante este paso (y ya que estamos les mostramos la funci\u00f3n apply() en acci\u00f3n): C\u00f3digo C\u00f3digo con comentarios calcularConteoPorMillon <- function ( vector_cuentas ) { #Dado un vector de *reads*, esta funcion lo transforma en CPM y devuelve el vector vector_cuentas <- vector_cuentas * 1000000 / sum ( vector_cuentas ) return ( vector_cuentas ) } parsearDatos <- function ( dt_par , columnas_a_parsear , nombre_columna_nueva ) { #Dado un *Data Table*, un vector de *strings* con los nombres de las columnas con *reads* a parsear y #un nombre de una columna a crear, esta funcion: # - Transforma los *reads* de las columnas a parsear en CPM # - Calcula el promedio de los CPM por cada fila y lo guarda en una columna nueva con el nombre dado # - Saca las columnas a parsear del *Data Table* # - Devuelve el *Data Table* con los cambios dt_aux <- dt_par [, columnas_a_parsear , with = F ] matrix_aux <- apply ( dt_aux , 2 , calcularConteoPorMillon ) dt_par [[ nombre_columna_nueva ]] <- apply ( matrix_aux , 1 , mean ) dt_par [[ nombre_columna_nueva ]] <- round ( dt_par [[ nombre_columna_nueva ]], 4 ) dt_par <- dt_par [, - columnas_a_parsear , with = F ] return ( dt_par ) } calcularConteoPorMillon <- function ( vector_cuentas ) { #Dado un vector de *reads*, esta funcion lo transforma en CPM y devuelve el vector #Aca estoy asumiendo que sum(vector_cuentas) nunca es 0 (lo que tiene un poco #de sentido ya que si es 0 entonces todas los counts son 0) vector_cuentas <- vector_cuentas * 1000000 / sum ( vector_cuentas ) return ( vector_cuentas ) } parsearDatos <- function ( dt_par , columnas_a_parsear , nombre_columna_nueva ) { #Dado un *Data Table*, un vector de *strings* con los nombres de las columnas con *reads* a parsear y #un nombre de una columna a crear, esta funcion: # - Transforma los *reads* de las columnas a parsear en CPM # - Calcula el promedio de los CPM por cada fila y lo guarda en una columna nueva con el nombre dado # - Saca las columnas a parsear del *Data Table* # - Devuelve el *Data Table* con los cambios #Creo un nuevo *Data Table* que solo contenga las columnas a parsear (y no el ID del gen) dt_aux <- dt_par [, columnas_a_parsear , with = F ] #La funcion *apply* con el parametro 2 va a ejecutar la funcion *calcularConteoPorMillon* para #cada COLUMNA de dt_aux (las tres replicas, en este caso) matrix_aux <- apply ( dt_aux , 2 , calcularConteoPorMillon ) #La funcion *apply* con el parametro 1 va a ejecutar la funcion *mean* para #cada FILA de matrix_aux (cada uno de los genes estudiados) dt_par [[ nombre_columna_nueva ]] <- apply ( matrix_aux , 1 , mean ) dt_par [[ nombre_columna_nueva ]] <- round ( dt_par [[ nombre_columna_nueva ]], 4 ) #Saco las columnas que ya no me interesan de *dt_par* dt_par <- dt_par [, - columnas_a_parsear , with = F ] return ( dt_par ) } 2.1) Corran las funciones anteriores para cargarlas en memoria, luego \u00fasenlas para estandarizar y combinar las r\u00e9plicas del control y las drogas 1 y 2. Un ejemplo de correr esta funci\u00f3n para el caso de control ser\u00eda: control_data <- parsearDatos ( dt_par = control_data , columnas_a_parsear = c ( \"control1\" , \"control2\" , \"control3\" ), nombre_columna_nueva = \"control\" ) 2.2) Ahora que ya tenemos los datos parseados, usen la funci\u00f3n merge() dos veces para combinar los 3 Data Tables en uno solo llamado full_data (si todo sali\u00f3 bien deber\u00eda tener 11.106 filas y 4 columnas).","title":"Combinar las r\u00e9plicas"},{"location":"practicos/TP12b_Data_Mining/#calcular-el-fold-change","text":"3) Algo mencionamos antes, pero concluir que \"hay 10 CPM m\u00e1s al agregarle la droga\" no significa nada en el vac\u00edo. Si en el control era solo 1 CPM, entonces 10 m\u00e1s es mucho. Si en el control eran 10.000 CPM, 10 m\u00e1s es insignificante. Vamos entonces a calcular el fold change, es decir, cuantas veces m\u00e1s (o menos) de CPM fueron observados al agregarle la droga frente a cuando estaba solo el control. Esto lo calculamos como: \\[ \\text{Fold Change} = \\frac{\\text{CPM Droga}}{\\text{CPM Control}} \\] 3.1) Antes de seguir leyendo \u00bfSe les ocurre alg\u00fan caso donde la f\u00f3rmula anterior nos de problemas? Respuesta B\u00e1sicamente hay 2 casos donde el c\u00e1lculo del Fold Change va a dar problemas: Cuando CPM Control = 0 : La divisi\u00f3n no se puede hacer (y de hacerla en R va a dar infinito) Cuando CPM Control ~ 0 : En este caso la divisi\u00f3n se hace, pero el Fold Change va a dar un n\u00famero muy grande (y probablemente varios \u00f3rdenes de magnitud m\u00e1s grande que el resto de los Fold Change calculados). Este Fold Change no se debe a que CPM Droga es realmente mayor, sino a que CPM Control es muy chico, por lo que no es realmente informativo. Estos dos problemas se pueden arreglar agregando un n\u00famero buffer , es decir, un n\u00famero peque\u00f1o que se adiciona al numerador y al denominador. En este caso vamos a usar 0,125 con lo que la f\u00f3rmula quedar\u00eda: \\[ \\text{Fold Change} = \\frac{\\text{CPM Droga} + 0.125}{\\text{CPM Control} + 0.125} \\] 3.2) \u00bfQu\u00e9 pasa ahora en los dos casos problem\u00e1ticos que estamos tratando resolver? \u00bfC\u00f3mo afecta este buffer a los casos \"normales\"? (es decir, cuando tanto el numerador como el denominador son n\u00fameros mayores a 1) 3.3) Usando la f\u00f3rmula con buffer , calculen el Fold Change para ambas drogas y gu\u00e1rdenlos en nuevas columnas de la tabla full_data (p\u00f3nganles nombres que representen la informaci\u00f3n que contienen).","title":"Calcular el Fold Change"},{"location":"practicos/TP12b_Data_Mining/#transformar-el-fold-change","text":"Ahora bien, vamos a analizar como se distribuyen los valores del Fold Change para todas las prote\u00ednas (primera pesta\u00f1a del plot que est\u00e1 abajo). Podemos ver que si bien el Fold Change llega hasta 20 en algunos casos, la gran mayor\u00eda de ellas tienen Fold Changes menores a 4. En el paso siguiente vamos a querer agrupar nuestros genes por como se comportan frente a las drogas 1 y 2 clusterizando con kmeans() y luego plotearlo en un heatmap . En este momento la mayor\u00eda de los datos se encuentran en un peque\u00f1o rango del \"espectro\" de Fold Change, por lo que al momento de agrupar por similitud b\u00e1sicamente van a formar un \u00fanico gran cluster, lo que no da informaci\u00f3n. Por esta raz\u00f3n queremos convertir nuestros datos a una escala logar\u00edtmica. Como Fold Change solo llega hasta 20 vamos a usar una escala logar\u00edtmica en base 2. En R esto se hace usando la funci\u00f3n log() . Por defecto esta funci\u00f3n usa como base a \\(e\\) , es decir, es el logaritmo natural. Sin embargo, se le puede cambiar la base a 2 pas\u00e1ndole el par\u00e1metro base = 2 (ver la segunda pesta\u00f1a en el siguiente plot). 4) Usando la funci\u00f3n log() con el par\u00e1metro necesario, calculen el logaritmo en base 2 de los Fold Change para ambas drogas y gu\u00e1rdenlos en nuevas columnas de la tabla full_data . Fold Change para la Droga 1 Log2(Fold Change) para la Droga 1","title":"Transformar el Fold Change"},{"location":"practicos/TP12b_Data_Mining/#plotear-el-heatmap","text":"El heatmap es un tipo de plot que no vimos hasta el momento, pero que tal vez conozcan. La versi\u00f3n b\u00e1sica del heatmap nos permite graficar valores num\u00e9ricos como una escala de colores lo que nos permite ver diferencias entre filas r\u00e1pidamente e incluso encontrar filas similares o patrones. A continuaci\u00f3n mostramos un ejemplo que usa los datos estandarizados del Ejercicio 2 del TP 12a (la tabla ejemplo con los 4 genes, matriz_datos_ST ): No solo nos permite ver r\u00e1pidamente que hay 2 grupos de genes, sino que este paquete de heatmap tambi\u00e9n va a agrupar las filas por similitud y mostrar un dendrograma de similitud (todo esto se puede poner o sacar con par\u00e1metros). 5) En nuestro caso tenemos miles de genes, por lo que es complicado usar un heatmap que los muestre a todos por separado. Vamos entonces a clusterizarlos por similitud usando kmeans , lo cual en este caso se puede hacer desde el mismo paquete que hace el heatmap . Al momento de definir clusters no sabemos cu\u00e1ntos son, por lo que vamos a elegir un n\u00famero relativamente grande, sabiendo que eso puede resultar en varios clusters que son muy similares. 5.1) Instalen en R el paquete pheatmap . 5.2) Corran el siguiente c\u00f3digo reemplazando log2_fold_change_drug1_wBuffer y log2_fold_change_drug2_wBuffer por el nombre de las columnas que contienen el logaritmo en base 2 de los Fold Change: library ( pheatmap ) #Como *pheatmap* usa kmeans adentro inicializo la seed para que el plot de igual en todos lados siempre set.seed ( 1 ) #Me quedo solo con las columnas a plotear (en este caso el log 2 de los Fold Change para ambas drogas) plot_data <- full_data [, . ( log2_fold_change_drug1_wBuffer , log2_fold_change_drug2_wBuffer )] #Uso la funcion *pheatmap* para hacer un heatmap mas lindo pheatmap ( mat = plot_data , kmeans_k = 10 , cluster_cols = F ) kmeans_k = 10 le est\u00e1 diciendo que agrupe los datos en 10 clusters, similar a correr kmeans(plot_data, centers = 10) cluster_col = F le est\u00e1 diciendo que no trate de agrupar las columnas por similitud y que no haga un dendrograma asociado 5.3) Mirando los 10 clusters que acabamos de crear, para que clusters de genes se observa: Fold change alto para ambas drogas Fold change bajo para ambas drogas Fold change alto para la droga 1 y bajo la droga 2 Fold change bajo para la droga 1 y alto la droga 2","title":"Plotear el Heatmap"},{"location":"practicos/TP12b_Data_Mining/#calcular-genes-mas-afectados","text":"6) Si bien el heatmap nos da una idea global de como actuaron las drogas, nuestro objetivo es entender un poco m\u00e1s de su funcionamiento. Para esto, vamos a analizar la lista de genes que se vieron afectados por ellas. Para obtener esta lista es necesario entonces definir un umbral num\u00e9rico de Fold Change a partir del cual consideramos que el cambio fue \"significativo\" para nosotros. Estos umbrales se pueden elegir en base a conocimientos previos, en base a controles positivos y negativos, o mediante prueba y error (analizando qu\u00e9 y cu\u00e1ntos genes quedan por encima del umbral). Otra cosa a considerar es que en este caso estamos analizando drogas que funcionan como inhibidores, por lo que no nos interesa solo los genes con Fold Change alto, sino que incluso nos interesan m\u00e1s los genes con Fold Change bajo (que debido a como se calcul\u00f3 quiere decir cercanos a 0). En este caso vamos a quedarnos con aquellos genes que cumplan alguna de las siguientes condiciones: \\(log_2(FoldChange) \\geq 1.5\\) (es decir \\(FoldChange \\geq 2.83 = 2^{1.5}\\) ) \\(log_2(FoldChange) \\leq -1.5\\) (es decir \\(FoldChange \\leq \\frac{1}{2.83} = 2^{-1.5}\\) ) O sea, que nos vamos a quedar con aquellos genes que tienen un CPM 2.83 veces m\u00e1s grande o m\u00e1s chico que el control. 6.1) Filtren full_data para quedarnos con aquellas filas donde el logaritmo en base 2 del Fold Change de la droga 1 sea mayor a 1.5 o menor a -1.5. Guarden la lista de los IDs de las prote\u00ednas que cumplen esa condici\u00f3n en una nueva variable. Hagan lo mismo para la droga 2. Tip - Calcular el valor absoluto La funci\u00f3n abs() nos devuelve el valor absoluto de un n\u00famero. Si bien es posible filtrar estos datos usando simplemente un OR , tambi\u00e9n lo pueden hacer usando abs() , lo que prefieran. 6.2) Usen write.table() para generar un nuevo archivo llamado affected_genes_drug1 y guarden en \u00e9l los IDs reci\u00e9n calculados para la droga 1. Tengan en cuenta que queremos solo los IDs, por lo que tienen que cambiar los par\u00e1metros de la funci\u00f3n para que no haya nombres de las filas, nombres de las columnas ni comillas. Hagan lo mismo para la droga 2.","title":"Genes m\u00e1s afectados"},{"location":"practicos/TP12b_Data_Mining/#buscar-nuestros-genes-en-bases-de-datos","text":"7) Lo \u00faltimo que vamos a hacer con esta informaci\u00f3n es investigar en bases de datos para tratar de entender un poco m\u00e1s que procesos biol\u00f3gicos est\u00e1n siendo afectados por nuestras drogas. Como estamos trabajando con Trypanosoma cruzi vamos a ir a una p\u00e1gina que se especializa en tripanosom\u00e1tidos llamada TriTrypDB . 7.1) Entren a este link y copien la lista de IDs que acabamos de crear para la droga 1. Hagan click en Get Answer . 7.2) Una vez que se hayan cargados los datos vayan a Analyze Results Gene Onthology Enrichment , aseg\u00farense que este checkeado Biological Process y aprieten Submit (disclaimer: esta parte a veces no anda y hay que probar otro d\u00eda). Tip - Ubicaci\u00f3n del bot\u00f3n Analyze Results 7.3) Esta tabla muestra procesos biol\u00f3gicos relacionados con nuestra lista de genes. A grandes rasgos, \u00bfqu\u00e9 procesos biol\u00f3gicos parecen estar afectados directa o indirectamente por la droga 1? Para responder esto pueden ordenar la tabla obtenida por la columna P-value en forma ascendente o pueden presionar el bot\u00f3n Show Word Cloud que se encuentra arriba de la tabla para ver un Word Cloud de los diferentes procesos biol\u00f3gicos. 7.4) Hagan 7.1) , 7.2) y 7.3) para la droga 2. 7.5) \u00bfQue habr\u00eda que cambiar en lo que hicimos en el punto 6) si s\u00f3lo nos interesaran los procesos biol\u00f3gicos que son inhibidos por nuestras drogas?","title":"Bases de datos"},{"location":"practicos/TP12b_Data_Mining/#bibliografia","text":"","title":"Bibliograf\u00eda"},{"location":"practicos/TP12b_Data_Mining/#consola-de-r","text":"Comando help()","title":" Consola de R"},{"location":"teoricas/inicio/","tags":["teoricas"],"text":"Hola! Esta es la p\u00e1gina de inicio de la parte Te\u00f3rica del curso. Consultas y canales de comunicaci\u00f3n Por email a la direcci\u00f3n del profesor titular o profesores invitados. en Slack pueden mandar mensajes con consultas en distintos canales en el canal de YouTube estar\u00e1n subidos los videos de las clases te\u00f3ricas","title":"Inicio"},{"location":"teoricas/inicio/#hola","text":"Esta es la p\u00e1gina de inicio de la parte Te\u00f3rica del curso.","title":"Hola! "},{"location":"teoricas/inicio/#consultas-y-canales-de-comunicacion","text":"Por email a la direcci\u00f3n del profesor titular o profesores invitados. en Slack pueden mandar mensajes con consultas en distintos canales en el canal de YouTube estar\u00e1n subidos los videos de las clases te\u00f3ricas","title":"Consultas y canales de comunicaci\u00f3n"},{"location":"teoricas/resumen/","text":"","title":"Resumen"},{"location":"teoricas/1-Teorica-Uno/","tags":["teoricas"],"text":"Presentaci\u00f3n de la materia Docentes, modo de cursada, cronograma, evaluaciones, etc. Slides Conceptos elementales de computaci\u00f3n y algoritmos Slides Experimentos en bioinform\u00e1tica Slides Material de lectura y consulta Introduction to Algorithms (2009). Cormen, Leiserson, Rivest, Stein. 3rd Edition, MIT Press. A Quick Introduction to Version Control with Git and GitHub. Blischak JD, Davenport ER, Wilson G (2016) PLOS Computational Biology 12(1): e1004668 Introduction to Bioinformatics (2019), 4th Edition. Oxford University Press. Arthur M Lesk (hay dos copias en el lab).","title":"Te\u00f3rica 1"},{"location":"teoricas/1-Teorica-Uno/#presentacion-de-la-materia","text":"Docentes, modo de cursada, cronograma, evaluaciones, etc. Slides","title":"Presentaci\u00f3n de la materia"},{"location":"teoricas/1-Teorica-Uno/#conceptos-elementales-de-computacion-y-algoritmos","text":"Slides","title":"Conceptos elementales de computaci\u00f3n y algoritmos"},{"location":"teoricas/1-Teorica-Uno/#experimentos-en-bioinformatica","text":"Slides","title":"Experimentos en bioinform\u00e1tica"},{"location":"teoricas/1-Teorica-Uno/#material-de-lectura-y-consulta","text":"Introduction to Algorithms (2009). Cormen, Leiserson, Rivest, Stein. 3rd Edition, MIT Press. A Quick Introduction to Version Control with Git and GitHub. Blischak JD, Davenport ER, Wilson G (2016) PLOS Computational Biology 12(1): e1004668 Introduction to Bioinformatics (2019), 4th Edition. Oxford University Press. Arthur M Lesk (hay dos copias en el lab).","title":"Material de lectura y consulta"},{"location":"teoricas/10-Teorica-Diez/","tags":["teoricas"],"text":"Bioinform\u00e1tica Estructural: Modelado por Homolog\u00eda Clase te\u00f3rica de biolog\u00eda estructural. Caracter\u00edsticas de dominios globulares y modelado por homolog\u00eda. Slides","title":"Te\u00f3rica 10"},{"location":"teoricas/10-Teorica-Diez/#bioinformatica-estructural-modelado-por-homologia","text":"Clase te\u00f3rica de biolog\u00eda estructural. Caracter\u00edsticas de dominios globulares y modelado por homolog\u00eda. Slides","title":"Bioinform\u00e1tica Estructural: Modelado por Homolog\u00eda"},{"location":"teoricas/2-Teorica-Dos/","tags":["teoricas"],"text":"Bases de datos Slides Material de lectura y consulta SQLBolt Learn SQL with simple, interactive exercises. XKCD Query Ten Simple Rules for Developing Public Biological Databases. Helmy M, Crits-Christoph A, Bader GD (2016). PLoS Comput Biol 12(11): e1005128 . Primary and secondary databases - Bioinformatics for the terrified. An introduction to the science of bioinformatics (EMBL-EBI Training, Online Course).","title":"Te\u00f3rica 2"},{"location":"teoricas/2-Teorica-Dos/#bases-de-datos","text":"Slides","title":"Bases de datos"},{"location":"teoricas/2-Teorica-Dos/#material-de-lectura-y-consulta","text":"SQLBolt Learn SQL with simple, interactive exercises. XKCD Query Ten Simple Rules for Developing Public Biological Databases. Helmy M, Crits-Christoph A, Bader GD (2016). PLoS Comput Biol 12(11): e1005128 . Primary and secondary databases - Bioinformatics for the terrified. An introduction to the science of bioinformatics (EMBL-EBI Training, Online Course).","title":"Material de lectura y consulta"},{"location":"teoricas/3-Teorica-Tres/","tags":["teoricas"],"text":"Alineamientos de a pares + B\u00fasquedas de secuencias por similitud Clase te\u00f3rica de alineamientos de secuencias (de a pares), Algoritmos, Matrices, y B\u00fasquedas de secuencias por similitud contra bases de datos. Slides Material de lectura y consulta Having a BLAST with bioinformatics (and avoiding BLASTphemy). Pertsemlidis, A., Fondon, J.W. (2001) Genome Biol 2, reviews2002.1 Selecting the Right Similarity-Scoring Matrix. Pearson, W. R. (2013) Curr. Prot. Bioinformatics Chapter 3: Unit 3.5 An Introduction to Similarity (\"Homology\") Searching. Pearson, W. R. (2013) Curr. Prot. Bioinformatics Chapter 3: Unit 3.1","title":"Te\u00f3rica 3"},{"location":"teoricas/3-Teorica-Tres/#alineamientos-de-a-pares-busquedas-de-secuencias-por-similitud","text":"Clase te\u00f3rica de alineamientos de secuencias (de a pares), Algoritmos, Matrices, y B\u00fasquedas de secuencias por similitud contra bases de datos. Slides","title":"Alineamientos de a pares + B\u00fasquedas de secuencias por similitud"},{"location":"teoricas/3-Teorica-Tres/#material-de-lectura-y-consulta","text":"Having a BLAST with bioinformatics (and avoiding BLASTphemy). Pertsemlidis, A., Fondon, J.W. (2001) Genome Biol 2, reviews2002.1 Selecting the Right Similarity-Scoring Matrix. Pearson, W. R. (2013) Curr. Prot. Bioinformatics Chapter 3: Unit 3.5 An Introduction to Similarity (\"Homology\") Searching. Pearson, W. R. (2013) Curr. Prot. Bioinformatics Chapter 3: Unit 3.1","title":"Material de lectura y consulta"},{"location":"teoricas/4-Teorica-Cuatro/","tags":["teoricas"],"text":"Alineamientos m\u00faltiples Clase te\u00f3rica de alineamientos m\u00faltiples Slides Material de lectura y consulta Sequence homology . Orthologs, paralogs, and evolutionary genomics. Koonin EV (2005). Annu Rev Genet 39:309-38 . Computational methods for Gene Orthology inference. Kristensen DM, Wolf YI, Mushegian AR, Koonin EV (2011) Briefings in Bioinformatics 12: 379\u2013391 . Simple chained guide trees give high-quality protein multiple sequence alignments. Boyce K, Sievers F, and Higgins DG (2014). PNAS 111, 10556-10561 . Chapter 10 PSI-BLAST Tutorial (Comparative Genomics: Volumes 1 and 2) (2007). NCBI Bookshelf","title":"Te\u00f3rica 4"},{"location":"teoricas/4-Teorica-Cuatro/#alineamientos-multiples","text":"Clase te\u00f3rica de alineamientos m\u00faltiples Slides","title":"Alineamientos m\u00faltiples"},{"location":"teoricas/4-Teorica-Cuatro/#material-de-lectura-y-consulta","text":"Sequence homology . Orthologs, paralogs, and evolutionary genomics. Koonin EV (2005). Annu Rev Genet 39:309-38 . Computational methods for Gene Orthology inference. Kristensen DM, Wolf YI, Mushegian AR, Koonin EV (2011) Briefings in Bioinformatics 12: 379\u2013391 . Simple chained guide trees give high-quality protein multiple sequence alignments. Boyce K, Sievers F, and Higgins DG (2014). PNAS 111, 10556-10561 . Chapter 10 PSI-BLAST Tutorial (Comparative Genomics: Volumes 1 and 2) (2007). NCBI Bookshelf","title":"Material de lectura y consulta"},{"location":"teoricas/5-Teorica-Cinco/","tags":["teoricas"],"text":"Informaci\u00f3n contenida en alineamientos m\u00faltiples Clase te\u00f3rica informaci\u00f3n contenida en alineamientos m\u00faltiples Esta clase incluye ejercicios para resolver (handout). Weight matrices, Sequence motifs, Information content, and Sequence logos Slides Ejercicios - Logo Answers - Logo Ejercicios - Pseudocounts Answers - Pseudocounts Sequence profiles Slides Ejercicios","title":"Te\u00f3rica 5"},{"location":"teoricas/5-Teorica-Cinco/#informacion-contenida-en-alineamientos-multiples","text":"Clase te\u00f3rica informaci\u00f3n contenida en alineamientos m\u00faltiples Esta clase incluye ejercicios para resolver (handout).","title":"Informaci\u00f3n contenida en alineamientos m\u00faltiples"},{"location":"teoricas/5-Teorica-Cinco/#weight-matrices-sequence-motifs-information-content-and-sequence-logos","text":"Slides Ejercicios - Logo Answers - Logo Ejercicios - Pseudocounts Answers - Pseudocounts","title":"Weight matrices, Sequence motifs, Information content, and Sequence logos"},{"location":"teoricas/5-Teorica-Cinco/#sequence-profiles","text":"Slides Ejercicios","title":"Sequence profiles"},{"location":"teoricas/6-Teorica-Seis/","tags":["teoricas"],"text":"Reconstruccion filogenetica Clase te\u00f3rica de reconstrucci\u00f3n filogen\u00e9tica. Algoritmos, Alineamientos y Arboles. Slides Material de lectura y consulta Phylogenetic tree building in the genomic age. Kapli P, Yang Z, Telford MJ (2020) Nature Reviews Genetics 21:428-444 . Sci Hub UPGMA (unweighted pair group method with arithmetic mean) Wikipedia Neighbor joining Wikipedia","title":"Te\u00f3rica 6"},{"location":"teoricas/6-Teorica-Seis/#reconstruccion-filogenetica","text":"Clase te\u00f3rica de reconstrucci\u00f3n filogen\u00e9tica. Algoritmos, Alineamientos y Arboles. Slides","title":"Reconstruccion filogenetica"},{"location":"teoricas/6-Teorica-Seis/#material-de-lectura-y-consulta","text":"Phylogenetic tree building in the genomic age. Kapli P, Yang Z, Telford MJ (2020) Nature Reviews Genetics 21:428-444 . Sci Hub UPGMA (unweighted pair group method with arithmetic mean) Wikipedia Neighbor joining Wikipedia","title":"Material de lectura y consulta"},{"location":"teoricas/7-Teorica-Siete/","tags":["teoricas"],"text":"M\u00e9todos de predicci\u00f3n de Machine Learning basados en datos (HMM y ANN) Clase te\u00f3rica de hidden markov models y neural networks. Esta clase incluye ejercicios para resolver (handout). Hidden Markov Models (HMM) Slides Ejercicios https://youtu.be/ Neural Networks (ANN) Slides Ejercicios 1 Ejercicios 2 Material de lectura y consulta Immunological Bioinformatics . Ole Lund, Morten Nielsen, Claus Lundegaard, Can Kesmir, S\u00f8ren Brunak. DOI: https://doi.org/10.7551/mitpress/3679.001.0001. The MIT Press (2005). Chapters 3 and 4","title":"Te\u00f3rica 7"},{"location":"teoricas/7-Teorica-Siete/#metodos-de-prediccion-de-machine-learning-basados-en-datos-hmm-y-ann","text":"Clase te\u00f3rica de hidden markov models y neural networks. Esta clase incluye ejercicios para resolver (handout).","title":"M\u00e9todos de predicci\u00f3n de Machine Learning basados en datos (HMM y ANN)"},{"location":"teoricas/7-Teorica-Siete/#hidden-markov-models-hmm","text":"Slides Ejercicios https://youtu.be/","title":"Hidden Markov Models (HMM)"},{"location":"teoricas/7-Teorica-Siete/#neural-networks-ann","text":"Slides Ejercicios 1 Ejercicios 2","title":"Neural Networks (ANN)"},{"location":"teoricas/7-Teorica-Siete/#material-de-lectura-y-consulta","text":"Immunological Bioinformatics . Ole Lund, Morten Nielsen, Claus Lundegaard, Can Kesmir, S\u00f8ren Brunak. DOI: https://doi.org/10.7551/mitpress/3679.001.0001. The MIT Press (2005). Chapters 3 and 4","title":"Material de lectura y consulta"},{"location":"teoricas/8-Teorica-Ocho/","tags":["teoricas"],"text":"Bioinform\u00e1tica Estructural: Desorden Clase te\u00f3rica de biolog\u00eda estructural. Caracter\u00edsticas de las prote\u00ednas desordenadas. Predicci\u00f3n de desorden y bases de datos de prote\u00ednas desordenadas. Slides","title":"Te\u00f3rica 8"},{"location":"teoricas/8-Teorica-Ocho/#bioinformatica-estructural-desorden","text":"Clase te\u00f3rica de biolog\u00eda estructural. Caracter\u00edsticas de las prote\u00ednas desordenadas. Predicci\u00f3n de desorden y bases de datos de prote\u00ednas desordenadas. Slides","title":"Bioinform\u00e1tica Estructural: Desorden"},{"location":"teoricas/9-Teorica-Nueve/","tags":["teoricas"],"text":"Bioinform\u00e1tica Estructural: Motivos Lineales Clase te\u00f3rica de biolog\u00eda estructural. Caracter\u00edsticas de Motivos Lineales y predicci\u00f3n. Slides","title":"Te\u00f3rica 9"},{"location":"teoricas/9-Teorica-Nueve/#bioinformatica-estructural-motivos-lineales","text":"Clase te\u00f3rica de biolog\u00eda estructural. Caracter\u00edsticas de Motivos Lineales y predicci\u00f3n. Slides","title":"Bioinform\u00e1tica Estructural: Motivos Lineales"}]}